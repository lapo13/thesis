{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80b337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import os, pickle, random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674923c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_after_QA = lambda s: s.split(\"QA_\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20627845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 16)\n"
     ]
    }
   ],
   "source": [
    "dati = pd.read_excel('/Users/lapotinacci/thesis/metric_datasets/NO2_dataset.xlsx')\n",
    "dati = dati[dati[\"serviceUri\"] == \"http://www.disit.org/km4city/resource/iot/orionUNIFI/DISIT/ARPAT_QA_LI-LAPIRA\"].copy()\n",
    "sensor_name = get_after_QA(dati[\"serviceUri\"].iloc[0])\n",
    "dati.drop(columns=[\"serviceUri\"], inplace=True)\n",
    "print(dati.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d394f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ora inizio esperimento: 14-19-07\n",
      "Giorno inizio esperimento: 2025-11-30\n",
      "Cartella esperimento creata: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07\n"
     ]
    }
   ],
   "source": [
    "# === Creazione cartella esperimento con timestamp ISO ===\n",
    "timestamp = datetime.now().strftime(\"%H-%M-%S\")\n",
    "print(f\"Ora inizio esperimento: {timestamp}\")\n",
    "day= datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Giorno inizio esperimento: {day}\")\n",
    "exp_dir = f\"../RISULTATI/{day}/esperimento_{sensor_name}_{timestamp}\"\n",
    "\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Cartella esperimento creata: {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7794e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "mask = ~dati['TTT'].str.contains(\"nan\", na=True)\n",
    "dtset_completo = dati[mask]\n",
    "\n",
    "dtset_completo['TTT'] = dtset_completo['TTT'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46880af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtra le righe dove la colonna TTT ha lunghezza 24, ed elimina tutte le colonne le cui osservazioni sono indipendenti dal giorno\n",
    "dtset_filtrato = dtset_completo[dtset_completo[\"TTT\"].apply(lambda x: len(x) == 24)].sample(frac=1).reset_index(drop=True)\n",
    "dtset_filtrato = dtset_filtrato[dtset_filtrato[\"type_of_TTT\"] == \"daily\"]\n",
    "len(dtset_filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022b3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def is_useful_series(series, zero_ratio_thr=0.85, min_nonzero_value=0.1):\n",
    "    arr = np.array(series, dtype=float)\n",
    "    \n",
    "    # Serie troppo corta\n",
    "    if len(arr) <= 1:\n",
    "        return False\n",
    "    \n",
    "    # Troppi zeri\n",
    "    zero_ratio = (arr == 0).mean()\n",
    "    if zero_ratio >= zero_ratio_thr:\n",
    "        return False\n",
    "    \n",
    "    # Valore medio trascurabile (quasi zero)\n",
    "    mean_val = np.mean(arr)\n",
    "    if abs(mean_val) < min_nonzero_value:\n",
    "        return False\n",
    "    \n",
    "    # Se arriva qui, la serie ha valori significativi\n",
    "    return True\n",
    "\n",
    "# Applica filtro\n",
    "mask_useful = dtset_filtrato[\"TTT\"].apply(is_useful_series)\n",
    "df_useful = dtset_filtrato[mask_useful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b897db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spezza_serie_in_colonne(df, colonna_stringa, prefix='col_'):\n",
    "    # --- Controllo colonna ---\n",
    "    if colonna_stringa not in df.columns:\n",
    "        raise ValueError(f\"La colonna '{colonna_stringa}' non esiste nel DataFrame\")\n",
    "\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Estraggo la colonna contenente gli embedding\n",
    "    col = result_df.pop(colonna_stringa)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for item in col:\n",
    "        if pd.isna(item) or item == \"\":\n",
    "            embeddings.append([])\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parsing sicuro della stringa in lista Python\n",
    "            vett = ast.literal_eval(item)\n",
    "\n",
    "            # Se l’embedding è una numpy array o altro iterabile, lo converto in list\n",
    "            if not isinstance(vett, list):\n",
    "                vett = list(vett)\n",
    "\n",
    "            # Converto tutto in float\n",
    "            vett = [float(x) for x in vett]\n",
    "\n",
    "            embeddings.append(vett)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel parsing dell'elemento '{item}': {e}\")\n",
    "            embeddings.append([])\n",
    "\n",
    "    # --- Uniformo dimensione dei vettori ---\n",
    "    lengths = [len(v) for v in embeddings]\n",
    "    if not lengths:\n",
    "        raise ValueError(\"Nessun embedding valido nella colonna\")\n",
    "\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    embeddings_padded = [\n",
    "        v + [np.nan] * (max_len - len(v)) if len(v) < max_len else v\n",
    "        for v in embeddings\n",
    "    ]\n",
    "\n",
    "    # --- Creo DataFrame delle nuove colonne ---\n",
    "    colonne_embedding = pd.DataFrame(\n",
    "        embeddings_padded,\n",
    "        index=result_df.index,\n",
    "        columns=[f\"{prefix}{i}\" for i in range(max_len)]\n",
    "    )\n",
    "\n",
    "    # --- Merge col DataFrame originale ---\n",
    "    return pd.concat([result_df, colonne_embedding], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1a7a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnQWY3PTWxt8k47Iy69vdrW3dKHWgLVDc3blc3PXidvmAi1vh4m4XKRQpUqBQWqi7u627jUuS70lOZmenOyuzUv3/nqdP0tHsTCY5Oec97+FkWZbBYDAYDAaDsYfg99QbMRgMBoPBYLDgg8FgMBgMxh6HZT4YDAaDwWDsUVjwwWAwGAwGY4/Cgg8Gg8FgMBh7FBZ8MBgMBoPB2KOw4IPBYDAYDMYehQUfDAaDwWAw9ig67GNIkoSSkhLY7XZwHLe3N4fBYDAYDEY7UDxLnU4nsrOzwfP8/hV8KIFHbm7u3t4MBoPBYDAYHaCwsBA5OTn7V/ChZDzCG5+QkLC3N4fBYDAYDEY7aGhoUJMH4fP4fhV8hEstSuDBgg8Gg8FgMPYv2iOZYIJTBoPBYDAYexQWfDAYDAaDwdijsOCDwWAwGAzGHoUFHwwGg8FgMPYoLPhgMBgMBoOxR2HBB4PBYDAYjD0KCz4YDAaDwWDsUVjwwWAwGAwGY4/Cgg8Gg8FgMBh7FBZ8MBgMBoPB2KOw4IPBYDAYDMYehQUfDAaDwWAw9igs+GAwGIwDhKUL/sDj112Pbz59Z29vCoPRKiz4YDAYjAOEmR9Ng7m2ENt+mIW/f/9xb28Og9EiLPhgMBiMAwQuINJScmH+B1+irKhwb28SgxETFnwwGAzGAQIvSY3rQqAa7z/8KPw+317dJgYjFiz4YDAYjAMEXqTgI2jKUPIfMLhL8eztt+/tzWIwmsGCDwaDwThA4KQQraTa4XXkqKvmmiI8c8+/9u6GMRi7wYIPBoPBOEDgteDDYDHhrhdfRMCaBUCGsGsHPnjlub29eQxGIyz4YDAYjAMETgqoy4SUJBhNJlz+6MMQDSmAHEDV/KWsA4axz8CCDwaDwTgAUIWlsl9dz8qlkktmTi4O++d5kHkb64Bh7L/BxyOPPAKO46L+DRw4sPF+n8+HG2+8ESkpKbDZbDj77LNRXl7eHdvNYDAYjCZsWLlELbEoDBs5tvH2I6acjJQJIwFOzzpgGPtv5mPIkCEoLS1t/Pf333833nf77bdjxowZmDZtGubMmYOSkhKcddZZXb3NDAaDwdiNzRvWams65PXpH3Xf5bfcA7FnnyYdMHewz4+xfwUfOp0OmZmZjf9SU1PV2+vr6/Huu+/ihRdewNFHH41Ro0bh/fffx/z587Fw4cLu2HYGg8FgaFSWV6hLmTfE/Ezufvr5Jh0whawDhrF/BR9btmxBdnY2+vTpg4svvhgFBQXq7cuWLUMwGMQxxxzT+FilJJOXl4cFCxa0+Hp+vx8NDQ1R/xgMBoMRH+56Z6vBh4LaAWPJbOyA+fBV1gHD2A+Cj3HjxuGDDz7AzJkz8frrr2PHjh2YOHEinE4nysrKYDAYkJSUFPWcjIwM9b6WePLJJ5GYmNj4Lzc3t+N/DYPBYBykhLzU6SLzuhYfo3bAPPbvxg6YynnLMO/Pn/fgVjIYHQg+TjzxRJx77rkYPnw4jj/+ePz000+oq6vDl19+iY5y3333qSWb8L/CQjaLgMFgMOJFCpDHh8QLrT4uqgNGdGLeu5+zGTCM/avVVsly9O/fH1u3blX1H4FAQA1GmqJ0uyj3tYTRaERCQkLUPwaDwWDESYis1SWh7cM664Bh7NfBh8vlwrZt25CVlaUKTPV6PX7//ffG+zdt2qRqQiZMmNAV28pgMBiMNua6yO0IPsIdMKG83uo664Bh7NPBx5133qm20O7cuVPtYjnzzDMhCAIuvPBCVa9x5ZVX4o477sDs2bNVAerll1+uBh7jx4/vvr+AwWAwGODiDD4U7nnmBXiTcyMdMPeyGTCMfTD4KCoqUgONAQMG4LzzzlPNxJQ22rS0NPX+F198EaeccopqLjZp0iS13DJ9+vTu2nYGg8FgaPCSqC45feuaj9256yWlA0abAbOTdcAw9gycLMtkibePoLTaKlkURXzK9B8MBoPRPp695FLwwVoE8/rh3mdfjOtjKysqxEf3Pag6oMqCHROu+QcOP/JE9tEzuu38zWa7MBgMxgEAp020NdnMcT9X6YAZd+nZTTpgvmAdMIxuhQUfDAaDcQBNtE1OdXTo+ZOPOw2O8YcAUGbAVOG9hx+lYXUMRjfAgg8Gg8HYz6mvr22caJvTizpYOsIVt96LUE96vlGZAXMHmwHD6B5Y8MFgMBj7OWtXROZnjRh9WKdeK6oDppp1wDC6BxZ8MBgMxn7Ozs2baYUzIDVD6VzpHNQBo82A2bmDWbAzuhwWfDAYDMZ+Tk1FlbqUuZaHysWDMgPmH/93nypAVWbAzJs5q0tel8EIw4IPBoPB2M/xNLjVpczru+w1e+T1hainzpmAkwlPGV0LCz4YDAZjPyfkD6pLuY2hcvEi6iiY4bShdQxGV8GCDwaDwdjPkcMTbYWuDT4kA72eECT3VAajq2DBB4PRjSz79Sd4nU72GTO6FS480Zbv2kM6b6bMBx8iDxEGo6tgwQeD0U18+tKT+OO9N/Dgv+9nnzFjnxsq1x7sKYnqkheZ5oPRtbDgg8HoJjaWV4CXJSTWVLLPmNGt8JIWfOi6tuwyYOgQdclJXlSVl3bpazMObljwwWB0EwGJZjZavS61/MJgdBe8qE201TQaXcURU07WThMy5vw6o0tfm3Fww4IPBqOb0DLhKvMWzmWfM6Pb4CQKPvSmrvH5CGOx2yELVnV915btXfrajIMbFnwwGN2ErKXCFUo9NHeDwegOOIlabc12S5e/tiQY1aW3ztXlr804eGHBB4PRTXChiDdCgLUqMroRThsq58hI6/LXDnt9yD7m9cHoOljwwWB0E7pgpD1R7/Wyz5nRLZQVFQIyZT569evX5a8v6sNeHyz4YHQdLPhgMLoJQyBSaklw1sDnY+2KjK5n3arFjetDR47v8tfnTDp1KTTJ5DEYnYUFHwxGN2H0R7IdxoAfc7/6jH3WjC6ncPsOWuGMSExM7vLXNyfa1CUvMt0So+tgwQeD0Q3UlBbBFKBMh8dM3QIrNq9jnzWjy6mrqVGXMt+1nS5hcvN7qUtO9MDD3HoZXQQLPhiMbmD9wnnqUgaH+qRUdb3az9LWjK7H5/R0+UTbphx1wulK6KGoP7Bgzs/d8h6Mgw8WfDAY3cDOXdvUpc9kBm+gk4LIJoMyugFRC2qlLp5oGyY1Iwsyb1bXN6xa2y3vwTj4YMEHg9ENVNbXq0ufwYQkzXXS6HGzz5rR5chaG3d3BR/qawsmddlQVddt78E4uGDBB4PRDTj91GYbNBgxvHcfdT3RWYuGygr2eTP2i6FyTZF0pCeRvNTSy2B0FhZ8MBjdgFczNxX1Bkw57x8I6PTQiSHM/OIj9nkzuiX4kLox+Ah7ffAByrIwGJ2FBR8MRjcQ0obKyYIAs92OhgSH+v+NpSXs82Z0KXx4iJCu+w7nsiHs9cEyH4yugQUfDEY3IGnBB8fTTyxgppkbDcEm0+YYjC6A14bK8VqA0B0Y7KT54MWIay+D0RlY8MFgdAchMepiVB8eda5pQRiMroKTqNvFYO4enw+FjNwsdcmLbEwAo2tgwQeD0Q2E09MmXvFHANK0UecWt5N93owuhZMooDUn2rvtkx1/5BRakQNYuuCPbnsfxsEDCz4YjG5AHyQrapuWCp8wcoy6THDWYefa1ewzZ3R58JGeldFtn+qAISOVIS/q+vL5C7rtfRgHDyz4YDC6ca5Lip2uRg89/lR4TRZwkPH7T9PZZ87oEnZuUSz7qezSb8CQbv1UJYGMxmrKqrr1fRgHByz4YDC6GGV6rclHwUePzFx1aTKZ0GBPUtd31pIBGYPRWdatXqGt8Rh0CGXXugtRR069ITcbMMfoPCz4YDC6mG2L50OQqatl2LjDGm8XTXTl6GEdL4wuoqSgUF3KnBFGE5VFugtRRyVEjo0JYHQBLPhgMLqYTRvWqMuA3oCsfgMabzfrSHwq+NmVI6NrcNZoWbRuGirXFFnr2BI0O3cGozOw4IPB6GLKqyrVpc9ImY4wPew2dWl1sfkYjK7B56bynsR3n8dHGMFipCXz+mB0ASz4YDC6mDpN7xEwRKfBJ085QV3aPC6s/P0X9rkzOo2klUDkPRB8JGeQSy8X8nX7ezEOfFjwwWB0Me4Q6T1C+mjTp8Hjj4DTmqCuz533J/vcGZ0n2P1zXcIMG0uCVk72al02DEbHYcEHg9HFBDRrdUkT6DXFbUtUl6UedvXI6DycSPoLSbPx705Gjz9K8exV1+fNntXt78c4sGHBB4PRxYgiBR+IcUKQjVQ3DzDRHqML4MP7WjcOlQujdNNIglVdL9lZ1O3vxziwYcEHg9HVSJQKFwTqbmmKTet40XvZjAxG5+G0oXKyTpsd1M1IOiolBhrY/svoHCz4YDC6GD6kDfrS5ro0pW9amrpMcNaoZmQMRpdMtDV2v+C0qdcH/DS7iMHoKCz4YDC6GF2QZm1YY6TCTzzvYogcD2PAj7lffcY+e0an4EQKdI2W7jUYCyPpKfjgWdmQ0UlY8MFgdDGGAGU0Eo3NTwipOT3RkJCsrq/czDoGGF0zVM6W1H0TbZvCm8nMTBBZ5oPROVjwwWB0MSZtqFxmWnrM+71WOlFU+emqlcHoCH6fD5xMbrlZuTl75EO0pdC+yzOvD0YnYcEHg9GFlG7ZBINWdhkwaFjsH52WuhZZ6prRCbZuWKUUQmhfGzpij3yWfQcPUpec5EFNZcUeeU/GgQkLPhiMLmTd0gXqUtF19B0bGSrXlGRtRobR7WKfPaPDbF5PM4QAAb36UlDQ3Rx13OnaaUPGX7Nm7JH3ZByYsOCDwehCCosL1KXPZIaphSmjQ3r1UpeJzlo0sKtHRgcpLy5RlzLf/RNtw1jsdsi8RV3fsWnbHnlPxoEJCz4YjC6k2ulUl/7dhso15bjz/4mgTg+dGMLMLz5inz+jQ7jqaV+T98BE26ZIOgp03LX0/gxGR2DBB4PRhbi0QV9Bba7LLZ+9gmkLf4p6jNluR30CDenaVEpXrwxGvAQ8/j02VC6W14fsYx0vjI7Dgg8GowvxaXNdRJ1BDTy+zJyIZwqbZ0ECZkpd12uDwRiMeJH84bkuwp59X81NVWCCaUYnYMEHg9GFaANtAZ2AraEUdbUsKRG1rrqox+n12gkjwK4eGR3d2TRrdWHPBh8w6aOcfBmMjsCCDwajC5G1uS48z6HGQD4fQR2PN/+cHvW4NDOVZSyuBvb5MzoEJ0p7bKJtU0yJNFxOCFHZh8HoCCz4YDC6YcS5judQbUtsvH11TfSBetyIUeoywVmHwk3M6ZQRP7wWfMh7YKJtU3L65KlLTvSoRmcMRkdgwQeD0YUIQSqjyAYTnJZIF0IFnxH1uNEnng6vyQIOMn79bhr7DhgdHirH7eHg44hjTtDWQpg/++c9+t6MAwcWfDAYXYhem+tSm5AVdXu1mabZhlE8QJz2JHV9Z209+w4YccM1TrTds622PfL6Nnp9rF+1Yo++N+PAgQUfDEYXYtKCjyo7BRsOp/b/BCtcnmhH05CJumA8rOOF0QF4ibJsZlvLnjLdhSyQ10d9BQucGR2DBR8MRhfhrKuBURsqV2FLVZd96rZBH5JU0enrc6LLKyYdpy4FPxPuMTo+0TbBEdEW7SlEHWVbJA9tA4MRLyz4YDC6iI0L5oGXyeejyp6gLnvoapDS4FHXV1ZSYBImx25Tl9bd2nAZjLbwKE66Mp34c3qSXf/eMBrjmdcHo4Ow4IPB6CK2b92oLhssyai1USvtMX36IsVXGVN0OnkKCfdsHhdW/v4L+x4Y7WbtqkXqcDeFIYeO2eOfnGzQgg/m9cHoICz4YDC6iIq6WnVZmTEY4DhYvSGcO/4kpIsVMUWng8cfAaeVMiRz5/3JvgdGu9mxeZO2plMFoHsavc2oLoUQK7sw9kLw8dRTT4HjONx2222Nt/l8Ptx4441ISUmBzWbD2WefjfLy8s68DYOxX1Dv18SlaT3VZYpmIDYkiX5mVXZbM9GpW/MCKfNEl2QYjNaoLKtonGi7N0jrQQZ6vEglRQZjjwUfS5YswZtvvonhw4dH3X777bdjxowZmDZtGubMmYOSkhKcddZZHX0bBmO/wat5q1cn0YE5xU8niGuPPBO6kIyAnsebc7+Keo5spJOHn3W8MOLA0+DaKxNtw4ybdBStyAGsWjpvr2wD4yAMPlwuFy6++GK8/fbbSE5Obry9vr4e7777Ll544QUcffTRGDVqFN5//33Mnz8fCxcu7MrtZjD2OcLxQ1WyXV1moFpdpiWkIsXpVtdXVkRfKdr01PGi87HMByOOfc0b2CsTbcMMGTkO4ChwXjbvr72yDYyDMPhQyionn3wyjjnmmKjbly1bhmAwGHX7wIEDkZeXhwULFsR8Lb/fj4aGhqh/DMb+iCjJEHkdqhJIbDo2KxKYp3ir1GU5T1mRMH1TSQeS2FCjliwZjPYga10m0p4eKtcESSB/kcpiyvAxGN0afHz++edYvnw5nnzyyWb3lZWVwWAwICmJnBvDZGRkqPfFQnmdxMTExn+5ubnxbhKDsW8giqhJyYcocDAGJFxxRKTcmB6i/b/KFB18HHfWBZA4HsaAH39/8/ke32TG/gkXDj728FC5pog6CrKDLuZTw4ifuPbcwsJC3Hrrrfj0009Ve+iu4L777lPLNeF/ynswGPsjQiiEijTqPEhxuaJ+I4PCotOEaNFpRq8+qE+gDMnyDWv3+DYz9k84kdpsZWHvBR+S5vXBBUJ7bRsY+y9x7blKWaWiogKHHnoodDqd+k8Rlb788svqupLhCAQCqKuLNk1Sul0yMzNjvqbRaERCQkLUPwZjf0QXDKA8LUddd3jJ2yPM1RNPhyCS6PTdv7+Jus9rIY1ItZ8dxBntg5f2zkTbpkgGoTHoZjDiJa49d8qUKVizZg1WrlzZ+G/06NGq+DS8rtfr8fvvvzc+Z9OmTSgoKMCECRPi3jgGY3/CEPChIsWhrqdL0XXwbEcGUjWn06Vl0bomXjNsCjG3SEacQ+U4/d7TfPBmKrsIIZoxw2DEQ1xSabvdjqFDh0bdZrVaVU+P8O1XXnkl7rjjDjgcDjWLcfPNN6uBx/jx4+PaMAZjf0IRi5p8XpQnkwhvaFLzn5YiOi1PtjYTnSZrV5BGD3XEMBhtwUuUbRD28ETbpiSmO+Ar3gZOZEJpRvx0ec7uxRdfxCmnnKKai02aNEktt0yfPr2r34bB2Kco3rAGLnsPtayieHpcfeSZzR6TJpLotHo30emQXr0aO14aKlnnAKNtOJGyDZYEGm3fXaxe8je+//CFmPcNPXQkbYvkQXHBtm7dDsaBR6eDjz///BMvvfRS4/8Vkd2rr76KmpoauN1uNfBoSe/BYBwobFq1DBXp/dR1h8ujenvszqAE8vSostuj2mqPO/+fCOr00Ikh/DLt4z241Yz9FU4bKpeYSmW+7iJhxpU4Zfuj+Ol/rzW7b/yk4xqT53/99lO3bgfjwIPNdmEwuoCSslJUplKbuMND5mK7c80kEp36DTze+SvidGq221GfQCeRjcXF7PtgtEqNkh3Tgo9efSng7Q78Ph96cFXgORnOTX80u99oMkEWKPNStJ11KTLigwUfDEYXUO1xozw1RV1PC8WeZaSITlOc5GS6uKw+6r6AmQ7iDcxmndEGa1ZE3KKHjew+Ld2i2TOg50hbYg/VxHyMqNPGA2hiagajvbDgg8HoAlwBEeUOm7rex9rypM8Uj+Z0ykVPuNVrXQtygHUOMFqnYLumr+AMcKRF64e6kpJ1fzeuO7jogYhhRM3rAz7WbsuIDxZ8MBhdQIM+EW6TAE6ScenYo1t8XJrmdFptyoi+3URti2ZtEm4sfvn0WTz++HOoLNjMvrODmNpKCmBljvaZ7oKvj5RSkrnYnViyFjTzzOuDEScs+GAwuoBaSw916XAGMTRvUIuPG2gnc6gquy1KdDrukFHqMsFVh8JN62I+98MNeXjHNQgfffIl+84OYrxa6a67J9rapIhZpIOPnfmAibaBGY0x4oUFHwxGF1CXQOnvtPrWvTqunniqKjr1GQS893ekBX30iafDazSDl2X89l1EjNqUYpE8RDb78th3dhAT8lFZTxK6d6JtUpNSSxKc8LqbByBWbYIzH2JeH4z4YMEHg9EF1CTQMMUUZ+xOlzC5aT0aRaeLSmuiWtSd2oyXHbXR4wnCnQcVMqW4NwajBzcyDs6JtnI3D5VL5iIiUj0nYt4vXzd7TO8BfRu9Purra7t1exgHFiz4YDC6gMokq7p0uEvbfKwjLDpFtOg0ZKLMhidEQ8Oasm3lLFDIAuySBaxf+EMXbDVjf4QLUelO4rvXWj2pSfChULl5QbPHTDzmVGWLlK3BX7/M6NbtYRxYsOCDwegks9fNR72NUuB5QRKUtka61opbtZvo1KQjEzKhiRYkzOY1y6L+v/Dv5icCxsEBJ0p7ZKJtuOzikiko1rube9Ao3TYyT23i2zZu6tbtYRxYsOCDwegk36ymwCDRFUT/xLZLIv3swZhOpz1slD2xuqI9QBTKa6NbGbd5mGswDvaJtnq+W23VzZxfXd8hUZCcJDXfLxUknUldumqc3bY9jAMPFnwwGJ2k0Ef+Hhk1znY5Tl55+MngFdGpUcBH879tvP3IY05UlzaPE6v/nBX1nJogvQflRoDNARZ8HKzwYvdPtN20kOzSPbIJZVJi614fAnW8yN6W/W0YjN1hwQeD0Ulq9NnqMqOqEoMPm9Tm4/tk9ESKixQc84sjAtXB44+A05qgrs/5K9rOujpEJ4ChAl2NbghZ4HW37AnCOHDhtIm2es0bpjsIVW9Xl3WyFfU8ZfOS+didXFLY60MTwjIY7YEFHwxGJ6m20cHZUVsCe1L7Bn2laPNfyhA9gM5toyCj1B0t9qsKUVAyyrQLiqG1cg06++tX2Xd3EMJJ2kTbRMqGdQfWYHVj8BG057Sa+YCReX0w4ocFHwxGJ9hYtAXVdroCtTcUtft5aZowtdoUbY8tG7VZGbvNeKnQPD7SDXXor2U/NhYxS+uDEU6i7z81o/nk5K4iSQ1vgVrZgqxBE9X1BLhQVryr2WMNCbRvCiHaLgajPbDgg8HoBB8s/A0yz8HiE8GH2l8G6WcLi04TokSnNj2pOnS+cGMtUSHR1WWqTcIAQ4W6vtVPV6SMg4fiAmWuCwWdfQa07KTbWZJ5yrzVyTZMOPZMBGUdOA5YOPOzZo/N7kX7ISd6VD8aBqM9sOCDwegE29wUFGTWuCAZ2l+Dv/ywE8BLMrxGAf9bFPFH6J1Ck3ETGmobg5Lq8gJUa1LT3v0HIN9ELY8bA/RYxsHDuuVLtDUOQ0eM63aPD5cuCUaTCbUyOZl6itc2e+xETSitBEVL5v3ebdvEOLBgwQeD0QkqddSGmFFVDVlof/dBv6w+cDgpuPi7gHw/FE44+yJIHA9TwIe/v/lcvW31399AsR1TQpuhh52GEUN7qrfvlAVsXT2XfX8HEcUFWtmDM8Bip4CgW63VE3upi1pZawMPVDZ7bF6f/pA5Kr2sXRbtR8NgtAQLPhiMTlBjoexDWlUhuDjtrsOi09ImotOMXn1QbycB6/INNGCuuIjKLGmcBLM1ARNOvgoZkKGoQub//gv7/g4i6qvJel/mu6/TpbhgO+xa5iNn2GR1Wa0FH8lybC8PWfP6qC2PjAxgMFqDBR8MRgepbKhCjY3cHdMrtkAXp+1CWqgsptOpV2u3rfaTLqTaQyeadD7iozBIT/qSba5oi3bGgY3P7ev2ibZLZtFgw4Csw+iJx6nr4bKLo4V2W1FH+6joYaJTRvtgwQeD0UHe/vMbhHQcDEEJSXW7YOLDFmDto6+FDtTVtmjRKW8gq/aQ5ptQpQ2SSxMiB/5+RtJ9bPaTxwjj4EAMT7TtxrkunmLKuNXBruo9FJx6yvAlt2Q0pkXeXIB5fTDaBws+GIwOsraOug7S63zgIMOmj2/E+eXjjwMnyfCYBHyx5OfG25MNdCA3eijYqBbJ+yNVF+mm6ZtEVtcbQlbWYXAQIe+BoXJmP+k66iXK6ikIjr6tBh+yFjALIdb+zWgfLPhgMDpIJU8eHWnVNErcYY3P9GlgTj+kaKLTubsiHiGD80jkl9hQA2ddDSpFbWKuLjJbY8pp/4CSeFcUAH999zr7Dg+yoXJSC0PlfnrqPqy47r/49q5bOvweiXBGiUwVBk88XV1aOB9WLZ7T7Dk6K/nTCCEqFTIYbcGCDwajg1SbSG+RWUklkJzsvLhfw+EhgV6JHBGdHn/hPxEUdNCJIcz83/uoEOnA7jBFXE/T8vojX9OArN/BbNYPFvg2JtomFiQhLWkERgaPw6xXHu/QeyRx7kaDsTBDRo6HW6YSzMYFPzZ7Tko2BeK8GO3My2C0BAs+GIwOoGg0qu22RrGpwqAxY+N+nbDotNoYEZ2a7XbUJ5JN+4aiIlTIlGLPSoturRxoqFKXW33MbOxggdOGyrWkbrZKlK0QTInosT4LdWUUGMdDstbp0sBTuS9MWHSKGpr70pQxE46gFdmPTetWxP2ejIMPFnwwGB3gvb+nw2/gIYgyUqq3IqDTI3fAkLhfp4+Zyi5V9sQo0WnATCeR6hCPsNfp0HHHRD23r4lKNZuY2dhBAy9R8MEbYwcfZi5S+rMn9sfKxz7osMdHyBotZg6XYewhKjM25ZDxE1XvEYUFfzCjMUbbsOCDwegAi0vpAJza4IcgBeEzRVLU8XDZuKMbRadfLZvZeLtOmxTqDlJLpdLvktt/dNRzh/ajss9WSY/i7SvZ93gwTbQ1Uyludww6yk7U1lHHSl/rYfj2zlvb/fr1dbVIAJVdHH3HRN1Xo2VVHFxsrw9JoN9ARVFpu9+PcfDCgg8GowOUg1oPUxtIbxEwUD08XobmDYLDRS23s3cUNt6ero1LD/llzeOjuZBPMRtLgQzlWnjuD+TNwDg4Jtrak5q7mzbU1UFnorbsHambUVe3ARyvwyGBIzH/8zfb9foLf5sOgZMgyjzGH3tW1H1KWKKQrGlCdkcSaJ8NuKLnEjEYsWDBB4PRAaqNJLBzNFAGJKTvuONko9OpHJnVMmb4SHUpBck7JE1oPrBL8WAYqKcU+ZaGZBxI1N0zEcGH+mLNnOadFQcrytC28ETbtKzMZvcv/exNcFoA0O/Y41Azxo2QtwY6Sypsf0pqcNIWNdtodkwDrEhMit6nvNoE5uQWjcao3ZZ5fTDaAws+GIwOoBiDKSQ6aS6LpB14O0JasLnodOzJZ8JrNMMlUA0/TYjtr9DfUKIutxxAZmNz3nkTSebV0AtV8P346d7enH2Gwl2blVO8uj5w6Ihm9zdsJ3Gp5G/AoMknYNKVt2OV8CdkSYQjaSgWPfRCm++hc9P+VNekzTaMJWe4ukxGQ0xvGUnzpxGCzOuD0TYs+GAw4mT64plwm3WALMPaoPlzxDnXpSm9TJSmrrJFugtMJhOc9mQ4dRR8pOpiX7X2TaCsyYZg9w0Z29PkbYhoX3Klgr26LfsS61cu19Z45A9qHnwYAjTcLRCItF6f/sKL2OVcqK4PNE7E9/e3rv9IkMhLpk7TdzTl8BMuhCRz0HMi5v3SvMzHm0mfxDOvD0Y7YMEHgxEnv25RrkCBZFcAuiAFDoIQn7V6U/4x5ihVdKoENF8s+KHx9pDZDKcmIHToY4v8Jp94JpTrzSpw+Pv7t7C/o1xR9zBvaPx/smYjzwDKiuizkDljo+15U8whClT9YnSWLP+es+Gu3w5OZ8KQhsOwed7sNttsa9FcQJ2a1QMNoPco3/B3s/sTUklvwovNsyIMxu6w4IPBiJNikWrhDk8teM1O2hDnXJemjOg9BMluquXP2raj8XaTjotkPmxkLrU7SgdMH562YdWGiEvq/sr811+BQVcKWfM2MeiKsGUF841QcNY2tDrR1qLZoXsQHXxk9uqH7b02Qwo4YbRlo+HjVS1+/mExaT1iZ9JqZdof9e7mQeGgEUPVJSd5UFYUEU8zGLFgwQeDESfVBtJmpPjLoQuSy6ilBcfJ9pLi1pxOpYjoNN1iglug9Hev/PwWnztQT6WXbd7932ysXxEJTBv8gxESU8FxEkqnM92Hgt8TnmgbW19k0XQaHr65y+iJ9/wHq6U/1fXMpFH46dZ7Yr5GovZcnzH2tORwu22SVp5pyoTJJyo5QHV97m+RDB6DEQsWfDAYcVJjpfRyrr4BhgCdEJJipMHjIVUTnVaZIqLTzFQLwHHgZUVkSI6nsYiYjcU+YexPJZdMC5VcNkpD4PTnqus9PVv38pbtG0h+ynBJQmyDMRNPWQmvLrbF+SkvPYPSuqXq+lDhKPz4n3ubff5J2lwXc/bgmK9RowU4jhgD5ix2O2TN66No+852/12MgxMWfDAYcfDXhsWos1Ha+6RBQ2Dyk+YjM43aEDtKH010Wt1EdBoMUinGHnJh0eIFLT53UB4JDbdIBlSXRMo2+xvzn/0PdEIVJNmEHtfchRKxh3p7qoHpPhS4EHW6yC2Im/V6KpX49S3PV0m89BD4nUXgDVb0Kx6Msp00GkBh6V+/wsBRgDPyyGiPjzD1fFKr7baSQOZn3vrY9zMYYVjwwWDEwderF6tLuyeIQ209YNDKLvkxrNVXLFqGK696Eg/e8FSbr3vR6CPU7hmXWad20yhUeyjIsYecKHW3bNx05Nk3QwlZlC3549v399vvc3A9fbZ13kHIyc9HRe4h6v/NhgLUVVNp6aCmlYm2ShAhGClw1ae1nIXrf/hRWJe8BHLIB0tCb2x7+pvG+4rWUMnLKVvQs2//mM8P2qm0lxwj86FuotZyLvtYuy2jdVjwwWDEwS4/pZVTXPVYt5SyESLHo/94bbBWE15+5zf8njocszSNSGuM6jNC7Z5RmLmFrkarg4mNmQ9/UBsoFgPVbExHV5pbaiKzPfYnlOAi1bJeXd+gIz+J0ZdfA0m2gOd8WPF++xw6D9aJtss+fRccL6ieHodecEWrr3Pa4y9gg3+uup6XMA7f33E73VFPpZI6TVQai6xBE9VlIlwoK97V7H5RT8EH8/pgtAULPhiMOKjWUyDhCFSgsJg8KHwms+rL0ZT3XvoQ85IHqOvlxlTM+vG39otORdJ3VIkUfNhCLuh8rVtW9zeQZmSLn0oV+xurX/oPBL4BomTHwFsfUG+zJybCE8hT1zNL1uBgh5O0jidt7k9TgtWkPRL99Wp3S1sc98pjqK5bA47jMUI6Gn+8/jRsIfKSqZNbnlM04dgzEZR1ihQJC3/5ovk2mrTgQ+sCYzBaggUfDEYc1JgpMMjiqlHjpNRzwECai6b8tr4CAa0lUuZ4zPqebKvbJTrVnE6rRFtj2SWhoTZq6u3u9LWR0+rGEDmv7m8M9tNgvGrvIKRkRDJFFQFybs3SM90HL9IJnTc073YxhUgIGghGDMbaInC8DUF3BQRTEjJXpSBJpufWai27LWXZamXSlniKVje735xE+ywvkl6JwWgJFnwwGO1ke/ku1Ngpw3F4biacARryFTBE+y4899ArWKxlPRK0k0GV2LYPSC8jlU6qbCTqqxBJvGcT3TAFfFjw3bQWn3v4kVOgvEOpzGPJb5/sV99pWcEuODRjsQ3WUVH3FdpJe2AzFsS09D6Y4LWJtiZrc02HRQs+fFJsLUYsxpz5D6wyzYEsBpGQNADpNePV2+s0I7GWqNU6XqyBymb39ezXR11yohseZ2xjPAZD3Z/Zx8BgtI/35v0Eiedg8ou4aNyp8Ek0cVbURQcff1WJEDkBvd1FGFdP3SdFBnv7RacWHb5e8BPKNaMt2Ug/0yXrml9phul36NHoxZEuZNmKTfvVV7rztafBcx6EpGSMveuhqPt6X/hP1XBMx9di6fSvcVATnmjroOA0lsGYV3MobS9nPPsytnnmqesm+5lw1fWDWx/xmolFtRZ8hNtymzL5uFOV0EPZWMz9bUZc28I4uGDBB4PRTra4KBhIdblUjUeIYg9AF6nB/98tz2BVAhmCHS7WIlVHGY9CS3qbU0XH9j2kUXT66/pNCKs8BDP9TKv9dPJpiQEG0oxs9+5fQ+YGymvVZYV7MMzW6JkieQMGwR+iDgvjij9wUE+0lamUkdWjua7HDPrc3EL8La6H/udmNNRtAifoUSPeDUitl+7CZZcUzQ21KakZWZB5CoS2rI/Y5DMYu8OCDwajnVQK5OXh8FWoS1nrPuCbWKvPU3QaHIfBDdvx+Gv34oTTx4OTJbh1Vrzz4sftFp0WBymAUCSnem1aaKiVjheFfG0OyqZA5zxH9iTb1qxGgolOUpvSD4v5mFpNRJsnH7yW3RvXLlOzCQpDR0aXphRM2vRjbweCj4SkJGzrtQWyrxa8NQuDK6jbqCWceker7baSQGUhZ3VzF1QGIwwLPhiMdlJjTlWXGRLVujmRggEtuYH7r30Sm+091WDjCAtlMCafeBTS/eRRUVTcthgwNUjC0QrN0TSdDyFRTz9To6f1E8tALeGxWTShobZ0v/he6z6aCp4LICim47Bb74z5mAKhp7pMNB28otPN68LdPgJ69WvuKaM3UGdU0NgxXYw/wQC7+DxkWUJK0gj8cvODLT5WcOS34fVB020lb+uZOsbBDQs+GIx2UOuqQ7Wd0snD06i7RQjSwdUk8GpJZa42D+PQui24/7l/NT43z0vBR1kLA8GakqdNr63RnCLTBR+G9uytric21MBZR5mRWEw592Y1+a6Ua2ZN2z8m3PYXyNujxDM45qRWBX7iSerSIBRj45JFOBipLKegVOZpv2jKmt++A2+kUkhSP2pNjpdg5VYkpayEVEszWQYZJuH7B++I+djBE09XlxbOh9VLmk+3lbRWYD7A2m0ZLcOCDwajHbw9dzqCOh76kISrJp6p3qbX5rokGPV49M5XUWTJgk4K4qie0d0CWSF6XIGJpuG2xrmHjFOXPpEEJWmCE1POuxhBQQedGMKvn33Y4nPN1gQMFEgpsrWy7UBnb7Nq9h+wGUkcu6PvMS0+bswpp6mZEY6TUfXtZzgY8dQ6W5xou/3P2XRfyIdDz72yQ69vCVJQ60mdCU/DTvB6MwbXjsG2JSRGbcqQkePhlilQ3Di/+QA52ci8Phhtw4IPBqMdrNZMnFKcHiRrrbBGLfiwGk34005D0MbXbcZN918T9dyMJDpQl5rSsHpZy+PMFSYOGoskVwCcj0o6qbo62JMcqE+kMsyGNkaV9zfSFfIW/74/4Zb/4X1wnKgKSo+84eZWH+vU/p4833YcjAS8gRYn2vIeTRPkr1f1Gx0hSabgppY3Y0v2WkgBN0z2HFS/R5b3LYlO5ZrmQ/8MdsoM8iJtM4MRCxZ8MBjtoIKjkorDW6UuvU5n41C5ZUU6VBlTYBR9OOMwKpE05dp7LlXvE3kdpr33c7tEp+Hgw6GVYQJm6maoD2ouly3Q11KiLjcGO3YS2pP0NZLQtNAzqM3HFosUfKQY6e872JC0EobECy0ajPlDHffVSOI9jdbqJz/4NNaKf6r/z04cjR9uu6tFrw97qLbZfRl5WeqSFz0HvTcLo2VY8MFgtIMaE3WQpInU6bL27z/ByzJCnID5RrKznlS7Cef889xmz01NT0eOl55X5W+9Y0V9fKA8kvmwUbCh0+rosmZs1hJjx1EnRKHMY+387/fZ73bh11/BrKer5vLRVMZqjao+o9WlWb8L1Zr+YW+x9K6r4H9wCDbfcS6KduyhTEyo5bkuFpECAa/c8UmyyVrbrEubWnvS1KdQXrcclflfI3nicnz96v9FPb5GovdM5poHPIcffSytyEGsWtpcE8JgKLDgg8FoA8XWvMpGOo5+NgoKdmwjrcKK5BFw6u2wB5247EIauhWLXD+1HRbro30sYj6Wq1FEH+p6r3zqLEgzUQeB2d361e3wiWchl6MT1cL5+644M2neNFXD4Q30weEXXdzm48f/8yqIslXtjFn9/tvYm34bI0xzYdQVoX/Cr8h8/xisuPNyOOvr98hQuVgTbS1aIOCJ02CsKUla8CElUvlQXT+9B2rzZsKXvBM21+aox9eCvEAcMbw+8gcMV4a8qOsrFi7s8DYxDmxY8MFgtMH/Fs2AzyiAl2RccTh1XpTX1sDPGbDcTmPfj6zbhiOmtBx8pIOCiUIzlW9aY5QUUD0iZQ4oT6bHjx1+qLpMcNaicNO6Vp8/QE9mZts9lP7eF+ml2anv8LddclFQzMc8fmq5zaqIb8hc8faV+PdjL+KLV6PdUzvCgvfehl4ohyzrEJIc0PHVGGmbDuOzEzDv/lu6rczAtTLR1sxpwUcHPD4UlOm0dtBzs4dEpjOvcG+GrNNcVSn2bcSrZQKT+djvKQmk+6gtozJld/Dl+6/j8Wuuw9ZNLTv/MvZdmquXGAxGFPMKy4Ae/eBw+tAng06A9X4fViWOQIA3IsVfg9vuv6jVT23E6N74cgdQa0jCx699gktvuKTFx+rryA9ENgmYuXULTh0LjD35TMz9bjrMfi9efvdtGFq5bGjgFFMuB2Z7EvDAvbe1ul1DsjNw0S337dFvfO57b2OSfhdkmYdnSttZj6ZD5uym9XENmasuL8Ad723GolB/DPAGcT46R+7WP6Fc9LsD+ai78lN4X7sXfe3zYdAV43B8CM+j8zDbfiqOuu8RdCW8RMErF2OirUFHWTmfvv1zXZqyeNbXOI0DgrKAcUcp9uiEx71E2Y1UdNbocqElZziw6zsko0ENuHZvk1a8PvgQEPJ0n+h01+8LYA7W4POpb+DB117rtvdhdA8s88FgtEGpTLMuHJ6Ix0ZVUIcViSPU9SOdBejbt7nQtCkXX3sRHAES561eUdDqY6s92jRcs4DCEJlHKXbuzgRq1c3ctRWOHS3/61NEduXVog3JrTxO+bd92QpVPLsnyVn3k7r0BPph9Eknt/t5hUk0rM9qLGxXhsHrbsBdr87FIk2QWSztdvneAXqYSaey098POfn56PfCV9hw/Jcock6ELOthMWzFUf4XUX/PEZjz5qvo6uBD0NpYwyj+Mnoj6TRkc8d8NVyFlEmqhy0qiHBok5IVJLsvajzA4SdcCEnmoOdEzPvlq2avKepoOzl/93h9vPL4Q+C19mBB6wRi7F+w4IPBaIMaQ3qU+6jCGrk3QrweDqkO/37uxnZ9hrlap0xFGz+76iAFHDDpUGXIbLy9Z2YaSrN6ojQzr9V/AYcNghxCQDBic9bgFh8ncTzMPg/m/bDnBrYpQUOOeaO6viU4OK7n5l90hVru0PF1WPzF/9p8n3ue/RJ/BJIRzhUoeYEtyzs+H2bx99/CpN+prns0rxeFIYcdgZznf8CCIa+gyjNKzegkmtdgUsmDqLjrWPV5nYXThsqZbNHj7ld/+xE4HQUMeZNaLvu1hslH+3Wd1sESJtka0bEEbdWY/Wwkm5Oa1QMN2vTb8o3NRaWyIez10bbAuiO4t0a6nnRBmnnD2L9gZRcGow3CI+57mqi+/eTdL2A7Rx0uQ+Wt7fZW6BH0QHH5KNSuVFt8PzGxsexSZYucEG548D/t/q62PTAdq0QdBqQn4F/3PxPzMQ9fdQkSnXVYu3kjWrb46lrmv/EKjtKVqEGE4Zyr43qukmnwhnJh1u+Abc1fAK5o8bH/98w7+N7XW9XO3Jq0FG/XjVZnsG5YOU+dANwRzHO+BuyAL9gTY888u9n9h513IXDehfjzlRcwqvgr2E3rkG5djNRlq1Aw5z14LngAA8eQiVy8cBJd3SelaHUQjaoN29CLGwkp4MIhJ5zToddO0Dw+6rTJuGGRtVkfyS4FzZUwNUQHJ7WyDUmcE3pX8zKYzmoEapTgo+uzEt999i70WveYAh90wuN0wmJve3I0Y9+BZT4YjFb4ccUf6oh7hXNH0uCzeS4BMscjz1OALL65z0FLpBrp51ZsTkdVReTguTtVynA6rezSYDVg9rr5cX9H/Q10Nbu1FbMxr4UO1lW+PXflmF84R106/QMxePzhcT+/Rhsyl8MVtfiYJx5/Bv/zUBnsWvsa3HLvv5GhCBCUrFN1x//WXvot6rLESx1ILXHkzXfA/tR8/MnfCG+wN3jOjzz7HPSbcTY23nE+ygp2xfW+9fW1gDbRNrd3tH26wWuAjiuEEbNQ8K9T4bx3gtoGPO/+1k3bmpKsdcmEvTsUvvnjI2U+ImTFaFfiIAtBJOsNMdttk6TmnT7JmRQk8WJ4NnPXsfZ3xfhMhmhQyqHKbyqEH6d/2uXvw+heWPDBYLTCTxuos0RxHT2s/yg8fONTWJtAJ5/DahfC0GSibVtcfP1ZEKQQ/IIRbzz1UYuPqxBpfkf4OvTr1cpE0/joa9bMxgLRV8pNkQx0MvGFyMq9u1FKIZkW6nLZKDUfjtYeCnXakDlj7OBj6pP/h7dc9NqXWLbh3gfuVdfTeLqKrwpEW9/HM33XZiS9x67e7StvHPnwE+AfWoiFvosRCGVB4J0YmDATKW8fjeV3XQGvu33dKRtWksuoWQiAn79ADWCq7zoa/geG4YTk95BpvB4ZCe8gzz5XFeQqbcDjhB/bHeSEO1YaOGqfVSitpPJUSNKB91FZx2KP3tdrtGAl7BHSlBFjxtKK7OvSbpRN61bA5KLBjlKmA5KOtnn7uuhWYMa+Dws+GIxWKAxqfgZuEtv9zWklmEAB0gLVsOqadx+0xICh/ZHtowNnRYO/xRN0uUyvmRqig3pBIHJSaC+HjqAAaacstKhz0IfH8WoD8rqbBc8/Ab1QBUk2IfPK2zv0GqYpNNTMoCvBmjmURQnz1jMP4uV6MiM7w1SKh+6O2Nyn6ai0UBXqmPNr1SevgeOCNH336uvb/TxFwDn+qdfguX0eVjtPR0hKVj+DQ61fg39yLP5+8PZm4tmKkhLMfvFZrLjrChTfeTIG/PwAru23EDf0X4SjDO9RAGNdBqO+ADwXUj9Pjz8Xle6xWO88GSEpCTqhGtVT74/L48NvieiLkixUSmnw2RAUtX3cIaNkE4mZFeo1QzIH37zLZuS4ycoepq7P++M3dBXTXn1HcdqDLNhx/YMPQ9RTYBSs7/oMC6N7YZoPBqMVqo0Z6jIlUI57r3kC2x0jwMsiRjesUG93WKMFgG2R66tBoSULJULsCa7b18xWp9IqpKEMO5COKmPkpNBexh5/GTJn/4AycJj/5+8xdQ5Jevr5G3x75sA9sHYxFI1ivXcQ8ga0z99jdw459ngE5mbAIJSj4ZevgcnKSQ74+KUH8FzNYaqbyjGGWjx513lRnRtpOqU0kIWqUPyBnEI/mUzlKj39kN3C9N3WSEpJQdLzH6Fg0wYE33wQve3z1QzFEXgP7v/7G0X+PDh01bAYKpAmlOEoToQ6orgJSgkkJKXDE8hAbTAVZfosJDuzYU2YhB0N8zHxtfuguMJsuONCDEr4CQOs81UH1pzefVrcLq/bhQTN4yOpF3nJKDg0sWm104GQuQ7KryBorcbid9/GGc9MVe8L2nMAj5L5aB58KJ+9JFjAi/UoLyhFV6DoOkzaVGdfUjISE5MRMuqg9wKCf88E0Iy9lPl4/fXXMXz4cCQkJKj/JkyYgJ9//jlKpHTjjTciJSUFNpsNZ599Nsr3shUyg9EZaizU3pqFGswxUxAwqm4T0j2k2eiREZ+RV4bWtVBopvbd3dm8aom6VCSnuUbtBGBtexpuLAbqyS9kq4u6dXandzoFVjZXnfrb7U7qqquRZlmvrq/XDe/UazWEh8z5d6jLr9/4N54sOwyKtHGCzoWnb5ykTvhtSor2WZSL5g5te6KZgo/NCZ3bdiXo6vvC11hz5KcocR6uCm+txs3omzALyZYVMOqK1WF7kmyFJ5CPctd4/F07BZ/uGIGp206C/rEtSHz6b/R64VuMf/p1cFDKUDw8ukgAYL/5P2qGRcfXoOG/D7a6PfN++Ro69f04TDguMhrAYiAdiDfYB/VeEkAHLRWweSP7YtYgKj8lwqUale2OpKOyXsDZNcHtfx9/BJzoBDgDzrz6MvU2XQJ9n7pg9+6/jL0cfOTk5OCpp57CsmXLsHTpUhx99NE4/fTTsW4d1cVvv/12zJgxA9OmTcOcOXNQUlKCs846qxs2m8HofpZtX4VamyayW+5DqTkDeimIiT04dby9Qv+h5HDaEj89dR82zJnZ+P9eeZSqrjCmYNaPzdPR5TXUHZDOh3DaEDrR1dsMmLN+Qdzb31/TRWwOxA6QJp1wGmRwMAYDWPH7j+hOVr/0JAS+HqJkQ7+bSIfRUYpFsgBPMRZj5ifP4LGdY5ULcIwQ/Hjh6qFIyYgWZSqk2UnXUtEBr49VrzwNgXNDlOw45KbmQ9Y6woijjkb28z9h/oCX1QCjznMItjUcg3mByzB/8BsI3rcdlieWIeO5XzAHPVDmS0CAIy1QUwya5sGni1irK5mOTW4S8/ZXsh9bm0+eDVO5lSz4G2BFciq56f6+6GcIPH1eE0deBm+AgteApQIpwUjQPOHYMxGUdaowdeEvX3S/10dJtbrwWVMxZCR1DfUZ3F9d8iEnCXMZB2bwceqpp+Kkk05Cv3790L9/f/znP/9RMxwLFy5EfX093n33XbzwwgtqUDJq1Ci8//77mD9/vno/g7G/8ZkyFIvjYPWGsJSnLovDajciP49EiyFBh9xhI1t8/rd33YJhNccj+BldoSvc+vCNsAVdarfM799TlqMpNUF67XTBh+NHTEaCmzIlX61eGvf25yeTzmFjyBrTlCur3wC4rNTxsnIllZG6i8E+ev0a72CkZ2d36rXq+pOY0aQvxKNr+0FR4/TjQ3ju7CRk9YwtZO3Vf6C6rAaHyoL4xIn9XWTCVefrp5ZPuhJlro0SYCQ9M0fNiBz+xMtqy27TkpEcIK8MSYjWF9WVFUMwUVZCSIoOqlJufQIhKQU6vhau11rOfuicxY3TbMOs2jhNXYYkHmOGHwarjT7ToKUcdl1q4+OUbayVaf/xFDW3vJc0N1Y+2Hmvj/emPgUhoPjkcBh4JOl6FE45R3EKVoIcET980bKIm3EACU5FUcTnn38Ot9utll+UbEgwGMQxx0QcAwYOHIi8vDwsWNDyVZvf70dDQ0PUPwZjX2CHl640zfUe1BiSYQ55cdYxg1FSRjVsn9GsOo+2RKorGxwvINnWDwXrIh0ruV4SnVaKzTtlwoLIVIECh1RXbYdFp1POvAJK3kYp3syZ/t+Yj/FY6KRT5ur4RNS2ULouHOGSizWiK+go4y+7EiHJrg6Zy+B2qYP0nj7W16p/x/AjzkI4b7Di7/ZP+1WCtlQzBStbOApg9jScZtQl8dGH6wUfvQ6O10GWJRx6/j+i7svM64kNbmoNz7ctULUmsbBrbbJ1ckS7ZDOSkZrLT6KTKePOUzpbIel8EBJtUZm8cHuuNdC8dZw3U9ZQCHVej1G+apu6DJrScfalESGx4u0h6SgAKtwUCfIZB2DwsWbNGjXbYTQacd111+Gbb77B4MGDUVZWBoPBgKTdDJcyMjLU+1riySefRGJiYuO/3NzIVEUGY29SpSdNhNtJQ70m1W3G6eefhhqP1h1gaF14mKzZsnM6I5a/+3Hj7TkBCrCLDM1NkcKCyFRVIElCV/V2A21LPKRk90Y+T2WcDbtiBxeikf4Gj9h97bY7XnsGPOdRdQiH3t6+DozWKNy8GIsl6uaZjPV4fGwhDj2q9aktylV6ujbtt7SsNi5TNOrQMSDzspuwN+C072b3oXL+CtJ5SP56ZA8Y2ux5Gf96BiExVXWE9b7175ivHW6TrW1iMJZiI1FnjYv0Hfm5/SAqUw6VbIitCpu//6XxsdVa8JGkWrhFY0+lfZkXO6fHmPPr9zC4Kbgx9Wn+OwgZKKwMOZnu44AOPgYMGICVK1di0aJFuP7663HZZZdh/Xq6qukI9913n1qyCf8rLCzs8GsxGF1JjYWCh5BLRGKwAdddfbz6f5eWRg4f9FrCZop0qaT4IuupWva80JIeNS9DoVITRDr0FHzkCHR/tbVlv47WGGigLMtWX+ygXtDRIUAKds8MDoVBMqXkKz2DYE/UrOM7SOmudbjzi0r8KVMW4kJ5PSafeUO7npsuUHtzla/9otNehWTw5vb3Q6/BHfMm6aq5LrL2XYUxBunvCGjB7O4o5a31HtJ+5FsXYOf65tOQkzSDsfomHh82E93W4IsY1AVCmnjUUoEEX2RfDJddHDG8PvoNJvt8TvKgqrzjHS9/faXMAhIh6ZJx/T0PN7tfNFLJSRdgHS8HdPChZDfy8/NVTYeStRgxYgSmTp2KzMxMBAIB1O12MFW6XZT7WkLJoIS7Z8L/GIy9TWFlMartdHDnnEFMrtuOkeNGqf/3S3KUoC4WPz/9AARTJAuYJkeu2KacNgacLMGts+Ldl6KdGcOCyFQbvccp2gmvzmbAXxvIbCoe+ppJdLqxiVCwKQnaCa272m0Vc64Ek2Yslhq/o2lTGmpL8a+312KlaMIaieztUw272j3GPl2gTEF1HF4fWSYSa24P0vvtDThJijnR1hzSptlKLU+z7XH3swiKaRD4BgTeeaRFjw+P6hYKrNy4FILS5qtoXXqSp4qCy29p1H2kiBHdh1NPgYgjRrvtpGOVCbnK/iVjzq8z0BHKigphcpLQNJCa1Gx6roIhibZNCLDMx0FlMiZJkqrbUIIRvV6P33//vfG+TZs2oaCgQNWEMBj7A0rLaW1NJd6d9yMkxb00KCG9rhx3PUytfQoinQuA3QSATZFLtDp9kE7qVmtOo+7jmJOPRbqfDqiFRXVR498VQaRC73wqK5w88mjYPXRFN20ldSbEw/AB1OmyXdKhcHNz0WpOMqXWrZ7umWxb+9FUVZuhmnPddmeHX0eZUHvni79hfsim6liOS6pSp8gqJ9WFH7/frtdIFSibVKlNCm6LBdO+gElfAFnmEJxyHvYWvNZZpTNF25tbRTrpetVen9ikZGRgnfcIdb2vbYEaDIZRgrYkLWgwZ5HvyuzFH6rdK0rr7alHRmbFNPgowxEwV8Cuj7RuCw7aT2N5fSh6DFmgskzh1o7pMd599hlwkhcyb8GVd90d8zEDRw5Tl7zoVIMVxgEYfCglkrlz52Lnzp2q9kP5/59//omLL75Y1WtceeWVuOOOOzB79mxVgHr55Zergcf48eO77y9gMLqQc947C0d+dyz+rKATPu8M4khXEXJ7RlLQsnYlyrdire4I0NVhjXsLpIBbnTy64r2I7iPXS8FHGR/pUljz9/dQXlm5ZdgRkampqS4KUAqC8Q/OGnvC5UhV5mAAmPvzN83uP3wyCcSV6bbrFkQ7hnYFAwQqyZZ6BsW8am0Pykny/me/wK+BFHVC7R2Ohbj8nifhDVJLbeKm9gVlqXr6HCu0k3ZbJCwkYaov2BujTzoZe4vwRFtLQvR2mzUXMrfQuli4133Pq8GfYu8uv/9o4+2rF/0JI0evPWIy7W9GHYlrPYHo0pTbl9ro9aG3puPvT19X/z94ImVHLJwPq5c0n24rCVSadNe1nJ1p7Xs3VNF35k9wIDMndunw+NMvUL0/AAk/fc1mvByQwUdFRQX+8Y9/qLqPKVOmYMmSJfjll19w7LHHqve/+OKLOOWUU1RzsUmTJqnllunTp3fXtjMYXcriZbOxy1oIiRdRaqQ0u7nBhZ3DFuPp92+Hx0UHUC5EV6L6Vn49SaA0drWuCk4PXY0leyOll+wQpYgLTJH6eXER1cXTOCnKJCvFr4lO9fE7nSon/EF6ympsbWheeuk3ZgI8ZjqJLfrrT3Qliv25zUgns219pnT4dR5/5k1846P23JsSl+O6ux9T12v8dFsO176r3VQLiW8rpOgMQkv0NNAguSJfX+xNOJm225FOPhxhTAKVXby61oMPpT14rZb96G1bgC0rqO15+4pZ6tIlm9GnP+kzUqwUFNe4o7NDOgNlOAJmah6oXUrlqCEjx8MjU1C5cf4Pzd47XJqUvfHrMV5/6lHwIUUcLGDyeUoJp+V9XNRpXVs7aaYR4wALPhQfDyXroZRZlEBk1qxZjYGHgtJ2+Oqrr6KmpkZtwVUCj9b0HgzGvsTPy8nfwOjMhdNGB19HaCM2JW7HJ/wsHPO/E3HZq2dDp81CsezWfRBGEZFazFTucJqrUSVQ8JDeRPeRkUQH7FJTGjatpRN0lZdOiulah0qYHIG6D6ptHXM67WekA/LmQGx/DbeFAp2i3fRaneb7d8BxIfhDOTjqxls79BJPP/4kPvbQie9q23rcft9DjfftMtLk2gRTyxNum5KTR14tFTIPV73iGdEyG5csgtVA7Z0lA47C3kIVamrBR8++0dN09Qb63gKaG2lr9L7vOQTFDAi8C8LHFLzJdbuaeXwkmClQrXNHG9NNGHaGupSMbog6DxL9Ed1HjSY6lWrp82qKqFn4C1q7cDz4dlCg47em44gprWeeRE38Lbv23IRmRudgg+UYDI2CIHWGBEuPhpRA5ZDhKMBAVx/oRSOcxjost22GQRO21XIu/DaHApam/Pnco+ANVshiEIf+8zLUWuh1rdbcxsFc195zKYyiDyKvwyevU3awOkABT5oQfTI5of8Aej+bEfM3xz/hNj+BWks3BG0xxZlBrRzi6uLptn2MJDQt9HRsjssrTz2CN1zk8nqhZSceeDDaXTTheNIkGIQyrGyiNWuJkUeeqZZtlNPgyjmtZ2Rd0yhwCoiZmHztjdhbrFkeMWgcNpp8OxQ2z5sNwUj7iy0vtn3+7tmP1T6yQ+9pX6gGV/ZgbZTHR2lVCfQCZfVSkqIn944eOk7VgSgEzRVwSCnNvD4SghQkN4UzacFHnMMLp334BvTaEMbskbT/t0a440VgHS/7DSz4YDA0KuFBsH44anVDAB0PQZTx1Pl3YdqN32H6lE9wgvdQ9HLnwegnEekOWwX+teMxnPTaibjj9UuwYSOls40NVC/3e0qRN2QUxt94E6SgR9V9LH77HfW+1PR05HjJu6DKT1eFVSKdTFJ10a2TZ4w5HjYPnRS+XBG/zfrEE85QT7o14LDw5/eaHwS0ybxiB65OW2LxN1/DoqfUfPnoiH6lvbz73AN4qW6M4m2FU43leOTuK5s9ZtjkyeqoegXvrOZ6lt1JSM5S9S8KhTsLWn1sPigbVeHZe10uCgXbtWwCZ1AHqYXZ9AuVOGQxgLGXts9/pP+DL6ifl2IVb/z8KXUmi0KtRMHD9N/+q4pNlQF25x0fMfIKEwjpG9ttbdrARYUa7fnJXHPRsjmR7uPF+DISm+cuV7tkQsY0/PPmtoXKJgdlb3SawJux78OCDwZDo0JfC1/pOeD8Ejh3CKkNHqQlUHq5V8+BePa6D/HhmW/CpGU+eF6CzMkotBbhN8sqXDT/Spz16qlICpCOo16k1H5mr35wuUmX4PBErlJz/NR9UaKnA3SVSAfQFM3boylh0elOzXUyHnL7j0Zfnq4812xqPujRKtAVrc7fdSnrhL++BMfJ8Ab6qBbi8bBg5gd4sYom1B6lr8Mzd5/Toli1PjxkLti+booMgUoYlZ6WZ7woI+0TtEFyWx2dd2TtDHXVlJ2Q+d08ZVwURIX89UjYzdixJRSPldUBLfthW4h0Lfio04SrYoj8WHxBY0zn3rAINWguh87swK8vkHFZLRJa9PrI6dNLXXKip90t0auWzoPJTVkPLrt9/jYjD6NZL8rguZ1bmvuZMPY9WPDBYCgD4H77FE6lzVU2qM2uXF0ADq0jpSnrF85Tl8pAtvev+QD3JV6N0a4BSPQnIyQEscW2E8k8BSw7jUWY+vH9avtuhab7aOr3ka6eXoECMwkJK0Q6waRoJk9NSe2E6FRhoIH+lm1NjKPCZCdSzd7She22vcwb1eUOf/wll9fmGdXTYn8+iOeuP6zZhNqmFMnUAeEwtE9omK6VtKqDLbfbbnz9OfCcF6KUiHG33YO9iddJ2yvz0Z4yxiAFDIFgfN/ZgAeeQyCUrTrO9uIpsHFrXh0pNsrE1Xlif94NXgqO/UbSigR3UTDhMdL+m8w3Dz4mHXuKtibi73YOL5zx7qeAHIQsJOCmB5p7k8RC1YRog/d++Y41OewPsOCDwVBcFLf/jpArcqLkGwJICzXPEuzatV1d+owm2JMcuOiMW/D+jV9h1j9+xeU4EcNresNsIWHj7+kb8Y40A1e8eyHqLPRaVktE9zF8pDIOHag1JOGjlz9EuUzlj4y0iAAwTHZYdNpBp9O+mihzo9YC3JRRh1IrvM3jxM61ER+IjjLn/Xdh0u+ELPPwTIkv6/HG0w/hr2CCWia6ofcq1SK+NZyDSQeh+HEU7aDvpjXSdG17fQzw0pVzjbc/zNb4M01dieinjJW0W/BhEWm7vHJ8LaxK9mNFYJK6rufpuXxyH3WZZKFyX7U7tobEqTmb+i00jC5Z25esuSPo/2holt1Q2mMVjw6FDava3reUybSmOtrXfclJqldIe1A7XvT0u6kqbD5nhrHvwYIPBkNpcw3VI+TpE/lhNATRx9pcJFdZr/kOGKN9EJQ09R2XPYNzy3qrs1wUc7FiO2U2thpLMfLKq1XdB683Y4mm+7j0hkuQHKDXW7uhAOFq9aAxzdtST+hH2oNamwGLt62M+zsb0osOzFslQ7OprkMmHQ2fNqdm3qz2XZ22Ru5aeg1PoF9c/hgblvyMt2spfX6OuQBnXB17HklTxl10qZqhUMShWz95t83Hh0talVqJa3eUk2eKhVpsN+s7JpTtShon2vLRhnYWTWfh1ezR42H4vxXtR7aq71Doc+hRcLtcMOqoJGUwtDCpmadgOWSn4CBZayc//IQLVTGqnhMx75evmj1NEmjfatA8O1rj9cf+D5zi2MoZccEt18X1d4X0Wgu1J7pbjLFvwoIPBkM5GfEeSJqXhALXEMT5Q8c0+2wa/HRgC7Qw18XmJlGg11OK1895DYKkg1fvxtz1v8HtoexDchPdR5424bZIT3V75Xq89yAaGd+Us8aeAJs3BOWM8dnSv+L+ziaecaP62ko49ceMiNlZOHBya6WNXVWtt6C2hxwzdblsCZJ3RHt55Ycy1eE1h5Nwy6UT2n3F6/KT2VhOLek0WsNh9kSVuHZn/n9fgI6vhiQb0fOKjrUHdyWcZqe7+1A5M0fZBHcbHh+xULI567xk26+IS3kf8MWvbzSKTc89LnZ3z7B+J6hLyeSHxAdgNWeqbeWpWT3QAArmyjfGMBrTkb5G9Phx4atn4t43r2hx2/hyClB89lTkD6BOp/YimbUZL9pvlLFvw4IPxkGPosko11dBbjLzg5NkFC/8tdln42uc6xJbsOgI0dVgHaqQnd0L6T6qhy8pX4oKrqyZ7qNHkE6GBXp6Xjrf8oC3VCcdmLf54x/OppykB2snqq21zWv6fjOdzOq1oXkdZfbU52HQlUCWdTCcc3W7n/fJ1Afwk5+CsmszFqJHn0Pa/dyyEAWNGQYqB7RGdjp9dhWyEFMA2aeU3FKd/v7I0Szu94XgQ9ot+DAKVI7wteFu2hLrbZQlUAKOtJn/Rb2LuqgCoh6pybHLLoePOEoNTtTHmUrBG+yY8xJ5htRqXiF6V0mLXh8IhbDWthW/6dZg247motA3n3scQkAJfnmMODb+OUC2VPpuBe03xdi3YcEH46Dnq5/ehF/xOpApoAi7XWwtbX4iDmpzXeQWhsolCpqtukHrdJHooFwquVEX9vuw5KJsJ6X2U4z0EyzX3CrThZY7ArJ91B5aYqYr/Xjpp4kyt/hJk9IUTvt7QqHw4JqOkV9ALqlO/0AMHn94uyfVvllGupMTjZW49Lb/xPWeJak0Tt5iKIDX3frJeMREKgMpJa5NS5RpqdFkmrVBcqG922Ibhg8PEtptoq1O8/gQTR2b5GoNRTw5etgWI89AWbkGb8saCyVDFhTpN+IVKMukqzFGtdsmSc1LK7KBSkY6rZU7oPPhvzOfaPa4mnU71WXQnIZTzvtH3H/TmKNIy8JJbqxbEf8cJMaehQUfjP0exVOivW18sVhevhQhT+SELjnogLrLH+3yqN6nZT64GHNdNsyZCYOVniM66KSQp6OMRpmuDmOuvkrVgii6j4WvvqLefsn1Z0GQQghqNf1UoeXuhbGar1NZUiK2lLYtrtydvjYKfjYEm2c+zDr6e4RAx1PWyneQadEm2ErtHz8/9cM5KJR5pEDGLadEskLtZfgV10KSDap756IPm/uYNCWr5xAka+HllnWrou7768MPYNQVqUJZ7sRLsC/AS3TC5gyRYHf+52+C11OmKmsUDVWLlyTQfiZKNvCcD6PqKfiodsWefhzGEyD9hse6I3qGkWY0lhyj3dZgI32ULhjZt9aB9sUwv//wJQweEora+jfvyGoPhx95YqO4dfZPndcuMboXFnww9mtW/esyjF11BbY+0NyEqr2USS6ImoW3clqSMulguTXWGHqRTgY6zRujKZu/nwmOFyD5nZh064PqbaeOukBd1plqsLV6B9ya30eyh06yA4b2R5bm5KiQqnVjxOK2Yy6C1RtCSMfh5TnxH1wPP+Z49QdfDk710mhKuoX+ZnMn2m3nv/gU9EIlJNmEzCtvb9dzvnvnUUzzkJDx6uRFGDTmxLjfV5nc6tOGzKVsW9zm4zO00lZlfXSWJ23VTHXpDfbBIVM6PoumK+EkbY6QOTKPpmIlDetTBMxjz+3Yfp/Ea+U+H31uueUu6AMSglLrIlunj4IMXzJl0cJt5fU8lSwdMdpt03pQGYcXIwZgpZZSvP1FJMO18Ls/1MFwot6Bm+7/P3QUSaeVD8uau60y9i1Y8MHYrxlgIlfRXsa2xYYtUcm7IHq1zIdJgJxIqeWtolEd5d6UsE20KUbmI8FHwYrbV9po/DRu9BQka7fPXPMtKnnN70OMXOHn+SIHSoe+vtW0d1Y9XR1uCbZtqb07+cMnoRdHwdOqVdFzOIYPInGozd2AqiLycYiXQdVkBV7vHYS8AW13iijzVV7bPlx1OzlC78R195B+oCNUaaWkbKHtOS9pAp0Eq3fLAOWaqORS4Nv7Wo/dJ9paEyMTbXU+CkRC/o7P4glnKJYY0uCRsiFIQM9CL044ormzaVMavFq7bRKVFc2WLLWEGLTntOhyOmHS0bQiB5DkTEJvN/3WZlctVZcF2zfD5KTXC6V3bH5RmKCBdbzsL7Dgg7Hf8vcnH8GkpxOlWV+A6vLmvhxtUVlVigp9PWQtfSxZdUgRg1AKL8opavbXr0Y9Xh8kF1BbWETXhBSRgoxaRJuTZWqeEgWhWtRofh82a0T3kaGdYBRSbS3PV7n6y0exI52CjlJrx1LTAw0U6Gz1Res+xp1yDoKCDrwsY+6P38b9us76eqRqJZf1uvZ1KUx95X1skvRqn8SN4+Mfud6UAhO1SScY2w4+0nV0gqxqIjBWJvBa9BSQVY44HvsKnET7W1pGpARoDlH2wR/q+GeWpAUfYkIulibRa+eUeuFcR/tkS4QkrSPM6oUc8qkjAxa98SqyBpFzagLcKCuODl4HHjKm0QCsT00mDtHRvrfZVIzCgq34+MWXAdkHmbfiuvseQKfQMkTh4Y+MfRcWfDBaRTk43Pjahbjw1TPw98LmAr29SfryGY3rPOfH6vffjvs1vvzlDQSCmY0/BdmiQ6anDH21ybJbSqI1EEY/aUsc1uY+EXY9BQY1xuh21Wxea0PknRh79dWa7sPSqPvIyYp4hkiacC8Wyxwj1UF0ChWJFsxeNz/uvzdfOzlvDqQ3y6o47XQy3lrcvimxTVnx/GPQ8XWqhqDfTfe2+fjZX0/Fxy7KtvzTvhITTr4KncFx6rmQFa8JoQJL26j3h70+KsSIuDL4w4fgOAmBUA9MvKzlVtA9iZIRAKjs0mfggGYGYx50rNOlqrQYdu25GQMmYHOPEOrtOjX7kfPn660+t1cOBRk8J8Hrpe4iizsBE449E0FZB56TsfCXL5o9T9TRPp7itOBfFz4DWyARfp0Xz894GIYaclr1JTrgSIs/o9eUhEzKnAjBjn02jD0HCz4YMVGGpF3z2rk459dLMde6Fmtt2/DoiqkoKyPNwr5Arpmu0pS2ToWsCppNEQ8b67dAbCI2la065KEE+VqGYGcT7w+lJdekDZXLyY7uOFFEgDoLtdWa+kan88f1oE6OClMlRLOpmd/H8CZDO1etjd3qOnf2zyjlsxvbgGWew8fLleFb8TGwB/3kN4lGNNSWRt3nN1Fqv1Zz1YyHQV4Sb9Z4ByE9O/KZtSRM/e+KHlDCuBGCHzfedjM6i9JZExDpfcU5NHStJVIMlPmoECNBX1+e9qUy775Tclm/ksoSAIdhIyMTbS2auNOj6TbiZeHv09UgISQLmHDMGUix12N7T/ruM6xLsfj7bxEIBfD1qu9x0/T7cOeMiMX5SYefo7bbKi26tRbKFDmCKWord61MwZynqPnvMKinUqbVY0CiPQmDAjQmwFUqgQ8ppUYdjrvkbHSWSSeQFwknebD471mdfj1G98GCD0YUi5b+jstfPQeXzrsWC6wb4dG7YAskwBAyotRSgpu/vkk9Ce9tFkz7AmY9Ke7L3WQGlqVv33yPppTLbkjevMb2WiXzcd6w4eiltaVuayI63bZiEQSt+2DQmGgjsKrFm8BxPELeGhxzM4lNw5x53NUwB22QeBH/+/1VVHFUeknVdB8V1ZEyTZUY+yc5Z+NvkDnqiFECD4WdfPyll6POuUktcyjJ/N++eCPqPlmrlwfElks/LZVcHNoslw2mtv05Xn/xGSwLmaG82/WDtrY6uyUe6rVSUm6odc1KRrKWPZJoqdiy203k+rotrbnB296iqECbvMsZowbrmTjN3bSDHh8Nu8ghtx42mK02WA0e1CTrUaVPBM8FULXuHoz7eDweWfkA5jh/wC81X+PRX5+j9zaZEJJoP3SmUGtsokBBd60WFFn8u3WyzP0WXs3TzeQJYfbPM3FW/mngZA69i+nv8lvTMfaIY9BZRow+XC3fKMz/XRGxMvZVWPDBUPltzjRc8upZuH713Vhq26SmRBP9DhzlGYZvTv0cp0qj1YPFRtt23PJe/D34XU3SAhqhrkxN3ZhAk0etxoK4W27L+YaoNtskScLxIyajb4bcTHS6ZQ3Npgjo9MgdEN1KmqyZibn8ZCTWTCgaoCBmi6cINWYKPuyWXNSVFaPKG+lkKDbE9lmoTIgIDsOUJjRvBW4L5UQ/UEfZmy3V0RbxRs3Bm4+z3Xb5i09A4BsgSnYMuemuVh+7ZNb/8F79KHX9QusWnHDJ3egqijhtyJypdbOxAYdQgKFcb+/YsBi73n5JbTcNSckYf3P7unT2BA01VB6S+cj+oWDQawZj+o5pPngffT4lOh6nvTcFAi+pqYz/pFJ2YkqgDA7JC0ESYArRfvdHYSSL4A1SwFCfTgG60ZKJbUvmNWm3jRZp/75hBtxmCtpNnkos+ew9HDP5PAwv7geTh0qUPce3vzW7LUStDdlV0XFBLqP7YcHHQc5XP76JC149A3dtfwKrbFsQFAJI8aXheO+h+PHC7/Dy9f9DZmYuHrn6DRzmoQ6GBZaNePDN9rtXdgc9tSvVXb7+yL/0KrX0omgOFn/xv3a/huKyWC2IgGRXJ9nKHJARpKu2o866Wr0yVxLbc76hDEFpJQUNPq080ZRkiboAavnYLX6ZiomZktbn3Bh5xaWqWI83WPHnC8+gpsmE1UKtdLM7JTYq0eSFtNHxsoxamxEfzI1/gmd/AwVIW7Vx9GFSTHSSM3nju6Ie6KIr6VrvALXttTVemytDOTX14UTccs1Z6Eo8I45Ul0ZdIQo2kfg1Fko7b1hZs27Rb+gfpMfWePrt9UFyTQm4fc2Gyil25jojaXM4e9uH7+K6Yjw/53Vc8tkNOObd0zD23QmoSqFW3S3mAPISKRBRkl2L+Gxs4x0wysBbW9Lw90Xz8Ohh/1H7z6t1xWoZRsHpIw2TN8kFKeAGJ+ix9otpqNHKLo7dvD6KQrXwadOEFQS/Bx++8DwG7CB9ht+ciqNOOR1dRUjL4PHKOALGPgsLPg5SPvjqWZzz2ml4rOI1rLNtg8iHkOnJxOn+8Zh52U947roP1dpsU1664kMMdvUFOBk/6Zfjzc873hrZGZb88D3MejLZqh57OnJ694EvRFe9trXNZ0u0xNd/vouQ5nOgIJt1yJFJj5GQnIW+PGkfthTRgbPO521xrovNSDXsWlN0yjnMADt1Y5QZq5DacwDcbnqfJHcqqsITVmUZLp0NUx+N7rBRKLTQ3ze5ZCHMsoeK7sr48J2x3681+lpI67Fxt7HyA3vSBFmbqx5ObbJoWyiOoikWKrlsNLRuePXOcw9idiBJPehcn7sUKRkdc2ptiTHnnKdmLzhOxI7PPmz1sRlay3FJmRvJZgpkNxu77uq7KxD9dPKUmwyVW/jBK+rJXpYlDD6lefBW7a7GtV/diRPeOxsT3p2IE749AR/sfA2rAn+hXLcDXp0LWSF6XXcoEYPUiT+A22/F/Kv/QpF0rvr/PsZ1WP3d9/hsUSn0WjnrveWfqkunl8pkNpMHHi/tS3afA069I6bRWKXkRnYF/XbCBb2abeth0dpr1/apxwvfPdx1H5xF38zUrC12bNuIv57Iw19P9ERtdefnGzHahgUfBxmvfPIgTn/tFDzv+hibrDsg8RJyPDm4QDwSMy6fgceveVstE8RCuf2/57+OHp4eaobkQ+cvmP33d3v8b7DM/gIcJ8MX7IXDL7hIva1G83nIQfsFsds8Raq/h5LxUJCtAo7vG2lBzddrolM/CRnd2tyTkD46+Pj1pcegMzvUE0Lq2Cbq0SZcetKt0Il6tZz12U//RWV4zouY2ThhNVlrq9xZEJ0uXrdqMYoFylLkeHQY5ok4cxbq4z+BTziChrYVyTxWzpnWePvEU86GyAvQSSLm/0BlrbZY9MITasZJki3of2PLJZStq+firSoS3p5hKsa5NzyKroaGzFGQluuMnty7O2Ebe742oG2/GfnX7jslFwU5SEGCJESCD28R6YMUI7u+Y5rb19/y3QOY7/4FxcJmuHR1ilYVRtGMtFAehujG44IeV2J4AwUPFlcfpBsowK5xURZi8iPPqNOIlSnBvRe/j7kbHaivIOO3YmzGpoqt8GuzdMx6P2pR1TjTSHCQWNfRxOujrKQI+VuDsPjpRxZ2x9G7lKJXCJIuEWtyt2ItyL+mK0jOoeyhEGx/Wertr2/DxEA9Jgbq8OFrHTcsZLQfFnwcJDz9/u04+fWT8Jb4HbZbd6nZC8Xs53LuZPx8/c944IpXWgw6mpKWmoX/G3MXEv3JcBrq8eSaV1FSQsKzPUUvA51YCr39G28r0PVSl4nt8HkIU8l5KfjQxA5GvYBLDj8j8j5Gqmlv1fQaAe2yTdptrktwJx1sQ55KHHbBtS1+bhl+OiiurFqFalNE9xGesJotUtBRzkcPrftu3pcIcXpYZBeuuPAuDKmIWKuXJKXHLQAePP4U5GlX/ksXRwKZhLR0ODXx5/ptrZ+8wwyop46bOu/AVrtcXpm+GRXgkAkZN5/f/qFx8VIWpOAxvQ3xcZpmY98LtO82+PojM4+cVvcVOE34K/GRw7Re01sEg7HN6HZ5yGwvM9QHp6SdjzcnvYOlVyzGH1f+iM8vfhsPHHMbHBxl8vzmDNhNdIKu81LQpvCjSJ01mdZlONK/HaKnL+RAspodfez3F5DqGKneL/AiagyUeUvQpWHwRCqdWDgfVi+hDOQbzz2MXmUWSGrOg35nQaOlMQhxO2xqFq/YUoxPpk/tks/tuNPPpBXZh9k/tx1E79y1EUZj5DeVz7dv32d0DhZ8HMAoJ6WH37oWx71+PD7hZ6HAUqiKRvu5euFm0/n4/oYfccc/nor7dRXXzqtTToMhZFJtkm/+5pY91gGz8rdfYDGQE2XZiIgVt3nKaepSmai6bn77Si9lnBOS0kqrWaWnydFp2r5pdILeKppU0Wl4xhd2mzCa7CeDsoZg61dvGeEhc3Dj0CsV3YcfnMGCMonev2eQMi2FJkpfh6myUzCSF9gFe1ISju15BPQyZUk8JgEv/Pox4mWgXpuQ640WrfostI3VXnr9tkouaVrJZZPQcsni8/8+iO999D7Xpi1A70Hd11FSmkUGZxbjrlaHzKUpWQFF/2Eg/cNWad8YJNcUXrPyl5sMlbNoBmM+sflV/bKCFajXUSbi/46+H0+e9CAO6z0u6jFetwuJoOfKaTnQ8fQevXNOgNvnx/hn/4u7uGPg8g9Qsx9P65TMJgd/NQ1t2+RZjsljT2tst63Opn1Wb82Av2gHPDIFRxvn/4D3Xnwe1hL6TWzqK0IWND2NZjimhCNnXXEV8jyU1fuldE6XfG75A4ZD1qb+Lp9Hrrut8cSPD2NAKLKvjBUr1c+J0b2w4OMA5YG3rsJJH5yCb4zz1RZZXhIw2NUH9zmuxvQbZ+Ca86PbQePlsrPvxGnSGHAyj822Hbj53UuxJxBmfqKaQfmDeVFmUIccezwCWutq3Q9ftquluFZtOhUarzB7ai2wYSaedrkqOlUOS3O/fbNxrouwm7V6MigzUiNEO5vuTk89Pa5UV4e8IaPUOS/KIc7H0c8wS0/BT4kpDZvWRq6+Sm0U3OR46Gr+6CmnY5iXOm8UltRF0vLtJd9IQsNN/miBqKSJ9byx7UaiWPjyc9DxNeosl9xr7oj5mOqSHXijeKx6ojnGUIPL/xXfxNp4GakOmTOB5zxY+E50K3FTHIYG9OTK0EMohiwLsJy9bxiLNYWTmk+0tWgBrFeVQkfzzpLP1LqGPehoFnSEWfTHDOg4EZLMoUJfoQYQyrpk7YcRT36EsmpF9yPgQz+V5tIty3FsYA2C9aPBiQb4dG68uuRDiDLtc1WZgOirU9vMi2YvbhSdShWbUb1sHngZ2JXhQTDLAlFHQYfeR4Gf8iua/eVXGC6QXmqTsaTLfIRCeurk8ta0Pqto9doFWGHchaH+yIVHuhTERy/sXUH9wQALPg7QEsv3xkWoNJerOoPhrnw8mXMXvrjxO1x4WucNncL8++rXcIR7oLq+0LoJ97/Z/bXS3lrJpahJySVMg49Sx3l+rSOkFX5e8RX5eyhHQD+daQ+xRrdoKoLIPmHRaaELvCbUMzQJPpTuA6uJruobTK0HH6ePuURtqWkw1qreB4rfRznoBKPI/q6/92oYRZ/qYvrJ65EulkILXRlmagI9hSFVlP1RKDbFXy7on04H2xWiGZc+9Bmmv/lv9f96LQvEtcOeun81DXGr9w5URb+xePGdGdgpC1Cky7cc2/2dJEkpKfAGSAeTtovm/sQizSbhWH6Zuu4J9FVNyvY1whNt+SYTbS1a15QnhsfHpjrK4vQw9W3xNUs3kCuuExYYDFRy8gSNuPP7QoQUbRPnxyE9S3HjC1PhVrMfIv4j/AbIeoScQ9XHLyibC1+QglS9UAKXj/RLif7URq+PNFcp+GAALrOIecOrkGdMhdhYrlRCUdrPfGUFuOPs/8AStMOrd+OFbx9CVyAaKFvI+1rfj1+c8zxEwY0BWnv5Gq1NNw/xGxYy4oMFHwcgGzxkTpTj6YFXBj+OT2/8Bicde3G3vNdrN36BIVoHzM/6lXj9s45PpGwLZf6G1UBOlEWDmhsSFUt0kk7RtBqtURisVPUekl2vbLr6S7j2zObBU189WT/v9Gc1quctTcouc6c+Dt5ohyyJ6H8auSu2xKiRk5Dip+zHr+u/Q7U5EnykcSGkpqejh5dq6NV+ur26sqxRVJrujkxhnZw8AoJMwVBpcjJKauKba3PipffgZGOFehr4K5iAO3aMxXkPToNPmwpq9Lbunqn4qaRrxmKbObJJ352fPnwCX3joRHhl0hIMn9i1rbUtURUg7Um2rmX9T+/8fBwrUPCx09/yyXpvwolasGtpYjCmWfV7dNHBR4WrCjU8Bc8n9NMGucVAcNFnUifb4LBRMFvmzgQkMwRjGR4/LRvfXk9W90tstD+nWpbjn94V8FYeq5Zt6/TlcAZomxLMdajlKeh2iCmo0cYDOORayByHPw6tQEAv48QRZ0HSRzJ0AVOauu/pPE78Nv07DPRTAL9Gjn8+Uyw4K2VZdIGWy4fzF83EKvNO9A8EoIQqbtmEnwTq+Botl7HSSzfDgo8DkCqO2tp6yYk4YvxJ3f5+r5z/uhrohIQAPnL9qhqWdQehGe+rV2L+UA9Mvvr6ZvfX9SctgUlfgIqS1gOQCpDYFBa6GjPqeSQ7ms+V6B12Og2kwRAgXUtSE2GuUENXWAF3KQZNbj34UMjQ2mqLxDoMveAclGtD5ewyfWe52qTSYu0K7P1pL8LPmWGQ/bjo1BsbX+eU0y7CIN9adT2o4/H8rGlxd4a8+n+X4+X+y3GUoU49ECwOWfCteDi+yTwN9UEz6utaNmma/8oL0AtVkGQjsq64pdn9ikbmtc2DoPx143RuXHNb2/NeuooCCwUTdmPLKXwpmIjRHIkzN6XFztrsbThZ2zeSI8ZzegMJgv366ODw9fnvq4JQpbPlslEXtPiadk3UXCYnItFCuobt9T2RmrwdS+8+H5dMoI4khSMfeBSb5YHqHJd7Et/DYE8AgiZMrdFKQnaTG7VGCpjthgw4QxQcJSidMLlJqEkMqGaFh407AZw29E3BMaw3RBt12BQtX4JTeh5L65YifD7jNXSW9F4UgAohV4vGg68tfQtBwY8xTsrCFEup0KeMh4vjkCYFMe2lWzu9HYyWYcHHAUiVJibsbY6eXNpdqB0wY+9Bkt8Bl6EBT294Sx1I19Xk6+hkURqj5KIw/rIrVZdNxSJ63Ydvtfg6iji2lAtADiVC1tOBJ1UT3u1On1RtwJxogkGb65KRQhoMBYc2DbdebJ83QA+eTiRlArVKFgXIDTIlQCeadHXAPFBoptet0PzMckIFyMmljp4ww6rp81DY6IsWqbaX0654CO8/ejHeGL4BJxiroJNlFJl74If0k3Hm07/irWcfjHnwzi9boC6dvgHIG0Dmc02Z+tJrWCsaoFTebxhVFWUP3t2kn3ERZJlXg6PF33wd8zGmP7+FwMlYJ/WEyxSt4dkXUD5zTqLPPbMHnUgL1i0Db6Tgw5wZ7dGyuJjmwKRzPaHbrRsr1jTbZegHg1ZSdIVSsPSem5G827DED/77HqZzR6EaSTDz1fjC+AaClTTKoFDxmlGHyPqQPILKfjpLKkRNc51oCqAozx0VcA8cpZRtBARN6bj2zodg70WtuXx9JYbkHYZcTXj6U8Hv6CwnnqX4lXCAHMCsH79qdv/MWZ9hnZnKTuNdms2+7MANlz6Bv8z0OWSHwrN1GN0BCz4OMBQtgVsZnCVzOHXCnhGBKowddRSuTT0LxpAZ5eYy3PbDHV3aAbNxySLYjKT32NHnqJiPUU5wbq3e36NyXYuvNWvOl3CF0lS9h1pyUdvrqLyyO5NP/aeaklWuEf2akr/foIiZVjJH7bPVWpdBWxyWd4S6rDJWqg6rhYrDqlJjFiklPXwkHchrDMn4+LVPUGqnoCJXG0bXlDG6HuBkugIttneuTfS4i+7EG/93Gd6fUIhBno0QpBC2y1Y8UT0BJz36C159+mG46qsaT4yZWpfLZrl54PHXt6/jIyd9Rv+wr8XkM2/AnmTAqNHqdFoFecGvMR/TR0f70q/iaFR591xg1F52bFQ0B/TdDhhEHTyrv/pMFXbKYhDjLom0dIdCIVRIdCIdlUXW9bH4be06BDW31FCiqIpNla6VZy4ivc/ulJYAPpjwBU5FQDbAZtyE7+qWwxJwYGeAAjY9H8LoC65B0EPZD4uXAqVEnQ8VPAUfmaAI+uxLr8EJ996Pq54h0fEVd90D0WBShbU/v/8uhnEZjcLTyqrooYfx0iOvb2PHy7ql5MDblA82fYGQEESmNwv9JMoAletyVLuBpRz9DYeghJVeuhEWfBxgzNn4s7pM8idj0EDqx99TXHLWrThD1jpgrDtwUxd2wLi/fEtt/QuEsnDUjS2nQ8sDdNLJ1Molsfhrx2zy90jQN7Z1DOFjDyNLye7dKDqtMKZB4nj0H08BhDKXxWQmpb7bGjt42Z1TplwGa8Cumrt9PvsNVGpXqT11iap49dIbLkFygDJXq1fsQpGVDoRZzuZOphddeBN6+eikU55owbLtEc+OjjLxjOsxTNqMfxZ+gqHcDjVzsU3S4dnacTjxqQV48cnHMPeV59TR9ZJsQNKF0eUvJTB5dWmK2osxmA/g5pv2jmFTnWY611Nq/r0q1us2I2mHfpNGoToU7eS7L7BpQ7ibiUfvgRTIifW0r4r+eiRlRrKan674Gj6dR53FcuNhsbt2Lv/wE1z92Tqkgbo/klLp9+EPGWC1RWc8wgGNQTs7VCAVP8lUvu2bMAc3FFiw3c83ttv+tvAHuLVOrAQhR+2e0XMhhPQkRB2cGGljHjJyHFIzSN+hnOj5FFoXq4px86mPqAMYlWGWz3/9QBfYrFPHS6A2Wh8z7Yc3sMFCv5uJgVykgX5vPcaRJslrGqiWXlLlAKZPjd3Fxeg8LPg4wCgOUd99mtg1k0Lj5cGrXsVEDwkQF9k24p43Lu+S1+0n0JV2WQsllzDFKXQlbjW0PGSuVKwnsWmyEZyHRH09bFRSiUVYdFphSIPPZG40Y/tz6jPg9WbVr2PsFde06+9QnpupTcrd7i1FveZ5kKm3YPZTNLo8VxOdloNHgYFKLWlOPyrrXJixiE6aYcbUksmXIu57c8FcdAWi0QiL5MXA0FZMO03ERZYdUK4hC2UeU+sPxa5ayho0+Puj38joAPftqU9iYcgKJaS6od9a2BIjJao9SaE2ZC5JayluSvEHr6qluTopFevlnhF7+32IsmI6mct8ZKKtKUhizkAoun30x02/qctkKRuZCemY+ckzaKilzEFRTTWGPfEKZm9IBkQrcjjat2w2OiHXeWIfJ+75fDF4LuJ1sZLvjc0u8vq4lF+GAR5By8sAO1d/iTo36WsSrHlo0CbnZMhetdvuohOba4LCHHvpPyFzPISADz988GlEeCo1H9AYLyGt40XwR3e8fFHwkzphWnF2zm+Q1ACqTrZj0olkLX/NaffjTwtla7L9rPTSXbDg4wCjGnQSTcXeSyW/esNnGOaieu6vhlV49dPOtc9tWbECdiPpG7blTGz1sQMvvRKyrFenrC78JPZ8jzLZB8nXA1KiAZyW+eg3sOWgpo+WRak0psKvXU0pWFx00vJ5SpE9gNoQ20M4DV0GN6q1n2AGeNhdVGLpEaQTw87kNLg5u9rVcvK4s3HK2wtw8zebcctH8xpfa5jPSrlzJVWPaE1IR9FpvhJyKIShh52GJx6+Cd9cZMfl1k1IhoxJOjogP8sdjscff06dDKuwdv73eLeWNAHnWXbglMu7pm2yIwTGTFGXRl0RtmnTiMP0C9EguR1+pU2cQ4W47wyTC+OspQBD5iIiTbO2nT6tTBCm2LdNXeYnDMJLTz6K69YOwbOvTMPUWb9j0os/wNlAgtpc61rYNTG6UQu2q13NRdZKkDt9Ux28PG2DINP+8I3uZDj9igDVj1fLayAFtE4tYTsqROpSsVizUa2NC8gJhZDuT0OyI/awRIURo0ZB1ALU+h2bcEIPGg5YYC7C9J/eRmfgbVrHSzDS8fL+tKexWct6HG89BA4vrRdpgyEVevUciEU8lYBG8EWs9NJNsODjAKNSR7bLuYaWf/B7glcvfEsVkCl11Y89f+CX2V90+LXqPnsdHBdEUEzHYde37lOiWGR7g6T7SNxIosimeFwulHE6dQouTLzqNqAcokZMPr/F1+yV4m/MfPg1Ey6FFC2DUSfFN4hqcAIFZqU6n3r1KMgyHOCQHqIDXqpm916qS1UDi2yxCPasgSirJfHrD9udaNAmnl595X1I91O2a0cylYA6i11PhwWDNkhPIX/4JPz7oTvwVOoK9OeLEZQFfC+PwTuuQTjjw0o89OhUPD/TiVpw6MmJuP2fx2Fvcth5FyIkpaiGdMXTPmq83Vlf3zhIrkCm/aRCih5Zvy8Q8ND3KwsR8ahVa2P1aPboCgt3LUODnva/K8acj7/clHWc6e2FF393QgqmghNcOGGYE7ckUnlBaSk1aoZ2gq75MMCrPlmCQ0J+BLggeJmDXaLgwKATcCnOQFBMRTKcGL7Jpe6f5kQfCgwetd1cMCbCpc1C6hEMIV3b5tboccho2hZnLdJ0fdTOOUWM9f2OmR3+/NTX7UffLx90wuOkQOq7yr8ga6MlbvvHk8jR2oSLJPoth6nV9YGT4+CQ/fj2lTs7tR2M2LDg4wBi2Yq5aDDSAea4Q87eq9uiXO08Nv4+JPtS4DY04NlN76gzFDpCP46uVMs8A9rVNVGjHfxyuOatltN+eQP+QDZkuw7QrtxyuVCrrzv5pEvAQ4JfMMGlj6SpEwU6KNcY4gs+Lj3pNuhEA7yaW6UDIShhkN2co+o+Lrn+LFXwGZT0alko11uEp39eB07Lc0s+ETd9StkGhdF15FfhMusxfXHnDtgKPR30d1nd1InTlP6lVObx+gfgMvtmZHMSlHD3Y0++OrFWCeauy16EtLzWy2N7AlfYdM4d6bxa9vKzalZMkq0wDqWMQIXMq63B+xJSQBsq12SirVnLmLmbGIy9r7iaKuWOYAoyvcDqEGXmKhUHUlkPvbkQH1x6CN64+AKINZQhqTJbGsWmZx17U9T7LtxQjFWlXgzXMiRW2QaP5loq8y4kD8zFY/VXqHqf7LoA+uz0QG8PInvKiQh6KPshevMbMx85urb1NJdcfwNEsw0cZKz4eQaGaMLTjYZS1NbEP7U5zKnnXKqd4kL4cfqn6lDNbcpcK5nDKSnk4BoOPmos5O8R5qTBZ+FPC32WOW5WeukOWPBxADFzBXk92P1J6vyVvY1iqnVdRqQD5o4f74q7A0YRByaYqOSyNT3iQdAau4x0IEmIUe9fWbEyovdw0wE+ZzfDpt1RTqQJMqW6a3SUnt22ZB6MFqpP+xNa1ou0FJhl+tMgB+nAnCmIkMUABGMC/njm3xgwtD+yfHTQ5eoCyHaVY742klww08noryK3mh5XGFkf0QB8vYYM5jrDYUeR54LZ78XqP2dF3ZetZQ22hQbgzgcewMy7R+OOpKVqtkPhDFMJLry5ey3U20uJSKLM1Cbi43715Hpa7+2HMcefrx4AFUXAyr8ijrL7BCGKNOUmQ+VMOgoCvE321y31FJhnm/ritxnfq39LmAHW7djwwFWYPJAmLVuDpF2qTaBsSlDUISs1ehjgrT+sB0QZiVqnil60oF7bBDfnxDWDB+AjW3/MrCaTv96FXmR43UifmI/6EO2zOi3z2CMUwpH9j2/Xn2vIoECRq6vA5UfcAVPQonbtPffVfegojrR0SDq6WNi+bjNmNlDg3N/TSx0vMfenL5DEudQgbMRJ0ZotxZTxbz0F4UOFQlZ66QZY8HEAUeClK4/U0N4Rm8biojNuwZncOPASjy3WnbjxvUvien7pey+rNeaQmIrDbm1f+jPh+HPUpUFXipW/R3sGlEtuiJ5osWmWJihtjSSZrozrefps13zxJThBDyngxpF3Pox4yZCskLTgI0PngddNgVJCAwU3eT4qpfD1QSQ5fXA20GnlsSPzwBl5yAEJN/yPrshuvu4x2AIUnGxJ7nzGoe/IMXCbKV2+eNFfjbfPeedNVUOhzELRnUpC4oTkLNxy778x88Ej8eaw9Xjq3j3X3t0W5dkj1KXFUKCWW8iVlQS7WzBAtc9PVX02gV1b2+9L896caTjno3fidpWNB04LPiQhkvnQGUhjFDL6mrmanth/Cla5o83SpvCuKM+PJG2gnDuR2mQbvBHzMoV3fluLsmptxomm95BCPC658DDoZR1ETsKs6cuRJezA8uog1oTo5Dxiiws/fvcMarR2czNPAU1uUMTxR7VczmzKBbfdAUnQgQ8FMevT/2GA1q20KtS2W3FriHrKaHobnCiwFqrHoXNyKLguXkwTbyvlZAwZ2fzCpoKn0ksyfPj2Zdb10tWw4OMAolITm6apDZJdR1VFBWb9SIr6jvDAFa9gkpdq0Yutm3D3G/9s93P7yzSvoqKdJReFYZMnqy25Ct5Z0SO1S8QQpFAypGQDeC3zkanVzFvDIVKAUsdR8JGgmXp5vKVISIqdWl675Huc+tYgPP5S87khvQ0ZjZmPNF0DKmVS96dpug+HnXQmfJ0fO/0jVD8SvVWHiyYPxlG5FBgsKfViZ5k2nbWeRoKXJCR0ib+K20p/Z3F9pByRs548M9yBfPUzborZmoDjL75rj5qJtcXoq66DJJvBc14sfecNLHjvbeiFclXvk3g+XemmCxTUVbnaP5zvrbJk/J07GjfO+Knbtp3XHERlbdbO8hmfgTfQ9546nDq6/vv3uxB5ESbRgvMHn4YFfhKPKuULhW3aCTxMMk9akaCd7q92p0S11j63uFgtm2XYBbi1TpcQ78GwQX1hkShQMfJ6nFSwEmbJh6/LR6M2UQedKOMW3wLUG8lhzGjJgbL56WIIVaXNs4+xyMzKgpxM+76/tADHZ1E7e4GlCN/NjC0cbw8hIwVfQpAycwM9vRvnW2WEihvNxWIxImkwZlvpWJrnbu4VwugcLPg4gKjS0dVKtlYa6CzffPINrrnqCRzz1CxcO9eLe65+osOv9coNn6kD7hR+M6zGy5+03cdftGM7ErX5IZtS4xvDXu8nt8TcAKnZFZSJmRWyHbJiqW4UGjMfmQm0bI2UAGUiapGgXkE7QnTgrkXLgct3857BTqMO3ybWo3Ab6TLCnH3E5Y3Bh1FXhRozBR8Jmu7D0JsCCN4VwpI6eq/hKSSMfPmiceBNAhCUcNM0SiWPraKOjpDA47H/TUVnCRkpiHCHNBc2JY2ulVx2BCiNv69jT0yERzOdyyhZhdytfzYGT4oRmUKaQCfk6mD72m1dHhdKk+j3tdNG+3N3wGsTlDltHkrBAhoNLwW9OOJi8lZZWkr7VBrXE7O/mooabVhbqo4C0s3a/rW7u6lkpsDGH4pkye74dBF8zhDAczjVtUPNcuhlAZfddiE9RyZ9khzcBYuvAX7egOkJZ2DVwAT4DDxyg0EcYp0LWfSB11vQ4MmFsuXzZpImpT0MP/ZENWwSvE7wFRZke7JVcei322Z08FMEdAkUPBj9AQiSDpfmR+YL5XA1McWmYa456wHMNtJ+MURXwEovXQwLPg4QtmxZhToj/ZiO6Nc5vcd//vU8zrv2edy9msOvqSNQZ0iEyAmYmdC7UxmQ/174FvLcuWoHzBeeuah3tjw7RKHgrRfAcz6EJAfG33JXXO9VJFMNOaWJ7mParDcR9OdAchjUmjqnDW8bMpLaQ1sj1V8JXhbhhx4LfnwHCTq6yqw1tDzJdqOBvg8/z+GzH6JLRkMHjYFOs2Z3GsuRf/pxqnOl0i0w+9lH4Eo1QDby6gBQv4e285YjKK1usxhxUm+6El1b7sP6XRV46IanoQ/RCWuFOWLq1FF4HZ30RO01//rwA3VmjmJbLp4QX+lsb9I4ZE4oRraZBJc7/ZHPJ12gzE5VO43GXpr1Gfya+1ZZkg0/rvijG7Ya4LSJtoJR86rw0DIUqG/MVFTKZKA2OmsUlhREsp0DUygg3iUL2L4u0pat6Bv8eg6qFlUGjhp7mXp7Ra0LM7bT5zAk0wSb1lqrZDvSMqiDyifR/uDTUUZuefYgNOgT4BJMWD3EjiAH9OELYZU/UO+vdQ9Rl+7C9hvfnXDGGZF5LysWYygiwtO2jhUt0XMA/WaEoBODnT1xyvH/UP+vXEDk8PQ5eZJjD0a02GwoQV+19JIELyu9dDEs+DhA+G7ex+pVgiVoa3eddffSyt1X/wdTbnodb+sHYnHyQAR5PVL9NTipahUSgg2o1yfg/e9aHlPerg6YiQ+oAlSlK2fqF/e3+viBIlmkV3kGwGyNz4vBOfgwdamcMJUMisLGhm2QdjMXU65rFC+LtrD43XBo2Y/l6yqgt9KBkcuOna6vrSrAenPk5zXHXAYxFJ1hETVzq3J9tTqUzusmC3VbfRKKbVmqD0kYk12PycMjFurPXzAWOiWDE5Jx6zc0/jvXRQfTLcmdn+lj09FVtM5PGZiMVT+qS0+wLw45tn0iwn2BAitlJ+ymrTDptBHyE89svD9FyxJUaN4UbbGqiTxI5jl8siba9K2r4CVtoq2VMlBmbWBb2GDso+VfwieQq+lNR1yJuT7tJIsQXrzySlXLooSs82dRaWjXts2wcV64bFSGEGUBhwyk7M/lnyyG7JdULdE7F40Gr9MCHykS0Jj1VFKRDSY0pORj8kl0gdPgt8Np1+PvnlSmS7b+CBO/BKJI2TGLP75ulYTeFBgKDVU4td9F6rFCmRf13Gd3d+hzXB5QusKUv1nEGF9kFMCvX74BC+eDKPOYeF7Ljsl9DBmNpZeerPTSpbDg4wBhhzb7IzVAVw7tZeY3P+P6q/6D4578FV+mHIJttjz1sqi/cyfOr1mFP/59Kl57534c10An8PnJg/DwTU93eDsPHXY4+vroanR1oOWR58pU2iSt5LIx4dC432fcRZdClBJVS/atn7yn3lYa9EL05ah6D85DB9gevCawawWv0wmT34v0gHZyd/dUZ2yIvjqceE/szo5ff3oSAZ5DSkiEWZJQYNThuy8jB9BNy35DUKar2RJN8FqljRNXdB+FplxISZHgY3QqGSaFMRr1OLcfBS9bKvxYvLEYI6poyq3TYMDX30W8LTpCjwQ6mVjddLLL1YSaO/37R8klTI9z/6FmawTeBY6T4Qv2xNgzI23oKUbSNlSI7dOqlBqonGfU2rR3GGmCblfDSbRfJjgoI2MRqc3WK1Pp5OfNJKR2SD3QsH09dkq0LyWaSpGaYMcAPT1uh5NKRMtn04C9OhvtU07FnA7A3DUFWFdKAeapfRKQlZqAgNbpIga1uUFFRQjtXApeG6zIOUbh5ilHgzdUotpLJYuKdDs+t9vUz9ihfw4mIwVLyYivhfnyO+9unPey7MefMMAXFp62TzvSFCVbskgohKinLKG/PNKV5tVKcKVyCnrktTzV+B+Tb8Zv2qA5VnrpWljwcYBQoY1kT5XbJzZ9+t6XcOE1z+KW+V78nHoIaozJMIh+TKhZj+u5Lfj11Rvx9Fv3N4opn3v7AQxp2KZaIf8qpKNwV8uBQ1uMstCPfbupWB2uFovNrz4DnvMgJCVh1K33xP0eivDR5ad6f04tBTElkgBZ0TKYdeBdJDTM1kW7RcZi/YK/wMsy0rWruCKRDmYuX8sW0KtqyIdjuEvAEfV0tflbVWTI2caVZIDGCW5UmcuxYeMKVJnJEjvRlIMKLiOS+ZBl3Dml+Un/sXNHw6BcyUoy7vxxA+4+4Uxw2sCNGQ2d860YO56cZK1eF355fSrM+h2QZQ7uyWRBvb/Qd9hw+EMUMCiU+KJ1GllpdBIul4UW7fibUmHXOjzKKNtU7HBgY1HXZj/U7ZCpvJGTR/uwRabgw6OJRks0V9N+iYPww89/aBJT4MjBtH35BtqXtmp25d4SEm7XKfOMlJZxF12k3PHzJnX/Mdl1eOHicfjtu5/g1rQhxkQKPj59/N8QfB4I2udjBwVG2YlulHgoA2gVZDydkozNvBU850ZG8keQRA4OLZBpL8r4ASGFLk7EqhJMSqILj52WInUSbVNm3vIAtt34Gb6/P3bm4pFPbkKtqRpek1aycka+3yzNkbWps2kslPlYu9BbLb0kwotvpt4e19/DaBkWfBwgVAl0Es0UWm6zVYSM91zzBI6/8VW8LudjgWMwAoIRjkAtTqxchRfGG/HZW3fhnqdi/8BO6WmGUfSjzJyOxx/r+JX1LRc+gQR/EoJCAK/NjJ1FGRigg3u1Z4AqHOwIZSE6iGUYSkgTgxQ166FgraMDaJaOSimtsW0zHbiTJErR7+JNkCGjVjMoisUGM50kBhvycVJvEu0tTAC2rqMrrvIaen+9zgmZk/DV32+j94mTSfdhSsLoogok2bUAguMw53/NR8MrbZSXDaKD564qP3bU8HB4KAhdmUw1944y/Mhj4DNQNiBpO22zN9gHY087A3uC1z57EM9/eHGXDplTKOhFXRRhBo0lvwrl29q2MtrTZHc+mfctGqx6cJKMeycMhd0TRFDH47k5nTd2a8qaFfOViFNdH6y5f5o5uvr2CG7M37EIDXra9y4fcyF+dVI5QQ8Rj512qrre20qB8uYQBcrmAP3fY6NDvsvfC6/+tBJVNQH1ne4c20Pdn1b9rVxgACbZgBseuBEv3Xs3hFo6URt0pKPiOSdcHj/+deQE7Kyn4MioCyIxlIPrs5IQkpKh5wshiRYkN5kP016OufSyxnkv0g4gy5Ol/kambYr8Bn566j4MMRwJoz0HmbXNxwoo4vLFAmligkathBiIuKDkCvS7L0bbTtA5nAN/WCn46+Xp/PBGBsGCjwMA5YdWY6SD0Zjc5v3qc36ejRuv+g+O/r/v8YVjBDbZe6kntL6uApxbvRK/3nscXn/3fpxy9smtvs/191yNY2vJ1OgPx2A899ArHdpe5eqmX5AEmxtjdItUl5cjOdzlYj0EHaUkdWijz8Pnf7yDkKL3cFD5wuimA1GGJtJtjfJaeoyV96oK/gZeQLkSfLTgbLp9w1/YaqJsx9FH3IxjTr8XA70hhDgOX/z2oHp7TUBLS/N0NbbDX4Fhx57e6PdxwrYK5AUjhmG7CmIL7h44ewwsCXq1Fff+X7eifw25upabk/D3Xx0XByu4bBT05ZnIA2OXb8+4liqtwvlpn+OQ3IV48eOWh5K1l10Cmc4p9vwTrr4h6r7eg8aquh+FjaujO5J259ft9N2kOH04rP8o5NVR9m8L1zUzdcJs30imeopWIa8PfeaGsMGY3oX3l36pricEUzEyYwi2hih7k26sgtVE+/e4iRRklco8Vs6ZhiTZhZDAIaCImBWdU/5ZmLqcgorMFAOuOpZ+K3odPd8s2VDf0IBgIWV1xJRsyJrbqpt34tUZi3DmqEOxzU3bxXMyRpkHoMIgoKD+YrWdWWdwI0ubGBsPTee9NOzcjCGgY8UGQ5k6HkEhd2dPcDoKjlP45mMFHpt+l6orUzRwZiv91pRgRqG+rhbZHB0v5R4U3LXG0T2Pwq9a8MEMx7oOFnwcAHz9+1vqlEZFnKWMbA/zwr9fwcXXPINr/qjBj6mHoMqYAr0UxNjajbg6uBG///d6PPv2A0hNbz5cqiUeeeJq5HpKVDHqLzWCmk3pCMdk0YTMQnMRfptDzqxh1v1XscB2QZTsGH5L/CWXMMOvuFa1gRZ4JxKKazRnU8p8BLVOl+zktn8C9Vq6WTQYkKN5SG6CiMRhsYWds+a8pC77+ELoP+xodX2ySNqAOdYahAI+VGti0yyB0uulWnq6WvP7OLROQoa7vPEKuIyn1HEsbjyEvr/SGj+yZW0mCM/huy2d68QImsyw6gLI5CkIqpsQEWp2Jx//+BIEnv7uPrZIt0ZHGf7wc9jkPB5/2y6L6UOSwdN3WlHXest1CUcljAw3fUcDeQo+CpOzUevq2O8gFpXlVDKRedpXld+YzqR141iArQ10AdDD1BeffvAMAlqL7eT+EY3QoDEnIlfz41+6ZKXaZuu0aR1MEoevNyUi4AoBAodXTm3S7SFQRo4TTfh06ouq6ZcSdPzjof/D+dedBZ0sIMSJKN5An4HDbg/PNYTJScHZZhGoC5GPisCHMPdeag2Oh5yRYxvnvRyWOAXGkAlOQz2e+exOzLjtTiQnDYEs099nsGVj7rsvNj5XGeOw1ED77KhATwwbRZOXedGJsqJC/PrJ8zBwQfhlPY698LY2t+Wck6/FRi4bDTyHBM7DSi9dBAs+DgA2NVD9NzXgULMKKxYtw2nXT8Urvl6Y5xiiziRJDNTjuKpVeGa4jC/f/BceeP5fHXovJVA5TlcPQRaxxd4Tj9z5aode55KzbkWGN1Pt0PlqbXTwMdBHqc0a70AkpcTuwW8PKRkZ8GlWzyO8TkhcGmSrHgiI8GoHzEMOp7R7a3hFOsiF9AbkSCTA3Bh0YtKVsctT6/10tTjIG9HfXHTuf2EXJZQaBEz7382o0lxoe3MUfJQbK1WBXJWRrkaz+RQY6rywcxRMFJpark3feNIhSEik7Mf80mzoNXfMxSlttxC3il6HfHuVOgfEG+yNCefG30XVEdKdvzSu2xLqUFVLnRYdRemUGvD8lzjqngdjv59An3FNINrxc3cqrHSFnS2S6+YDx5+nCk89JgGP//QJugp3vScq+Fj62ZvgBFpPmzgBtTy9/8kDjsV3JdQBpYeER8+/IOp1+umpLXenJ1M1GHNaKRvnCVjw607KIIzIMmPswEgQ7efp9mDAD2chdQfJpp6orKhCz949YdXMxjJDtN8+dsrx8Iu0bbyNhNPrbLvgFk+Ey0vzU44wfqu2asfDxdddB9FsV8OqHfMWor+PdDvr3YUYKlJ2t6J+JYLuClX87Vod0V898eND8OidsAcS8eAZT+H40y8A1OnAEn76+lPoysgbp0RORWJScmOAp3gaKeL7WPQQUzHbQtmP3qz00iWw4OMAoFKig1WqRD+Ot9+eidWJ+WrdtLe7COdUrcQPt07CW+/cjzMv6fzV60Mv3ImJNaSDmJnUH5+/S2ngeBmgmftsESLaCcUGOyXc5WIa3ultrdLq/Rk6V2PWI6VS+7wgo8+Q5u6ju6OJ/iELAvL9dGW4PmqKRgSlnXatla6gRySNarzdkd4LRzTQ+//umo9K7bvqI3hhCBkRFPz45PsXERqcBVkKqVe69u125OtIw1FqSsWmtWTyFYs7x9HfWVsXQE4tnXS22npi3arIALp4MQsc+tuptFTo7bx3SHtJSG0i5OWAPz6PnrvR1aQJzja9PpZtX4VKzbBqSi/KgGQ7MpCrWayv8ZPwsisIemkfk3kKFhq0co/kb8CP8jZyNQ1ZcPHIs7E1QEFptr4uykpdoW9YdBrIUDMf4Tbb8kCWas+vGNW9c0kkQH1/6rvwaGVAn8kPXQPtR0Z+FL7+lDqpOG2/tXAu1R9kTO/ecIeoVOMw03YvTFdKfxxq5TsgS5wqHB+7+Tl1TlM8NM57qa3AeBuVhS7ffKja5i76G+Adz6E2SIFYmp8Cw9VrF2CFkbIeY0I9kZ3dS812iToqvZTtLEE2SP9SKEY6A++/81XV00gR399/7ZPNtmWYtTd+0UovQ4RCtXTD6Bws+DgAqNJS9hk8/cB2aDMgJlevwexXrsVz7zyA3J4RxX9XcOtVx8Lhr4VHZ8G0xR3rfLl41D/VWQuV5gq8++VT6m3LX3xSnToqylYMvqnjJZcwBSbqrEnTF6n+HgqpNSTk7KGlmNtClLQ0iSBgeIgO4FsEfczuiMVzP0S5XoBeltG751l44ZrLMfV+Go512pCr1eUSG4cyzbQpzSYhw0+it3X1m7A+VAKnNqNnVLUBT1w6URX5hng9Pn295eFn/zh6CBxacMWVUxuxyAv4bMkX6ChZgoQcC52AKg4lIWN3858Xn4Bkpqvq8BTf9NwNWL++++ytw46glVoXUyzeXzRXLWUpItN/Toq4ZPYJUQt6YRJl2LoCebeJtoYABT2BQAOWaa6m6Xwv/DDrO7i1Q/ikjObZoT6J9N1tCllgl11wasHHxmrSwJyZn4C0pIi/SW0xfe5WyQJbiV3ZEICzgtf1QGpDOl544R1IQdq2INeAt/+gYKJOa9tNNQTVjiiXyaAGBxxvhrOhHyTZCKO+EPZ3r29XR1GYC267HZKgBy8GIa33Y1JxXwy1kK3/ptBCHPHPW1BhoEA1RUfi8hfnPA+fzoMknwOPnE/lTwXRQL992eVHLk8arjKegshHb3sOPzsouFGYa0xrVk6+5uyHsFyf3Fh6+fG1+EwPGc1hwcd+DqXqKXMwLG2Y2gK73Uo/qlxdxBq7qxk5bhSO99AVxrLkAbjvuuZXC21x2LgTkOeloGhOJV2hD3SRiVmdZ6BaNuksjlPPVQ+IqXw5HDYK0pJdlE3I1rWzHVWzutbxwDC9QxOd6rDk1+YdPwvWUjvgII+Ibd/9jLOSLsVoZ7Yqojzi2BswzB2CCAHVmotkz969kCnTwbsUblQkmLDZSNs3hDNhUP9e6OGlE0uVplNpiYcm9lQVIrUVkazMmtSOi0THeMsUt22UeW0YeGT0LJfuYOHiucjndqliaOUPqdo2TL1dNAfx40+/wO2KTO/tSlIMtB9UiC23qe8IUoYhoyG6w+m6cePBizJqbUY8+/P7XbNBjUPl+CiDMb/oanQ1HdtjNN5ZSFkpHWQ8dlPzMuqkk89R99VacCjhHHBbKJhZVTFEFSk/fUH0yAKdZuVulOyQApRlCyY4ENQFwYFDaEcGHHma7T7vxYoNlHVwu+izSdArQxt74tKhl6DWTyUbr2cYCn09VK+VZMsK7Li//XOdaN4L6ZkC5YW4vuBEcDojPA3bMfyea9XbuTwtQLNl44vn7sYqM73vBLmXamoYRtScYnWBADI0W3XboGPw9+9/4XsuHSKvU7VsOimIIksWHt2tnJxoT0KPQFaT0guNM2B0HBZ87OdMn/mmaleuE/U48/ir8eZTn6gaD+Vq+fI7o2vAXc2Tb96PUXWkzP/VnKNqTeJlEE8HiC2GclRXlCPFopVc9JErkc4wePzhCIh0VTRaom01+iiYyNK13CrbFEFzJk3zc7CYktBTCxzWbqTOkqZs4CnVPSjgQD95EHS8HrmW4fj+pUfU24/kB0MO2SGDU30XDznyPPQxUpBVpq9BqT0Nf2XTycZhzlavwHL9dBVWrKcDX0uceVh/ZKYY4Q1KSPBQALLKNgJFWu1+d5549xa89FHLI8sHGXaoyy3OVMyZ0f0j55/c4Ua+Yy79R+Rx8sWfKGV6NRiZ4vgE1335fbe8b3oifZ/lmlFXLMrNWvkuUIRPP/kK9z/wLtasWqN2vfSope/nr8r2D6drDV7TGMla8GHRSh0urgF+wavOKLn+sMuxSyv15AixvTR69DkEvXnadxcZ+qmZGyWJt62+F+6bQK21Yf7z1OuQeG2YYdACMUQdTumD8tGQtVNtLbcGrdhSLsGiOZ/me+nxAJVHzDofxPrRuGjSZSjVfgdB9IPPEFAFvwoD7L9gziPtz2iOOP5kNaAe7LEjKWkwZEnEK9nT8fZMmjN1/J2PIqgKs4FQsV8tX6Z60/DIJdHBg8lBvylD0AmBk+CWzZhy1hV46cvFqhDfEvLgkjwB4+so6PrTntvMy6gvn9xYelG6XljppXOw4GM/Z43mapkaSFWj85IgZTt6u0vQty+lV7uTc8fkqD/caqMDU9+Jv7Xz5pMehCFkUi2Uf3/xfuj4OnUSad/rOiaIjcWuIGWCxjWsQZLLj1qtRp1ubF+Hgi5I5ZlefspQ9NPEdrt80S1+Pk8D1mrxQaovFxkm8l/gOR49Kymlf8H5r8Hqp1pzAu9Xp8GeP/kacDKvfgaF5lz8OCBHPcgK5mTMefExpKtnYKUziNoPW+OJYxStD+Aoo230CSa881Pzlug3P38Mnwl/4n3xZzz9fnPh7KrZf8BqIOHs5oZUbG3ndNKOcsfbU+Fw1iPgID1OfUMyrDYbnPXa9OBMJwbVVuK2t1/u8vfuP4y0OcreULh5abP7lU6WikQSCPeR3Kial4Ae1b3x8zs7UVRUhJ5eEnwX2Fp2yowHbvfgQ8uMVWreHoqr6eJNBXDKFDwcYd/a8t+mueeu4MhczRO0oEeqGZceRT4w9XV1eOi+j2HfmQ8PT5kln6cInCxC0htx0fU34t8PXo86C71ORlVPGCU6kadxTmwurELfXMqK8UqdzN0HVQ1O1BnptSRjXyTxLvR+4gPUekaC4yQcJk6H190+87HjTzsNnDUZQzMoeClqWIw/c7djWSAS+Ndouo8+XgoQj+Dz1bksTRl52DjaHtGHoMSrw+Tuu+l5LE0eqN5+Sv1mXHvnFTjjsN4wij41IHn2sehpuhccfg0WGi1q6cXOSi+dhgUf+zkVEv2IU0U6QG0zk4izT6BzDpft5YIrz8Px2tXCX47BePyO5+J6fm5efqPd+oQQpZTrvAORmReZY9IZlHLH3xylbsfUr0VGfQWKtCvcnPT2WWobNH+AbFHzvQjSZ7stEN2i/PuPz8Al8GpXy5CKQRA4AUGJnpvGH4rSks1ISM7AQCcdJCU9Cd/69RuBNF8adCKPIl0O6ixm+LQ5L6ZqG4aPJD1BjSEZn775v1a3dcrIXshLNUKsjuhZNmY0bwn+WXFg5WS1RfsrcT6m/fBG1P3yjx+pJ4rSkAN1QTNqNR1Cd/DtD19iRs+JuGbnDHiVab1KmcNNAtdC31Hq0m/kcZnrXXyTNwFPvftC3O+hiCOVYWyx6HfocQgXXNYsbB5AT531JQJ6HoaghMRVudBpJ30lE/Dxc0twYjbtF2VJVkxf3HnDMV6Knmhr0rRchSYqvw1IGoypPyktyEoxBLj1opZdZ/sYKGhcK1JgVOFNxWtnUFZRyeC8+dBfyKztAcHgR4ALgpc5hFyUfZQTU9XuOYVDj7RBggRBFsCHKMLmORfe+2sLjptwutpuq1TL8hPKcfc33yG1N2U0eWsWbAH6e2oufRmSbIVeqMDy/7SccdudCbrB0FnT1XEG83MoIN5hLsTc+TTtNqz7yND1Ug3JHvhH8wD1iCknAxxddNQEzNgZSMePyXRxcETNOjzzNk3ZPuef52JSLWVIZyf2xaK/yIlY/QyGHY50fzYrvXQRLPjYz6nS7JbTeLM6cbbIQlfjOcntO7F2Bf/33I3o59qlTr79JZSoDqmLh0MtvRVVJ7K0qaOb+M65czZl5uz/YbqRAplhrs3oW79LdbNUDtqjjmqfW6fJR5+xQ6DMQzpHtfatoWiNwLJimrcxxK2INcm8aHPgd3hCThgEG4o/pJNmepBOBC5TOZb+9am6niHaMZjLR5AzwiR7UCHSZ5geysClN1yC5ABlaVYtpVJIazx/8iDUNvjIal0R8dpGoboy0kGiiHu3WSjQU4R5Pr0H/y3+Qu0UCNNXRyegdSG6Yg6Gukc/pASHrwbSVQOo/rbZamlA2eyxgy9X77/67EchSrx6ZmvoW40Hls/Ehz0m46vv2j+q/d7/LcDYZ+fi8Bdnx7xf6YbI4OgEWVbR3JFzTQMFAVk1PiT7qCOm1lKjliISfIko+RlIr/Oo2/jFxogxXGeHygmaLbhem02yxVauamGuGnMhSrWrfGU2UVpey7qefhn0d2329YQkcyjz9cQh+Zl48N9voubvJDWAUv4O0VLdKDbVeWhfyx0R6dY66bQTUJZC2Qber2Wj+AbML2xATU2ZMt9QpW/STswvqMexNz2IkJdeM+jshz9+/ky1ui9zkWngCHlRuz6LGQ//C7mJpE3ZXPoLUGVGujdDDZo/WUmaq9J02l6DLQsnVGY3BkxNUTte9BTEVfutmCmOgl8wooe3DA/dEn0cuOzCibAHnXDq7Xj3w+h9pqecyEovXQQLPvZjlAN3lTbSfUBCP/z67WI1AFAm0N70wBV7bDuU+S/HJ4uqWKvQko1H7ns7ruffcu7juKogGzq+BpJsQu5VXTc/Yf6uuVjHDUapIRUGOYRJJdSdkAEZWT3bDnJ2rFoBvRhS56tYzFS+STIUqD+cGnBY8OM7jY/daKCD4CBPL5iEBPhENxLOPBq7PNSp4agjfwJvSLsq1NXhm2VkjpQjJMJqoAxHbrAANSZtzouRTjK5XsqSVKgSwtZRfBt6pRqRVkO6jwYhEa999Uzj/T9WzVOzHr3debivzzWwBO2oMVXh/rmPqQLm9QvnwWakK8z1EgVufKB9nUHxctv/PsKa5CTctepXVGfRGSwk6TBxDPmvKCeSoloKqCtTjTjf8xGCchDPc73a1QHz0OeL8NmaGnV+SVltAKVVsTOC6ZrZW5VWWmtKmYG+g15aTF1lqYQ1oRxlyZRVcLhT0LeERMI7TZ0fNMdpwYfZbkHZzi0QjJRZ2ZZYg8RQKjYU++GS6Cr+cHPrwehRZ18NI4LwimaUudNh9ufg0Tu/RGZ5PnjwEDkRFdlbAEEbuuZXLMtkiEYzLrzmGiya8RlmP/2wetfdd50Jv+CD7LWqZmNBTkQvpwefz3oDbk0L3cNWAp8nG5tKS+H0kxbD5x+IFZo1+rbh56gCcJtxI+a82bpHkKJ3yq8YrHqcuGu3YLW8A2J1CQYF6SJgva5CPQb+5ChCwKVprarpNxoLScskVfkt+FM3Sp1ldbrFhQFDo4O3I6ZMxJF1dCE0N3kAvvnkm8b7JmcfjgVmExp4npVeOgkLPvZjZsz6AH6dD7wk4OwpV6GIoyulfHdp40C4PcWdj92MozXvj98cA/H60+0PQJT67Jkucmms8+cjJz96+Fdn2OkMIGTJxpJESjX3CdIJo4dmLNUWG1bQFZqDSwJvsKqzV8b981LkaVfKa9aRmLOiZDM2aN0EI+vpxFniX4kJk4/DFnknJFmEgeuLOR/fjUptfDunr8Nfdg8aassxZcCJaLDQgbOHpxiZk4epug+d2YEZj/wLPYJUXivUTkRt8fKZw2CpinS9bM6gE/jH01/AVi3rcXzioTjp2ItxoWGyKmLcZS3EjR9dAd/X76rTgAOhbIgWuso1eeMbENYe3vr0DfycRz4TJ7h/Rq3WKlztit53RZ5s/4N6DnprFZ5ZNA077Gbcta6y1Q6Y/5u2GB+trlLN1xQUScIrv9E+ujvpmtdHtdj8d1Nhp1JmblUIAT6AlZ5iTPX1gr+qCBUJlFEaXkClmCKHQ/UE6QycRIFQUkoyln36LjheUPeFXfYG5Jjz8frsiHfLiYMjrqax+HuLB/kCZSyUOSzC4vFIcaWqBZsGUz0Gngo8+vB1CGkZVFETb3KJaVjw+vXoMc+OfrVHYsV99yAxKQmeHCWzwzWajfWX3VjRUI56kX6/GdYyQDbg7m9/bJx9FOL7QdTEyxMvuwJOPzmqDtzSuoD4738/BXtSf9X3Zk3SCtVnR8mQ9a3qDb1oQL2xBv9675/YbNmJ8hC9fro2SC8WNhNltYp8yahFAk6p3YC7n4w9lO62+y9Cir9G1Ux9Myfir3PRGbfA5k/BHxbKevZhXS8dhgUf+zFLixaqyxR/CjIzc7HVQur3vFBkdPSe5J77LkSmt0LttvlhV/u3Qen9zzJTRmIeb8Lsv7/rsm0qEY2QHAYsSqC2zXQ9aSmydfXte75mdZ2ho8/W7ylF3pBRyA+7R2qi099+eVqd3ZIVBPKlUZD+n73/gK6iXN//4c/s3tN7DyX03rugiIhdsPfeG1bsHXvDjl0UC4KiiAgC0nvvCSSk92T3NvOumWdD5KAezzl+/+t33sO1VhYh2Xtn9uyZ57nLdV+XIlNii8lkp2VQ7hULWGGxlbqoyFoTdK00GfR89vn1tC86gUqbmBpI9tTT/4yLCXpEoGRpsJNsFoFNuTX1L7W1uuSlYou0EWo3xvXE3dzMnOrFmqpsvjeXGy54TPvdrRc/xQlBIei22bGXdnqh31Dl70jnQhEIOj0tuJv/uQ/OX0V1TSUfOnoQ1EtcsmU9WaZd+KziPda2ivNwCFeddQ+hqEFra5Tk2RgX/YKsFjfrk1O49pu5R7323G9nMPmNhyj3zmVUz030HHqA/FHNnNBpNUsqft/oLDl2PdTFlGcP4b0lX+K2CTO5zIYwpcatbIwXDsMbzQk88sz5NNobSGmJEu+JEtVLvLb813/7vLS0NAl9DfU+LmxHuEEEyZFgE1E9nNJpLA0escEmIjPqrBv/9PXuXbiPrlZBSN3fVIhJtmltloqkUu596QzGjj+BXdu3440pm0qtFVpF5NSERHJK1Wk5Ndg1kiyfyLK3b+T+e6+lyd6IIRZ82CUP+w1BaiNiK4k3i8rSjpoILRbRnpQthcTr3Ex58wlOuv41PvaKlmSKfRO71x9N8FWx6cev6IJQSK1wb+Dsqa8SdYmKR6i8nA6xEf2lth3a9bzXGqtCGQV/7PeQEqtMqtUtdUrvhXcFz+P3oJL1R7lFC21FQhFvPP3W4d/lRZIOe70cExz793GkJN4x/FehKiqyteSog7eee49ai9gguxSls/LeG7GF/j5dBL/RTqc7H/tTuXP1hh0b/YKPlWS2u9px51VP8uw79/3T114x7SWO09dpPiwv5TTQYcsMjht22n98zKoJVYOUqImLrTWK4CPHsF+bJkg3/rWNtNHr1RodKUZxbluiYkEtVNUjQ4mUxEinW1o2QILKKynQsspK/x7G3C4mdk699Ap+eehJch2dkQLDqEVktkNDPn5SNU6UHaydu56D7UWLw+AVLZZ6pZpsckkJpzHxqmHMmHlAC+xefuQ9Hpt2zz899sdGt+OcCj8Rg0S9Lo3nPn2QPXZR9RjjOFI99tlrP6R+2tlUSMW4Yi2XktwRDD31bDbP+x6DHOXX2V8w/tJr+Ttw10+LKc7ugjMsc375j/gSdciqqIh6HeUeTaA82JBFu9RS6hItdNPXM3X9O7zTvTdmYytXfPk4jeZ46syp1BpTaXV2gU6/8SuJoT4nBe/+sEY8/Uc10KRYMFkXPXKc+We1s9MD0puj1MeXsbWlbYqi2J6tVfhufmAi0x7+haIKG6uL9JQo//6Y+NZ1qqOtQPc+g1g3bx2YIBBpwhKxU1MfR0AWFa1BMSn+P8JTs9ZhaGmgXeYB8KiVjwK664Mo7Sp48vYrDz9u7oc/EbXJ6GVwyjaGZ5+MPSRaTXb9j0SVRALyAPJLJrB0xj0MHTuWHT/LakxCRNdKq7GCypAO7FFsBnFthwOZNHUJo+yV0VmTKGxx8FlLE5WuXuwknzPkBWTqKpE/fQ76fn7Usfvn7Cc5bhARfyOm8SKgyOk7gKqFc9F7mugRLGSHo0RrH6rjXd7kIEqrrKmfzn/uQW0E97dQA/Yki49yTIQjEhMHHL2OffzLdgw6ifNGimvnoeduYNVDX1NhTeeX/W4OOdR0sWTzpX4PrZIOFz5mTJvM+VOm/+XP+BgEjgUf/8VokER1IUWysmNnFaSkkRaoo2f9OgZaZ4BIsP82+J5fxfJudzD0/D+2On/0tbvZd/UzrEjsynxXAWO+mce4M07609dtV7kcnNAa7ECtzQ0xotp/ipnzphEM5aHEmdiua0dEsWCXvHSQKkiz/LUxW084quV+8TG+R4NRBB8FrlZtQd8bY/7vsKkZqoHe3uHa/w9EtjEwXyzwOfm5VOndtITq0JuS8SIy21M6ncjC+nfYajfQvvUX/NIkjEqIfWFRnak3q8GHyjHJIr9vTzI+XKsJIH3s7M5Pt35AR28NOTqZK+4693fHqod26UTa1pVUpIoS8f60VBSvTK4vh1uvO1oU7o0rPmH5gxORbCWEomlUZplwxidq7rbxrY3sPlDCeP5zPDX9BRbmiymWibsWUmRdQWW6WWMBR2Q9px4vPGQWzJ/F2uIVtFp1+F19aUcpUaPEgBHvUyb9+VhrnNxMaqSalGA9iYEm5qacQr0ulQ6GdXyxfA/nxzaYQ0hWJfGbVaGxtjbG+9M/o9UqzmtmQwC5rorixJ7olChxYTdNpng27q3juvh4Lp7cn5p3d7C6yEJZqov7Hn6dJx8+0kH3r6C0ODY2K5lITsvAFnOsbVUaSdPn88kGlQgseCWD4v+Y76Fa3r+/uY4iqYGcpDKohDJfGmOviKNrnyPvR4NOvYZbsIUlTsy6FKPOhISbCN+RYJyhKZTWhx4lpHSl/dZBHBi+iSZJVIi8Oh+pQSv7g6LyoWpoGM3lhIPZfOAxMMJXg8GeQW5DO6rjD51ziWnRcTyhe49C+3pt7Fb13zmEOVNupY/jVO37Haxk/ClC/fj8q6/lmRVL0PvdGIuDpNhSNXXkjr58rpvyFiU3ztTExpQy0RL9Le67710ezqpgn8GqycHXVwlOxyFs2lfNAwtKtaqQ02JiwsD2Wut6eKCGz63prIvvyFN3vcC9z9zOVafdy6w5K1lkt3K6x0uhf+u//Dkfw7G2y38tVKJVnUlk74X2HMpiAlTtfLV0Qmh/BCNZuANd/4avLpr2hs1UzODdk1lz1597bVx+Wm+N9NpqdPHRPHEsf9pysYnRtl2Rjprceq21hg++evY/PkfrKrYQNbXXnDuNQYlASBA6++t2k5vZ5uvwp8cnK6gGqxa7yAR9TlFWHnTCqVrPsgGJ7z55kANmg5aE9fF1ozXUQF3SkVLdhrhk9rZuoCam2aEu3aMm3EJ/jyAkeByCi5AdOUiFvY66+ipSh3YSvA9bEnMfvYthgVoyVOl1RaHGksKvSd2YkdCD8W9u4OTrX+HmK57QKmC/RVZAVDFUbIsXkwajrGLE8B+hkjv7SULP4WAwi7cavmbD1uUErGJjqA/856RTlST6RfowojqJgXVVnLR/Pxadh9oE8TeavC5tMueMb1/jIlMhr3S+kA/yz2dm4gXsorNGhuwau75dSgvtQ3sY5FnOuIYfOKfsS47b+gM5izdhWB1i1sAJzDr1Rt6d9ACpUdEC65BazsytR1cM8gvzxXtUuRBNVdRX1dCw0cXBZJGfxbGZpVbRYuvXvJfBraKCtNkhsvLs7GwmjXVgDcr4zTrC0a488vgb//L5aawVVS9FM0JrExhr0jXRL70frW5xDOpvTz6nrXrxW6jaI+c/9TOhoEwBtdiSmrEbvUQUPTtXHz0KrDeIzbpQn6cFHuh2sCdvLVnmr7Sf7/X3I9n0qFrPQ1aSyF+WxXHH67DJYqqkX9MwGj0ph8dteyaLjb20yYQ3JDgxrkAH5FAaOsKcWb+J70MDaFVsmPW1LLz3jiNIpkWNPZH0Rtwtexn2yJEVPlP6Ib+XGsYbetHF047ruwlyfUNE6H2kho7U37n/+qfZnJRNptRIkimmI1N9ZOXz2Z93a0rGKi/o3kWiBazi6bfuo72nDFnSs9wTs0RIziA3mP6bqZeyY4Jj/waOcT7+S7F42Tf4jV4kReKEnmewLyapXqj4cVrEZr4i/kKcT6/4G75WsrzwSc3ZVDOJss2k/q7RFG/9fYnh408+gRNbxQ28MqETD9wgMpffw4q3pmHU16AoRhLOu5Gc2AjhLzWCz/Kf4KDXSDRebGoZLQ1UhmNKp9JuBp30x9Wb30LVe0pX4pAMJuSwn1E336X9vKDzAHJipNNfy8XG1i6QjivqoNizgQtvO1Ikrf2AwZR6dlARIxOmx9xqRzuHaf/Wqrb1cpBM/0Ei+hAz5r3KgIlXEPSKBdVUZ+bpt+9j5cuX82BGA6fVb6Jbyz4s0YDWilHbXN+m9OKp+jQG3fI+l1z1NFOue4pulth0h6JQqc9mYLAXd176/O++1wM7tuO0CG7KLLueJksDDyx7AtkkNsJg9I/HbT987zMemfwFD941gyn3T+fxp95kwzrhHvpbPLi5lCqbieRAhHvz7RRahJy+1xZTGW3N5KEF01gZOy8OpZXC8F4twPAERMvj7OhMtq2cwM4lZ3LX8h1U0Zf5huOZvXcoKyt74jVn8vPVg47wLckLiGBBjjewu+XoIEpVmlXp2uonumHR17zy4kJ0WKmNExuOfaeHSmsaRjnMmA4JDO6Tq1VA1CDwkZvFJNHQIUPIaRCBzZ4sM4nlHXj22bf5V+BrPeRoK8jjFklUrepMzfg8OURkcT33MXhIyjy62vX01Df58Okt7I2Jj45w7CFq0pHvEvyF4oYjx8OXv3MjcoxsqrZvd3sWE3fP2ej2NGKQQrijyXh11yATIt18DzLNyHIm7ZZIWA6JjQUTiIYKiSriXPV0qAGHTDSYTq1eBLM6XSEGIhgd27nnpWs4M1zBtxFRJYyP286UmD3D8gefwaGaYkbD7EnZdhRx/oLb70A2qH4vEQx7dcy8YTZjRohR2bpYGyrhN7yPOTO/Za4ll+56QQy3mmPXsO/Ia6CsqobdxnvZa7yFRyu/5Z6P23g7QyXRvt7mas+DsbWsQEpglTr1IulwSH6+nzb5L32+x9CGY8HHfymWlSzS/k0IJvHdxyu1mXTV5v5EVzk6KUg4msKQG2//2/6eylL33TyfUvcozach2bae3C/O5pepj//u4599Z4q2OarOuj8Z0yku/v0ScWGZuMndwY4U9e1Hp9/Iraucjf8E1TrbYTO5zNBBdkoxpVOdKvb1x6z430JR+SF6wevw+6qIT28T7GpvFBv7Vln8vre3B2E5SLGukvjEeKrqmxn15PPc9eHXnHbeuQSNOnYGRTCRrogKyMTzXsYQciITxuxbTYpXZIo73SJ7bJBFYJMabvO5ufzWS3j53SnMfeMWFtw4kPObtzCiYZtG9tXetzWVJUnd+TSuB1+vS0cfjIqUNBwlEiNL/h5qPnz18LVjyOmrSfaX2Q4SOeQRFAr/8XM32Un2JJPWmk5mfQEJpR1Z8W4Tr167gOdv/IEnbpvF5Ie+oVrOIKk1yikli/HMXkSWeQd+vQ5FJRyoFT1/KnPSJ2jfn131NftGj2DF2InMPuUGesWdp2XXFn2AemM6eilCUWANw2oPYFpXj6SKTcQZmXNBVzKSjySOZrvFeaxxpOF3R9hReiRpV1WaTYk52S3eIpHamkZ5kkHTHXF5Q6xHfO6Dm3ZrSpiq9krHGCFxz28Gp9rJMa2aLCMSOswlBbz1+tEeQH+ESKy6JOtFxcWsFxW0VlOQ+XvajrlfjER6CN989S2P3/4Vjv0d2GDQ4deB2agjI0FUidrHuD7FMS5Hc2s1JU/cRmbxmTRL4j7bVb2AzeZGnK4kkg3i8RXBfqSSyP7AIPRSI375CySpmWi0PfmKODadEkHfUkAgHHO3NdZhtIjrfIUltsXYCsmkHl3iGh766RkefGkyoUgnTXtkmH4La+ITufvKh+miEyTTg571nPbo0WJyKalpKPFtfi+/haNHGoqi8j5SmTd1ilZFeWfxfppNcfRHkKhlU8zjJdx2LS/afIDXW77CbDiIUV/HGUkfM2XHZOZPe037/SOv3kX3FnG+l0kiGJrU/xLNo2mhPTb1cqz18n8bfDz11FP0798fp9NJamoqp59+Ort3iyz7t+2AG264gaSkJBwOB2eddRY1NX9OjDqGfx2VYZFRJEedlDeLNCfHV0U3vchca/1FmrDO3wnV6C3v+Tks0V1DRE7UKhajfC+w9/azf1cu+ZR2Tk2qWM0Opz71+6JQGVZx/RRHhczxjSfdq1nMu00tvPzFH7PR/xmqqw/SpGQgx8Y3e8RF2WPPJKpIZOrqWPON0B34Z5CiEZLMIlBpRvA9DkEjnaoVg6gYR+3t7USpZzu2vHYaqXHiZ7fSkPUB33s/Ym9ZDTgSKA4LPksqLlb+9BordtfibhILrtWzELtHfK7VeI/I5lTex+9BdSt+8s17+eidu1n18mXcnVDJqfWb6NparPn7BPVWlEZxfehLvSzb15Pzr3lOK0X/49RMkbLz8LVz2+VTOSEkSKmtZrE5mWNia/+IBx99E3vIofXLfWp5XxfWvleJtzr0WCIW4v3xFNTEcd6vHq6f10LW1t4khcRGvTO5UIuNZFnHrIKTNaG1roEtPDX+yOrRiUNPwxdzeC3OFZtzR+sKPLubtMBDjjcS6JfMY0tj/jC/QVqreA9lljxNYO71xXuPfoxObPzh1g7asR9IEQRYe6ObRnMClqifs45va1l1DQmS6mZX3mEfkBuHDkcfVWh26KmJQ1MEDWxN4+vP2rQi/gxKWFTTFJ1Ymk1GMVodNERp9bQp6g7qnnK4xaLKo1f8bCPBl0iTTmGDRbzG+T2SsDhFZFRoFsHAnnA8K+a9hP+ZOZjcZ9IgeTQ5fikcosVfyahzz9OmonItoqrpL2igdOCjePQjxOtYf2S/YyESPnJkMX3i17lp9mah+MXG7LS20DlVHP9Ms2oVEEEyORkV2I/etp+VLT9x1seXMvLOy2iNjd2eb1jISCUDvSWeiK8B55l/LJzW+6RTNL8Xvd/Dx6+LAEHFiCtuI+QR71NXLjFl8jS2xbVHUmSGSyIIcxvF9aMPe/j64494/bFH+OGDt+nkEmJi1d5CrQrrNO9ibO1DHLxjglYRHBantl+jlDhyuOfqJxnYbwwZ/vTDUy/HWi//x8HHkiVLtMBi1apVLFiwgHA4zNixY/H+ZuO57bbb+O677/jyyy+1x1dWVnLmmW0W1Mfw96A+RjZNViyUWMQCVRSoI84qlCn3JB3pWPl3YtRDT7N73Me0+HsgSVE6uBYgPz7qqA1dzRDHNorjWZTYheemHCl7vPj1VzEZKlEUA+azrtB+lp/XicKA2Gg3+n/fEO2vYOaCN4jqO2lWtMaQzM1jJlFJBrsUwftQVqpzJv8caobksInjaTQdGXzkOwVpNRDMwCQb6epvx17vZs6+7momfHwOLS5htKezl3DNp5/gyMymPmaTnoqejDX7efnXYvKUdBT0GEMlSH6xeFaZGrVAPnFQOy2bM9iS+f7xf27Idd3dV/HKu1P4/vWb+eHa3pzhXkNijJ8gJ5mJtOpYkdCZT1zdGf7MEi676mktQyzftw/XP1w7z1z7AQO8RTTa6g6P26rH9I+IqxXn1Gv2cOerp3DL6ydy0dN9kXocpCptL5UJ5WzPhZ3ZRuqdOi0w0ROhk22x9ryGJBEklyp5lBoKsCseTlgZ4PWHljBt2pFOsQfqBNHUkNjILv8AJEnhLv0XmBwGxibt1z7vn7I7c9s/eMD0yxBqnQ26VHLtFayqOTqQSo4ZtHl0atNApjRNVHxam0VFZETTHk47RxAhVVx41Tit7eUxOHj1ceED0rewJ9mNgk+wsUOz9joGxUjZr1YWzRfVyj+DdMjRVqdn5tcvozeLCs5+awZKrM1RIEUZdurV3P/Q23z95HZNHl2KCYbNSlcDP3DFGXlo4gBkW8wUEXFMpWrVcklHopEuWgCxQxLBrd7vJWqPo0//Aax56lmc+gaikkRz+xICcSUEev5KQzgXoxTC2OCmLG82iYoZvaIjJEXoqcQTcIvqnNPq5dkzJoAUolVJJeoVY7AjAgESIqqDbJQ98nomfns2MxwiYLlAt5geSYLPMSdYginj93lJKk6YMIGoU3C2Kjcf2dpriIrKYXIwnXmJQkRwgHszBXrx82CL+Ewl2c+BuV/g37aWcyOzMepC1AbsfFqWydTw7bQEumhaNznOX8n+/BSOU3bRL2aiucSart0zuUpcrPWij7Ve/j4/qv8F/EvBx48//sill15K165d6dmzJx988AFlZWWsXy8W2ZaWFqZPn84LL7zA6NGj6du3L++//z4rVqzQApZj+PtQHxsNTFVS2B8TpzrZUoZOChCRkxhy2193jvx30HXIMCyPLGCz+3SNDW8376Hvxlu0Ed/f4onnbyDPV0FEZ2Rei1G7aQ8ht1gsxt5gB8199hB6WcVmVmyp5GDZH5tm/Rk2V1QSconsMK25mQRHPFWRONbJIqPKlf+aDLYtEMToFMFHNPHItsPg49XZDwUlEkcHd1eafVU02HRM/PpSKnR7NCVHc0hsGFW2reQMPxGPQWwmKvXO6B1JcZ2X/CQPQZvY8EOUaqJxPqNbE5Ebcu41h/U+rNWw9KG7aG74a9NA6gRMbZctWI1faP9X4k2EusWTEteEUQ7hN9j4Jak7D9wxjYPvvvi71860yz/BaJaQJQljJMz0Vx464m9MefBtrbKhBhS67LYKpypIdf31l/D4I9fgbtfKrMGJzB7swNVlsxaYdLLMxaprxRNNJOoS1/JC/Qnav2eULMBZ2x5H0ImyNVfjkBw+573u0VovBn2Uj9J6aTyDduYNvNS0kHevuoYxlaKi8XXBcKZOF+qxKiacej7pURHYdUivoN4dxh888vM0hsVn1aJTqEjbS22MMxJulTUC9RWXiAmdQ+g9sC89WkU7cZehbVojPxAzmktKozFrr3ZuTLKJjd/5NSfcv2YqJ7F3u9DAUCJBFkba2m7djC08c9N3ZNS0xyAbtdeviatCGWOhySdrwce9Q4QORsAmqjchv5lUIlo9ajdW9PpdlAzZTKNOBJO6gBdzsuBKJFvFet6YYEQKJSBHdPhSdlDpFByTDraVdDvvKZalfEZyrPVyms5NZcyzyGoMUJSRgcUqzrc31mrMkuP45dIfGZ88CXvERVgf4o3sMkr1Zky6IHbjYmoai3kxoYjr3lx0hLLoPyIuX7QP9S31PHvTdUy95jKmXn4BtW7x+SdYsrQ1J9tfzvGti7HqQkRkiRZ3m0KwrIqlWSV6J4oK5q916togYQw1MNj2EJ83XEY4moxB18AA62e8nfglRUoZVdY0Hpo8jSEpfTVtn0U2ETwX+v+cXH8MfyPnQw02VCQmirKzGoSo1ZDjjxcKjyo6depEbm4uK1e2+Ub8FsFgkNbW1iO+juHPsWL1j1pbQkVgRxohvVlrbwy1ihuvzvf3t1x+D+rf6Pn8h/ya+RDBcA56nZvB5o+pmTxWy6RVqISxsUa3xkcpduTy4OQ2SeUsq2gRFYeP5CHcNukpHKE4QoYAr/4ghLD+VZSHTG18j4DoDVdErayTxd9KMB9pl/1HaO83aQqT0WArI265/4jfFXYdis0ggqm01l7aNMvqdmXUGg6oqSs9arvwbr04D3rXZp5bvA1vrIyeLHtRlASuCRwg7DITcIzWfr7KFSU55nq78uAy7d/GaDU6WhkSN4sR0lvYXhzKqnuu1yaF/gyqWNsOaykBwz7iPCGN9yFn2TH2NZOebGV4g1gsf0zsTL6843evHXUC5rkznsFjF0HTen816zcuPeyImlIvtElarC3ceefRU1AzZn3I3Lwh2vdjy7dw22W3aIFJh9gGtyvUH4NRVPF20Y2BnhXk+HKpSCnW2jdq+0PlkKickZVLVtC/xxBag2LDy89fz0b/GO37PuZFWrtg2ilj6NnYSEgv8WHWCGZ919buy42RTiNxJggrvLNg2xGW8vEB8bqN+giGnhA26CAsI3kijGouYeBw0R77LTrqRACzw5nPj9/M074/p1OuRvCtjbfTbnQGNekiALFErMybvl9rlfwRdHIs+DDoMcVIo+FgE75YNVBFRnP6YU+WFmsz9v61PDr1At7fJ66HpASTplXx2axXCMXE6Y6rG08nxOe6y7Ab023jGH7qXQQksd7qAwFOOP9C5j7XjzzXWu1ntaZsmnfcRmCdaPc09NxJSDGTaKhg7SOP8Y21DkNsGkeRQnT2iVaYQRfRKmQDc8U1U6kTf8Oqz9T0Vaae/AA/X/gTg2xjMcs29vtFy9Wh/5Yv7Ns0mwa1vfHkejcvPHS0I7OKSydPJmqyai0VXe1BDM11GLwtlIbVSqqMyZZMT289Y1qWk5og2lA10UR07XsRMYn7K5iUw9mpXm082BMsolidjFOvj5Z6HhyVx92OExgUeIpi93FaKybevJsfLFO40/A5q10ZDOx6Kq5gPD86jrVe/j8NPmRZ5tZbb2Xo0KF06yZEdaqrqzGZTMT/A0M5LS1N+90f8Uji4uIOf+XkHKlueAxH4+etQpbYFUygPiw4DUXeMhJiZfPdcX3+Pz1tI6+5gaZrvqfCIyYU0hyrSf3gFH55SYzLTnn+DkbEpNd/iu+oObMufe8dzIZyjbzKhEuOklvvEBKZ3k75yFbHX0W1Lu4w36OT3aONT1YqusPBh/q3/2ha5xAaq8rJQQTWXn/1Ucx7r7uJqDXW0lD9LNjFvuQqTaqc8gu4OrKRnsEQXYJBJF2EattuWnViAwj4BL/iRJzU2tMIm4uw4cCv0xGvCoiowZIs/m00VZBkegSLUXA0TIYqBlk+RX5sEIsf/WMRt/c3f0hEH9aMuDJaY/efolBi7IBV3stpk8aQ6a/RrNsPtVx2x7WZiR2C2grz20QVwBCy8cCqp2hqrGPqs99gjGXeGV2PVrRtbm3kbV0hPoOOohYPL5xxivbzhQ8+RrZ5u1YZ2p0puLAtxBFUTFwWsnDLzVfw5GNXMfzyFM3ATYXKGVnzuYcbnviQlXVCkj0/7iD744cQls2km/ay8eEHiXclMrW9i1xPgEaznueUNg+YHLc4BzV2MYo5d5/g16hTOY6yQuyyqBI0SjLbPSJw1TWHSA02cOeDR16jh3DXU9dppn9qlv3DXBFQnTlgHOnNooUzu7iexx6+lqqU/dp5UrkxHz2/Rgvcfg+6qNgoZRPEB8UxBCMeUARXwa6AM6TTPFYasvZw34tnctkV5/Hhwm00N4e0qsc9Q8Ua6q0W6q8WfxR9sDddEMHJNslFUnIO77zwNgF9WLsm0BvYv+58XN0aiGuNuf+W3EN6tyROuH0hgYoEomaZ6iRxHeSatlKjb6E8lgTV6lrp2jxOM75TP883P3mB6zp31157kzmmAWLP1bxqVDjMdt6Z+DxPSJMo9N+MrNgw6qpo6Tib9PQZWKMe6sxJTPem/e60nBoUuzr1IuKIJxKXQjQ5Cym7AzsSe+GLkYsvilTyyAcfkRQnrs0yKZlbnniSiFkEC9mRZpKsom3zmXQyzqyYj5G3ldMHFFCQYqFBb+cE57X8nPUE7oDqVB3lBsO3fOl8nE1vvUSuP5HVVgtuyXCs9fL/VfChcj+2bdvG558frU73r+Dee+/VKiiHvg4ePJLBfAxH42BIbMgpERf7rEKp73TDPm0MNiLHU5tRyLMXnMEzl0ziuVtu5Jd5/7nN9z9Dem4eWc99z9LoFdoxqFyOUU1T2Xn7eVqGftu1J5EcbMRnsPH1xmoyt83XnucLtafncSLr/y1GpogNpsxazrJVP/xLx7Jt51r8ps5g0qOPyNw08nRWzftUG6NsIElrLah28RVfffKnr7NrzUoSzGKjavoHsqmKBXOfAKvIYssCMnuyWjDKJvrrLkTnzWJguEYjN54fIzsandtRJEkjrlU2qoteBJNSSLm5QFuxu4QEga/FKPgI1YYWqstKGWpfglm3m6jiZFHrJMrcIzU1WKtxP6PkabjvGcLiV184qjq2LRYYDdLlkyeL+8oYG5fNyWnghc3NTDA2MZIt2CUfHjmegbf/vtV51CQ2QnPYxEFbOdfOuJr0RlHab3A0cPmVR48u3zFrDrvinFgjMleG92qBgYokn6g4lAV74i0Um9duOjNx3zxOP6vNELFPvz7c/8LZWhVEQcaLjqUtKXy/9wSxX0oy5dklbPOJ6kc3+0Kq9pXQq2c/bg3vJj4UpeQ3HjApre7DpFMV+1tF1WLep/u19oU5Zs1aq+io0Iv3pmsKMtJ9kPU7fuL2Ny7inGmnMeKtUfSbPoCXPrpXC0h7t4pzu9Um2nwqcj1i1LzUKgTBnnjsSqqSyrQAJM4fz8uP/z7nSJJF8FHn8JIaEhm6N9oW2HVT9FQlHeCKJ4bw0AOHNDfhhbViw01ONDFpWCdW/fwWfeLEubX5QGdaQXrCcnGuw6Ii0Vol3r8uFCCv1w6sBX6SGiLaNVsXLqA8Pp1BJ52kbfSpjhsgaKUqXxxfgWUdSSGJLXFi826SPJohIGoyoZGnG/nqne+163qxPQUlEkAyWFj95pFmcomr9ejMabgDou16YYuHlqSd6IpexaKrwWuw85m9E5OvfOKoc3XtlCncPf0T7n77fe6a9haSsz0/O7tTHBTvu70i3meOTgSwlcQIuzYx8TIyboPGGWrw9+KEm2/h1Esv06bzdNEwX73/HtPP7Q1GHXIgymuhjpgeXszK4EW0yMlkSQ2cn/A5b1VXcXy167DXS7tjUy//t8HHjTfeyNy5c/nll180cZ1DSE9PJxQK0fwPUb067aL+7vdgNptxuVxHfB3Dn6MesRg5fS4qrKJCcIJZkKEafJ04sHENukgYfcCHVH2A9R+8pvVDX7xrMrt3iYz7/wojHnuBbcPf1oTJJClMZ9cPhB4eRaSugrF+sVFviC8i0SZaLiWh3x/9vGLSPaT4U5F1MjPWCzLfX8WXv7xP0C42mOQmDzkpWZRViiw3W4riCYjMMNfTZhh1CGrpfvcOYQy2f/8+HA7xWFXz4h+xpWYZOovgY5TojFSkRrij5z0cKMniquT3sSoKAUlinNdLfDRKNHa7uaJ+QmpmF9lDsxHq9WJTPsEyDIssU6OW+9Vj0ddjnXYBTvPemMrkw4TDaeQ+/y3rer1JrXeAVjlyWrYzsv4xTXtlxReizfDWune0nnqyP4UHLn6NSd06a1mo1koA9iV1pKIhSO9zT+cmRbR3vpH78+yU3xfGMsSeZ4xNY+xw7mNX6kptM+0/4uh79pUPXmZ+jhA1m1C2iosmXqZ9f2DDFjpaRQt2g7EzAbuoBKl2Jo9cc/RopQq1ClLfrY5P4kK4dQrmoIOATwRqac41RPqeSUB2kGgsZ/+0qdrPzz/zEi48uBiDrGgeMNd98x0DswdqZfpGXTL5zjLCvgg3PPQJ8X6xyTfFl2gbrzrzUmUX7TFnSy3L+s/jgdoXWWDbpEl6q9dC0OBnkUdUzrqkiUx6vy2Llx8Vm+vwFHGeKhLiWbFHVESeeOIyauIF/0E1d1M1Uf4RkiwmbmrsjSRHY8cVk1NX0du1kSefuEJrXR3Cuwu20RKretw3NJe1L11Fzs/ZhFW1YLVS5tOTfN8tDBwtOCvVSGz4ZSa6GGldH/CT1LGBsNuAbZfgW9WE+uGzi4BGRf8zLsO9uSseh4Fmp0GrAFxbnUKdtQqrbNYmZvbpytFFxCZc4NrPerv4jEpJB68IhB0eO97Y/jD7rltIj1VpN/jUMVmJYQE/w5rS0BlaMLR/Hb1tt1ZV+iqpJ9de+SR/BHWUf1ajSdO82WgQ5yvenEVTfR2Zkrh3pZyB2r8J2Slk25opsFehKHqe1J1BggU+eH4NmMR6WrVrB+0yEzmxQFR6Nlf6Wb23lsFPvcb6vq/yTuhUgooRl3k3z/h3079RPO+Y18v/UfChKIoWeHzzzTcsWrSIgoIjRW5UgqnRaGThwoWHf6aO4qqk1MGDj+6XHsO/h3pDrE9bmaMp7yWFGsm0iqBil6MXuMVGG3ElEbXYtQVV7YfKpbv47uG7mXrVJUx7+CGaG/+axPi/il4nnIjp4V/Y4T5ZjK1ZdtJzxbWMT66lX9MusqU6Eg2l2sYZHHPeH75Oh9go3x79v2ZotqcuQiRBLIJZfpGV1gTEYp1p8FEZFf3zZJPYCH6LK798mydmf8Mjd15HRWkFervIliztjt5gt1jM6GN6Bm6DnYszT+eMrqfRLIcZrAhi4QJnJo16AxPdHpSwOIb4mMbHMk8pu52x6ZdoDedfdDdDWmOZY0Thh73xxFm3atNAxQ2TCCtFh/U+BpxxFqnPLmBp5uO0+LtrlRxVe2Xw9psonzweb1gc1wDytMz15N6jSWlpy6D3mIrIs1Vw//fb6Wrerv3se3kg35PMlvVHu7LGxezI1XHbPs1iPHJZwddsy1zF+FPHHfHYkv17+TRpIBGdRO+GBp69oK2aUfbxO9j0Lbij8bw9qA+FCHKmueqP3XqXbzvIR/UJ+FAwGyQmeUx4SgSPJNXVQMG4kWzxjNX+392xgD2LBCfl/ivv4Iz9wivlp+wuLKisJj2mm9I+XbRgAs2p2kRKSdJ2GrIWYdKLqlNE3U1lBb3jC7yWFiRFp7Wveno6MMorfIIO2A4ye957TH7iZnJ9lVqWv7VM3Jt3nnQZCZ4gsl7izdVtZPvHnr6IOqdon6maKPff+9HvBh919gZcighK9+nbSJIj+x2tT/PKupiyZ6KJdqueI6P6YhRcBC2izdLitmGyWOjc/yRyYlom69ZtJqgTFQKzXiJUY8ZSfx2ZkqjYBOnLmEtPPOLvnH7PTOSDPanIFAHjUN16MvxxWGImc1ukCLrYKLTe4aPUIgisPlWMLyJet2NQz4bXB1KxaztdPf2RJB3NzTs47tVpeIJiwuWhcgN3dXuAZDkZa+6HGONXa+f2x+SenH3ds4fHmn+LR5+eyUFbpkakNlmqY47QSSx6+k6MUoSAYuKkC2/THnvciSczPFVM0pV5+kLXATzz/Fdaa8+oE4R0ObaGTrt4MBanQbsWbv1BJHijTxvP1ppOjA1NZUm0pzYVk2nepwVP6tTL3JduPer4juE/DD7UVssnn3zCjBkzNK0Plcehfvn9YlFTORtXXHEFt99+u1YVUQmol112mRZ4DBo06F/5U8fwJy2FZpO4MTx+sTidLW9Cr/MQlV0Eeg5BHxQL6MBJF3DXhzPJHT9R64nKRrOW+RlaGwjsXM87N17KM9ddyQcvv/S7I5T/CVTSYpfnZ7A48V7Nml2va2GY4T2edyzkXMTmsD3akbSuPf/wNSZ1O09b9Gus1ZoV/F+Fah51iGzaPiZBXx0W5yrT0ERNpvibNlMZ7hhpWsXb7zxJj6Vr6Ll5HY6yg2Q0ytriGAg2sXpvNTPfm3aY5PnsJ7ez19KMpA+SEBUbjnzAzdNfLObMwq/p4RWP+yYwlAWGIs5pbQs+TAbRU29p2cO2eMENaO8Wn9mJ2WIs/bqWFtKtW7QAbU1gEnv0Ypoi/h9cO1W+TdzUZfxivk1rYanVpmzHcr5oKmXGtgyuHCIWXO29e8WibQuHUCQ9HQsqua5+mXbthGUXa6JFmibLBV/s5sxpv/Dwl2tYtbNC0yzJTRbtPYenlfyK0+hQ1w9FklmbNfuoz+b+FZsodViID0a5NdGnBT+HkG8R/IuX2p9BkzUJK36iio7Lzzq6rK5iza4KLv56u1b61pn1vDGxC6GsvdTsGROT81aY/eljtPQbp6lxqiOizXPbJOZfvfIGRscmYL7NG06uP0Y6dRkxJS1mU/t3eL//vfzU8W2W23cQNomxYikQxdISpJ8ic3ZoODMHfcDCa3/mkxtm8er1M8jyZWluqt+UfK89vqdXBBSbnNmHJ7pymsVEVYnhSB+a26aMO8xlUcdk75syXeOA3HuvqoYqsvZWmxe7XlQ+VplF9t1eF2HwuEuPeK23ftxCa4sYr53c10Vqg5gYCjm+I0YHo6mpLbDrGJuS26pXCBpFm8nikOk/6keUbQcx63z4oi4OxOfgijvagsBgPZUGexZhg6Sd63Oq0tSenPY7lXC+2S8ShmpDGFnSkR1uIM5ZjWIQxGvF2I7hoWpKXnsLqytPa8eU5oiJoU1GkaCm2jcxSN+BxVf+yIW5V5KStBRTqmi9rovrwlmvf823s787fEz3XPMkS2NjteMbdnDny48fnhDL88VGcpUkrHZxHltnTCfT6iYs63gl3Jd7JvQguTELJaFc/ePivfjcVJSXawTZ+wZna+e3sSmkmfWpUDlAvoCBS8J38YLnfMJRtZUrzuek6GKWvPOvS+v/r+FfCj7eeOMNjZcxatQoMjIyDn/NnDnz8GNefPFFJkyYoImLjRgxQmu3zJo16//i2P8n8f2qGZqToz3k5IBFZEGnmETm2ujvxPblS7TvoxYbo04Q2eDESy7ReqI3vfspcf1HEE1I0xQUVYlifWM1DSt+5pWrLtRG1uZ80fZZHsLstfN5ZM6/JhN9CMfdcge1l35HjUcEn3nO5dxoFnogM5VB3P3E0aXnQ1Blk3N8okqxsEr0q/8KGi3tVRlMzQb9+uEiK6+MiAU4zdhAvyuv1bxq1LLzunffPPy8fd5aLKEAYb2BxoRkEmN8j7pIDZaaA5TPn8erl13Mw1eeT932MuLdetL9iaSofitqJuxLpapiMT2UdZpU9x6jhUWtp/O65wKSo1GyfGLx8yXvICiZsMoBtiSIwKV7vYtQIMCJpz3A7bUhLotNfa3wD2bg1DeI653Vpt74zP1Hn+d7H0b/4HIW+8/XPH10kpfu9tUUfHUqm++4RBvPba8Tx6kqM6rYn1TIhFgwUOfrolXRVLglOxsO+vhgfR3nfriJ9o8s4JVmMQmgnp+IP8yQ4nNI8GVqE0lv189hzXoh0vTIOy/wS4Z47OmlSzlxtCCZqlj0yFPkmrewJy6T6Tnn0AlBQvaHLCS4jt7oNuyt4ryZW4n6o0hmHW+d1pHRPfN56P7rGDApEV/M5yQzZx07lsWzwSMM03o4FrDsg0/4cPkKzp/+AXvLq7Gt3Uu0bCnJaoVCa6tkYE79kZBrF2FDAGPUrBnuZURF0Cr5I+S11PDBDV/z0FWv07lT7yOOrYck/vZOcwWVlQcYfVwX9HKEenMiz04R11T3mEDcwcQ0KhuPHEO+6cHjcVtaxTRPQz7v37eKxBZRQVC3sLA+itEsAuYdJnHd9Iu1+H6LVzeKCk5akpkuG6YjyxmaAul3WXVatcAcjOL5jTpunkVk/Luac1FUFVVZpt/xk0jNziVJH5sKC/Ulo4cg3x51nU26lOZ9k6hMEwHlIOtawpHAYbGxA7Fx24hejOpcYLTzrPwpKXZRCZTsOQT9ieSbxH2537eWk6cIQumAKU8SimRo92X4E0FWv2f0TSy97GdO7ZBCQuqXqhoatVJ7bt9QxcVTb2b6Kx8y19FO42r0at7Dy9OnHHaEVhEfEcdzUBbnUr0PepvEiP+6hiyiKLz84qeYjGHqzSU02WqJuNK0JO2jV8TnePHoruSmiOvi3a31tHoDmrjfSI8azEtM041jdFoW5UFx3Rv1zYwov5+yO045PPV3DH9D2+X3vlTtj0NQs5xp06bR2NioiY+pgccf8T2O4V/HgZgIVZw7g3pzkkZe7GQRwcdOS3fCzTFipOPoxVz9bK6cfBd3vTmdS196C1PHnkSciRoJUh8KaCNr+77+mGcuPZcn77iNC995nQFfLOK61lTecA3gso/b1AT/FWS3b0/ac/NZEbyIaKxEq2J+tL/mfnvzFb8v0a6isyQy7r3G2r9UnVm64jv89g7a9wlNPjpli+8romKxzHAEcMbF4YuZzKVVtrUYvDF56Mr0XKafcyvZBrFoe7zVRI3q4qVDkn043a2klQQ4dVkmJyxxkhISWeyv3kRGFi0ht14svN/RHcnYRHUkn8WmFBJiI6KNphoiMfXMPbEpkq4tVta/dxs77r6My2IS6687U7ihU5Wm1jrs0psJeUXLoKisB/NuuZfm6oqjqk2f5NYzuEDHYv8gItEkDLomejpnY3txGBO37tQIuMFYC2WvqYgkmwgA9lq7Mv2crmQHxCapjjvqzKqNm7oTypoAkyd2rLvN9UxzRamovxIi8TSbG7l1/Uu8NHMOn6cORQnJ9K6s4MyRk7TKxaGvOPdWIui4pusDBCQr/ZTV2utVu9OPeJz69cOaYiZ9tkUEHiYd007uyAl92ioIg0cOYV+LmLIzOWqpMQb4KHIy9ZFszaiuaecCHvquiRV7U6hrKkRutKHsa4fcKu6PMnM+SmtXAtUT6O2+moWnz+Oz82YQCCQcrny0M/wx+f3Os5/SEgDVX+n5OQ9yxoVn0Mkjqip7I2Lk9P7xF2ILRAmadDw5X2it/DYAmXRTD00RVg1AVKJyODb2GjYoJAWs6AwWTZmjUS+u3Z4JR37e037YhEetekhwb/8EkpqExIHPOR+jWTzW4YmiuARvae7jp5LaXiQn5UGVYwHmiMSgYcJjJcciAoTGSE+GnHLyH773CqefuWaxqWcp+2mn24dOkQhJYfStggOYYGnGisIYUujuvRaDtQYl5NYM46rd92uKpxFvJfk3nHjE9bvPLzgg7W3C7Va7Fg0GnjvlYZZc9yr9jAuRdF4ioSx+dQ/k2Xo3HqODxGAT154oRnZV1FvEPWSytlfjK6r1IlE7+OStmPTVBNSx+8ZsknytxDdko9jaOF2htCwUnR5zLZQUi3bROxN7aeRT9Xq8/EPRRnvw2Rs0VemozkBr/VhOKQriVwSZVW3F5DqXYn3rz004/5dxzNvlvwx1sXE5Q73YPE+OrsegayUqO8i54Br03pj2SoFg2f8RVI+Emx57grvf/Yixdz+GlNORkD2O/dntmD/oRN4Yey4/tx9CWUqi5m+hYq2z73/UnhmikrV6v0yTrzf73aPp1CAWyO+TunP/71i8q7hu3D0YoyZazc288tkfj5UewtdLfyAYF+N3uGNZbul2xNwJdOgsFqj6kGhfZOh/s6DHph/cKeL5cSaxYJWbvNz1yUfsnlDAvAHVVOcbqU+MEjLIqJYkqUGx0DVEDNTMTGLbjk78WptPQ1Mun49N5Zz+Ib6Uh2qCWioUQzNyfhkhg4k6q5iQKGqVaV9qpptDlJM/cMbzRrKVqD7CjPlC62CnYT1y2IfJkUF363gaH192RBCyc9dGNlvKtJL4t/mpVF/+M7vdJ2rXhjZ9ZP6UeRtupH/LVlwhD/1btmOU3Nrvu914N2N653NHvwRNUEsl+fWq2cXau0dy/5g8xrR34bMJ3kuC1KpteFGvDW/ZxSiyCbe5hDcq5+JfWY9lcTU7t8KkDzYd/rr4vXUUWVfwZLcL2WnsglXx0hHRQ/+1ZsARj1W/rp+1i4gvAiYdL57UjvED2tHk9TBt0S+c/dZ0+j79Km8d6KnJ5aujnYHuP7DQLvNK+FztNcdZfqBAqUNnqsYYtw6DQw3QdWwuG4ykRGnSJdHNM4pw0zAOBDuTkJjC43dOo95wqPIRZUKRyGR/D6qzaZfYNbRFEp9/l7CYatrszGP3tj2asF1Ok7gGd0bbiPmHUNiukFHnptBiadG+/Fax0QVMETo2i2tle9ijKY2qYespF7e10FS8vkm0etITzbRf+5aoetCC/pyLSXaIIMvpiZDRdTDfPTMAy+Dt5CeUoSeKXzLjxYRFFhXBBfc9TIKhUhNtq3Ue2dr7R+yM7ORtJUid3andVd2yFuCIJRXxzeKesRt9HG9ZgYNWwkpHKpWzwSfaK3qX4FW4lDeYN/fIhMZ44Z1aVVINENY/dWSFz2V18tWjr3KJvB8rDSiReAIhlXcYob95O+POEJUvFZmj+2i8D501iaAvk7guJ1K2eyed7aLlu651ACHZgDnowxqxEjCI86UGUVGDjmBKFoSq+PR1QRbulJvMmDzRkllX4dPakeqk04iQaNO1BHoRDKXyi0XcI7UBsT4n2jbwy6ttYnfH0IZjwcd/Ger1gsHuD4gFYpI+NuoWKOKnb77WRvXUlsrEq6/9S6+nBhOzSlczr9dQ3j37Nr6acBnbi3oTNpmJa21k8LpfuGDWmxjDIerjrNwx653/6PhVomTCM4speP4bXnjiMorcB7TM4Rt7O1578ujWTruCrofl1tf72qyu/whlXgk5UWwg7cxiU1j/y2wtg1dnEnoMP1s8zi42FqdFZLdzZn1EXK3g0uQE6ilsaMBgSdBaHQdsAS7+/EZWyouoSQ4y1DGQuYPK+XxMOUG9TNAmFnC30YVfZ6TSH8eahhySDtay7LWX6bJgOrdPuptyRfTDJWMzy+OC1Cang6QjIdJCZmQ9yZaPtb5xnXcAW6W2Pv1ujyiVpxQY2LXrScpaVmkOuyZH5uEg5Idb7uH5Hx8jYPARF0zggXNeILugkKLnv2D3+C846B6hjef28G/nu0038uaOx7m8UrRDm/ydNN8eFWoGP96zX5uMUaeSpt75Mlee0I3pVw4nYhYZuEvyMP2s9lzaN4Veqe0xtlygke1MiaswxK/RzvU/fl0b3cL2tBTeSrxYe42z62Zoo7Jq9r26qs/vPgeTRJK9insX/kThg+/T+/GFPPuTj3X702loLiToz6MslmkPzlxDpuJnT6AfFaEiTQb8NXkOI9J+wJL5FUmp32K0lNEYTiYjpnSaliY4MOXuCNWVlSyxZyE7RNXC6I1oeh1/hnO6TEQn66i2VjHt04e49p7zsEV8mnLsOy9/qT2mgxIjNiZk/27g3n/oIO576Qzty46omAVNMh1bxSa+QhbP6WtswREnrh8VL3+3EW+rqHpMGZRIUpMYN/a7fqSw3QDiY348No9M68HHsPVrEN6Cu6xkxUit9apDbkwkLD4oqmpVoa4Mv/HP7TCqZa+mDro6NuKc567CKImMX/O1CYgN+KzE+ejMj6MQwCZ3Qx9ta0EEmlaSmLyRQZGFh6dftPPVuzc1XtHi6hn5fWHKh5++m/sLDJp6qapTak7/jtVFP/LYgja35j6nnEfII+7tJk9/jjvtYsJv3Y9B16yplj6rGymON+xGNrnx6Lxa4OH0C4J5OCGFiMlDgtvGlAfe1X72+kWDNRl/ogo3fScqhk+8ea+2hqlbaajuRL6LE9ePzVxHi7+bdj/3qfhrPlL/azgWfPwXQZUabzI1aAt2tT4XCZl+ZjHut9vQjZaDYqGT7XHE/ZOR5Xd/+YJTPvqYPj9t4s24gWzNaofXasASjNK5opSzK3/hqn2/0qd0E6lN1XTfJYhWq42C6f93IDk1lZtG55McbNDm+T+tMbBsYZuV9SH0NGUflltX++t/hgpLBopN1RtQuLC3GK0rrxULeLYufFi9M2vixRqZU5VOVsdTV1dvJKlZZDFjR5zM+btFOybsr2NrVgkbg6Jc3bOlBw1ifSHFbaXalMePST1JNovAJbOdjxMz9uB0GbBaFXJHVSHHt7Bz+Ty8WvgDTl0T1UaF2lxR9RhTvYQk4xNaqdYb6ofl/q+Y0KlN1KpK14SnvgbnG9+QU1yL49fp7CvcyMHfBCE9rCdz795JXLt1ML19GVomfwiqdH3O89+xpscb7IoM00Z+R7es5OR6ca6n9ezF+x+IHruKp9+6j6FNYnH9Ib4jbz33Ho8/+SaSQWwwRMKM6V/EwxMHMOuG45g2qC+K8yztV/aMuUw7roHSp08+4utE60Ju6nQ/UclIL9868sJiI/KHLex98ix2PHw8lw+F9KT9GMxVSDofktJAQ1Mqfk8BcihVLRmpOuDozVU4nSV0zDzIjgYxIZFgbuX1y/LpmHiA1W6hOdLZthhDQJDhR8rtOcvnJCMikeMXRNAWp03bvFUy6+Qnv9DItlJcrGweEKOyf4YTjzuHAr/IcJc0b9Lk7Hu2iutzh1Hcf5NHjsMYkXHbjDz949Ej4z5PK9dedS83XTWZaFAQkQPGKDleEXys0osluqdNTAUdwltbxbWamWQmf/Wbms29WvWQJp5PRXU5+hip2RiWsbX3I0clfCuzOOWmTSTFWmtq8KEYxL2REeON1YS6E5/cdu38Hmpj03abbZ3xSXZMYYX02PHtlULU+sXzLYl1fGwYzN7AASJKEhZTzFk27Gd5yk78kkTPcAsz3zxSI2ZvlzO1YFadklvy7lu/ewwXXHM+PzxyDjcllJLuOEhUF+HLig+5dXZbtSQQjVWS5B7sWrmCAqeYfPq55Xh2mNSKiaTNeMuxBMQlx3PbM9dp/jNqpBZIzycSKSWjroDnn38Hs9nI5P6ZWmBc1xji+W9F4jfU6Nc4IhF3N5ZLhXgwaVMv65RMbY2Js2zll6f/uLX8v4pjwcd/EWYteU/TvTD6svHpHfRXXRp0zZo6YLtr74CYI6rB5eLTJ3px2wvDGfveGRw//VSOe3c8o98+izHvvkbvr37lfjqyNqc7jU6Llq3kVtfQvvhrXFVXUx+9nyWR9/gw+Su+6L+BL0fup9vOZVpVpTw5nvtn/X1M7glnncxEc6Nm0KV6Jjzz1foj/F9U3HzOk1p/XdVWePnbR/7wtdTMssUlxkCdLUGGdxZ+KbXBWBsmNkapol33HgQjIqgxrVtEkyxGBP1OB8PGnEyvarF4V+Fmd4pYrCONA+leeRmb7KJdkFZnJJho43nb2xQkiIXOTzKd42tw9enC4OG7SCxqIX1ILXtinh7xuLnAK/rLJenpdPKW8HTJNM3KPhDtTbN8A/5gI8eNv4P8UEwrwlzLhrPGaNwAFcaIRNw7H9DnxZso6bRVC0LUqQGzM4vTDBdx697T+f6Wu486j4POOpu0ez5lbM/3+D5Z9PkrTclMzziHx3MHMfmjezSdExWTrxhDSrBey+K/3u/HVJmJOZbdGmMb+iE8f6CVhoRTkAyFyIR4q3jmEVn+oiee4Y3+IyjT5xGnNHN+g5v0eNEyKPcm0umxaXR99FveXw51HjOGhJU4OjyFo/0zODo+SnzeNHJyv+KsAXvZev9Yih+5kq1TbuKnm6/lyQtfJCLrtKx+yZrHefSh63Cc1IUDgT7oJJk76kNktrTHUD6M7NYMzvSaSW4RG3elPQOLQyyB66yCF2FJElWzqKywe/0C/hkGWgQPZa/1oCY738EkRll3O3L56oMvNc5RVsxobo27je90CC/dfxc/Jg3ju6Tj8AdE2y9klEkJJlOPTHEs4BvWv62N+tyc9fhiVY8HhqaS3Cj0OwKun2jXYQizfpmmbZ6GsKza6hL26glvHMEpU5aybuUq4kKi8tMgO7jolnOZ/9xrZJhEsFlvbCOn/h62bFtJg1lcv107plDsUf2NoLci2hlboinUxjRYdplyufOBF1lstlEabCQucQ2Ghhns8u7hFWsvvjaLROa00Ep+mNlmBDji8qvwBEV7tOOu2X94LGrb4467b2TWeTNIixRo00cLm+dw6cybtN/rYiPkBltHkuc+q4kwqvf8jdbxRCxWZL0IECNR0bY0RVx889JMEjNt2pooW6xEXBXafacvztF8ea4+sTtZyeIaeWNTHR5fkAdfmkzPFhFMe+tOZnnMQsFhOkCTX2jd9G8RqtTH0IZjwcd/EfZp5T2wNIie6YWSiOSb/Z3YvGkz+qBfi8qz4lZwQXg/T7m3kh/cTUDqhcdxK7sL72d7u2FUJTm1ykBGQwvt9y8ktewW/KHJtBhno8RsxVXo1MqAbNTaOFva7aXTPrGBLvEIAa+/C3c/fSunt+zWsoctcR24Y/LrR/w+zhlPh1BsukA+0gb+t5g15118LlE2TW9qe1xVRJBWM41H6oU0B0U7J0cuI6xamaqVDqeDBz5fTVLsOTtdOgKOEQSqTyNacwbj0bPRLqTIMxssnNolC3uvKvKdInvaJhewyZjAiRNvIxIzojM5IviNYlNy6VqY1OpBp5qjWYx8vmUyDiVAq8nF3tA9KKSw/X0xunpcUGTVIb1MKCyCoYhejPPZArBxVB9GXXUH2feewS2ZT7OveUksCMmmp3UCdVPmHRWEqDwEb8jJFV0f55aUx5llPol0uQKv5OSTnHM5feW3vPrmA5pp2snRGs2TZ48znz1yA7ao6HnbfW3+Sw+/8xzL03K09tFx3iLNFO+AvYwHP7jm8GP2xu/hC5co5Y8r/p6XKnXEWUX7cH3NQALeHAz2vVjzXsde+AqmhDVIqmeKOkqr9xO1HaTZvo6f3NMZMXMkx00/ifNmXMOrv75LQA5S0SSujfwUkX2PHX8Ci/VFWvbc2byW80qGkVVfKII3g58Et2hJlJnzCMbOa0BvwRr14UuyoRhFkLdr4++X/X+L286fSmIgWZOxf3vlNCY/fg0pwQatlbh4mRCxKwjGjOZixmy/rXr8GO53+P81BhFsRvUG4hQ7qxHHVqQL0//48w8/bvo2sflnJZnJWv4qspyNRCvRMyZqQV+yUQRNDm8EN1aSIvcy/i4xfrz0q5kkS+Lc1yt2rBYDzqpKTTSsKZLJiU8faRz4j5iz6mNt2s4ZiuP0066gwtiHkCLRTDkhWaZOcVDnE/eOzSqC1EuvHsxqfxERyUl61gx6JZh4xt2Tj5pv5IDeTJLaKi45siq02SDGbtPsG9m7ceOfHlOSPYkfLvmKPKWrVsxYH1jMWR9fRpJjPUo0jNESJsOxRnvsV75xRCUDmTaFiElcz4FQE5IiMVjJpX91JhnxDuw+kYx4XHoUs1cjBM/5UHyeb5zZHQySxkm68iNBPh2RZkCnRIj6CpltyjssOLap/URNp8dh3s2Sh+/50/fxv4Zjwcd/EWoVkbmHvOoipjDSKMYkd+u6sG2JGHXEYuV4DrDB2ZkH29/G0nZvsq/gTA6mpRLVSyS1BuizfytnVX/HJam7uLRLKnf3uZ1nBrzIWyPeZea4r1hwxkLWX7CezZduZuNlG1h6wVK88S6yKkXrYV9WOk9+cqRM8n+Kp9++j3H1Irj5Oak7d151pO7D8GTBgi+1VmjS4b+Hhdt2EVGlCtUFn7b2TGUk5iRrPFKltFQnFgmXpRxLvdiQ1PbPx5sqsFnEhrYqIw6DawyR5m5cZiyl0VxFi8GDISKRGElFjn6A3iITFxst3KoUsEXfia/ev4HWWAlfRb1LTIoEJB3p0Sgnefx8tPd50kMN1IScLM9xsC1BHHOw6TTGvfomF0x8Hb3aY1PPSW/Vih6yv59NU5LYHOOaFZaM6cFT301hb1It9/adx5asX6loWXNEEFI75Qfm3nrX4SAkKyD+zrK0Htx4x2t8nFXI6bVzMCohtlt68FzH8dw44wFueuBijouZzy1xJGjCYCpsfi/FG9eyb99u5mSOEJ9PdSkvX/0MvX0iQ19s2M3qdQt55JUneKXTOdrPjmtZxJziUSRLCjpJnZSDDeE6XB0fx5r9GQZbmbYJpEbyuSTvOhae/QuX5l9PV8MgksKZmmeOajZXbyhnW3gFb5e8zKiZI1kaEJu03eTjm19mau3Jd/J2sC0k2m5jrCJ7VsXE0vv7OLXzGI102qxLpJA2d+P2tkYiBgkpZsZW09gWiP8R1AmyblFxrWw3VGuTGT3dIpPebBNVhAu7d9DGvlXOlNruPIQXptxFmTMDaziAIRpBMYrKpaQ4sRvsrIwFH30tbaJaU2evw++OVT2GpZHSKKwJAs75dOw8nAUvHUdqongdlyfKvtoCTZ30ECKNNcSZZQxECaNj4Zevk2IQVY/y4B9r7hzCgWBMIC0cmwrqbWSHyUq/YJCDUXGf6SOiMmA3+w8Ta2tT91MXFpVGSTpIEXreIIMfQ/drQeJJwX289tSFh/9O33sfJxRNO2Ls9s9gMpiYfeEndNaLamd1eA2ppnrwlOAyfopObWkGO3CfaZT2+55NISKxEWY1aYuT40lB6JUEy5IYcfZI9J4W0OkIOndp106CL4EpU96jZ2Eaw3NE4LKq3KuNhN/+yE0MaBYV0YWeibRg4aAjg/LqVdR5hV/SgND8f2oG+b+EY8HHfxHq9R6th9is5NFTKiZO14CsWMi58jYisRHbwpRqViUOYXyfN/ko8zSajS7Sg3WcsH8dN7SuYftpg/jh8ouYdv6D3DriGq4cdBHn9jqdkzofz5CCgXRJKyLdlardzIegmkA9MvJhdmdtIf9gMYpOxxJP/N8uTDb1+evp07xbm9n/Nr4zT9zRRiC7+pz7NalwWRfl0z+QWy8zuFCcYsOf2FOIDqmoiIkgZbhihlkxSIOFDorZUEFerdiQtygZ9HV9jt7s0tjyKwriadGnc27BWi6VrYerHumNFuJTZGwdvMiyREWFqLiUK6kYnb1plywWdHXTUeF3ikyqLppGvaTnnqZWCgKVlJrTmVXahYaKODJ6vEMUmW6YCVfkMWTaYpJjpfpVRTqqixwk5HdiyPIdeAV9hPjqMFskcUx9wjmcfNujDHzjDnbnrY4FIUEszhx6WU6hdsr3zL31TgbEiSpMdbyLbWU7KerSkzfPeYhbdn1Nh9AugpKVrzLO4rQNS0nrHCIrUE9YZ2SJ4sAbM+Vatmg+D6/aRJXNRHIgwp0dRKn9ptEPITX3pKnhOM6bc5DNBXE06FJIlys5sDYeSe9hWJ4wPAsqEI7fgKL3Y4paKNL1Y9rwt1h4xXdMHnU9qY5k7hh5HZ9f8A6Lr5zPsvOXcUvRXfQyDSclkqdNQUV1UdbLHkKyMDTb7X6QsxacT6u5iYcywjRJRnLMW8gx/0Kk0wEuungSI447icxYqV2ytC2B3hxRCbPHprsawke3SVTBtWZfi/Z1CDeOvkvTCWkxN/LsZ3fRMz9BqywetGUw9Z6XNHXZ9GYR3M47KKoOrS0N/BgVG+XxrSsZ0bQWiyIqSlE5Eb3RydpY8NEzKdb2i0T4YLuo3uUkm8lc/kqs6uEmfPqZrP3mfcy9REtJhcMToUXXJsOuejzpfK0oFhuJkkhk9pWnkmUSEx31MU2MP0NN7Hmp2Ph42mQKdj9Ir7CPVgxsiIoWVFJYnD+Tvi14e+KRa2iOea1URA4gGTZhRmJCuDe7Is+gKCkMlxdz7ptvau/TarezzyeqQu2tGw6P3f4Z1MDviwunM8B2PF2DIhnQS79i0wldjxmcgoQOvUVP52YHikGcG13QT7ycgipQr8q1dW824C6rxNzUDHIUt8EL8eJ6yWjI46mpb/H2pUMw2g2qFC7XzRYB+gnd0sAF3vxuDBz0Fcf1e59vO4xl16ArhBeTqYR1j971T9/H/wqOBR//JVBdRNVea9SfQ1QycbpOlPta/Z0w2O3otcVQoWtcBVPa36L9Lr+2nqnrX2T9qkl8VHoH3db++2JvozsMZ2TGKThbRG93W7uOPP3oH/Mv/h2oPdyHrxqjzc4H9Wa+VtK0vvlRcuu6o31WVNTECb6H1R3ilL6CiV+yfTn1Ma5Et74iE/7t5I3KfFdrCgWGOqJ6PRX5yxjaKjK3kKecbl5BtN2YOYBotD0b7TsOt1xy+whS6rLSQQxXVpEXG7mMBHVYE2OLZa0FVU29VV2V1IyRAEbFRHw0SI0pkcsLbsAXMVFRnE7U0owvVfy9s9ERDaVRXCt0AhpcEs7b22Sbuy5dRcgAS7tLtNhlnH4990xoI7Udf9P9WhCyM3sllc1rUaIhLM5cellO5cyf7CR4Q1ol7I1lPx9+zuTrpzK7zygmVX6FRfGxz9SRD3ufTF7fGk22usqSyrpEsSHsaarnlwzR/jv54K8sqnXT4ZE3OeujElqrztNGWMfkFLPCMUyrMly//XPi81aTXvAaHWIVnqqwRFw4hTHxp7Hw3J/56qL3Gd7uj20Y1CBYDZY/Pu91Fl0xlzUXr2ZKz8cYaDueEm9ML8UawW8QGffeuDpG5mVwVmY6awrmsNy1hNM/vIhTPjgPVKVT1XiuVWy4xsTFuO0isDLGLOA/17vpP30gfd/rT+/3+9Dz/Z70/qQ3w78cxogvhjP83eO54LPr2BmqoKM/NpEVLuWm+6+lMKYmu6tBBOh5XtF6KbWJKauXHphCuSMNe8jHZZccT37/FiwxYzu9J5mdFgfqFeRUZE6+UNzPU+dsFFUPHTw0PIOUhkNcj/l06jqKmuqXqDJlEYxl8OqYbSjm/aQd23zV6E2HbLaSohPX516fC5u+laBso+CiI517/Z4W1vTrzNaunShdOV9LNmpM4t7Lc4c4seF9OkZ8NOj0zJBH4sWMlRBWj6gcqdWtTTGiuoqaWEvXhJe3Q4m4Ez5Vjx5ntDPVwddoH+hHft3PFD32IZO/mtU2dmuoYt3TD/BXMX3ii5xYJwILS+JibeLEGxrAyzZx/xfKMjp0WI1iPdEFAywN2zmRVs6WmnCrJob7E5FsFsx1MfsE80HCJrfWurOV5rNt3Xpu7hvTAXLLHP/BHJ7L60RgcBbRfAfNZhG4LkvvxrPeEFVeEWj2kxb9pUDqfwHHgo//Eny54C2N0U2ruuArnKxfq/18t9SZb6a/iyTLFLqa+bDgQmrMySS6Q5xQsotJ101jXUSV3YYzDCv5fooQIvp3oAr96GzlpNXXEzUY2ZSUwbxvvvkb3yX06NuTS/P1OMNuGk0JvLGu/rCXw1mdz9LK8upo42ffCu2LQ2hxN+OOi3m2NLYFJ5uWi81VpYB1GTThqL/nDgqiYZa1ldZ4OzpnKd08ojfv8VZQuEEw9DfbOlJii7DNJohlhZIRS2KIgNvE58WnM1LZTTdJ6Bjs8sXhc4iAZ291L4JBE42BBIxEmKl7hjj8+HVmzun+HGUmkREbWiNsL+9IU67I0iago69nO0o4lYi3vdbLfnjjpwSCYgG3OuKwfvw23wwWt/CZy0KUfnS0BP3YWx9gwJu3szNjKZXN67QgxOrKZVizOL6W2OZ7CEkp6bxywePcuXcB3f2biEhGFmWPxdxNbChbzZ2pNSXjkw1EdRL96mvZFrLz5q8Bwv4cVT8bydBCl+RlLGovBKR6tsziHcdWys0r8BibSTLE3GNru7HsykW8dNrjxMfGlf8VqJmuWrV7d+KLJBpvEOdFB9nGKJaIBVvEqbUn9phNzElQ2K3fRDGbOCBtoyVcgqHEjSKrrqoVmFLm0xAvjkE2iODIG7Vpo8shfUBr96hk71gcq5Ebm401bAkt46GN91ISE7Xabyvj87lv0D0grsGNzlyt3TU6XYxIVSa4mL/mZ+bLYiM83r2KPsPGscnaijksPkudHM8qlRSkjdg2ayO2ajXg412i6pGXZCbl15eQ5RxR9TjtDH545hKsRR5+4BTMhNBFFWy+KAkFol2pva+mWk35WF0MMmJjvcWq74rWculOfp8ehx+rtgd2Dh2E0wOGqETF5NuY9ePbBIw+hnkD3BL4hVQ5wn6DhTmOC5jnFxobHfQNeCMWraWmYvnGtoSn6ZBFgKGKlNZ05ur6cGDgGvR6tXJnpyl8B7cE+pMZMvDVOjPjv11FtVcQNnuF/zn/5rfoHBbvL9HQrFWL3coV9KsXAWC/RgObTRGCNqMmsKhyzfYoNYSRaFAMPE2Abs16EhKzMTbWaMZ7ISmC5CrXjBRVHtzcb2r4tW4tcf1SaDgujW15eTQ5zRgiCsYqL9YNNTy+52Xt763L6caLhaO0QMpsPMiWR27/l97L/7/iWPDxX4KdjWITVNwd6CodIFVXp5Xy0i65CXeF2rdWsLWz8H7m6drjxq0PkFbamVfuXcRP5kv4NSyqAicb1zJ/iphx/3fwwdnTSGoSypQbu/Zn3fdz8Hvbpkj+Dlxx+2WcESzVVDaLHbmHJdjV0cbsWIb500HBPzmEV96aSiBBLG753t/wPZpEiyHrN0Ta36I8KkYaM22tlMeLkniuLIKPxkA1UrNCd/82bZF6L6eMkC6KNaCnqEiUt3/eOZah+vVkRUMU6cTf3a8zaAu8wx3h4mveptSdS1MgjheMr5NnUh1qTdzb4UZ2OdphieynLk4slIvWDqfcWE3QXo6EhVe8u3nm19dRtIATDjib6frEB7z8szBunLbqDeriJeI8CsdvUkj85Bc2fdLWqvotxt7+CAPevI0daUuoal5HvzqRkZen5/Ld7UcvhiMGncnJc9I5f/83OJRW6rNziKaq7qU6fko9nmgoij0QZf/uvWwvz9KCDpO1jLtOtLPqxlE0du2MV3JgCJZQ3vo9AX0Ea8TBILkzenXCUYHjet3B34Xzxl9NIGLQguyxrghX2k9l9RUreGfUB9xQmsdFLa2c1RyiT1M72ku96VwbQl8mMtAUVxWG+qvwWfTalEN+SJybLF97bug4mbu6PsBjfabywuDXmH7ch3x10jc83e95+lqOIzGcqRGz/YbYPSDBU/Vvsq3PGvRKiGZTHE/f8wY3j72QRHcAWSfx6cIDVDhScYR8XHmlCIirwiWHgw+LwcmqWMulj0NMUT3xzQYC7ohW9XhsdA6pDYK7EHT+RFZWT5TcNZSSRxNJvMu11PuzUJAYdILQtZnz2efoA15kq6gQ5agnSr2mJBdBxUBVqN0Rgcf2gb2xistSQ3yDwprS5UxsdfNqbS12RWGjMZ7t7e6mpbUTm3XiPhqgE3wTRRbBVigsWoLaqckS3IdM0w7SjXvQlWbR/bgbsN59Cl7b1yhEiEaH8BFJDEVH2J/LE2HRGnWYd7Lk/el/+XrI1sWUnjUNpIFElCxGS7vRmxr43B7mJ1sYs7EF2SQ4YoPD1QxuVwNShF+J8C1hUs0DQFU6rVJ1b6DO2MC29m6+GOrgnXG5LM3tT02SSbuY02tDdN1bwRd5MukHZqDURcg8WMrFlXO0tePLdmPYGhQTZr1NSzSZ9/91HAs+/ktQI/tQomYCkWxO0gvmtjtQRH6XruBpJsPm5vkuV2ubQ+fyOtrVRLQSoSPkIKGiMys8d/NLSPirnGjcxOIpQ/8t8lNGXDqTOmcT7w4QNFvZUdCRaff9/X3MR1+7m1MaxajcbyXYOyGY9Hv+QW59a3MYxSX4HhN6tMn51wSFUmSWQVQY/hHrU0U7JMPaSr2rBsWXjs0qApxquZaI0czp+0V/f5VTBICZTWbis7ysq+3Fdy1jOdksqisGswhe9ofEMRqbDJqZ1fq6cdwWnc0p+lWaIueS4ES+SRWL6klNO6hIEW2CDE81L2y+gaYsUf2I5JxA14Z99JDWoMhGdAY3krmRFxd6GPLsK6zViYpQr+Z0TBGRlBsff4f9y+b94Xk9cfKj9H/zNqLhH9HJCrviDCiJE5h9ryjtH8IXM7ZglEwUrBnOjdsWM8C3inDXBBSTjiZjAltcRShr9uH15GtUTlWf4/PLh7Gi+gtOWPY8Byw9QA7hqn+DQp+VAaEeLLtkCV30YlMNRw0M7ikW478DqgT9Lr/Y8IrMCtecK8r0g/L60qvoMjruGMb5Bx08U1vG1OwrkbZ3VIc2iCaamGDwYrGLDDupKcK2VsEXckdtXDv4Ei7qN4nTu4/nhI4jGZDbh6LU9pzcdSwfnPMKS66cz5wJ33FS0kRSg+JzlyWZWnsJUrwgUM/NDHHep1eT3STIrbszRSJwvGcl3Qcex4I9S/AYmjGHxHLsQk+xKuOlKIwa2l2reszYLTb1gmQLcYueQ5ZVnR8PwdNOZvG007Ckhvg4dA276cQv0gm8YLmDeqOLhJhmx54Vol1KzOY+PqrHpagcBwM75TyUDr3bAo9BIvBQixcNKYLorGb8Q3xreLChCfUs/2zOwXLyZ0w473a2VLi1YLu7UkE3BKk5EhYcp3Zpe/C1ivvirGsfYkNEBDkjXO9gjZh45pnZxLvSKXrwJdY53scglWJU4piKg6mSl0XWIloDXbTWSeH2r1gTkzv/Myz4+j1cMW6KrJjZ3ixaHp1DBVjy3kSyVNELD16dR2tBqUj21/LZVZeTnyq4Ha8RwNFqAFsClQmpLCvoxUeDxzG7bz67s02aW3FaU4SBe4rpu6OS5o11FJdJuIw5dLLVIhnrterWY/tepWfLXk1i/+r+1xJRnFobaf9Tf1/g/d+KY8HHfwkadD5tjEvdYk7VicrDXqUz33/1NfqQn7I+3dniLMIeDnD65nrSkg/QL6GO0+IPcmp8CZMsVWRFTqEqJNouo4zbKH98FIveu52VP71GSfEazdjsr+Da4ZfQrlbwHdb1GEq0rpwZb7cZtP1dePHdKYyITVsckmC/7vg7MWhy60289nmboFBpQkdtATR6w1wy/IzDP6+KiOAj3XDkmO0hrEtPJhDVY9LJJDrcDC0dic5o1Yia1VILisHIqeXpZPlkCAu+RweDjF+x8NnOs5CVCCNksSBGdGIhqw0k4w1bqawW2eCtB37lAv0iZDXwiOawz1ZLUGfBFvVzS+3uw8FHXqCUWm8yMypcyHo/+lAWkTM6kOHKFKOnahk5YaEmtlXZ0I7q6nPR+bK44axnaTx/lLZJ6JDwXn0bTQfaMs7fw/V3PUGXCjEe/HLXOHr6juOnF8SY5U8/LCCtRfSza+OrufXmB/l2wnVcXv4Z5q6i/XLAl0O7/BbSzWWM6+7luK7NXP7zRayX91GbMEl7zJDGj5hTsos6Y4iSaBUtzQ2ku0TA1OA92nvoP8EDs+5gnkdUVMx6mfdmt7Wgfl60gOKmFuaWF2CW6tn/41tssYtNMNIhDr9DRucS78vWFEKOcSYakTRp/n+G/ORcnpnwIF+d/SW2kKgsZAXSSDCLz0DdPLeG1uCOiIpVVYYFl3kb514mHGg/3fg1+qiEQRbLcYtecE86RkL0GH4mj369nqBHrXpIPHF8LqkNIw9XPZRmGVOvar5rvIrdpvYaWVjFfmM+MzJOoaFOtIOUmLaJYhWvbZKNtLRphjYAAQAASURBVFNEQLMsMojh11+tBR7b1MAjIAKP+kwDw37dTnO8hH9iM5OC4h76yN6Owdcto3OvIdTX1rLBKUbCe/vqyJHENRUKiPNgN/pZOE0E2io8Q+7W7O1TjcV0sf5MRmM2n37ylfa7M+7/iJ3OZ3Dov0FBZqiSwQ9SmOUhwQPKsm/klreWMPT51yj/TWv1t3hzyRJ+3RgLtFRCbetQ5utEMpJq7ohO10p87lv0MYsqpdkorkNZ5X2M7s4js1/XlHAtViOP5pt4+/Rr+Py0K9mWl0/IaMIe8DGgpJLL59dx9U+tjN7k5IYCEwZV2DCicPXXWxiQXIQ5dR6/yL3Qy1E+3HE3jkCI0sQk3ksSlaju1l+pLhNeQP+rOBZ8/BfA5/FQZ27Qev9F0kFyddUoipG4865n14qlGBIMvNtJ6AD0KdlIqtnPdopZaNhNq5SOjk4YpW7YdD2JyrfSFBbS6+0MOxlQUk7Oom6Y3glS+/ByKu+dTeV9n1B1/xtUPvgc5Q8/TOljd7HtmatpbhULmYrnx43G7o/gdsSxq113Di5bSHWVkGj+O/GPEuzzv1x9WG59nbdNrrkpXs3AIaGxbQpBRWVELILpMWGkf0RDxEWlX1Q/Rre4OMktbgm/txJZgkJ9JpKSyoSD1RhCYsHqnu5HXp+IDifDrAtJkdWpAh1vhM8lySiyvNqaTPyOUey8/Ry6O8Wm87Q0iaZ8PfEtsSw2uJ+saJhcs4+AKYpRjpIVqGLgj7uI6IX6qCllND1iZmjqzuq3V9Mr7XX01hJkfw4tZddw/Y8r6Xf3y1SPaqdtGnpZomzCGRph8M9wTUcDprDM9ng9iwrSKCwuYtOPX7Fykbrt6ohKUS64WGSNKlqi+WRV7iclRWS3e0pyaBrcEX1oNfNqviaig0Dytaq6Ez2Cm/hy+yf43QMIS3rqrXXcN/NmEuziuXWtf59WzA8LPmWdpZiaiE4j72qnKjhH+/fTt1/G2iyuS0UJ8E3FSL40FGmBanyiByXeRJUrkeZY8BFtDoK5Td30hwXf/+XjUFVlu4bEtRmVJWad9Qz2iFuTMHfV9McrrdHumZBRhzO3kWt33cfo6RPY7dl4uOqhLsnlsVZAl6APj8fD53vEOStMMWP9+RlkOU+revgnjKV4/T1857mRzxNP1FyJ+yurOK1hvvb4DzNP58Wvn9USA3WcNKo3apox6kWSac2gu07oVqyPdjsceKj6MSrqMwyMWLSVL955mPgJLfTT+1Ebl/ekJOHqdiP2eEHofO7+d2kxxWGKBhkysheuqJjMccccnFVY+tbx06uitTdi/Dn8HBUjvQOdn2CRPJStM7RVKhMmoDe9T4pxChGpDqOSRHfTKYSjwu32+eBiKuoKGP78T4x/7W1avF6e/XE+/Z55lcIHPuLpeR4uD8eUVBUj15uH8UNanMZ1UifYxpT11FyM1ZF5FQajqAwZwgEiwXRmD70RR7de1I5IZVeRnVaHFVMwQPed6zln5TYuXP0TfcvWEhfZqY3fGhQDW37ycXnn2CRPfRBDwlnEW8oIpPzKarmzNk5/2cYZWqXxyS7n0SIlYtDX0/jyvfwv41jw8V+AWT9NJ6wPEvV2YPyhlkuwo+aDEGlpYMWwsXgMdjq37Kd3cZjSwHbsezdjLN7Ij+7vKTbOIuj8klbTrwTZgjvansaw8ONwGOaTYFR5AuqCa0JWkrTFLRrphqzqJATGoPeeQnzjRbS+/NLhY1KVGzvXipt8Ta/h6IMBPnrszwWK/g4J9hk1BtrHxMH2WSq1cvueHVs0HRIVWS1tug0qKuTYmG2C2Fx+C1XNM9wkUekTzz3JbSA7JqTVFBJ6Br11IkNOaPoO1eM1YsyiwVVE30u+xBOUOccguCfzDXn4A0by4kQVJFQdx9iDv9DZJTRJngmfwxJrF5w5HnyNUazRAGlBUeK9sbmBimRR/RjRsoruDSUovy7W/u+o60NBUSPZajYe69MXJ5Zhy39bU/+0ZMzioL+e3lNfpeGKh6jqGq8FIGobZvsI0Wb7I0wcNJ4e1aKa81oHE1JcDsbZzcR7RDZYk1hOpy6Cb/LW158xt7UjJdVZnLJpDk7JgxSU8e2S+Dr/EppSrsEQfx5+UyF2xcNbW59Ej0KtoStDQ8JZuMS1G6NebOxd2reJZv2neHfv50T0IdJ96eyvFZ9XVmIVjXV1VPyqSmBHkWNjlY3+JnZ70zRztUFJQpehxFagkQVVtLYECeclaBNQKl44kEVlkwgW/wrO63aOJrRWbavm22Vv0btVXI/Og704eUN/kmtF+08xDdYI5HWGUtFyifE9IpKVbbFx5uRwkAfveYSQN6KOjvD02HzS64WuSsixgAOLf2Jm2h18lTpCuzaOV+Zxbugjztn6A66Im2pzCoszRlG+SYh0SfGCXO1QbHT1SQwxiIm5fVIG2wa3BR516QZG/LJVG6UdVP06XSIemiUdV6enshwb445r++y2x0ikPVr3M+7sk6nz5WBVDLhj15BaidIZFCJp86gpFcnC0Fs/o1pOxKrzMMj5Ka6AiykPCV+nc697ktnmvlj0W4m33EjQpAbhBjzyqdrv+7lWI+maUKIudpRn0fPx+UxbHKG+sRA5nERqpIk8i/g7tf52/Pz0Hbj1yXjdouI2rmoA+c0diA/Fa8FDQ3wLfrOVpf0GcdEjz/DZCYOoSrJqhN2syiC5axu5bsZrjFvyDR38u0iMJGlkY4MtTFXCHq0d5Qw68W3YS3KiSWt9vrixlpxgCqakJSw3iMrr8f6VdN22i4DezJOFYqqoo325Znb3v4pjwcd/ATbXbkAOuzR/i3E6EXwURztRUV5OXUoiS7KGoFci5JbPIUdvQV+zX7sJdNEwSl0J6/Yd4LPSEK1j+tLu6Rt41xrlvZaT+anlds3F0q5fSlD3IPOt8ynp+i0Hc2dQn/KRNgoXdH0FVqGYqPOezOrX2pQr7xzQXsucGxJTKcntiK6hkref+n132v9cgr1Bk2CvtKaxc08R1qBDk1t/Zc7DvPjpp0TjxeYxMK5tjG3bim85lPv3Gnr0lM8zMx4mtbaWiljlI8lUQbxe9O2r5AacxkRyJLVkK7PRIDx0QpZuLDScwHPfrUdPmOERsblU6rrSPauFns5dPGl4l2u8C4izbtOY9vN8J/F69FQSzU3ojQoqNeDkAwtI8zay3phI32AQd6Jg98UHVTlnaKpzI+t3Iil6EmtHcnmyG4uqQeC3Yo0l5pI+gDFuE9bMLzHkfcAjG+7llRFxrO4LYb2qRAorhgp+wR/h6VF9cfgjVNn0zMzWExdfxCBlH2FdmNtuFNLZL/z0M09ttSHVh7UVw29zMK5ivuYtpK/2o6v0ELQPotolpluu2T+TAm8NlaEijn/qUaZeNp1sXxb9HOI9hqN6Thx6Gn8HnnjvJvbaD6jjJ5zuGsSAHndrG54a5Lz/6vXoQ2rFy0DhuBEE7KINdlz9Ys5mCecERUWq1CwIxgnuCMGojK4lRK5BBKveSDzHvfrZ4Smjf4YTRk6kUJ360fxettDRJpbYvY4cFuiGI1cLAnRtUjbXFNyqaZvEhZNxNYvnVFoz8atmg+rZVWQ2yB1RPeHbpZoxzn8aWc5XG2scGNqL11LH8HNaN+15E5UZnMbXpDseJFuu59qDQsys2JlNyCeCJ33s/ZtkB+7oNvroRfBVrga2MVfa+jQ9IxZv5dNp9zCi8SNyo0Gq9Eaekzuw3mqhQ4XClvfEPf759C/Y4RQVx0560RY0DxpPuqLQ2iJ0b7RzGLJgTg6xZpZox6k8lEUWMQrf1bqAFEMxabUFrF0eUwud+BJ7DDbiFS/F1s+oTv8If7RfzO22isXRFeQnl4DOB4oZpBBmWyl98qv5VJ6leSRp5z9xILNX7iHsjbA/IqpH2dgYUyPaQDWWZhbmd+Sd829nba9h2uh5dq2XS35Ywhf33crIOXOobfRzIOZu7a2rxuw0YFSDK52bNAzUO2POwk1ZDA2Wq8IihDwRgvJJGGUjC7JiEza63TRUyuQerGVG5smUmTM0k7vgW399hPj/33As+PgvQE3UTdTbnnZSBUW6ck2u13zWFXz23tssGHay9pizyn/CUZ9BpXsDunAInd5KJKkbstGsOjlhbSln+etv8sSV1zCsZzyTXzuZZQmpzG29mahioJ1pM2MCy1m9rh8rfL3pdcc7dL77Tdrd9zLZDz2KYhMZfHbFyaz79RPt+5FdBtOpRtxcq/oeLzbN7WvYsUVs1H8n7n76tiMk2J2lIgPcHq1hT1ymlhnqA1HumXTV4eds3yjGkZNRKOw69KjXXJykI6PmINV+J7JmMteEzSkqJQd0TbR3ChKeYtzAHocIasKWrmy09KO6cRunWubjUmTqdAYG9pjEq4GnuK/6O843LEKvjmL6u3FX871cp7tI4+rEG8TmG5fvZtCuFaS0htig766dtzHGSi2L0skmfCY9r/c4g+9jirbxB0eiGvVekhyk2AB+vervYuKmcB9Ob7KQF1DHR1TBrBpK4it4YayBy2438NREHSsL4OuzuxGNHCmwdgjdcjvTv16ITL3bzkSzUSIroTvdpU0kZ6Rx+hvv8sovXggYUCw6hmWUELZaSQ/WkmoVxlqm7bWkxqT/B3mWc+1+ca2U+PseVgG9OOtkOlnExtsYELyE/xR19VX8FBacoK7eQm644DGNxOoOipJ/RrzoqfsTMzjroqup12fj1juIi7gpqG1lQP0OLWhXpdVVJLnFBqVrCOIwHVKnVQj68hj4/FscKNnApuevovLBF6i8byYr37jud49roLXdYb+XcRf1JT1Qq7VE6m2JhGvrtIDdYzVQWRfUtE1mT/qWxHox5lpqEyqggzBQKUkccGUysH4rz5xYSEaDIOg2OJcwpTabjenZ6BSZq5RpnMos9jV0ZsywccRLXq6q+AqjHNEmLZb1Ga0R0aWYK7FNcWLVryFVaiFF8WjjyCXZfahP1TF8yTY+nXYvwxrfJy8WePzoOI+taSKY6FihIL0rApslK/dq7VDVA+iuJ0Urt+85Z2KLgt8fpwWBmudOrZjMsfZo4fsnhdrt+fe9y6ZooUYkHeF6E70iMe8bEcjntVMDfKFhMjZYxjq/m6pTwnhD4h5ONe3ls2YTL/bYxwUDIiy6bRi7H7yeRzq3p13MPE69n8dccjdvrxUVj/WxVpbLlk1YcrMrPZeFPS5kb35/jTif3FDNuT99z+vOSsbu/ZTE1lou3fotHVprKI75/kjeZq69+zocQdGqcZtqiLNWa7oyKrm/XWU2nRNEdXJLXR7jwmNo0NnYZTRq68Fx+i007vDjbInwbP6l2uMKnSvYtVZw+P7XcCz4+C9Anc5PxNuBk2JVD0+wg+ZUuiIhnxp7GpmBWkKer+npS0XfIEr5W5OKeMM1HHfuePxZhUQ1VncYi7uCrZ99xgNXXs8iX4hb7R25OnwzfsVEvnkDo50v8UN1EoPumkOXB97XhKM6PvIGZ+lTUXRlKEoCmT814vcLbsPFhUatRFmZlkFxTg6GcJjvph2tN/F3S7CXRIYR8XTkgLWcmgSx2Dsb3dpGdwjVKltdLcHHpM9/iycXvkSznIE94CUkGQmEBWnOotuFv/UAbgLkO4Xx1a+WtXhsUVSZh1xJ5UIYMLWPcqJhufb7ZsXJgFU3kO8tw6jIrJc7MDH4IGPNt3GwJUJKSIhWxcVK63F5boI1QQotGQwbdw+NOj3nBltoiI3crurgYlVud16SC5CkRgzheOxVfelslRmbImo5PQL5XH3lhzx261rmXrOFz3q/RHZdHyLNvZEjTk2AbGN7HR+coOfhUyTGvtOD217uwfS3z6V8v5DlP4TXzzyH5BY/PpOBFzLF59rRMYjpNz7FptIMjeAaTTLTJ9/NpzffDEYjZak+vHmz0KmOoLKZhJ9ruG77R9ywcDcuQy0B2U7qKecd/hvnnXoTaYaY9kkkzIIlbeJx/y7u/+JWGi31WCI2bhsozMRUHGq9xBe2IhvjuenpJzWtmGWOAhYni6DV661md1NPcuW2Nl1WpFhVGEOKKPhiNIR2+hB90HN9axeUt5tIrrsYOdRfc5HNLT2TZW8LfZHf4tbzniYp5vcyfdUb9PC0yaOf4F1BdqPg8Gz0iZL8nd/MwRYVwWGZJfNw8GHWLOOhyppK9PvHiUYLaDIGuLjLBEpSEzFGZW5UnmMUi1isjOGcPvdr3I14yYMz6qNLkwi+tnfqQ8iRgF8vAuiMiIsssxD/KoyIXsvu7A4MX7qdz9+4j6GN75GnGj3qjcyzn8d51z1LtUmQTTtUKlpF7eCaRax3ZGhVh17+fVQeWM3GFV+wauE7HNR5aTQ1a0RuFb5oHZuKzaz36dnccRPzZzyq/by+960EFSPppn10sv5CoieJR58QxPXr7pnBT2ZxT46JLiE5vScbcoWUvEW3Vh1TYsCmPly0Zx4Vc59k6af3kKqZx4n2ZZWSRFQKsbtB3FPV+izkSJBlWXF8PGAgi4v64LGacPoiDF3zLZd8NQ0dS6mXp2A+6zyq+qRiUKLcvfp96g0pgksVCrBg7lzOv+00XFEXESmqVSYTujVoLRy9omd4WRi9VQ9hmeWeE7lAP5qlVtGaGmdcQgQDkY21fB8/mj22PPSSF8vnT/K/iGPBx//jUMdJ6wyNWuXjEN+jJFzE03PfY00XkS3dsu8dqr1FtDRs0MbzTJZUFlmFiNHHchoWe3t8BV2IZnUhalLbClHi3WWceWABl1QupSSUzMWhe3ArVvoadvCs7Ul8uiC+cKomHBXy51Lrbs+1mitsEDncm/IXBVnqwqGn06FWBDzr+pwqRHia63nl/vv+T87HbyXYA+XnEQkn0BovFvG0JnEch1AdFmOFmQaxoR5Cg7eBbw98SUqzyMAjdhe1wZjDrW4HB/R76WTIw6QzE5DqWSUJHkeOT8eQGjH9sDZhAIOigoDbQWlCr3PjterZ3MXJjZGbWKt0onvddlal96TOKEraeVGFiKLHaI8SipeQdizQJgaWmNpjURSsLhGklKY6GZwuEcTAjphwWcY+kQmOcka4OSXAuJYW3M1tXIRuPccwb/KH3Nj9MgKlV+AtuYVAzUk4GtNQ3dVrbXp+jld4ybydCUsu5Jw3OvPwS4O0zUI1m+u/X/Sef+yYzobwHiRJx1jrAM5uPUiknZPEzk6mDhIjqCGrl1971iNJMkW2FZoeS4UljbptJlL04lzt8w+i42ix0atYt201Jp3oF63xw7Ttvy+R/1ehBi/rzKLqNihYyMB+ooyvIrA1jWhIh9kVRuoTJi4ugWcf/YA6cxJV5jQCVrWVpvBLbTodfkNaHpJhIzU2rp0REtMhrqiJV7BzMiaMmPDTQsQ+G71xIwoWCkpO5df3bvtjvxdjNfbfaE7YrYkUhGJGcy7Vsj3CyrIWbNEQrQYHjUaXtij3j8osiS/EFvZr/i/26vFUWCUuGhBPdbwdayjKPcqDDJRWU0Yu3uoECtsVsXHFz5gk0QIZUi6qAGGjiW3dR2lCWaomSXqkEae+nohiomuMz7InNZOZbz3AoPrp5EcDVOuNfG87myr9Bs74uA8+lUitKDx3pp6L79AzYfst+Hu/iLPTg6waPJuJmydz8d7HuKr8Fd5v/z2/ZP3C7linSufawgcmPZ80mvnMa+L+8Be8PnUEx595CQsjYg0b7PwQi+TFWZFPfZUgrbamTtSI3B0iPpZ+eQsjr7tBc7tVqyUO6StV2QhH8wUU7DmTDlv7k2oTbRvtc5MHEX6pnCVBK8swMi7LylUDrNzex0aty4UlHOaGXfX8sHIt55T70SkK2U2prCsbRCPv0O/lmVQd155Mbz1XbPueWpOodny/aCEpaekoEQmdaqinb6S1xEdN+j5t7YsLORgUEQFQaV2QlJxL8fj7a/8fqtuF01hCKGzAsKmOZ/IuF9eaczWbFgiS8P8SjgUf/49j/uKZ+GQnubKXLrpSjUMQGXc+X/oLiegMnNCwgl3yBkZWF6LziIVkfkoXrDmfMizrQS5Ie5IG2zLChhAelwVDXh+qc4sIm9WbScHpLWfCwXn0qtrJs/5xeBULfXT7mGt4nEk+Pyf5jIz2GTSDs+3hTGYZxSZlbT2TXz8UDPYJCXXawlSWkcHGziIQCOzfxpKYGNb/hQR7tq8KRbHiK7+UULyodnTwio36EKpi5lcZ/2Aod8Pse2g1G8moF2V2j95FTVCUlU3SdvS9U+hsF4z86tRfKVEnBNQN3m/jvK6nMKF+IV9tvAubIjbTiCx0L1b3i8dn09NJEVniZlNMuClGFK2r9FEhZx9uvdi9gnzYEBKkztNNgoGf2KKnb/cm4iQ/L8jqcUXRBzuzZX8HdZqPQotMyqD9LPtlEN89NYR965e3vbfRx7Hu7nNIcQQINw6jquY2otvv5rQFWYxfGyXHFyEqSeywGfg6wcv1B1/mpVfH0aUkhQ6VIU0E69HenWlt2oukN3GzOYcTo2WcXrmMjp26cqC+jLXZWwgbFZJa7My8aRpjG3fQv3k9BU3bWFgdjy9ipUbX+YhzvnT9NO00qFMgB0NGiu2l3PfWFf/2dfDmto8JGYKk+tOYevE7h3++ZtnPmCrqaTkQa70UHGD1rytZHC8+i+FNexh2/qkgmSHSjGm3+AzVSYSB89bxgn8NS6RWzg+I4KFaG172sFZXyvV4GUuU59oPIHz5MPSGrdoGWLhnLEs/vvPIa2z0XZgiZrxyK79a2yaGvjNmsb1ceP40uCz0fOxHAt58zNEwpVaR6XdDjzXYSpMtiYFNWxiGgaqEdC4fYKPaYSTeF+ZB7qaTfqem0/EhV3B2rgi+SjcLg0mPYiXVE4/TLdaElUXdVOUQHIoDQ0SQpCsCnSnwCt7HzrCNAXVva4FHjRp42CfRZNzD5/GtlJtiZG1JwmOTCJokYlPBh6EmPRZZxhmVSYxEcYTteMKxyqNBT3wgFachkzSDQgCJN9MbeXh6Z0wdxlOrJGDTuenv+AyTbOLll3/Snnf2FQ/yjUmcu9ODG7R20CadGLu1G5fitc1EpzuATqrBafgESQprvBAVYZUro1bB7EYm90rgyoFJbE6xY44qnL+jkheXl3BZqRlrpBv5UpH22KZwDd9bdrIl3IFfP5jAmDe+o+70foyp2IwUFkFpqDnK5rJS7njqNuIj4hoJWBvpkeuiNk4ETYPrXMQ51OsGnl5VwQ13fEIjdmyKwoi0NzAYagi1wOK6Lmx2FGHGj7xUEG7/l3As+Ph/HKtLl2pTLodaLr5QB56r2k9FcjzWqJ+7d73OKkM20RqhKeCIK2Jv1h4Mru1sdoWYk+hmbuZOvs2dy+z82Xyd9wX78ooJ9NlJUycDfpvYoC3+auJK63l7/xj2eFPINZRyZ/zd9FJq6RsycrxfcCFeCOdTr1cnJIy02z2A4r0ruPOky8ivExt8abtzaXSG0EdkVnw2/W83nzskwX5Rrg5HxE3UmgEGHVIoymMXt7l3qqiITa6kmtos5X/a9Qu7QmsJm4s0vof2OHMyjojYLI26gwQO7CHelEJEDlGuW01VjAzax1dIx1m38e72R+nqLcajs7KXJCovmEdxUVDrr6fWh8jViaCi3qoajInARcVn0nA2yP0OBx8VbhszX3uQbt9vYDtmuhtbCRmjGKM6Vq2czbj2dnYSR0vMOG5sxSC+3NaT5o3xRAI6THERbANrKKm9lO9e7MOyj1/UHpdgd7D6zhu5doQJnbGeVlMCn2TfRH3jOTz0upVn3aO40p1FT2+UsCQx3VXBqtzZZO5o1DbF8iwbN+U6CLor0Jld3L/dynEShCIhLp9zPR6zD5tfz3Hrkmg4UMr47AF08ewVbzLSzHtl4xl8/5H24Yl2ke03++Po5RWBwCLdTjZsbQuc/iqeef929jhU1UmJk239sDnaxjoXTp+JpPhpLhVVr1RXA1NnLKfV6MIR8XDpecMYOfZUAmmivdEaaw2oC2GW+UzyfcPRK9mka9NfUIvM6JFxFBfWs8dWrNb1mLvVwMzddfgu6YWk34mCg7ztY7jpyacY9OxrdH38VU75fA2NB24ia91l1FvjNQ8XFQ36DJpbc0lTybtqqzBJkJ3N0SCl1rzDLZdgyK2RF08f34WhCTauGWCjwaIjrcXPQ7rbyTGIQPsLzqdD/X6GDReaITSLVkuz4qD1YAl9N4vqh99sZE9ajtaiSrWJ6l11aw4D7jpT+74OA86wiVqdge+sE7EkBPnEJciUhUERRHT2JjM1PIapb0No1+149jzAuJWns+rMpWy8cBNrL9vOisu3s+SKHZy//2Lax9SI+5jgYPM9lGROpTb9KQrtiZr66tcGA5/bprPeJSaRutvmkWTYT1pzJtOmvS+u+fNfZ6fRoXncZLTOoe99TxDW3G59hJubyXzyIvZklmHXi+kwOSYb/2FKC+cU6Zg0xMbiNKMWHI0oruabX73cWqzDlr6Qip6vUdzldd4pEFU4l9dIQApQ40liV/sg3z91HiOf/pjGC0dzQrm4ftMD1dz0whdaxarv2M7YZStBKUR1cQt33Dsen9Gr8T/OqlJVjsHXGualedvYHRFJx1ifG3P+dPT6JsLlYV5wXqD9vKthCW+/+Rz/SzgWfPw/jspIs6bvcUjVdFukE6tSRRnvjtIPWReKcMLuTkjhAOiNzEzqjDlBlB9VSemxHh+FoQgmWdFGxFpNrexzFmtZ75zCYmaO2sS3wyopSw9qfU052Mp3ZZ2YXtqHZl+UsxLuxZewgm4hia4hdaHWcXk0GUVqQJazsHwq1D2H62JjixmZrO8aR1SnYPK0Mm3KkZvQ34VrJl/OmYFS5Ewxlmhr8pGR0eZTova+K2ISz7lpbQTHp5c/pzmh2vUdSG0QlYZGfSouZ1/CcoZW0i2KCUUVB/awu0YiXQryQnUDk+S52M171e4ub2ZNpP+gmXyRchwtBHFaRMCRqpZaTW36GoUxe3WdHMVvtDJfOUlrvVgSQoRsErZ9i3G1KNSU2bTKQJpLBEoGdwsXn5RLkuRlpsoIVDkMviEM3XUZVXufYdv8qRRvmYCv1YXeLGPr2UIg4zXmvt2dH6aKIOye8eNYOfkMkuLVVojMwtx+XD/6Dmq/KOPMAXfx4dVbmNTg0vxy9qSuYWvuC2QeFJlyfZd87uqrIxpowmhPJXNjCle+e7k2GqqW7kdsTscRlPj5i0W4W7dji3oIS6pRu45gsJbnb598xOeV4hTVoJqWDB6d8CRxwQS8JjfPLP3ndun/6OEzLyg4K529Bdx+8dOHf/fclLsw+cRn2mLqJcY8JQV/gU4jKo9v2cewMcOprd3P8Xk+4izZVKYJMmFEUqiy6DFIu1gnbeJGGrXFMYqEyW9kVupAvrl4HAZLBcgWpi11c/yHBxgbTWenWpnCzpWtQzA2tMPrKSQSyEYfiNNk1LXroPWgdgwqEqT9uJpE4BvM1LHsrkEYI1EOxpR1B2PAG/XROc3C2voWnujnwGuQyKoN8pDpJlJMldq1soOuLOJ4jpdTtOt9xqMXMkwRY7XNsh19ayPd9m7SfJ9UrC3ojMXrI80kWk3e7J5s3bSSXEmYp/1KB76zTaR91468yipkSWJMs4Q3KibAsqQsxl/5EutT+hNUUnEGotx87zXYnQnoDW1aHdr5jOjxxsZtjcYASkuIokYvww5UsDrxJWxxKkFdYbXfwJtZIXYm2bTPanjcm1rFwLsr1jLNbccS3WjUdzA6WMEHr1zGPq/wq+loW6+9774VX2ktQE+gPV6DjUfyr+P5bhdSnG/XhNk6lAe5LbCR0SX7SfH60ZnsuHT7KAlu4PGWraxKqCdkkLU2ihqALHWtJ1hyIpVFG9ny8zcMu+9lvP0Ha4q49qgPry6NG6+bzNCRI5B8Yv1pNNbwzhMfUzgkgkyUpKieDooIbN/b3kCJsZP2/WhfiISohCX/XfQ6D4tL27Pa3h2zEiYpuIGSmv8d4bFjwcf/46iRg2T6nPTUlWgtl6ldxuM36ynylnDxgVnMdsRhqhULbnJSHypS12hBRl9/gDsbm3m+rp45FZWsLT3IjwcruKg6k+4N3WnnzqJjMIpFVmh0hVnUp5pZIyvYnePWAodmn51vD3bjtcoi6izfcLDwCUYGIiRHJRqx8DBqXzOKEjhOmwB4duINZDSq46ESkaRz2dhBbKLRyn3M+kRMx/zd2NQ/nUiuCBQ6VIqph0PY8utXqLmm1j8/TqgK3v/j09QZyrSMOckbj16WiZrMXOQNaS2GQEiMXCbrRY++WN7AMH0Fc8qrOMHv1XRR6r19mKH0ZZOrM03GODbm9OTnVU9om4HVH0X2WBg4pM3MK1sS5yFXFyU7UovbnMBOqcvh6ofOF9IW4cR1Fpp1eoZYRLaZVW/mkS+e52S/mYTmdkio0zBWetvLtMzKEownvOs0yn58loNLb8ZT00k1LMXa3oe5/1LmzujKd4+dgCXkY/09N3HRIBm73ECDNZ4Hh1zN4y8sYtPubRxouAzpwJXIETt6SxVRHsIQiVATb6LUUcCP8WuRw35srgJu2NJLHSNgoOMEzBGxqXqD9RxsFZuZzZLA0mQxkWFrreCJW2/Wvt+1fydmgyAA2B2jyc/rxDi9aGttdxQz9f0jORN/hvs+vlYTLDNHLNzY+8rDP9+3ewuUCPJo0J7B5EeepbxRVDcGpq/ntMqfucC/lPJHHiD8wg6yai9lWPIEKtJFq6P9gZ1syfmEdPNkBkkf4JWNmoy4ivSWICVOK88tXso3V56MzlQHsqqCG4cXPbfTygGCJKHjbfT0s++me24lJ7Qsp8niIsnfTFLXxfRuEdWh/KYwFxeJykp1gp3NpZupMSYS0RlJkCO0R0ezEsbgquDdooFEdBJ9KoI0baxH8ke1a011rn2LGxnWtBx2/kz9k105X/6OLF09UUXHrmA2khzFHI3QzS+mz7xmK1uz1KqBTH04j8b0AL2qXqefJLL6hZzGyJPO5YmKd/DqdPTwRrjhpA+pt4iqZt80kfQsyhatkMHVm9n3YpvT8m/RYgvS6hY8CXXX7h+p5oLNIV447yJ6NTZSGncJidbLsSkyJUE918UnsttsJMu4h27pn2AP25hyv/Byufbej/kxNg49LrqEhpFnIisWTIZKqu47F6dlu7Y2vpYxjoEDP+ONvHOJGNQqZJi+SxsZXbKCTiXv4TV48XrENeLb2Zfnw2aqXRKpoSiKXpgKdq1L0uTxD5pqWFnfnm2lD2nV25Oeup9EiwgOc/zl/BI3krfOPYPJz91EYuxeUKx+cvMyqMtUK2QKx7cYxWflibA5/xJN2dVJgAtrs0mSwZI3HZ0S4FnvWdrzT23+kYe+E9YK/ws4Fnz8P46aqIUTdSLTq1I6siJfRNDP7nmeja0p9CnOFxmV1cWXzgJMCWJs69rmFmZ3S+bjTu35IKsjXyUWsMuUzLjwLoa3JNKrfhAnVQ5jRWkFP5VV8EZ1LdcE6kjPL2PH4P3szm8hrJdxui2k7cjAuMdEcf7jnBhQMCqwUHGxDJG9pdSdxbK5z9HPL45zT3oB0ZzuVCcGUOkSuxfOpqVVkCn/Lkz68G3W5MaUEg9u5sfbjxx73LNDcFPSJJmU3I5U/f/Yewsoucp1W/sp9+pqd5d0x92IC4EQIIK7uxM0WIDgEoJDcJcIECLE3d3T7i7lXvWPtb7G9t7n3n3Ovf/djHP2ZNRIU1VdXVVrre97Zb5z2pv4pX6pfJ/eNQhjm2gHBbQ2BmhE77bVKxYgveogKt7iqrhFTFR1yJtQRTSdb5X3Mlg1mxJNKdfUC7fOneZhZCaKzTepzU9lJJmy40I5Un59q1iwUtUBRuaLcveRbpKdFHxUu2JQJYdoH5LFRm0+OaYueeGyubR0UEGiz4QWJbVhQYBM0sbSlHyC5phGXDonYckuvKkPdRvvpXLV43RVnEYkrMaQ4sN4WgVbd07lvTevxHb8BF/fNIp+DjHlsCpnBDe+d4RNoVTsvnyouIVMr5qwogutSzgV201KRl19KTtYTlRSX7UO49U95/HeeS/h7zYo6wj7ULsE8Xa4NZUZ5iT2xogRZV1jNVvvfQ7/qhcE7SWqYMoerayee21lHz4uv5fXKh9gTOUQ6h/+nIaHv5RHWBse+p6GhxbT8NCSP93qHlrCjQ2X8EXpPL6peIS8ZWFq5yyVb0df/h5FxIVeZeH8lNPZ9sgPLK0UMvtDU/dye+4Y4jMeAe/pRLHKU0TVSaV4DSbUoSBTNi5luzYNX8QsT198ofiQQLc1a+82cXxXZ/Rn79aVzFZ+zSNx9/Oc+jXuyTzI7rlnYDi3DaWyBgsGFniyuCOmiR1GEYT29G/iqKWZQjkchqPWHAp9ifKEkZSZf374FNU6IWc/OBSUWxJfDMhld7aYtrqg2seAHd8xOHkPFpu4jj7mOsY37+WVI29yoWK1HHQEo2q2hopZ0/slyrtE5SBiiadfze/TNit6FuFFz6lQLv0b36Yg5CVfJVo4zeEU5my6mSaNioxAiGcnf8pPO76RxdCkds15U2/khYdeo9IsuRdHmV66jdi1f5af73J0cPWnn/H+8BEEHCnC3Vah4JbYZdQFQix/72cuV9SiDUc5kTiBYf6zSA+EaI8ouSw1hY0GPcO1S8g97UWyQ0qW/yjGtoOZl9KpVJEb8lF9/C1au91uc6yC4/JN4lTm9z2fLo2VTGcbObs7se9pZoR+NyP6v4MvPgan0kVLRFxH8YFsmbvSpzrC+2PeJ6SOYXXCeI66LyRk78cW81HGt45nsQFWvDwRrV6Pv7s91MtRhl+t5VvbGaw4exhJOVZ0UQ1upYftyw7x5GM30WxrxBxVMLjbb2hJdYiTYbEW9PTVMLfX3SQRQp/1MXv8uaxXDUATDXNO4GfO//R/Bv/j38HHXxjrt/yAK5j1W8vlo0whlHVp4zIGdB1jZTgRU5dbbpdkJZxGaeJGicnGMBcccF6LvW0kaUldZOZ3EN/bCYPDtI5Uoy3sQhNVUUcan3ADv1hK8CgSGOyNMru9i4876nnXcIiLCveQnlIPqhBxTi2BDg2xOW8xOiiy2DnROBxyRm4if3sMj46bTJzDJ8tH+7QjOVqskMuZWo+Pd+b83zOfu/KzN9icIbKw/nUn+eEKoRj4RzS5RaslrXvM9rYfH8SrdqMMGeitSSO1RQROFmUieksmUckeXCuCD53yJKn65fJ0xiGtlqtTkmgZczcfU0i2spYBoU6GOI6QFRSLtkUnRhiTWgNURpPZevh3obNDUUHATVS76Ozu7x+2i6kRU7KXoEZBY89YPNPu4pTrDPSqkOywK8Hm8HMqcS+lCVXcqZQ2J69so35zMIGbdE1cmLiJMQXfkpz/C80Jp2gI66k6cCFly56j7ejZhHwWdEY7+SVb6DvwE06sfoYJ1iyuaCojweeUOSlBBWQFFVyVA99d+gtF4RyMzpUoQx04jSoe3LCFV3vuZUVEVK+KLRM5dNNzTNIPZ0ra1Uzz9iQa9aJTGkgxnM4URR75saOpMEpiWGH2NO7DHiOCE7Uvlmion6yeGw6VkBzIp8iXTWZA+v6z5c8mjbBGoslEoolEogl/uhFNIC4UK9904TiIxKMIx9PpCVJuF+2GIQmnE40kMyek5WBHIQ6/GZ0qiD1rIxGVD3vqFmoHvcjxiffyc6poRyS1t2D0eYk71MAW+wWyRkQfwyaGRkXLzOLtolennYAyyjeB3XyYXcdryUpaEk9wR+vzNM3rQ+2yjznU4xRKZYP8/tP2D0SpjyHB20l176OyFb2n5BgxAel1tCxZtJWsbm2UKl0+1XohZDUsquTxPnqW9xTtoNtO+bmzZhHDxi7nmt5fyEGc3ZPAC7ve4/WTz5EU7ZIz6vXB3uw8bSGnPb2Tgn5jUXUTTQccPUxBuQVt9zXbZdLwcvydJFl2UBDy0KZU49KJv30wouaoQS2TRh/Ln01W4RBOucQ5nuyPl6d4jraJSY48dy05DkmzBPZ/8oJ83/c/fMX0dUdZkdmHsFaDMWKTKxISMuL3c1iq4tpTmX76TMY3CGXddVkXcF/OI3KVxadQcHtyIl8azPT07Sdv8jwcHQvZ9s1bnHvZfSzRigm+Gf4DbDaKqpYEj1LHswVXk+Tr4JWTz3PB3qUEPXXcPeB9Rgx5D40lRFvFODwqD6tSRYIUZyhk5tYoV59KIOzxsyJ+NCcsxdSqU/E2XIyrdA4LIkqSqy5mVVEnq1+fjaGH4G0khDuw+Z2U2zJYpRtL6tcvoPeK1lSXppFXHn6V2Q9Ow6lzMMyvRhuFoCfEWs1I+Tk91fWMH3Uuzw+aQ5rCiyH9c17xiEB5Vssa2mLiue+7N/nvjj836v6NvxQ2Hl9BuiOPQSqJZ6Dg28zx2AJO5lS8y8HOFKwOabMMo7Clskwfi9YmgpQBDWfRpNGhqC+mUpeDKbYdq76ZBHUdsco2ctK2E2lPpb7TRB0GUsLjCQ5ewmb6Uh3JoiUQi87uId7VTlZcA0O0jeyuyaSg3sySgiquVq+iun4i5Uojt0RMfCaZ3oWLiXz0Pv2zC1hnHcHRpJ682PtuvnQ8w4gjNpStdXyyYAFXSjoR/we49cvXWZ06Ss4YixtqWHr+P1bKbAqKxSBNZWfp4eWUhffLBDBv20S8BbFk7xQCWYMRi5jdUUpJYgmhaDxqRTsdfgM/+NJ4pV+ApFCUAaddTs3q5dxsXCbrfRzVWBjZvJvS9GzUijA6XxiLKwS549hjF4u5hG6jdRJUXezoVpjs4a0gENagVQWxZrtwNqqoW6XAyHgOZ3xCvqmDRk8MGa0G9vdby8brfmHso19xLHSCntEBRCKpEEhF6mQkuCQRNYmkGESprQdTOW5NM9WdRsq3XoEytpG0/O3oYxqJK1xPbMEGXA39SD85iXUuG7qogguOL8cWG+TntUr2Zc4l4t+BpfN77Ik3sDe9F9ccHk9PUw9CdSdQJxYTax1OjKMWlS2Jk61CyC3ZmI1fuQPM9VzvKeS++IFYQk4SA+10RuqR6iReh4nW+I+JhEKECRFVh7Gbw3hjgsSqQ6ilL1YRltuGUUVYLtf/I0QDoPaCUjJA8yjZuTdVrhbpTCnoNJ9xPzOpJJeYqJeoVw86Fx2Jq1H9tA5vDz/2JCUaZZRKnZB9Tw+7CSuVpNTUcSg9FovnHIaZljJMs4td4QzawjbOalpEo6+Guki5LGgn4WOrlRkOFzk0kaNsIlSxi2pVOjGcDepJzEfJxsAqKpUp7MLOcV0r/Z01bIzvw2F9PKeZ7EhnYZ0+BpUmIAuG/TAkld2pGnn65tGjPs5pcHE4YwvmWJ98zmsCEaYdOIk2FMWl0LM1UEzKuU8yfqgwm5Pw0wfvydVQbShCRquDUzoVhS11HE2XjCnhs7zJ3LN7gRx4LNbP4IoLr+fdtysIRPToAjbuNvRjxAQxidTcfQYnY5S1UvZZhaJpX18HEUVU5kkEX/+Ie/1afsgZg0ujxBCKcE71NpRhHaGQFq3WR8Aa5PTIbmK9E1n53moePXcwB085aDJo+LBew3uXb+PRD8ex2hbhlbhYSp0uznQHSczajyt0kJ9e/pA+gx/k8M4j9Ak6sOoPsEk/lDGOXXyYeh55jbV8XvMApqifeSkX8lTBM+hUASJhCFYOp0LZzIbUDYQJcONRL0qNkZEdw0i49Qxu/d5Fo8om+9OUuCuoj+lBW0RPq7sIydlHfeBxGhL2c6FkmqfSEQn7uTXsZh4WlhaMZeC2UgZtfZ19E26gS9UJKgj4fYydmcTOb5wM8anZagjxSXQid0S/IkHRxeJ3n2LmjY/yqt7I7M2PU5q6m+WtQ5iq2s3s2o+4I+8JBm9fxoUjpvHfFf+ufPyFUdbpYlxY9Ch3W3vTrEtgbsXr2IIOtrVno/WHiajU9LCdxs6E9RKrkTHtCbSqRdYfVQWxnIxh+AY1Rb/kYltzOv4tF1C/fQhKfTlxiKy8zaGjq7YPhZxiknINl+i/Y1byz4zL34GxT4BdE4owqf3oAyriWs2s069neuJqLHipUip4KyxaGGr3OVzrOIzFE8StV/P1kTqK+0+lKsWNMgr1e9dRWfnncdj/DO7//k1+TDxN5pXkNbew5NwxfxIV+yMaQ4LslqJp49Wdr8l9XIMvhUDnaTQpk7G4HShQk2kRI3kRdQOR4CBaQ4+yKDqZjysGscpqkEvGvd1KFvy0Azc6xne3wPapejAzYzQjEQZw0pSLI2qmpb6ZJlMC6rCYZvgVcRoHtTqRzea6mgjVGX5rvVS6bKRrNxNWhNgZHk6uWWStKe167MpGvtq3mMdnDuLmaC6X0cD7isMcUG+jS72TqPKULLctTR9J0tsR/ygMrlkUe87krPAQpradzoA9V5Oz+RpsR6dhau+JLb6KgvEvccWo5zk3cxFJhWuxtZwg+/B+vtu7lY07Y3j/6GkYfHVEVAa+zLNyxFCFMqGIUHspCqUKpSmZQ3VLqXKJsrtHH6Dw2QcpnPM6u+MyeUSVwtbE0/Cq9BgSxAYW1DfT1n8jXcO24By2A9eg3ah67MOccphgwnFcsSfpilTT2d5IZ7md9kMBOjd0Ev6igfcrm5jtbOHrrU0kPNaI7dlGrK82snVfGqFgpzw6G08jLztO5wC5qCIhznaUU+sdJQ6AOSDNXhPzo5rkZ5UYOu6n3CBaHQPVe2V5bfk8aPbSPmI/1bZEMhSC+3MoDF8YtqAKlmOKRLi/3U0vTy5BpYLHYtNZERwoe5VIQWi+qoYE7Zuk6C5jgPptbrDFMsXaW/Z7aTY0ERsvjm2FKYPEU8jXSqRTVCUUFiW7Uw3oQ1Fe2FPF2Q0hvIYVZMTVyIGHhJ4nnbSqEngp/WKaLlzDlHkb6feHwEOCv00QSDPb7TJ506f2UtQ92SX1QexGDc8n3M1i/XRuuH8hy1bOBb34nfEdfTj/8jfknxd8Pofq7vuztUm8/vQnODUWdGEfF185gZZscQ4rg3q+zRkpBx4FDg9PdO7ntetuIxgMEPCL53j0KqZpV3OAECWdSVTtOswZtVvkxzamFvLlsm948da9XGlPkjU3frKYeb3RSnNzLip1BOOATjp8D7PHnC/PIS2Lv41bej3M7NwHSS06gwuad8qBh0+jYniPtXLg0dSRTfDYDLbYU1iVugq/yk9qUI3TLdbUUEIRs1frOBWR6MJRZjT9yJj2DUwKrmZK7IdobDtQKX2EwmYONY9mTtNYvkm7gD0xAzAE2ujT7ZT98qCLULlM5B3aiyqqxKGy88WrPzBi7EjC+TUM9KswRMDu03MkKgJAY42QIejbewRvTnqRXE0bi1RZhKUJrrbNFAZLea4hhtrWP2sX/XfCv4OPvzAa/EbOUIvMclniWPp1lHFB8yq56uHvnuRQJuawTqNF3V31yJfstqWMJCzm0qWxyHTLFiZY32eSfgFTI29xRXAFl9dv5fLg66RGdLJSX3N5PxI35ZO2O56UYyaSaiGh3U8Pey2nhXeR1T1uWlxr5rBeS1SzkgtjFsv+Jl+p1ByJSqV1JcX1UxjUIjakQ3H9uXf8LTQUJeDRhdD5Qnz54tz/0nfxzI/v861lOEG1ksy2Tr6Z2EsWx/qPUB8SLPQmXRMdmgZ5QqOrbQJJ6laibSKjzjSVyMx3aaIj1iQ2n4airex0x8p994Zus7ee2iJWHG6kRHmKXtJ4r7TVxwwjq6CYgdE9v/E9KsLJ7K0Vi23fbnLhrwiq/bSqBLck9lQPOusvkn+2ZLgJKpWoo5u58PG+9B93GTq9F7PaL4/cJnfo+ezg10wYUMSIeD81GPkkms1tod5MC5UwOpLCaYS4lSoWqXZRptmEV7MLhVIK8gKyEFYkXITOO4bk+vPI3HcfBZvmU7D+DQrLLqVfYBSp1texGeeS7p5OSld/1MEs8vxZPHpMnEMeyzhey9zA3H53c+qMdwi4TqLQGChJHIdBZUKhNBJTuJmf5g9k2Qe9MeY+RMvpd3DzhA84Vlwi+9mEfCoaNg1GqYoSCSrwt2jxnjLh2RNPw85sXqyzcF+dgR9b+5GqupT0z9wUftlOwUofh5VK9sWpiHjgknVRQsoodpuCbSPykQUTpA02KZVdyhFsihc8ibPaj/D02w9x46x5hCJKuV1Rc4mohukDChq3eejoNpObcHwK9f1yaLclogj5qFwzkPLeEfwW8doNyigBZZDhXh9L6hrZmn4LwZhr5HNqjwUcPYpJebKS7+JuYXOgB80RG2qFG7N6JUm6V5lZ+gmPNfnJDQSpzzxBhqdJFsk7XNZBZlc9ym7+kS/Nii0Q4e0dHUzoVBGjXki6+mO6YsVxSGwK8mzCHQwf+hWfNU8iIbGb0PkH7Nu9C013yyWty0VLdk9cCjdJzk6yJMXUbs2ZL3MnMv7yOSxf9Djvao+h0gteiMYveFQff/8in/nWEFQFSPekceeFz3BEI9qG/R2VDBs9gr3TL6AtJhaT38fknVuYXHeC74fncOUFompSMiILb7dvkjTqm6k9Sm24AmsIEk4kc2ZyPv06OmVC7be6YoKhELPvWMs17fmYwxGO6+Edl4N9Oy/C64xDbQyT1aeWj+LG8n3+QNq0sbSGjPSIKCjSi1Fbp1WFM2Di88OXkRt3N4s0e/gp6Re56lnoKOCeRUHaAs20EeE5SzHlERU2FPTPP0llTzFun1hbgdqRjiVpOYbCp7jAWEOWrgkUQVrUZrbHDecRW2+UoQQMCh92nZmXB15E/sk9JLnFOebWtfL+y+9y773X05FUIbdfJCwNC0J2T9XvQUVhYT/eO+sNmpOa2B8Uo/gPVC6kMc7Clb+I9f+/I/4dfPyFoQvFMaR7hHVl3CgWlD0pZzJbW3PlSkJYb6K3cSi/JKyTR80mtuTjkNapKEyM7EQdlDL3CItCF9EVSpXJdNLEhgSt0kespoWLFR9himpwKP0cCp9GD89JerVV06eyjX5HnQw+aGfEni4GmqTFKUpKuwGLW82HNitnsIarY8Q8/l0KI146iEbjeLQigD4Qpsus5Z4ln/PeVe9woFgEL/r2Nt588on/1Pfw9rqv+UA9AJ9WRXKni4WDk8hM/H2s9m/hdTuo7x5z224RgVBSsDcBZ1/6pFaQ2q3IWmQQ5N2wqx6FQoczcR/tSRvQuIJ4tWE6raJ6MXzojdQHDMwyCHv1A5pY2X1z0bpHZTVJRUBJjCNElTGJvUZh9DXEVI4QZRao1QiCZkKkBY2vGE9VT6IRhez4aUl3E/CGeOGx5+g97HQ26fPINYusSmq9NHCKY80n+fy+89jz8AQeHh3HuCQ/+VqHPIqrJsJB4ng1XMxVwf5MDhZzWiSeCbh4QnGMddrNNOrWE9LsRqmUjmMYVciMsasHekcuiqiaiMqJz3IYe/KPlOW+wU0Fc3g1fjY5rW2gUOO2XcSuYJCX/G6ODX+ViLsBjc7G6OTzMMWZsfR1YOxrx5DrRWsLygFwqsbNWX3EpuBuMuBq6GT3komcNmI/Uy86zrSbDnH2/bu4/KF1FLhK5NbiHs1RnO9+gsEv7xc49fDFOLFMjS810PPH5fQ5doK+q3fSHhJqvWFtAr5QGj/Fie9+ZMdRFnwwR5xvej0dnaK1ZurVTnCYpKURpToqdGuS7SHyfRoyfQ2sGjtdPmK+9jZW7ejDS6IwSCRo49G2dt5rakERp6ZPwkZsKQcY6BdeI5/5NuF2dnL+Hc+ytG0kIwJvcIvjdk6F8mXRK7Wig1n+Bn6sb2SufRs3a38gkU4OmNMpDlSh7BDXhsUQ5oOdHno1t5KquxaLeinl+Qb8OpW077FAew1fpJ1D1BGky2Xg5UeFTPmvkMZOqx+8T9abMXv9RHRBqgZeIH+R1qiHS5pWyM9ThSM4jWoeWLWC57u+wy+No6oEEbMskMjSFR/ybudSmaeS6E3mhdFPsOiDHzhhETokRdoQ1338EfMLz+C7icJ88LbvPmXh+dNJ6dZPkTB15jkEXWISREoaJIxWrKHWoCAhAIYDcczoPIImEuVwrI1HPxPS6nfe+wN311jIDgbp1Hr5KnklG3deSOXB/gQ8Kj7IuFeufvZtauUc+wfUe+4lXSOul5PhXOZsfYRqZzJPlj/ALlO7HCQObBvImIYppNYEafC0cytualVq4iThtT5KDuX2YtPwKWwdNZ6IQkleWQUT9hZhCEb5Oe8bkot7YOu9m/SUFaR7xfpxkAjeqKi87kvuwWsjb2TwL59giZgJKkJ4OsX6Me/JG0g1dGCOwIqw8DvKVLSwafk3v31XmVkFLJz5Lkv0JnkUf3zXHkZ27edYWg4Xf/ou/x3x7+DjLwpJfGl0yCFbe++19GRk0zF6eKvZ1Z4uVz2kRVKZXMBuaY+17ZFkHEjpEiRMS8BAWstARjgFgdKj9bDZfhNbum7j564bWNZ1Ncs7r+KXzqvY2zWFAm9I1nooU0VZHLqXU54RVPv60RwowB5KIRAxkKJvJ9skMsERFQmySuYjifHcFdjIvdYX8BHh7qj0voLEBEuYUi1K1vtMAzCpTFxy1t2czBRaGI7SvezZ/rsU8v8K3+1Yznx3Hm6DmniHj5cKI/TLFYTNRV8t4dGHPuW5u5by9DNi4ZKw65fPkQrZkuuqT9+MIWSmsUVkFP4kI2nNtRjVVuLMon+tNqYS0nbS3OtD1OvVGN0uGuNFNprvC/H5/jB+NIxXiHHeQyoRtGTGiomatFaPvFH+lDGGdkMMpqCXK++6h3yJmCC9fhTcCd3VFl8NhaXfMWL7YzQ74n5rvVS5YjHFh3jojodoUPQl1ySy16wWk6xL8sy61+T/j7OauOGsEXx8z0zWPnkxe5+9gKNzz+SVs7I4KzNMscFJktKFniAB1KyJZvBYoB/n+wcxLtiDkREr02nmTfUe9urXUBrzPW8UVTN0QgqzExLwf7iMVzqPUq3pJLcpyjknN8jCYwHjIDTqvjQGlTwdVFBuehFfyE2sLpnRkdNw7YnDczAGz84UvNsHEqm+ldRNb5HerX9yvFO0t9QtTSx87XdtDgmtpw5z0ecHKa6JyhMIC8+Q/HOi1PeJ49Wr82RVzThfAg8+vBxbuhi5fPWhB39zrA2k5bDUICn+ash31fD8nN8t330eNynVl8sBeVQVovWKUrouCnIgRWSoKc52jhY3kO5spT41m4oe3R4/5T4Uiu4JraiWiQ6lzAs5WWCiWHGMS/iMM/K2YIlqqdYpefPDmRw/uIPVphFEUJLg76Do6X2sTz2P9sBdeMPD5Pt7BgJcat7IDt1tvGR5H+Mpt5QfoNRGeWzrRrI9URShVhSKABUZJpqT9PLEyL66UayLE0JiI8u3yefbKvVwWhu69UJ8Pg4NH0BTdzUn3hfCMv89AkpxHmUo6pnUKkr94e4Wzq603rRr9OT5QlzVXUU8GdbyUvUnuLQObL44nuh7p9wa2HGkXjbHS/a1sn38CJZlD5ArFvWFveS1yBDws/ny3yXuf0WgS1xjUktYovf212+kIqaUZp2CNF+U3g39mdAgpsNWZYzi1AmRLAy+5EPeqncz3OuVqy8re3zCHk8ynzXfTmVsDOpQlPnljzHVWUOg1YvZLkaX32+eid9wCnv629RrVcQFYxnXMI5cZy7JtTtoTijilawJ1BMlFUmkro504zG5KhkXaaMxksLhgcOIqCUFZCdnbUsnrtPBHuNmmtLOp7zfddjHZFASV8VQQw0iHBP4JamAK858nP2uTFrCZjpUbbxy/1vyYw8+eCY9FUqaieOwbKgH7dtE4vYrUlIymX3bQlo8ovr00PF35TbZxrShzFksXue/E/4dfPxF8fF33zPGIja7tdZRPFX3oiSxwI42cboHbQn00/RmkVz1CDO1YTA+TRCiSs5wJaGJn0gPYy9yw0ly5tNkU1JsHEV/w9n018+ir+E8ehrOo0A3i0HBIVzZ0ZvLWgro3ZaGv2s6LV0zKOu6gL1dl7Kp/Vra2wdQaBUbSXaDjoRglHqNmqcT4rg9cIAXrI9wXBHg86jwUbm1ToM6HKU51sT9S95nVr9ziPTujd0YRBuIsvzj+f9b9dONx7YztykWu1mL1R3gsaQ2UiKx8vz/C7f/RONGKymdGVh8Viy1uVSUC1+RqkqRmSi0wn9kiPV0XC6xadWYJHXJBnLNfWT/knBXDUpjPI19FuJz+Uj6GbQB/28tl5LSKBUHDjNEfYD8kBcpl0nMPp36pjriTELDI7nNR40+hV/SJhFVKRhoP0ZadhEJftH6kbKrJqvY7DIddWTWb6CtfwxNzj6/BR+SmNVwzwGWxE2iptqIyybJdUUwe1RypemUZx/egHhPfwudTsPM0X1489ZzWPn4Rex65kJOPDedLy/ryUVFSvqZXaSpnJgVIsNuw8xXoSLu9A3lKvVZfJzbG4VCwVBVLQ/fXkBlqgKLJ8p9i8PM+G4lY0tF0Bk03UyxRxopVDDfqmZz8/eyCqw1poisiisYe/U6zn5oK9PmfMfkq+/hmMVJWCs28CpnDuXGXDkg9B89xZIvFuJ12dk4qR+t51xAfEeUm1aE5U3lYJ6SD24dwMnpEzgaIzbXKeo+xMaJNsPKxV+ibxPaNi5bKiu9GTIXIS7Qyc2DE8jMFlMJEn5+axWFbT1I3PUIvqBkvw6eMVHKB4oyeHy0gilXXUi8w43B8TPbs3bg1oewejSccbAArXzEoT6agDoSQbNuNGWbe3NsVQFWr5+pceJ8XxzTzpvvfIpDZybF3cY9Tz4m3z/xpjc4VuCgI3gvTb7POKiYwSGNQXY5HaU8wh5EK250w2ayAmI5VoRdnLROpjJXZNW1HamUm3LxKEykhut54LT+2HxOWozxzH/6WVxtzRwfOgC73oxHp0UVidL71Tc5tv4YBk13W1A66sFWSgLS5h5FHbQT0sQQNUziyX5PMvWS2egR0ucdSjXmgJXZ2dcwZuTZOLq62GcR36kmScWR2BhZpnxmxQ6+uPhMJE6vfB0c/bONgQRne/pv7rZN+kR0Sg8xdQdw9WujQwM5UiutJpkkb4gWvZqndgtNkryinmyLjuDtplYusot1Z3PWPjZlisrBkNoDBNVVGKJRzq5yYA6E5ISjIW01hvRvkL7KAe5czq++jNhArGwEF1vv4r7TbqBVqSA9HOJNTIxv62CjTRjWnVexguEaBb8MnMrSSRcQUVmweJWctT2F3ieX06vTIQcDbXFp7B9yGpvGjKBmcgz5/ZvJjW1ARQi3ArZozSwPlrAo0JfDGi311eXE2GxcOVqNJapgVUR8hhLF7yPQv0I6x8sH30gkqmVI4DiTKjfJVZ6vdEP5ae//fbuKfyX+HXz8RdGiTmCETzi4pnW0YY16WdeeQzCiIqpSoUnIp1whBSF7UIXVWHwF8nN7eOOwWLJozfmWysJ5ZGWvID9/F/qilZwsfJ3G/HdoKlhIc9HHNBd/RkvPL2ntt5T2QauwD92Ee8QuAiP3oRx+HP3QcmIG1xE7pJXavgNJCuZgUgUIhuHMlnzZ7+Vns4kfzEYuCFTxieUevlA6qaCNuICGaXWCaLhDJcrh71w2nxPFKpklb+pyMfvJSznaKKTD/xYHK49y5/EwbTEGTL4QUw4foPzbABvfbiGtLRdT0CSLbYUUIWFmF9Xw8Xvb5d9t9IgWh0LbTmIomz1V0pimhhhDJR6HEXU4RK5ZvKdoOEBH9go88UcxL1bQoTfIG2RDggiM+h5V8tSaj7gxKLKU3dpEpl18D9+selheUJWhKDZ7iL3WYkIqLeFUAwPim3j8yXeIUYrPb1E6qNULsmlmQwNBVZSJX2zgkrOekhdmtT4ij916nRFyFY18aTmDw44i0rtHbrOazfKY8FNr/nNuwSN75/LcNWfywyMXsm3eRRx5diZr7hjGjf0NDLN5SFQ7CPQU1ZfC+iZOWaqp11XJVbDzTmaQKAWuATc3f/KkbAPfGmNmlP9MLrW7yG0w0hFoYq3jG6LRCIm2/hx4+O0//f2GuHWidxKFMfo8jph706pNQBn1Urp8PftHjyWpLvDrU9Bo1Qx0Cun1LYYKFju3y5Mvhe4cHr52wW+ve+CHNfLIS0QTywEKqDOmyvLksxTNnHfV+b8979junfSwi4ClVJ3AyBFbqWzNxB/VUqUSQfyoul/Ysvot9qp+wdz1NSFNkJM9RJCW1OIlr3vc9khIVNt6KNfiPh4lUKVh847TKDRaydBEcCuibCwUm+QZkR3Y4kVQIWH0Na9SmfcTEXTEe6/lZPQRbvFdxh3BW6mKpmCKeih2nUSvEtWHQCSOun4H5B07GFaRG/8A6xOFSd+4xi0MGjGJyV4hm75KM5Lj4yegDUBZsiBZB1OyqTi0lr7RJ2lFcC70qMgJhRjSfBhT1zfoHYvk+z3mWajSetPW1Yamm1yq9eRwU9wMzj1DjLA/M+ct2nTxMom3tk8eOS4fc5p28Na1N8ltLd8Fk+Tjp44o2DTnz2PvEWl6qbvVe9gkql9jDMsIHT5BU2EDLjX0cqq4pkK0TTakFfPxN0JcbMaDn1IezmBORwe3tKhxx1xESGNE52tidrGF+tyH+E7fi1almiaViqtTk2nqloQ/3aHgtpZhBBHHxB608cDQq2lXKMghyl3+SpKkClVUtG9HOTeRWFXGkMOvc9OmZzHTzBfDziGkjZe5V2P3Wpm87WOWbWimR/nnlJw6gMHnxqs0czR5IMeHDsF9eha2/gGS4zrQKMK4ojrWh1O58O2jfPfWY5w1bTJ5cX5Wdwcf+comTh4RU3d/xOgLL6LRJYTc5lYvROny4zGqeaJMS3mdSLD+O+DfwcdfEJ2uLnJTA6iIcFyXzyzPz3hCGg61iQvFn5hOPwr4JGGtXPU4q3acbN+tiWgYpuxFS9GXdBQtJ5BbSiTvGGnpJ+UbuXtx5O/AnreFrpwNdGWt/adv7fk/0NQrhWKrKOPGlGkYpxdEuKfiEzil0TAq2MEi02yeUTURwMVV1VHZU6EmMZY73n4NtVrNU1cv4Fi+2NizKn3c/u0VnPvJZeyo3vvb55cY3tftaaEpzow+EOHiDQ6KqwuI8UrUMCk0iNBp7KAl/SRXPTuUZptYNJPsKbz11ifs7jaX0mjauWXg7bR0iamG05KqSWppIlmfg0ljIxr0IJmPthZ+j7dMT9w+BRXp8ThMITyGsFy5KZKTkyg9TWJx9JRF2T68JzkWkaHZ2qWahSSDL1pc0WwDk2ZdTmxzGmZ9KdO0RxmoL6dRJY5dn53lOC8V5fPUhDS6PNbfBcfcsdzq+V4mI76gvJ707spKUbMIprY2CEOw/xMUpCXw0EUT+ObB88kv0RA1qsEboq66gr1e8foDI8MZGjcH04THUeWNJamzkTMPC6GttwqnU1wxjYxW4ZvzYZ/dbPZ9L/+cZx3FyjsE10KC0iyCZ2XQTEK0J5dma1gXPwa3yoAqZGdz7/6yt4w9RoHtq/cZs+Ewz132jmxH71N7aDE0owlrua5QkHMlPHfvXWh80gajpNSUy/7YYjkbPafrOHNevvdPn7V0nROJfnIieoTeFe0ce+A9LpiylFWNZxNWaLBFOygYdogfna9RZlDKEzOOuOtJSxtMUJ6EiaLurs69oZxFuXcQqxvz5GBLQnx5C893PkaxXpCVo3EHSOEwAwZtZuUrt/7pvYy64Q1qsxcj5ecjXP043VDMsogwScv316ONhtCrRPDQNmCFzJmRAtNaxzX8WL+NLmUctkgHV/Y8W37OrfdeS6zPIWu1/Jg3hpUFfdicNIQViafztWY4bx8O8L7nEraEiqgO2TCG22kOZqJp2YPRuRy9exMGvwevXsec9Tu4/ed78RmF0mkf+xCunCXk8d/7/G22WUUglaDqYKSjie/6JXPDZb+L+p328OuEVKKtaPlJEN9/xbX3X0U4LPg17TadzD2zqtoYHPyQQxXtlGfU4VPCrDoDg9t98gTRV+o8uSqq0+s5nnulzIEYpDLis4yTX0dvf5/Hjj2GRu/i/Ae3sVSZywXpKRzS62SNkjebWni5vZpi3sSutNMaMfEdCdgVUBQK0TQ8mb3dkzo2XSop/mYGnyxn0qJTDFjfxYXfHmb+8+/yxQdzGdO8i7AmJK87mtoWShvX8EBDGmeu/45bPnmO2w9/w1ltK8gJlsvBYlNyLtVD+uCcmAGFRhTKKHWouL9mKLc8/jGPDglTqcmmJpKIRhHk0Kcfy+/jWNkxFiy4j7fvm8LSqwfSdKKCcFBBvrKGa7Z9K7lXUp9k4aq1Zbg8IqD6r0Jq0a2fM4pF7/zXyP//t/Dv4OMviOu//47JHpHZRN0GDAo/K1sKZMGesN6INiaDDqUCp203xoAFrSS4JCk5hvMIJBzDniVIfo32RGraU6ltzaSmqi811X1oqOtJoKMAQ0ehfHN2FHCqI4+yjmwq2zNob0/H0ZWEvSsRd2e6/PtddpGRdeVvIUMlWgUut4+xYR1FUhldCfckptGoVNMj5OUT3SO8qzlOhjfKpKaQ/Pxj+mE8+/y79Egq4OX7vsUZo0MVUTD6QCy1wUPcuP4azvroQh5Z8CyXraiiNiFWLsFftMlFql3aBqKyaE9DUhkzHinmkVfOY+6jN8vlzBtvG09QGZQXiLYyHUe6iZ79UPDB1iqiYRMKtZ1gnEU2k8u1iM8QttdSP3QhkUgE1SYDbp2GDoP+t5ZLL1+Ym8+aw+LJg0mTvFkUChL3qbG6wsRYRbk9s0kIih0qy5QXiLBZz9d7l8v6GpLhVLLCh8tslgMKa6SLjLIGebH+FbUdItO35Tnkd50abWJY+0FcShOlelHNsnUpUIUUdGga+fqAUGn9P8WHX7/PplTxt0vKdmNI/VwmJxudxVzecKlcDu/Sa2i89gzqhw7kOccDxHiC8pjmV+kDZEn4oEaqEsGzAzdwwiU8fnrpJvLDPUIuPTlGZKF6RxYl9S2M/Ox17t73HSuSTiekUKEOtLFs5EiG7zxG2gCxgScmpHKOYZhcfZEwyJfP1MnCfGvP9nWoG0QlotWSzWqb4DhNbj/Ei+//HvRIWPXJN/Tv1NEWbSTfk4QpJp/smJFUPPgFlUFR9UoJnZK825hiC3F/ko8B1on4zWNosiaSndyIXhVE6xfnQnNIxw+OQuq9MWiUIZL1ojoybPcmlocvINopta6iGHMXY8r2oum/kmXv9GXjx0KAS8KIm99me/zPBBVBYrzSOSg+Y4JHuKHq1Wb8pgacxaLdWtmSwcwxV7E+VXw341o3kZFZwNP3vMRr874jzi8Sgc+Kz2JB7yvZGj+SMnM+7dp4DkeK+T48lr2hTNaHCjk3+BgjdTfwY4Iglvr8p2NpEefwwaS+VOscaCXfGqnq6u929G1u4G1jXxrDIijqRwfPTxxPvQt+2naED1fu4uXvN/LYp7+wu4c4l3QBuOXuuZz79DecOfdrZr26grBfBKomUwc3Bu+jK5RCjLqZ60Pz+awuxKLYDsIKeOhYCHUkysG4WB7/VFTRpl9zP+vDvbi/UASWvao7SOq006JR8XDHF9z1Wl/eyPDTqZKcc824Gu6kIjKOvdp0jlBEU9TC6kARHlT0VJZxRvwHEuudhoR2wgEXSrWOO3dsoPfhTeJ7SYziyoCoOooyoMBWA2ftqaYytZ0IURocJ2grLyVbmyGPBAdPbuDsvW5e22Tm6VMrmF79LYPdOzEpPfjyYvGOSSWcZpCn55b7E7l4rYZBumNU+cWaPc63hAOjS+DsmUx+axnjfqqhx3YvUhzYcUIkHXOCn5O6u0q2NijNSuKMb9b/Hxl2Ln7+asZrDjOt8XUO7Rbjzv8K/Ftk7C8GiWB5MqGQ0d2VgCxlOQ1eC5V2IZfsS85iRDiXZxLXyHyGM+rGE1WGsUVMFCgtVPV8Sn5eoz2By2b8Tup8as5LhDUuFGENA8+ZyuE1zYyym5DodZsJ8iRe2a1FR5Ar6SKgF+qLVk8SFzx2BbvWnkbE4sLZ20DOLjdVHhNtewu4+IwdvNygk0l3z8XkcqezjryQl8fVT7KKJ7mychCrUzUcy9Ix7nARjz7xDk89cRNTr7qHjW++jNUD4w+k8cvgeqoVx+iIu5jKdBPKcJTztzpJcDhpiG/h9Am5jJ04/R9+ZwkJCXQkV5DUWMSx5I0E3EIJcYI6wvPNIsPJiu+iwprDxOYNZHQT9+zZBwiamvDtjSPliJc9uelyANDQTTbN9cWxlRhKkk9BCHaqU1DaNOh6+uSwXRGOEmcP4pXMqLQDUTV6CWea2JPeg5HN3X4nnjgcGWIRSXQ5iHnx6T+999GD7qOr+RK0lhA6W4Bah4Wz80/grdXzTdxkZqiX4Azp6d2QzMGsJj7d/xUX9f/H38N/BsslFVGFgj7tLXiM36JUu4j4Uri9/lp6RJW4VNBQ0ICpoZOBWTuwKDq44uQWXh8wnu19e9PryCqUGjPTtqayqX8nswcu5sM98SRZBzAgfDpfPXg1CZNFhqbe5cC79gnU0Qj9Wqo4u2Iba7LGc0brGnSuJubdcRtzFghtCQmSWVz12zW0R3w8Nevl3+5f/b5kue4lpLLyk22UHNBJI80vv3TLnz5bwOdDW5uGP+LC6PKhseYS8TtRaE0k2Pqi0IqAuNZVxjcBDeclBknVRblEu5SuaDZ+lYEZ+t2UJ9nY5RIy3saQg3Bng5ytjUqqJ9PYymcVgyioPkGoQ8ualLMxW0/Qqveyr9bCoCwnhiI3gfC7/PTaV2SWPMp+ZRFzHZM5N/57Am2/i+OpQ+J80+iM1PZZgDTKFgipuXzGKh7+5EmaY89B39XO8eNpnLZ3M35tCfyuYydn3MaQm9RAE2eb99BfVUm9IoYVoRnUoyEY1WPXtBPNEAFm0N6PUMMY7IoQivgQPqOaUPApLHXN8nl9KqLh+uufwZ9oRmew0amMlx2kf1H14Jf5orX5dyi4iSUn5qCPBBm5Zx+PnCYI3hJ8nnj05g60+i52KlK43j2bhaYX5QDkndDTXN4yh9VWA/PcOi6rCvBxno6VGaO4vuwkBQU9eCv/Gk6Y84gLdnF/6ecc7bqb9UXvU2UrZ61NJBoznS4ONlxBYnoh8c4Cku0aXlIfYXUoXbb9G6E8wkLNy5j8fq7btZ3JQz+kJdhKqtZMUZMF2wFp9VOw4awx3P3ge0z96ifU7mMMLNtJj7Z6BjodfDs4xNj9ibT6ajGprKjRUFCmo0f1IqLq7+mfrCA9WcuW6HD0RjuJRa20JPflZE4m7RkJaI51EXTBdmcJh40P8kX4KXrE1OHzJqOLugmZozhSlTQnGWlMSEIdk8d1viUYzC4WtH7CbXuvp3lwOmU5mZz52TLWXy88q/4z8Lol7aid8nHeFSpk9JBuHZx/Af5d+fiL4bVKBROc22Wd/7ZIHEaFl1+ahBJjMCYegyGekFJFq203ia40lIiS5tBQPg1F84no/YTCKgb3F+W8X3HTLZfKioOS8NiiJWu56KEz2JXUJFctRqPhXbWZLNmQWsN7JBITEiNzXkMHL837kENtgrDZlb+BHkbBxvY0uohByXnxgpS3PsbHMvNwdmtiMUpEMOVcUtzVDG0LEVEq2NVDT3JTIXPmfERCcipe2ahKSVqrmvN3nEVSZC6V6TlyGT2v+mcOJz9P7GWdzJt3NWMnipLr3+KRB+9iwVUXEGjex+GUrzmStI1oQGQVm0kmIimdKn3MHTOUhnAqvRUZqJRqQq4G2kauIOBQozdM5Uh6Mm6dFm/uKIa6zsXqi6PVOxhlNMxYSdVSmgRQ9ZRbAxWni0zQ0ibNL0CZOxWvWk9CuWj/HDb3xKXVExtKYuqEWFySi5QUyHV6+WHln0WDBvcehjvwu+CYlFlnuk7y8h2jCdvBahIs/n6N4jUaOMlV39zBbUseko3yXt34Dl/s/Y4NZZupaquRrb7/d1j+yxJ2JQoOSrTrPRyaNrm9cVfrdYyLmvAR5RXaSc7NIq/xIyzqNrlcPspqI6XdTUCrZdvg8RRXV8j98Al745jakcDdfT/E5apAqTUzUDlcdimVSNLRzU0QjaBK7k3d+L48/ONHpPr97LKJ3reuuYb5cx/+83Vw85d8futieQJAwiuPPoDWLUima+OH4labSfM2M+eSYVhtf9Z7+enNZeQ6g/gd1bIhnmSM94SvgUXt2wmHgxxPFM/v11zLFS9B4nw1Eb8CjSLEnbzMrYF3UasCmC1gUoolUh+WFEijhM0WfIlubDovabGiimALNMsmc/lNgtOwImTAvmsU3ho9ShUY+zhojD7E7sr30YZ9rAoXsKrb+j1Jcs2NBNApjXQWLMdvrSYYVvPx2ssY/vBiFleehnZfO1T4qNal41fpZe5FpruOsU3bOc+3glubP+Sa2k95MrSQu7Q/EKevoVgxlsEqF2O1FTyqXUVW5gIUKi/pbh3jj+ShytUSSTZgrhYk0VCuBY9aBMnSdr46vh+bIvk0detWWIOO3zRCJKgIy4mKkQAWhY9YlY+d6WKdGtB6iqJwgzwKXqx30uUUbU+VxidzjY7qErjRfS/2UBI2dROf6Z5B72jmYoWLYJmDREeIZoOGp7bvYeH6b9mTIdabx8rfZqJ6KfF0cPrxWxneUkJ8UMnc1nYebe3iRCSfc21eets1/IibH0MZcuDRN+jn1u2f87WhkBNaI/NzrqFal8lJswj60iLxcpXDkxrl5rsEt6jIVcWu/Cl8OuohHkx4jBcTnybN4GH5yCYCOsnp1yHzkVqsBrwaUIQUmOohZ1+Ay/Zv4qmtH3HHR8u444P3OW/fBq48spqbq5eRLU2xqcDl1TE98CRzI5fzzH23cv2rc1lw/6VsOPNMxj63jFufX86ND79BuUtIso8wH+GhY0+RckCsMccLCpj45hf8Z/HTc5eTqmzHH9WgHPcQ/0r8u/LxF8KtX71OWcpoHj88X/5/HX4Od6XQ7pOsoZX4kzIYEcrh1cRf5KrHpIYxBDRB0sKxmKzraUuvlPvEp1qmM2WyEMz5FYnpqehUOrz4iWg8rFm8nJn3nM/yhV+TUZ1OXlDJmxobK411/OBS8EEoiWuULhxKB2ZNgMWnZtA3sYKI2U2wX4iYjWrsoRAH945hwLD1jPCG2O5Vs8RyigElj7Fs36tM89dQrH6SyyvfZVdCDAfy9Iw+6iOtPZvlL1YQzzBCBg0h7waOZdo4livU//pU7KRJ8w12Ncw/8TyfHfmccwumc/fYm/70mV5/6mGsVRWoohHi2xvY2aOJqKxsqpIXxz1dgoYfa2lg645txOsHkWsWpm5Oy2a56u0/mE/znu10mA2EE/oT0osFaWTjONb6izlTt56ESAi7UsmYM2bT6egkodse3ib2HtaphJHaqFP72TPEQLUpg1Pp2Uz59GP8P9bQ9NI8+fEElx2FIUB1ZTXZub8P6dW1Z1Kcdoq4AgctBxLQuH0YrfE8e1EOa77JQE0nFocKq9eIw+Bhr289SG/zH3n1RUET0coEXHVUixodaoUWjUKHVqlDp9LTHo1FEVtLqruWZs1J+Xcu7biMM11pUoGHx/CwLaDi9mXPkWY8gT9iZE/kQiZddzXDHn+GH8ZN5WDPoah+XofLqMLscZJYn8kXd7zKdw33M91+E8EC8eVU+1S8eYOGIZ0ZTPKNQaURo5evzLuai5/4llJjHoWeCkLHT7Hos/eYdfkNf/eRqkqPEimX3HyhwlzAKVMhppCbS5JDstjVH1F2aD+FXck02/eQbhssG+K95T3ClvxadsWvp6y5CofmJllFdN7hsymL7yC+tI7U+2DvY/GkxzcTiveya2AsB6r6USiZl7jBqTbLlaKL0teR1V2pODOuig87E2TOwEve+SzuOYCEQBNtmg72GkPMu+ooy+bNwtuzhriYDmblL2NCxmY2HT6PH1ERq+ng3GAKnREfttQo7XnL5NddeORy9igG0J1XEDWqZDOzouY6hlYfJDtcSWC4h755LrrsMSz19EKjDOM1aXlHP51+/utJ94fx6DbL/KhPU/dTo1WTHAyzYPQLFN0ygUuWvMg622R6u3dR4RITZYVZLkJVOqrQkBL2If3nVhjRRQJMiglzxgU9SYmzkB4fI09Y/S06q/rQeMYMOSCfs/8Nxq45KN//8uuiWqJUhhivbOHV2Zdy49uruK3jHt40vYJN3chnzOMS/yMsUsWi29GCqsDCuvQenGxxEUxSktbhYFDDIdSqMCNtC/il/Xn6ld/IuYbNTIt5lWPRbLCYiKlXsCka5CUka3sl+QonT616Dp9WxxMDX2Vqy1p+Sjtdfj8pug3gK0FtzQelmvisDr6efy5XPbiKq4aOYHFrFI9JQ5w1hMehpbNtJo6cJSwaVcO12wbg8bYhRZevT42nPrWL6fVZJDg7SWxzYqxXYZZ0PlwBYhxesBpI0lmZt+lZamZcwKcdWZxwJfFVeCL6gwGcxUmUZRRCooJPD52gl/t7Cttr6NdrOHnVu1Gr2ugf05sPPn6IazUv0NQ7haM9ezHxtY9Ye+fV/DPobGtlglIQXDeHSpg0+Rz+lfh35eMvgtLGCtaah2EJuRjbIcbjNBEfm1tyfyOZGlRmdAo1tbbd9G/qKwce0sbRP6ygbchy+XlVbZncfunvfeY/4q4Hb0EZNMql1217hLHT1Osuwj3CRZURYoNS+TKDe+LV/HjHKKp8Btmt0aV0MUPjYUWTyFQ7c9YzME7wJnTHQ5RTwPS4ACnKCG1qFR+XvsSY69fztq4famUjZzpepYcjTECt4FixyMwVsoJJFJctl0O9J7Bh5Bny/UMrDrP6upt4qPfjpITz5c/Xrq7nw6o3Gb1wIk/+8pKc3a//5jO6ysvlwKMxNZs9/Q202QIoPGK6wRbo4vKqtYwLbWOav4Eucx4TS2tkXYpIJEj7sI14qw2UtuXQbtQSUVvxxXev9lJ/OqqStTLO1Ar+zA5NJiX9R/LRkofljF4K8nI7BSH0W8N4+d/smHR6VInM5Fh6BlZHEyGFmnq1yN5TXQ7ZWXPpu6v+dFxSUwWnQR/vR20MUu60seWD+xg09ixi022yBbo7qKV3aR9y3BkkhXKIC6ZiDcZjDEmcH91vHAlph5Z0EaTpGKemk05NE63qGhpUpVQpjnAysoe26GqsHe8T8gvH0En2iVzYNljWYdiX1ExxbxVvhJfTx7hBnlTY7LiQSc8IclpB2XHyq47LwfD8S27AY7TI9zuiBlqmX8yUb2spL/sWj1WcXyVVg2TRq+2J9TyV+R4vJT7F3QsGsXXdS9wyKoV91gG0aBNQRH1UrNzIwT1b/+68/eKFBSjCTvxKI6vjx8iZ/wx3Obc9/PeByv4V5dTZ18qBh4Tl4S/5edhH6KQ2pTLMpjRR0evVFcBizaa44AYWDLuSXzKHkPW5m76Hnej8YbxGFUUl+7FmC8M6n0ovZ/5x4QjVSgOvRq5mvSaXPJs4BwJ2P1+Uv8vtXaLdttxyhM9emcvuwvu5b/djvHfoctp8cZjVbjZ0j33Hp/+MN3YlJqWbpDEnZJKpsbofXeVxjG8/THrvLnwTUhnS7ySzfWuY4VhE/pgDDJ3cyHiLnbhwmM3tIojdb+nDfcF7iVMOIdMb5ZTCjV8R5ED8AQ4ZgujCSh5Jv56iPhOY/fblqLrEGnPE2J9BreIzluUU0EsvKiEJRgtNU3vRozdse2QKTz55szw9lZeW8A8DDwmxOcU4Yrp5LHV+mdgo4axpImmQCidBdxdpCTZ+evRCrr5iIvM8N+IIJRKrbuRL3Tz6RDvxR6NoSh2kHHVRlWSTfW4u0JVxOOMSwlElhZpTpBk2yRyvVFW1/NoHInkMsKho7lAwVzJgREGesp3zAm1oQ36WjJtCvN/F7pQ+sl7JMNc2smbOJuJ3oFDrUMVnkZXp5irfDt557ir69xtMry6RZBRlBOWx9/2+4Qy16/HrImwZUklO98Rc7yobWfXxfFHShC3tQQa8s55h2w9y4zU3cuWUR6nQi4SnJd6IsdVM3iffsPKRq7lBu5liRQ2+iFZuydi2VaHvcmJX2thmGcUnOZcwO3cc8/PPkn8/N3Yf4WIlH789m6RyEdwf7d2fcS//cyJk6+dfKfvKeKJ6kqY/y78a/w4+/iK4a/UOWRH0rMataAnhjWrZ3JorC4qFtDqCsUn0C2UzP3EV+iAMdQq77vxQAq6R78qbji+oZfrp3/6Hf0NijyfHiqmMiMbFx69/KP88YuqZZF6YwJGYCLoIDG1J5sDne3jhiSvQuq2yv1eXuhlN1SRwG4mqfdCvUxbqCvjb2HLiHNzKOC5P9CPJjO2yqHjvywu54u7V3KeZjEa9gcsqROtiW348HUnHqE+sYNIdmZQPbuSXkWLzHnxgCyO3rsLr9nDJoPNYfc1SnhvyMhmRYiGPrmnhu8ZPGPvReD45tBiD10WHLYHTp0+gNFl4xmQ5e8j/miNu9AEffWoPknqqilrdIMY5xUbZ5TpO0OSh5tQIlC3dPg9p/WTuDFJrSmLnS4qxihZGRcTiVqkQwmLJVpE5RBw61NEorSEr9cok0l3NqBP9ZLc3Yg64caksLL1mLPsm9SCk0GCMuknrEmVtl66F91/53TZ75sTL8IfEgh6T7aLFZyHHJ0bqbpjzOkajKNGP9NfjO3w2C0fOlc3mtl63gZ3XbmPvNXvYd9k+fpm+mnfHLOTRfk9zQ96dzEy5nIm2cxlqnERv9QgKFAOIjfTDZxxBVNOLmGAiw+1Duadxpvz6u+PbmXnPeYzeu5Kplq/l+1Y7z+Nuw2h+2XOCL95fgDLUydgdv8jCYyczE2hJFSVxt1r3myppWvlBXEnie0pwj+Gd3VdwVoeW+KAZl8rLmpgAj/hX8Lb7MQalfcLqtP64VEaUITsrFizEbhdESgnvvPAkeocI6FYnjCGg1P0mnR4K+Ni48jVee+MM7nytD2e9349jrm/ooxctuv3uZbzRdzuqkIq+rhC3egqIUYsA2lrfSNjnwGBJ4b6YHmwsmkJqvxBJXX48FYVUh7PlzTInowqjWoxMd6pi+K5xMEuC98sbxH6msjbpHLwpWdRoctjhyWW6yyULY4WUETYZvsBS+gjpyiqOeUfSL+sj9h46E0fASqyuk/sK9tK3/1L6jjmByupBLY3J7x/Nmjduobh/O+XpvSRxWSac+oX0xK2MHdDCMLUH6Uw5rLHypn8c7V6JzKzglLaITr2VA6eEdkSlop1SaymV1kq5XXRNYxHjzrybR9+7gdX6Q+zjCOmhGoIKLfGaWmJdfnw6FYcsIjDqCIRl8ud1ccG/a2v9r2C5704hgIiCLdedKd9XnFvy27itNVEcSwmSZcDzr8xmcehqHKEEYtUNfKqZx4BgMzFqJZ3F4nrNLvfQbi/hnGsfYmtIXIdjLR+ixE+cVtgYHIrm0aO9lWcJyEF0obKVUZoKCo9sJ6BW88PYyfQJ7KZBlUFMpItL3EqK+g4k0CmCRV92P7YbReLSI7pT/NspAuja+Cz6WwSx/EjrlegiUQ6ZOwhnx9I3VpxrJTUWhu+J5a3EV1n5sSBfb7jnVmKsFayIWNFHdCIYHHsxVnuUdTOHM2PWTBZpHuMx9aeSMxM+lxbFTgcDtu1jXMta0sK1cqD0WsZVVBjS0eFgUM8aMnp18tmCu7DVdcomhyf6DeW0F9+gs6O7FPsPUF9TwQSVmNDbGOpJ338h1+NX/Dv4+AtAEo85mCraJBdVrZb/DYeiHOoSrPNAag5G9JgVasosu5hz4lra1U7ZxCgjZxFRo0/OxFt915MQK+SM/yPcOPtGlAGzvEvUNLX/lp1k9yhh3J2D2R0nFtqhHSbWvbabi245g9hQtyeJup6fm8RJ25W1jkGJIqIft/cgr/AASRo1Z0uzjcBXlmZ2rXuDqTOf5krllZxtv480Txi7Vkk0JY8n5lzGm4dWsSrlNNk0q6SmlrE7V6Fxd/HGQ2LMT8JZvU5nxdXf8cbod8ilD6qICoe2i71FZSwZ00RHzzAvVXwuZ/uWYCy5QbF4Sj3d7wtnUZNRyJDks6nQhsk2ip78MdcJNm0ci6dKTBnoDLn4TV65yrI3fg8nrELSXqVx4wumyDoC51zyLG6XiySryAxNjeLS2esXfe7TtC4cKge6iJJRXYLouyl/FKf6isczA9Wk2Cy/SS97O0Ismf/tbzdXp6iOxBWJXkrQGea7Z1+TH4taxGMGt1P20nju5cV/+l3p9tMbi9nx0Saaf6hGs8FPxl4r/Y/nMLayL9PqR3BB6yQuaj+DjpS7cSbcwjTvTO7uvJfHG66SM8hdcU5m3TeddU/MY7jlG7nactJzGneqzsQZ1XPX98cp2y0UXWO8UNIkgrJ9PQdhUAVJpxltRkj2XNn3wHSiOlGVM9gLyIgZzpSy6dzWdRfPVN/BBPtgjJEIjVoVW1LaCfb8gLX9HYQUCjT+Vt649wH5tTtaW3AelNQvo5QZ86i0pNCfFcT1+ZEr3+zJ6M8HcVvzQhZa6llnk6ToU7jac71sfFfbtY97UtWMOTCAnZdu4Ytbj3PTzUtosXZXxhJrOWBdS8jTjtaYwAJFDJluNe0KK/cUPMQTzrl0lsXI11W8QWTA4TQ1HW4VLrf47NJ0S5zKRyg2CV96HqtM03k+ejeFbWNk+4MdRh2DVcdZr3+EhXHXceTQFaxwi2tmQtYm2cU3XgO2HDF1knrkerzCY46dmUJp9fSOLdzi3kKPaEAW0VqnSedt/TkU3luKp0m0FSO2FCYGhTLocnN/DupaOGk5wuE4Mep8Y6uaW+Z8x/Mf3c1Pmt1ElBF6ePMY0i4CxANJvSlsEOd8baHY8BujEUY21DJ92gX8Z9DrvBvxdxcQE/cLjo783YXEnXrr3wtrXfXcHHapr8EZFgHIB4aXiM80yi09abKspdLOd4c76PXcWjYWPoQjaiJOaaen7T2SNSJ42Et/PvaLsfVBCi8jNVXYohbSq/exdshpTLBvY03sJPnxWdU/c+FFN/HuB/OgWZzTeksRR5TD5Z9H+xv46NXb5daLNhyl3qhlTFqLrBzcGMqjT5cg/3+a8g1FtiGMTJouWxCktRvou1vHmugiOtpbZWmBnffeiNpYizMsGMLtMZLfEqQcs9Px82eUk8E16pVcqlxJ/4hUDYbjzmSO7S/mkp2HeOj498xsXMr9JbezLnao3E5O6OWiZEoji1bdS0yjA2lkq7z/SCZ/8AVbNgkLiL/FvndvxKZw4owa6XHlm/wV8O/g4y+At461EFIryGlrY2BYuKZuktstCnwxMYSNFrnq8UbCLzx54EwqpY1SChjUdiJ5InM/1lDMVefe80/9vf498yCqIKJx8/oLv5fs9EYTM+6fws7EFoIKyRxNRfkXTVitUTRRNS5JnbByJFGPgajaj7pPLTGaBOyeDkYdauNdxa2MMYfoqQ8TUCp4pW4h/RONZPQcy0Xh25hWKUySlman8PHr7/JD3GmEVQpyW1r5dsYIlGliXE/RXMN7z/65LDg6fwQ/Xvklk8pG0rc0Bk1QgcMcYIvtAI0qsQBdUnwlTd16G1LaqvGmcL0yD39cNpftPYZWpccd7KLeV4GttAVFJIJfa6QjQ5TiJaGoqthTWJqrUMntqSg/haazQ5NDWlY+7/2h5ZLTIoK05ephGAhi6TYhswSSGeMOo4oGKdcUsTNFVAYyPA2M6sqiKCiCkQ51C4pmLUOaUuVbn1phnW1M8qDUhDnlTKDEdVR+bIxKTLc0eK3MVGxkddxQIhWVv/3uP3vrUOXSpleR6ItwQ1kqw9rFYr0n1se0Oyawf/FP9At+hUHppDmQj+KMB3linJUhyhNMVOwlzi2ZB0JPWzkvlD+HKeShOVZP4igrd5pXkj+qBf1kHe0qsaD7wxqqO8XUVoF5DMba/WSESriv4RrubZvDHb4eDHGG5QpSZ3I9W/p3j+Y6G7h/9kxee2I2ylAXfpWCnQOPYukxl/KSjSyK9bDPrMKlUqKPROjnDnFJXTEPt9yKUmOgq6ua600ZXNncwZuvfopOb/5tksxu0sqE5ksGDuPcJ1/hWNpOgu5GVPpYOniWlS0zaNPGobBoqVqbTuWKdOJ1ohKj6RUhfVQThrZKutqNfO/vyzFXKpZAEiqPGyIhtNYWEtLbucyi4hpbgNZ+BjaNSMBVqKFZm0SdJxmt0s/YjG0SBxdfp5bOMiva7TMxdpbgU7Xx/asj2WUSXJY7q7+kXalkrTOe74yXMWHOMW5+8DM+fPF5VF63XPXokTyVK2KmkOxpp0tv4Uf7z6xNEWZq4+wJDG3qxdtfzeXbyBbCyhDZ7kzeveA9BkqZdjRMqbaYqL2VWEcIn0WDXiU2wUHNIlP+z8J5thDIUocVbH3mdvlnb7far9rURtlJIaf+R0x6Yg67VVIAEs8xUx7HC8S5GecM4c81yyPRfleID06oeEZxufzYKN16mZD/anAWpWFBjL0QNaep6uSqldkjpOY3DR/GjtQ+RBUqhrq388w1L8r3p238nnCrCLoM5izGjLiUPZo4mQiZ6NvW3XoRycZedSILLhsqt2L3tF4l64lU64IsMiwm09SDMalnEFHriHFryDvo5vH5Ytxcr9Oy7vaL+UUhnecq3EoPO8ZKAT/EfrqaGp+oKk1Xb6PcpuQ6j4YcyRlX0pZx9mdF3WBGO1Vc5Fdxc6+HubrXU3SqbGhNYXoVlLPr4L30qS8DtZK6PqO5ZccpPvjiz213SchsvFoEoutDfWT12L8C/h18/Iuxt+Igx5NERn7jieWyUZk/rOK4I0lSSieUmI0hqsWq1DCmLorB0heH0os2qiR12E/yAuPwm7jhfKFY+M/gnMtmogyK2XtPwIu9TfStf8Wse2dxLLuOLg3kuaG/uzfWoGCsG9QNLK8f/Vv1o0/KQCIRH5PL1rIjMoJlzOLiOD8WZYQqnZqnPz+bl86bSTDGwLImPRZ/mAajkicHSmRZJbltDj4dk0+iNYFbn3mOkDVevjDtR3axZd36P72vt595lMSKegaW2hhbPkZuJUh8BwmZkWJuG3UtteFurWdpIYp0YlP1Zn+sirFOsfjVOY8SNP3+HJIHElH7UUTUbExfRWFtAiW1FgJhURGq0+op8ws9iQSTCJ6cHjNpUbEobY/2ZoKqkrAiLFc1zrpqHNdccz+DPKKnLi3s8vtzOjlllrQO4kjoriSVaUo5rg/J9zf4+hGV3FeVEJPppjNgJBzaKT/WGBuLVovc75aULSNKJW8HrRwz+OXH/5nbCXOUT3JFa+fcOgdVJjhpDLPTchKPajmLn76EzL0PySX4UFRDVO0gbeMFXLj7PL7TPsmj0Q8JhIKoFBFOjznC4Mhx7qr5TH69Z3KvpzliJRJV0F9VQQ+TKIW3u2Lp98xNtHYdkKXs+2gmUe8VxzTHncUll3zIh7cdY9Gwt7msLYFmi4H9hV2/cQaMHcIfaHfPVoLdypXpgRBj7XC1PZlXbZey+cLtXKG+gQsbz5MDCJ+7hdu0Cq7XreeR1/6suPpzqWjNJTh8jC4RG2TGxLOwmh4n4qxAobUwRj+Niw6exK/W0WGLx+FK4UibOIbt3lgSe3XS45wyYi37GJmwhTPyvyKj90cMGLGM00Z9Tf8Bq8jOPsLAWCd9LSHidBF5Iwx5VSw/IbxP+nKEuh+TOfRhD059X0D9pgISmsRIb8/IYQ7HjyWkVDPYcYCuY01ULUph0D1rufT+3zNWV7lQBk639GaQPwG1ysQZ/r2yns22XicJKUMkehN5qM1BnSqOj9wrCah9pHpSee3MF2U9lSsvv48Sv2gtxOb4yawR3483TlQpfF5xzfxnMWbeJ7LzsHQd678VLYhWj1hvdHoXSxYKftrfYsITc9iiuJp7Cx+Uq6ED65uJr6wkVGglNCqZMWpx/n7tG82OSInMGnsxeAGvhWfJ91+LTpbDd6rEOZR7bBf7inphi2+SeVfWaBcX2gXnbMueTeQd8BJxNQneh0pD2Q+/sEclrvWJgXIWffg0PTpFIH0sLp/+eanMKjbgjCSS3yHI8YtTN+CIOEjV9WJ0XjY+kxZdUEVWaSez77lCfk5abCwLb5iEKizW0M4kHXaNUa44Zq9vlCfC+isrMDhaKU9pZ5Zdw/kBLcYonIhouK96GOuOaJhavZoVCWMYMvxzShuziYQhxnCKVaU38tjx9zCog7T0Hs2LtVoefeN3kbvKr+7BrPDSGbUw9Jb3+avg39Mu/2I8vWUvvsyB2FwBRrv3SjrIHLVLrRMFzqQkFBot/YLZHAlsZrLyIr5Ti35kceEmlOqwvOBHtQ/JMse/YsGy/byyU2SpWq0Sg0ZJrFZJol5FllVLj0QLvYcN4fDezUTUPl6fv5BHnv691SHhrJsuZsuPy9i6+xhlXZXYnC50WcV4lF7SKgcSztiMyuBF0/MECS3pVDq8vLplMXePuYiicCWXxh/gnVY9v8RG+HjhZay9/UP6PPchiRUunCUxsilVT3uYtw5E0R7+hs2DVYw+537OvesBfnzuMVQBH1s/f58+gwcRY7WyZck3tJSWYo6EZYLps4+/JH/mRnsTXx5Ywo3Dr6Cx+igt3cJNFmUn5+qk70RNc6SaeGMW0WiUCv9RND6/TJg0apNwmgSfosJUS2JHhJGHxYKbrNuKNzgatyaEM1Agi/okW0VPNdJglDeU6pDkVQGJGrtM+Ix61RT0EIHkiLpKdvX4fRIj1uVhwiMiaKt5oxRHq1RJcnPMX8qdTwji5GeLE0iztRBb7KSzwkqXQ4GzeCfnXj2bPTd+iDrQjtOrYap2B8tjRrChaQnPvP3PlVAfeO9VqszjMQcjzBik49TqT5jsWU5CxI5sX/KHlUCtCJKi+L1/HIiq2WsXbQCbEb5jEsFgGGNzgJgUP43GJG63vsAdna8ySnMSq86NFxWtzhyZLxB/+0hcbxzCHFNAH/9AKjhJnq8Hv3y4ghl3XkheyWgeKFnP6Tv3csv3a7HE7aOgwyVX5+ptcFLXn7PLu7j+wpso6PXnkeuao3vJ2huDNjaNsN/Bo8EOrs6v4Mr7ftcN+RV1ChH0JblFu01C6Ic7iNc3EFE8jaPrAXQxPbi3XoUpcILWjBSG5Peg7+4O9umSqW7LJ5KvwBDnZ9Skf2x1Lm0I/k4d3g493nYdXS41rR4NeHtzNLZEThay/T7aLIOJxGlAJb54Y5fI9Gv1Oj5LEyqmI0q3YttjoGTrDgzmmN95MPPmofI6ZdL2oJjRsibLydR6SoqjWAILiGrdmANmxjafhjnyOc/n7sOrcRHvTeTZ4Y+Qn9uL1i4X019cRs/CUo5l9+FA3EDuitRS6wzjiNWiafVRFvijmMh/Di0940g70onBB6VrF+HyS+2uOjQaH1rVfxzUfJSfQnW8GV0wwoLKh4n1+bms4ln252US7B3LSwdcPGnw87D3GoqVtSyPiFbJLeiYhpYflJK4H1giFjIqdrPxxjP4JU5Mt8ys/plLrxZVj9LPHmV493ht2FODTdebfk4l/XS1nDSZ6BFyE2lZwVVnviZPvUitl/e+Wci8q25j9xNfs6v9ctJj59Kqg4WGj7nHfwcZwbPol/8G25ogvkVBan0HT9xwNXe/+Ar9srJZpPSgiipwqbp484zbuXv5KxicQTo9FuJNTiar9rKUM0mLryGnPYfrlXr2xLjYGlWz3J+ErTSRHjGHORnfh+vPeIj3n3mc1EF2zCk+bmn5gnO61jCn8A5+6TmSr48oaHnlMm4ZdT1j1SLAXBfuz6z0P1rh/Wvx78rHvxANHc0ciRdTI0Oa9pKlEyfJMXsy0q6msGVgiGhIcHmZEjmLg9pa/IoQ8eY2rKkiS9lROYSZEy/+7TVX76sQgUcwIt8C7hD2rgBVLT5217hZdKSTZ9bXcM92F/aA6F2GlX7GPfMjZy1Yx3UfbOb5JXt4c8GbLNmwCuepzaQ016L3dMrz9/Lzte1sqhHEva7MdfRJHYTL38kwzyrS7S6e194jz86Ptwj+x/vK/ZQdWskXl51Oe1MTZneY1C4fb+3fiDmsRBUYRe62IdTOfQRXx24yRk+SBaTUbgfvPvwAbXXV/LRmDWaPi05rHDdeetlvwVZqTAr3jr0Zs87E5tW/q3++Js+iJkuap4yoES2RJm8lDl+nXFKOjyjokHQJFFHCYQ31lr0Utg3FqzfjMMcwUFPGeMSIoNSeeuuD+1ApRcslpb47e6Ivw9Wi/y/xYma/eNdvf7+oYwJZIXGMNFE/559x3W+PXXXbNRjlxRic2mbefk4EEK1OwQcwpzlloakTjkSMp8RnMiWLzb/SFcsL+nfooajhB8M4Nv74+T91rm1PEhndiKYTdC56gAs9X5OgEN+LLyJ0RiRUB4pZFhrC10zhG9v17BjzBe7bTnC0SyxaO8z9eSR4JU+Gr2abcRqDu3kDO/r2YJNxAi0aizwpImFAyVXyv1m9BuGYECHgakCls5Lps9ERaSLOkSYLgv2KAcMGcVVyAtsMZ9OgS8Gr1LPGdDFnncrk+Se//rvAQzI8a39lK+bYQqIhP286yrnkNA9X3vePmfwtJhF8pEUE6fGbx2cxUF0unw92o4ucuIcIdhxAodJyU1sKY3xxlB/uItYkWmwdrjSW/HQO9lazfB4E3GqcDSZaTyRSsTufgyt7c/ijHhxaWkx8aQ/O959iS24LSwe2sj2jSG4FDlW5SdcnYY3mkKpQkxh1oQ6FUOpE8PFW1hl4VEYSPR3oO/vxzbkXMP/zubR2G+nJx6tMtAryLP1wmK3U926hMvohz0fXyYGH2p/AqOZRJIf0lId74jI6iPHH8mjPOxg0YAxHqxo44/nl1Ict7CkvRBf10qJK4aCvAaM/QtQqKh/HQ4L/8V/BqM/Xyd+rlAq0PvIoao1Q61WpQqDuJrb8DRbvWsnOFLGuTCw9TkqgQ67EfV7xMEVtraxP1hCJ1TDDq6KedDnwkKZQzqeFS9CxFD96lahISi2XyvRkVvYeL5M2B7l38Vx34NFp72LAnm5V2dR4EqKCo6VQ95DX4JMh0RqdHDiOs7nit9bLbqVo7Xx9z9lI2r7JbaKlujHjFGVyBUnLQO8Uhg8MU1rQ7etkb+W1u2+Wp7iefPIuYrrbQ330Hh4feQVhhZKQ6BpzunIPbkcQ6+C+dJja0UYUjOg0c42+gmxFmC4UuPaZ0fo9nLCV8P2IydRuiOVIdU9C4XgyAs18cnQOn1c9QkJ+Fmu8wzm++jZZIbslGsuk2aJS+VfBv4OPfyHuW7YYp1GD0RfmhrIDaBUB7AEdzT4znamZSDX4we5kEkjEpVVwVFWLShWgqI/k6QJtrgQeve6r316vqqmLm5eVykGHxqTm0YnZXNwvnpG5ZvKS9cTFatGZ1Sgk0iewLJqKMqQjqgwywlHD0QYvh05UUrf1a1zbfyGtvlKW0a5PzaUuPR9n0wE5GPIqfSRUDyfk08uiZRTvI82Yz97OQt7c+R5+hYHntE8wRRclUxPGoVLy7O4H6JeexIUDDYS21NG5o53HFI1o9PegU0q8ADUK7xRSf05jZEspxm7rdGVrLS8/9zRJbY34NTr6DehH4ZA/azv8iq/rhfiX1EUtikhTL2FWxOyhZ1hwOiqc3T3slFw8McWEtBLJVMGRxI28NfoF5r/4BqvSprE8cTJDQm0M1mxBHTTIAUqSSbir2n0W8hHtgCZFMmZlAENET8lQQQqVUH3yOL3cJsY3Cp2D3GAFefliCudXXHr3uVgjFkKKMAGXUGm84hxhNKdURbGkenGFdKSF2mRS8JmXXSn39yW1U7dfy6fq5zBp/bzzkwh+/leYt/BlTsWYyfI0Mrf8SSZpDsrclQPhPH5xXiV7CEk45Dqd7Gd2Mu3pNVz0xLdceNdLDJ8wjU/fno8i4gaFhluuOZ8MtVOWi17bpMVXZyOlwye30NanjWd9gghSTK4QTRt++O09DD3/Wo6n7ifs60JjSkbv8pLmcrPqwyV/eq83zr6Gc/21/JB8Fh9kXckwR/XfSaf/iv13vUVi4gDZa2VJ60FmXZLF2Zff+R8aFbZZRcY9ISuRDT99xTSEtLS0FRaEPTRF1fxgX0Vrx2GZtDo2NIzB7X70SsGxCqDjZ9NE7tn7NAcrH2PC5INMu2gf7/jmMa/zTt7kGpxY0IUDfG3tzb7IWTzY3kk0rKfMK87B060nuWfeXdz1/M3c+OQT3Dr3JdK9drktFY2EWFcszpM+1RU4NW0YlAqUjUl8/tpi5j7xMg88fgthT4dc9TAnDyIyysHPzU/ygbVRJuwOt0cYXHMWppCJmoCWLXozpoCFu9IvZeKY6fLU0sXvbqc9akJNmKn5SQx0iwCyLtZGfbyaWInXJHnMRBXsXvMl/xVIk3VtKaKqY+uM0j9DiGVJ65bLWMOCOW+zfqUg1/+KV8slDpaSxC4Pz18+hR2Rq3CHY4nX1LD4wD2MPNrIa11OPiEgS7TlokQKR++kAD9RlJpTOJTdLZfju/n+honUqbOwRB1c0C5IvfbmFnbfdwW6dgVKbYSSvKNYzN2+UuZ8wkEtgwJO6lRabJEwVfve+1PrRaqAxllNPHJmEXs7zyMzECWgjfBhjGSw6CMS6kVBQz5nDHWyf0CnPPVkcrv48fUX+eKjNwj5ReLiVbbSGV/Aa/1n4qwTidRI5VHMePjwaDuX3z4En9ort2ZszcVcllpKqiJCe0RLwu4aWWp94bSL6bDaiBztZO/k96lxjiESVTOxYycbTlzP7bYjTA6KteqXSB9ibGJ9/Kvg38HHvwjSSXwgRohT9Wo9RiGCrV7qTEBr0aE2JGL1K8n3WVAb4tihPCm7wRbl7UWtCcj8gM7w/b+9ntcf5JyPdhHyhECr5IPpJVw7uTfPXjycL28cy7q7J7LvgcmcfGQKlU+eyYE5E3jt/N64FYKMp9N1cF5kJ9MbfyCn9gTqSJjmxHS2ZY1jsf4MFqsnUpFRQLxdtCn82k4O14g5966M9fRK6UetK0p/zSpmnDpGtSaFH/13cnlsAK0iyiGTmhffmcKT08/hvtOtWGIq2BUYxjmha6g1vUyC5iE0ihNE0aN2TedczekMSB6MWqEmoVVkfYrcHM6/5c/mYb9C0v446Rc91YHdp3XI/COWYAiNLgZ/2EODu5RQTBI9e5XQliKyuk6ll3uLz5X1D+59/2fqo7Gcb/hZHmcsVxuwWaTvJ4otQcjNNzelkqIU0w9BpXgNtdfC5HOn/vZe9vx0AnMYzi0fx+U1XzG9XJC9/ojE5BTCXpU8EdKpbuPl+96QJ5U63IKAFlsiFstGh5HFC+4hv6iAsEmU3r+v600kEOIj7Qsciu/B/Af/bGL2t9gcO4BzWtaxbu/V5CkaZXXD78NjcCXdyAjDMjRKPzW+viTe9Pw//H13lWjBBPTx9O0/gLWPzpLVKyXsdVgZeES0II5kJdGaLDK7WHuQie7l8ojfrzhrznPs162RFUcl5VFvVyXqVnHM/ogn33yQy/ylzGw/9HfS6b9i6RWPk58i2li7G3eTP9rEsP9Afl/CBzvWySq7Zk+I4th+JO1+FpNCVF0k1tARlZkv60ci6cn+pNzGCV+ZHBAUxJ3GtCZRyelEgdmsktSy2BbIAoWKMfM3yFVFCSlWDbttYgQ+7+RerhtyAy3e88hr7gdRHQZNM1me4fgkcuofEBsR52vY34VLbyYu3M7A+iAx4Vh5xNyr8GFXtUruRhhIxJNZSCCtB19bf+G+qvtZHRuRDRwv6ozhnVsOkiONjEtGhMoUtgXdXB9zDueddSMfrNzJnd8fxxHVy8TJ2aMSmHfVFPo0imO03zKIInsrQ9x7iJpE4LBmvxiR/6+g8I2Fv1U/Qs8+IXMbJMRYmunQNLNn235euv9V+b7bvnqd0pQ0mQx8duSAzAGbNO9xtoevojKUw5PRs9lXF6E+GiEGBQ+i5zq0nI1Yvw7EBNBFdFIuIXOvynr5WJUoRn1nVi+jtz6XnfdcC6+PpviUuB5jcr1UhQaxIzJJDool3ofd3o90bTl7o6J9Oil4gKkZ8b9NvUitFwnnjenH6BQF+hZxDh7KamNnUOj3xDjPxnpyBlf0d1A3qhO3LoTRF6J6zQqcpkqsYausjjpF3crq7OF8lDYVv0MlO+GOUx2UibXvbW8iZbikVyKR11U4ThVzT/Y+JOZMh9uC7WgtbrWJBRdfgcahYN9PL5L18k9szniaxkgvdNEgd7V+RVSjpSqaxNvxfr7/+Z/TA/l/hf9RwYdka/zei4/wV8Adi96n3aqXrcpvPbmbJL0wkyp3xtGSkit7m5zbkYnakkZDuJkaTTvx8dUkpJbJG9aGE1O5aYYgWkk4661NOOxBmaT6wMh0xvQRZfr/CLEWA2cOzmf2Ded2T3ZEiFVY0AX9dNgSCfco4bybH+bM089gWokNhUbNT6pxHNZFMEa0eJUBdBUDCPm0RFUhgj22k2XMZb+jH/dVfoAqEuWH2JG0NY5mVqwos35ns/Pzd49w64TxHH74drbMHk9mppbLAvex2OAhSTubeM08/Mp6olgpMk5kasb1sippQGfg5rsf/Q8/zwNLfsATERlENmpU6hNU5WVS0irKvVWuo4RUGvzmyeys6iSqDEn9IwYktDHq9Ft5/pv1LC0Pyxn9RLXYTHeri7jtwVux6L0YjE4iYRWxdWIjaogm4lMYsYbiuffF3zd/qY2Q4un24fHu58Zj+xlaKtobf4v7XryLuJDYfCMGD4f37qWuU7xfa5aUwUU55Uwku0u8n77TZhHWGfCFtHxT3ReVy83rmtf53j2Q2nLRsvtbvPLOM1zR+j7vHZ+LOeKlNpLEqryHCSXNoLqljfWKC2gO5tHU40ZSCwSJ7o+Qxl21HjHtoUoWwY8kMrXqsfPpbRIBksVVQVa9RyYJzrfex26GYrBHSVJ0cvzdP1usT3/+NQ6FV8vKo3GxvYltOsjqz4Qr7h/xxIL7eXnhnL/TmJCC9veueIRByWPFcW3aR7hHLmdd92f1279FRVBkfQldTuoW30FPpagYSTWf73U9+bnxTJQyF0hFYWsTV0/tyZ7uenjvuMFoopKtGBRrROBwtDPIqNc20NAm5dwwqdDK1kem4otLw662oAkHmLxjJdeOvo46uxDQiyRspk77PMtfFeJuEg5/+yamzm7yd0SU6ie0bmT2vJu5+6k7GT1iBDZPCvGhFPQRScdbQdgcQ32Sj4MJu+nQKNCGtQxtHccWZSzXvXwdQYWo1LRELfhbxnLtBQ/y5OereW5DE160shz6KzOKuGmaqEZM7XMOcZE2PAozg5wbeeO8q9AbxHm+PCqCqf8KUnsPwyViA5KqPATD3Vo2Bj/6qFae/PAYHLw8533WmAUBuGdjNc/MEgFne3MNO4xmpgaf5sfIabKf9SzFDpJ7auirVzMWLUPk+g3YCu2gFMdG79Pz8eSLCSvUDPLs5pKjpfQ5ejPDrN+j97ThbtLLQcraknPIe24tE+fPx+4TI8DtPvGd9PBqaFeqSA0HqTn45d+1XiR8cNcMmr2jyHWrCKuifB2/BaVKSqCMFDsNeA/dzYVpBvSTW+mwBtFJEuwnyrC7RECnVDVjIcwXJVM46BLX3hW+X+R/vy21c97559KWXiaLMepDBo6X9uTO2K3ypu1rUKGudrKx/0h29OrP8J1VuN1uxl5/M3EPr2MRF1OnSyIh2EWOooUX2nxs2v8DL3z0z01E/r/A/5jgQwo67qsZxnvtw2Vi4r8ae/SiX3jxqQ2crv5SLoMftyfSYMxCpTRzdlM8utgCImE/q3VlaLQeiooE2dTTlc8N5z3+22tdu3AzFc0i+zq3h42bzxDcgf8VpEX86Tn3sODJR9C2ih54UO/GkTOYR15awP1PvsjQXtlcN7k3b1x5Glf2i5cX2R+UI1AGRcbvMoSoPCXksu0ZGylO7c2Rjgzy9Ht4astP8v1vp91GcY2NAcaQLE8937GYhmqReWTExfP9jddybO4daCa/yzO601CqdpCnuZmI9g08YbssZDY08UzOTbiULXPn/Ykj8Ef8dKxF9smQkEmI8uF23M1LiDWI/m2l8xBeSz5OQxUKSTJb2kydpVx160I+XrWbD/Y7ZB+Iwepj9A+KzdatFZWdxEzRPunoTMPmE4tyrSKdcFSFJfZ3VVQJqz9eQqYrTFvoR8YYnqHAsJOR1i9Zd8+fCb2/IinXIqvISgvxukV7mTz8Ibn1otZEMCaE8IY1xPq7aKqv5swZM5g2+1FCphj5b/9cX4Kho4Mbrct48TmRkf0R37xyL+e3f8wlTctlxcf1wT4Ybt5AdY2axtYWSlUh9ql0fKq6iI3HRHn2b/HhKy+giHplu/lr/vAZJA2DZY9eJHt1NDsTcJ60k9jlxaWwMF/xALfbXsGj1DFWfZTnb7mCSx98kdOf+JoJj33FC+ZBHOp2bc6IGQw7y+n30Pf0fmgxJQ8uofDBH8h78CdyH1xGwYM/UvzgUno9uJiBD3zB8zc8zxkJo+QstbPtOMrkHnzkCTD58a+ZOvdr2U31gue+5fKXFnH9a0u4451lPPzRSpp0IhgfYD/C+d1cHqdCybu6Kdg1M1G1C4K2Ir2Q1uJZxHuc3HTWAI57d8ql7xRJ7Utqh4RElcDnDNLaEZA3sXNLbCy8VmTA3z84i5Pd6r8pVccYeaSZDgzoFJLB3QG+SKmnxPUOK157n3VnD0b12BvoVd1VOEUQU9TJzCTBe5Cg8fsYZurNjFAvMmqbMZUfpkF5kk2pm/CpfVgDVsY3jCfDncDI9iH0dveRSw1SoOKPKNkX15OH7rydj4/4CKImTuHms+uGM3XY7+OWnx07ygC7aL0cS8jHbDQzMCw4ETUKHT/vX8d/FZrbrxaiY9IX5RLXp8/STEpiCrZwnFzNXV9gpsusw+QNMXegaE99Nn8Os+YfYKGrBK9CSRE+vlU/z8u6BXx+8j4+Su8k1C3qeyQmzKJGz28tl939/dSoczBHnbx79Bn6mdehVfroCGZwpFysBy09VVz63O+k5BaN+LxKXQ+CPgs9tAfYohSJwNjQXgpaD/+p9fIrPrllCqrWCfLPp9LdrDJI01xBIsHBZKu24+q6jKHRInqdXUtTUkgmnFobqtG01BAkyAVKMcX1Qrzg7Q3UlWKKeOQK9n1f75KduxvjRMs33h2Pu2Y056pE0K8+6UDZ6mP+JdcQtet5/4Wrf2t5ZYb2ctyUx4LMSwko1JymPshLwZ1MOnGE+18Ro8r/avyPCT5mXHgFSURpQ8Gnn/34L30vD3z/Jg1xVnrbS5nX+iJKRVD2V9jYmkd5XC8mNBlIjBe97MXKjQTVXooKd6DW+CGsYdOJC8hKEeZpL/+4jzXlogRekmZgwZWn/W//vuSJ8sQ9t2EoO4XN0UHQV48qYJEXLZXaiFLz9/LJcy8YxrAskaG9G83BFNHL5Fd1zTCUboVcSfAVbiRZn0uLP5FzA9+Q0+WiQ6fiq7iHOdejIE4VoUmt4qkfLyT8NwZo5w8ZwpyHl7NQN41mlYos5Uqy9ddQ4V+OMxrEqo2nv+Ecyh5fypY3/pzlLty8hSJvruxLIiHJtIGOQ3uJOz5C7t23+xqwB9uwx0QwSepPEgIapo8czIpdx3l+fR0BpF63h3PMKyXfJ45qLFx7z1tiyqVbPbWtLYtyRKusigxULgvX33vjn96Lrl5FVPk0/c3voVYE8ISFPPow03dseFGYVv0RF113GQafqJQ4NE1s+HYTrm5NhJheYpGpctrY8P598s89+/blpvlvE44Tkwjb2rKJa6knI97B9+/M+825csWc8cxyfEhmsJl6XSJv6Wcxft4WPn7lOzwhF3alD0NULY9xu5VevEY7Cx56j9ZmsQn/imCTWND9xjjZDPBv0adxLTts/fEGI1xZ8xzToktQRCPsTC9h3IDPOGnOZXLCUXZHCjDX11HYfIB2f5Rbzf2o7pb4LjYO4xZvBa6o5D0kDUuqZV8OqQoVQoUPDcqwjyEtdVxu64dSa8Jrr0Edn8o7CgXHwlZK/RaOeS0cdJnZ1WVic5ue1Y1afqxS8OWJMC02kYLf4PpSDlG7FGpWZNzDhBlz6TiwQ7QGrPGoNUVySyDRKT73R2OjnLSvIaVboTOmKQWLWpxp0l0X94n70zVnMxu56fJpdGpssidKc724NotiYkgIqWhRq1mTfJLejZ+QWCPGUY1KcbzbtFHGtm9iwkTheLvsna+w7bHJcuk1oQYavOXsLGxge/YRIooIgxwazi0/jyxvPoaIjrAiglMpzhnJUm1cu5BN3xXoJVeaUlVOlt17Ov3z0397v12ODnakDMYTFtf2EX1fPv30Vc4xCZ4DjiCvHf7Hgek/gwFX3i9dajJMLeJ7s+idMun66nuvIKzMY3+WaHGMqjjE5k/2c/VjX/Bo00iqoiqkWttt1gP88Ohk7JGJeMIxJGkqmVc1l5/jjnLcGuVE7AHSutRyKyNgimV1yhj59R6uf4N0dydVvgGsd1zLwSmvoK8Ux3X/YDEl8yvcseI46SxZNPMVtR3v06vmQhoaZ5DSmklJx9bfWy9f/96+KEhLYFzfmeS1imrKcvMJAhaxvyS2nUNKLxsjL/gIc9VIJpxVSWuOWH/07S3o68pRqxow6cvZFy2iPWpBrY1wb/038nN+rnLi8viZ98xVtFqb5QqIJC2Q357IuLC0SinQHmynRWvjo2nnM2LHYXm9WvrhCwxSlTG5YwelvmzGDf6Y9bFD0CpCDDTs5InObSy7fxZb94px7X8V/scEH4lZRcy0iNbGIlcf2hvEhvKvwKZwETneOr47dB9qhYcGr4Wf6ko4YhvElPYweXFiMdviW0KXVk9Kailx8fVyu6Xl0PU8+4CYIlixp5zXdzfJ8uexsVqW3iiyL/l3n7yZyi0r/vR3v5j/LLPvvIXAkUMktjcRVGtozC5gxs23MaDXr8JjHl5/4Z1/+L6/vGEUqQmSl6UST0gQLFssahoPitZBV/pGilJ6sKV1JPGaOp7bLtjVm1NyOOa6gEt1IXlL2WJV8fobv3Mk/ohbH/qcN5znUu2OQafyMybmLXZb57Lec5JgJIBVkU5O3aVse+hbPnpDuDJ+sGEf96OnXc6xIHl4PzqjtSRrhb9HheuQLDAUsChBFUARUdH3QBWBfmdz/5Jj8obXU1nG3THvMCUoqhz71IL499GPz6FWhmV56I72DNq0UBUqYHe4mGnnCP2HX7H+7vsYwf1k63cTjqrZ6ZhF6ZC3aA9mYlJ1UdjxJY1lv3MgfsXVD10o94GlzSMSUFDbIbL02BzBLSlzxlMSFBMOEqTR4/vffh8ypMxMmopJIqPxFKeOlrHqu/dpeH4IZ2r2yVv4soSx3Jg/n9se/IBX7n8Ln9GJVxEgNqJlpLeejPQMYsPxcgbaoWvg8ze+5p3nhT5GTcUptF7xHoyZIkD6Iz57ZQ6fa8QY44CuAxQllXExn3OL9zVM3jA15mSmDnybPZn9uUi9nn3xJayKHSONDzG6bS8/qMvo6DoqB4hnqvrzWHAj94+M5dkpqbx3Xj4fXljIS1MzuDOzhnx7G3cbstEa4wl52nBaFFQYLDiMXfQyOSnSO8nTOshSO0lXOemtLOdSw1Ietcxnak4NAWnkPBSgj+ckfpRsyJzDBdc+ytJXX0QZ9BNRa9DYhtCpFVXAfJ/YcGtMWSRu+gZ9WPy/w5jCt23tJKh8XDcokecu+Xvy8/ihfVGkZNGkTaJGbUYdhbKSGLyxwsPn4xgrmI+ROFVBV6INg0Zs/C16SV9CTL0senkRvaozkASDK0yw3rWYVcOaOZntkvkd57WZuSpwFYMD9Qz2HGCy5yBT/VX08ftJ92tJ8R7Fn6DBEPJRHpPJdMd61j46U/ZV+SPmffOpvKEejhlBdrBCblXsVncw+Zwr5M1BEYxwzJbL6Z9/x9wffrcE+M+gc2Iv+V9Nk7g+E8ydrFmbz669g9g+KkpYqaJ3+ABJxm18qkpgfcAmt1jGZWxm7rgH6T/sQ7buGAATP2fbOA1rR8dzeIKd4oEvwtBriMSVEh+olat7v/QuIqzQMMK/g4EHg6yL3kvOcxsY/8orVC56Vnav9aZEufnuP49iS4JztfYdBD2C36Q0paCXxPxir8VueJmzu25m7eKjLP12ExlHXCybO1uetpJw54xRZDX3kdfhE7FBbs6Lo84YIBq1EVoew+tfvk3jkPPxHRjNpNH1BPtKE4ZRNK4uVNWHmRaqR2WoZ01YVLzGaQ5i9bsIe8Pc+aWodj/xwsUo+9bRaRTX4yCnht4RlcSpR7OvnUWjTqcxmss7C+4hp/IrWY+nNJzO67c+QHJbGxf3eZFrej5FvTIBo6qNacY19Pn+Stb/9M/rQ/3fxv8onY8rLzub796ulLUgPvroS2bP+ccs+v8/8fLKj/Fa0/jx4L3ERjpxhTQsrumNX21kmEJHf7MIPJq6drI5XU22tp28PMHG1rX0okWVKpe8yxs6uO1nabIlitakZvm1w34zfNo2sifxHVG8X25gt+keyqafzp7OCCkNVaRGo0QUSprSczh35AjGzBLlvl4jYN/D5US0LjwBnyw8FvM3C5X0d5ffeBojF2zmM2cMN0aMcrvA7phGjv1dvDHgLFiNtaU3kciPDNf/xMwTo1hc3IfFOVN5rMzJlPRlrHBr+SC2kVNv9OT2kS9TMlAQwyTMffhuYmuaWUQfSkpqOZNqrggeYFdiNd+Wj2OooT951v5kkUpWXSpLH1rKHdGev1U9YohycOvX2I7mo81PIRIOUOs6TkeskviwJCsfQedJoTltAG98tIoLDBuYot7OoGA7qu5qqiSnrosTgZwWUXJ2+Q1ovDGEtV5+jJxDk93M4LGil1+17xD2L+cxzrpKltzuDKWzLzCdia88Iz++ZucexkTeJl13nIPvPETqSyKz+RUxNpscdCj0CjpV7cSXDyWaegKtPog0gel3qNF63OzZvIrBo6f89nv3vjyft59+Cv/R7TT6rAzSHWbM4Z8wKINyJefR/Dv4JP0cri1dx2sPNeA0tMjZWUZEw7jAOkw3vMfogjzsXV189Nw3OHXN2FVdeD0aOVDxh0+hjQaIKo3cMPvPlvf7tqzkzcoifCYdvTrLGOzeh76b2xPT3smCPnaeOhWhKimBxwpuZ1zsbmZt2swGRV/aDTFsThAL7TZ3Gx90VmKKzWWidxTHjv/MmQ+ICo6En794ncXHDMzHgNmaTiTgpkHbSqqqBHtJK0svvJDyY3v45cfXMNJEerSBwlArGaEg71tv4JWC62g3CyG66a2rZYbA0vBYzrvmHt547FHUXaLsrUgchFta2BUQF0xG75b4HsOp0WQTUqvIjbSzmViaImEstkK+7qyhYd1a1mxcTlDpl28RbQhtrIncEWOZ8/RjTL//I/m1iwJtlCtsnLO6kqOpEQ7nKnkhNpHXQ6Wox2TT5RQBR0TXwqwZt7HkhVUM60giEglzStvCCfcSfhxwEo8+jDGs4JEmBVN8FWiVj4L4VRnVbhvbanvJYnQHVEo6csyMbt/DLwmj2KwbQnt9Gcb839stUpa8PUlwLUY0nyRGfZzqlDz2JPSXk7UC5TFORTRE3EEOpRcizYp9+8MO8rtOMjPXwlVjhCfQ/w7j53/PkZJijLtUeEeH5IkXCdsZxRFFPzTtLhzH4Tv3DPn+vJgqLi35jhyraDf8PbpfQAoSFFEGxq+kNH0oBzTTqNOnyq2rKUeq6P/S4t+eJ/EhBu6VqnoK9gzKZOAfdJF+xYi3RXVx1UtP0qv8CKpQGh5VCVpTNgqNCYM1mwykm1RehM65W6kItFFqDBETM5qB5eXsLeigmgPc33cqr+/zkeLTcuGpway1q3mx95UYomMYVHKAtLhy/FuiqP1e4iqPM7yklA2hXC5kA4bMIGcf2sIXJWewvsZFh8NDnNXILbcI/tQXn39P2YEIE11xtFsiNHrDqA928dLF1/PKqgfp10NUL/fFnonUZLqt73ja9lewPHcMG2IHc8+ehdzgW4pXGcSU9nsV7P81FFFJeekvBIfDQUxMDHa7Hav1D1fW/yXMe/pF3nf1JIUoP9/dl/hu/YT/Vzj34294vuVZij2VhKIKPi4fiD1oJMY2iNNNw1BqLfg7y7iq/4dMbJpEvwE/Y5X8REKK/4+9twCzqm67/z+nc7qboYauoUMaJARBQEHBQFBAEBAEFcUgRFBQDAQJUVAwkC7pbhhiqGG6O07X/9p7AwOCPuDj+z6/9/++67rmgpk5c2rv893re9/rXoucA1/w9AfdxcmW5p/sobzUIY7Nfj+oHm3qSZWI/Z3qE5QlXYqzQ/3YEt+UoOw0lK6bPwuLoUXNqvedGjl39BS/bdkqtlCUTi+mzbj/ZMmF5Dz6fHuap+1FKNRXRdvght5b0TfOBbeC6AMfkJO7jnahWzlr6szTnd6kUKukc+ZVnkxZxeZaVzhskoiSBg89y9w802YRx/YeJPPkcVQuJ9nR1Zk3dwFLPuzD07b96D0errmMrL/eBKPcm9jg7tTWVBEDrATsxM57WKmJmR7py+mi7IhfWEtSKhI5lr+B8ir1QadBadcRYb9OrO8RmrsyxPu9BaHVclJRG2Nwe554QRImb9sZh0rhJD2tEQHXvDglRMJ7wFNi5b1PP+T3t96jgec3gtVSReOKpRuJxl48/rZUnbqF/RPG8ojPSun/pcN4ZP7Ce97Xz95aRJEqB71bR702K9Co7GScj6TgsBc1vApwh/jy+MxKseItLPn4fVqmf099X6lvnev0Zm7UGL6v+ShVSyp46uQF8X4F1HF76OZezfmgV2n36it33c+8N+aDyiWmGAvwTcvEZcrG6hXOW99U7nrNFWUMmbiEs/61RD+KT3tr2bZpPY/0PSJeWDJN4xn22Fjx4jb0x5Ucj2yETaHGz1ZO2+yT1LuaxKn8IE761MWs0hFqt7DKIUdjCMJWlsnJiNM8+dZHYmVlQWpdZpsqqBNYG4/LQaLzFGEGP67r9yCXX6WqK4caznK0dxzHXwxP8GG14aT7SRUFo9XJxNRvGJG7lsvOKGq+dYxTR49xaPEC5C4HLr9YnCGh2GUOUYfQ+5lH8fP3Jv58MlaZjhnr38eeU4+PqrQgzmNmidMbueqv3T9zXTYGya24ZDK+Ki0kymXB7nFgwUyWPosSlYl4WwlmPz3RpiHi/SV4fiTSbcaoyMNLkYW3Ioct3jLeCwjAJZjZmWUsL8wk5mbLUqjGlbuCKHWFcNkRyLksNzKXG5dcjsLtJiu8CubgehzP8aJQ50v/ot/5ZLE0XSLg/SUf82X1zmI74WtPGnlZ13kjqoPoi/Fa4mpSc2uxyRZCAy8LBdW8SQ0MEuMQbj44EUVl1DBfZkyzxrcdY/8Mu/s2I+xKBQ4fN6df7EWBty9f6bpiT7agyJYEst4yFx31KVTXCw6tLmQeOXqHP/JYX9Sau7VV1uRr9HH9xtW6ShxquUi43uFDUuTVeCb9R+YN+/Cu289/bwiP/nAGl86D58e11I/7a13cwQmjqB2wmdP6hthcJXTMLuGKqz3FsngiXQb0umCxYncnhDa5zZxNriuZdK0Du95ChFcM1YvroBCiMuSwrKqa72LVOOQyauYm0nvLryhsFrEScqGWla/d59DJHLxYOIFT8hoU63xpWcXIjy9LAus7sWXDNo4eKmWtTI8VOc4IPTsyX6WONpUEVzU+iV7AsTwrlnKH5E9Uw4/UanpxTDfuVAK6QhNPRXnx3CtD/yPX7/9VlQ8BwwZ15OdlOeQg49ulK5n45n/f9Muyn5czvfBrkXiYZRoS8oNE4qFWBdNFLfSyvXCUZ/J1jYO0yO1IdMw5iXh4wPvMM+RGS0LInl/uF4mHMF3wZpvI28RjT+94QrKcpEUFsrthI7xzswnLkC6KeYHhVLGUMPT33RRR6fB4Jxq2jGfjxj045RW45BYunThLnWaS7fOdqBcbzIddqjBlk5MxbqN4sUorepqWxXMo8YPSatuQ5wjl6K000O9h4NE2LOrQmb1hNWjq6MTjyUE08z/Mej2k2BWs81aw5+IY4nJjqOXykBscxfS33hEfa8TUDXw953l62jdTgwp6hV9kS0YdLmStJTm6JnVUzanqjuCSIg1cwSgt6SjtKnzDpOd90XYGh9FXJB7Ctr+nfCNNjOe5VSpJV2g4oqpBubI+wyctQioQS1jyy4dU9XOKH1xLRjytVItJsr9AidqNwhDIoQkv84jXOlHMZnUbSTS9glLfljbDJY+SOyGQjXOTcmho3EFLr5/4/S1plPBORNcJwny1SHSRtZVGogm8gX+1ApF83Kjwp1fIvS2bnz57gz6lPxDiK50bJwsjOJgfQ7aXHb9yK4NOn6FIJSn127hK6SD7lgPm4XR69RU+nbkQo0HH8PGSAdqk2RM4cfgoRzafpUieidMsfEpAdtOc6xamTPiAswEdULscvByaQOtuczl9eYVIPNxuGYO6jhBvJxjB/fTcSD74bCq7Yptz2ViVjVU6kqyK4avOjVCVl/P9F4s4Y6nKJHUIC2xaNN4RxKXZ6DtyPteNjXjDlEedQOlCUWL5hvjg7QS4ndT/g09VmUzOL4YefBM1kqRgqWInTJI1ybzAnLS5xHnSxFAta5c5YnPuwHffoBSIh9YLgiOwy6ziiGbdptVvu9RGO/ZwVV2bq7VjaH5F+syUy7Wc1mwhvCgGDVrUMg1K4UuhFfVSMsE2W65gncKDCxmNUFDf5+7zIebO1Vd4HTc1EV3l61DppIkNQRI9J8CPNd6SGDU6R8fknBByZE1J8Xjh0PlS5fE+VG8ez6bPZnPj5Gl0Lgu5wZHkGUOpm3ya8KwUXF46QpwVrKA327za8MTWNbTp8aR4nwf9pUmW5vlp9Bgs6UxWbVlOgq4xF4P9aFCSBcL4ulnO4ae6sefiYRadusA1Qy1Rs5YZ4ENmQAsOZHqIObeD2s4rvNu9P1FB9+6mW636neSmLVGVyolb/DvfPDUHZ1ExCpeke+mpyWNU9wDqtR4ntv1cFXZKFMUIjQ2/82o0Yd4MHV1J6E0V5Uz5rgU9ThxA2WI/SqWdScxirXUI0/tMvefxm52SMrOuNjHS/0+Ix+eHtrCrJJd8pYH8Xk9RqpD0XHGmZHqbnqMR39O2WXdu6KOIKCmif+IFGuQ7ibYa8FEHi5YIWkMEMQhfgogInFmFFFqP46vRoNU3YvR1OwMyTMyqbeBgSG3ONu9CwzP7UVaU0vCSjl9DYxjie526PqlcLo5G+FQnJBWQlV9GeNDdF/OefR6lZx8I/vAd5pU0R5lp5qCyHrU8qUxyvMTVJEn/I5zvBh8Vtdw2lDkVJIUGc7VJfR45dPgfJR4Pi/9V5GPKoudpFdOO/sZillbU4pfyhrxYnI2339+3EX5Q5KSl0vzKCuo5EilVGFFarRwtjEEuU9DNpxNKQxAuSxHZegtntFl0R090jGSKpc6RkWJpz5ARHXl+yX6Sb0629Kvly8jukrJ+/dMdSKgWT1lVBUF5mQSnS5qWYp9AdEYFT23dh1aYwxVU+Nsucr5OLfIah9J26TZRHX0Lo8YN44uFS8W8k5/X/c479yEfAga1rcWFzFIKzlWgVV+mSFmIIs0f/MopDT9IlbCerM/oSZ+ILQy3/8KmrEZkhAfwU0BzNvYZTEBAMPV/WcaBwo/5zRtK3HKO1UnlRriBfsZc9n3+HO1f+RYvXz9emrKcLWs+IyPpU1p5FZDrn8GpokgqMq5T0KsJVTsFUPhVitj/9LaU0EAbg0ypxWbJo6w8A1s1aWol1m6iieY8xXIFR2TVyCjvSZmpGSNmthVbH3+EzClVGVwOPSZnEYEU00W2h59pj1tVgU6eJBKPDFtdkj3jiFVFcNzLRP1wsTB7D/yfe5esVWmEay7T2PUTF7a0oF5PqXUj4PGnn2DB64uw6nNIz4qlbuANdDorCp0Gl8WG3eRi48oFPDZsvGg8tuOD3vRTnhY1KRUeHZsq6qCx2cRJmEbnTlOv1EGJWiFOGjzqTqa5Yp2oQ+n0yVxmTJuHU1lBcbGc/Zt28kjvruJzaNa6pfg1d8yborbArdbg9FHw6RuLeW7KIL56/w02BkgheEPM2xk+9ysWfD+OunUkTYrNoibpzDHqtqrcqb097kOavN2JIzVb803kAC5EVKX/sTz6JK8nMrSQ7mQTbXORlGOghkJIZq7KnIJsXBW/4R0gWc8rC1dTP2KzOBsrXJiTlAaSFCHkysJJ1dRmV0hnrodJn2NhTL1OTjID5Wk8lvwZ4fJCLB4Nm72e5Kn2j/LJ5NdQVhSL7Ud5VCMq5BZRsGkwGO7ya4k2ZYjkIy0ogl4lu8Sf5XnkdJ/2ATrD/Xd1gg7g+OrPWZfaUDQJbFGYQGJZGhq5Do93MBq5Bq1HKWb4aOR6VHIvlEo9HtNF8gJiqbCEkYGeL6KvcM1oFnUEja76UCc3hg5LV93zeLNmzsBx/QJGm4V8/xB2G1qDTEtAVDHhaUmYMrMYNmYc+745R7J3BEt/OSqSj8++/ZyE6LbIBV8NRaWgtEluIglVGnPcrxk9/fcjJJxdc2lY/dk0kSSITiolaVxP13FcVYPr3uGUGFQkq31IVjdn1+50qpScpaH1GvGyPEEqXPlk67fG5vJnUc325OQLCg0Il3mYmPgjfgF5BPlLPjMvTxklCp9XL9hAqTqbYkURltwK0QvntblStc5g9OKxOB+2mRuRndWEbtFriCGV4aqv2XkqhP6dn7n9sN98O5c2Vz2iINXUbfh9j9vH+zcwzxmBRy9N29yCoM2LNBWwzxhH+4orvJ44g5fjvwa1kdcmvnhXrMXicaMJz3OhDAwg0hOLjy4WpS6AYJ00nusozwBbKYHGaBacUVFkuMjnAUYskdVR52WgKcolJyeMTSYlXaruZW6959EU2KkoVjJ55jesWnDvmKzN5sBW53HCT6SR5VAx2zmYcrURl9NGoExGbbuCELWZWJ88xox8XnTVfvz3i6QF+XO0ZWtxkqlXY2la578b/2vaLpu2r+SNHMle12D1pyh1HHa3lmG+h5j6ypvojTcH0v8LUF5aiu3DxwjUnMMk13HBWJ3yKxbOlYTRLrAP4V61cTvMZDtT+L7aMXyLomnedD16fRkaqwv18efJq1KLi77V+PJYrrgg1Q3X8eOwRnyz4EMyyiwE5GWicVRuBwv8g1H6+vD6lLfx8pUmY/a8+gT+uy6hclZ2TQWhYW51A61+2H07P2Luu/MxUYpgGtKyXmMeHShlTdwPT3y6i9aFZ0WVfUNXObEN11Lor8Y7sx2KA83IlX1L99ArLK0YzczuA7Gq5PRKPcPS56SxMAHjp7xCvuosF6qW4VYIOyEPbYxOusjcqK/5EdHwNZo8Ooji/Cx2Lh3IE5aLos9FtsUbt1bDU+/NZ8jCA6SrfOlZuJVJqnjU3tU5XrGRRFkZjoBQlC4VHdxLKc00MCHkPVqqS2ieHyOOUWYFpDJzZuXzuYWtO+JQK50U5NRAcdWXAWzlgrsKvzmG4tRUoLPr6Gy7RG7tzjS8Hiv6DWQ9UkGrnpUalj9CmHhpXvYxekWJGFkf/uZqvO4gPoL+YtnHyylVlNKm7Srkcjc3Tlel7ISGKoYivMOUaNqOJeTwu8QpJG+CK65Iclu/yyM9BjLx5fF0157kqL4dHrUGuctNb+clmmh2ct3SnJA3fuLLBcuweMpunwRyu5F3Zt09Cjxn2PMobfnI/atSGiKdPwanD6usEZQoDXQuOMK8T17j162PExMopYgKKa2u/QacZg2OAMEuzo7BY8XoseHlthHjsrDXvyVja75NicaIyulhzOWtvF4wB7lMMOaVk5LZFW3gmJuOny6xilCWe4hE79/QGQJBU5uA1q1p0bUfG0/t4tPEUi6FxuK+2Q6onpPNkKBiapnc1Ds1jWB5sUjMtgY8z8Bxs1m/dg3X1q0SSjR4qjTHpHOLic1am4HXPpSSSG9h8rdT+C56MNUcV1k0/gMef+xDXDJY3SaL1o9J1Z0/oiwnnSVvrGRhSCPC3R6+3vA6B+tVxSzkrxhrsKnTQNzheppnLCTZfRy3TE8/e2devt6DdJ2MGyG/sFS5nXyVAr3LQ6szwUTl6Qlo3YXnXh1/21Bv6ood3Lh2iXqFZ/EpL6HYJ4BLfg1o36IFr/ZvS9KZE3z/2ScYzeViCzNK6WS+pwdyt4tZMef4IbApx4LDaFqQx6aBkmhYwInje3iyQo1ZZmDE5ZX8nNpZkDf84/Co5ET5yPn6m4miRbr4M/HLg00rozxQjaJDG44WV8NjcIoTWcIN/J2hdBvSjlp1pRrl+x/O5+tmj2CUlTHPM1ZMuXW4FGh8FtKxuaSP2vBcE2octYjjte1/lYYO7sTptOsMvp5OqcyPao5r1HOaaeAbTPXELDqmviluMNY5H6Gfcj82ZLSOX0amsSpvpu5j3HOVjro7N20i4btFXIwt40TtYqJMCoYlDqKBIwQv72q32zTCee0uTRcdbRU+wWzQXSdfUYzMbEefliAkKxCiLWd1awXnYl/DpYpAbnEQn3eGZf0HEuTtx88Hr7DkVCbXiuy4bS5ayC5RXZ7FKlcXwfuO/uwjqrgzKsEb5ub7WqYtQxGRR68nH+H544XEZWfx/dhB/7Hr9/+aaZfUgmsEW0LEPqJJWwQBUrrm9+YatPuxM4992YsRXw7i428nk5PzZ0Knh4ewQ7XOeEIkHjaZireqj6VGwXUSSsJo4NdeJB7CSbhTvhmXjx+ZTgs1qx0XiYfbqcDvkosseXvkdZry1ck8cLlorbxCrfQNfDJhNO7ES6INukA8hEwScaFp14HZXy3jg9nzbxMPAR0//YWGFxIpHtYFi9CFuDl/H3bNLJZE93WqT3HKZcZNHYX8pvHY8TOVUxb3w5ox7cnzSDv9C3IjYamSu2JZ2CF8I0IoLYpjfUYd+mt/wZAg6Q52RjZixZql4v9nTJtIVEqKmFTbLaUFLSuc4ojlwQoVH5nUnKxVQp78TTZ+1YAjy9+gz/hdfKPtRMfIK2gVDtEYau07r5Avvykq1KSLxEP4gB/TZuLwlyZxIlOzCPhFw4GSztTzcbLygxco9JJ2fKGFUWL/9E6sXP+ZSDwEap6cVpuqnkzx56cd1ekg2yv+36KycLl6Z5yF0m7pko/7L4mHgA6Tx3HUNBC3R06c/hAX3qt0qb0tPnVKx6WiXDp2AdUlUWSqyY/6pNDk6FiReDg9CjY6mlHlrVMi8RAQ6F+TQz5dJOJht6BLvsjZjCJSzDGUNhnF0i++w+IpF4mHeIzF7Boze9ZL7owCDu3ditImtWq8aoTjZwsXn49JWUo3wzVa2NLo2DOAQ0faUCVIIh4qq4u2x4voLk+ll/Eqj9uu8agtlXb2XBo7SqjusojdBWH8b/+poTTKS8ehlLGgXk+61FjFl4Vt+OJaKzZUmElN2yw+trBYmwsusd10kJScQBKTIDHxCr+vWUf/BcsYU+grVlEE4hFVUMzLpcc4OLgHsfmlNDz9pkg8yjwGdoSPEYlHaVkZV7b8hsztxhlaUyQewuvSmn3vIR7ieXHTiDRNGUOJj5vAm/u05Ov3d/3c/86LpHbszvqbbaK+uYl43nkZbVtpZ1mz4hohCTfEHn9u8KM4VDHIPWZMlhuc8XVwzO9DPtHsFIlHtM1Jj3M1ReLhNPiKxKOkwszwBeto8vZ6Dl/LonbJRZF4CJ/7iLpN+HXOayLxEFCtcTNUEdJ5GZyRTGh4DI2LEnHLFaw9p+NkoNRK61h+tzlds+YdaVIujUBfjKjKU4YrRMrcRDzAV7hgVCgHtUqOR6fAra/8UmgUGJUy9EoZzigDshZBjD7/ORXeHjEB95YTqqDhEsLogjPsBHy/h56bv6Hdtk0E2IPEGwjapc1rtvHJ2wvISE/ht7p1xWmZoIpS8oqfF4M2VQoXlpJXOX/lLMfPHKXaGcm87VSzFvccM5vdzquJp0TiEezOZnWTR/i657OMad2D7sOHc8UivZ9NnEVcUHmJGrUxNxaIPzuhEAJAK9G1d29cah1xqV4E2D2kG1ysq/0zE8Nu8Ao3SCg/jLU8TTyvFX5VUAYI02oaHs0xUD8fVGotIfE61AoXuVYvOh1UUf3y+2jK9uPWqTgR05xea/dT8/1tTNp0nSvZFpF4CN4A09SreVf5LXWUKXhc8IuyA7boLWQF3cCuECiTDB+rD7rrVdmz6DA9L/xOvYIkVny+jP8U/tdUPm4h8fIZfjq4hGRLLgeyh+B0a9GGr0blczP3QyjxulSE2IIJdRuIVYcwqN0IateS/B0eBBeEXIGDy0ix5zE9pZRYwwlcyBlZ5126Fh5GfjoPtac1TQOlkvt2+ypqeLXlJ79dVPPoqN9QuhBUu2EiI7sv6SGdWZZSQg17Mn5l2fiXVpZJrWotRcHhVCnNo8uQwdTuJPVuHwRnv/8Yx/xvMAixHTd/JpwM6SE6jjd5FJePJPK6WhxOouyvQqY8tPHKIlBRQVvXEQIaXKIoQI13VhvUh7ow2KAVy7uCCM4pU2JTqkXBmsblwH0zelvh8aB0STsgtzEVd+RO0EkXXSyByDO7Iq+o7J1HyXKZwkqOZoZjlWtYEvOC+PPNRQfx8e9JXtlZNnpn49GqUZo9PLFhrSj+m9R/MttuVjlOHDrKke/LRftiYYRt2icDbt//4h87US04FYdDzdEjTzLa9S3BiiKWFnanjc7ET8oOuNQmFHYjg2QtMLjgVFQmfcc89UDv/fGJz9Hce504krvXNILO8z68R3yqitxPzbhjIgE6t6IZ2CvoHHqdRn7Z5Ln92Bc4WLyo3sKCKV9Tqs0Ry8tOt5uR9u/YnlGNMocWmVyOOboxTo1gD+5G7jDw6oQRfDp/sUg+7qx+zBgzBl1BKm6lL5NXfS8KTEdMXUGgvxk/uZXY2JNERCZKUwseD+HZVuKumyiUK0kTsk2KVdhcSnL0egp8fLHL9Lg8gvW1jiaWi7SQJVHkNjLG+y32NWqBW6HAaCqj566fqZNXSJCxJgFyGT4eP076phFWGkSFNYdMWzpn4+pxqGknzHrpfAzJy6Td6QNEleaj9QvE19dDX/NqfGXlYoT4gaoT6fOsVK6e++oY5Dmp2H1DsAnZSYKo1hLG+Dl3e7XcQmF+DvHnb4hOthNPL+JgVncSVGom5x9mzNLKiRxLRSmnu7fGr9DN6ZrdmVanKwYP/DxITe14qZ01Z/hQsdWTZwgnv1skW0L6YLSeRZf3sdjealMGB32kT2Hzchfd9KNI375d/GzomrRnn6cK50uUmFGLU3LdTPvEvCOzzkD91m15fOTYe56/IPidNmUiYTlpouarXs1Qpmc2FQlIfX0q5np12dX/XiHje4sm8lXcMLQeCytlJTzS8a8J9f1wIS2ROXt3c1Vbi7QAf1GfdifapR/np2FSS+3WJu30wjew7dyDV54Nrc0jJkXf+VcnOz5PerCdQq2KDP8QMiN8uW6ogsrp4JX965jywSy+WjOdGoHfi+emyaYjb5c/bTbli+O1dbadvatNImDo5uXs1DdG5bEz09vEsKYd7/r97ndn0sEzT/TqWUMrnuSIaE7XpOVPeDm9Ody5wV33+dGoF1EU5ZBT1cb2uGwxj0lAdasMZWFTTpc9Ri9nBgNNdqJUVVHqK0fYhVTmivIUnIHbOZNZTqHdIGbDHGhYyLWAepRWHQFyLaqzhaiyTUS7iqhXM5wW2d8ylE04PApWej/LrLLOuGwy0Zl59wsNxMmladO/xqcwAq1PNoUqaSMVYI8iulEwfQf9eWX7YfF/gtM/gVCuFEjEO7W+FL9/+/3P+M5cDb+cJ6gns5GrsJCtKcCqNJOpz0Q4RKe4yi9HDxG0N4hQlxeRCl8erfc4HdtWXuT3HFzPtgvryHCVkq0op0Cbj0ftZtW1YGIN0i5ics3XOO1dm6lnF3LC0ZOWIVKp81zFFkKDG6NwqrE5ZdSsu1/8uaJYjTqrjK0WI46EXXTPzxLbEeLrUCjJD44gwGWh26GTGE5cRDb7tYciHgKq9HiarUXlJF3KILfCj0xNKOmGEPL1khX1U7ZktJoCqhkqOCyEs92akbsPjjvl9FRcJlleheapJ0XyURZ2mNiw3vTIKucX37tFi9Lr+IOZ2a1vnfUhpS4q3xOog7Yj1xXgrv4DtvI62HJ74XEEUIw3I3iL1wO+4WKFRFK9KcNokHYqu30q8AgKeZeLgFQplyXZN4j171T2gpu1aclvW5cQXlANX7Mf7834iunTRom/i/SX/B6Ki8OIc1lE4uHyyFDbjNRauJYqX6wgKd+ES11BqiUfH30w3Z9/8A9x7XcWcOPDdNENtrn2Jw4vjqP1yMrWT/X4cM6frYun5jHxbdfWLsd6Tsbl0iCsXt4ED1vBwJp1brdqvp27hhKdlIHj4wpie4EcH/8ujK6yjt8y6pDlqYFLoxQEESLxeOnlIeIotbdeR4nDLCb3/v7rFrr074m6TJp2sXlJF/g3J77LIf/OBLgKea/pp+iMkr+B2yWn+gUHhnIb32ubUe+RycS37s6Hb09Cce0qco+brKhqzJwxR1ygN//8C4f2aojzycRfVcGktIVE3TjDpi5PUuQXyNrHnqfnNQvTkp2cj8yiwytPcWPuZhp4vFhd3cOKmjpKjBIh9i0ro+3J36l19cztz4W3KZn+8vN4qewUOQ38aOpKiDxQvAj/tOwbZLlpOA3e2EIl4uFvD2PcnxAPAQFBocTYd3NFU4ecYD+C08zC9pQidxAlmcn4RsRybP7rGBZvwP+mCdn6atL5102XRe34ytZMVIs2ZO3ahFZmYleQ9NlvX5ZKsqwq+dzgoNTx5IliA9NG7+XjsaNEQV6xPojFxTWw3fxwCCFpXayHpKBFtYbo+vXvSzwECO95l/hGnN2eTXBBFle9DbQvOsmewBZU5KhoEyg4vd5LPiY+9Q4/nzpGvjyEjWm/8QgPTz7qRdfmu2G1xf//dmI73yVmcN1Yi1w/AxGFpSwfMOSu2wu6s1aT54M07Soi/+p5EuZNwZWUyZkuTThfw8NFnyZkK+/WZXROShCJh4BRT77Hgu+LqRe2GYPGQrU2mbi3KO87XvvF4a3s1kmauR62SwxreveEmoBO775F0pQ9VNOdoJ5ZQYqXliouKy+kfsanNd4XDcfubL3oA0OxFeUQnO7FvOad2JS2moM+Hq4LDx1xgtjgYxSVVGN00UDKXApesR2hk0VLkL6GmPjsoxGqZg3o5JtFmu0iF0xJdDwjx6fmZc4op1Ee+jzuOnGM2beKbleOodjsIrJ3CULEzTF7DYa/Np/r08eyWtmDcquOod8eZP3kaEY89yjrl26mUClt6AJtVXGWBtOh291ma/+d+F8jOBXGUzsv3EeMUcUPN8eWnulVm3U/2cl2axhqrsvoKe9hrqjghy2fc7YggSwqyFYVUa4uJU+XSx654qz7lqST+F78hACXF4XKcko0RVCZSi7iq4thNNBLBjFzIp9ndVhvpl//kpM5nWgV3Be5TE5m2VHkQVWpa67JB6FL6ByajUZjwWb2oktiMvuyq+FfVNn2EHYvKm8DHWLDCPtkmViiFJbdinGDaN6vMrL9fji0dQ0n9u0ns1hJtjuQTFUIGYZgHIpm4Ct83X37IHMx6XYXNUJkKNRlvFh6gqjw+0dh30JOaRCZSg+eciNeeS4KArSs9LnM/orKqpHabaOmM48Kj4d0dbhoaiQgzGXlEU8CNQMsKJWVI2zm3GacVJ3kZJAJldcltMZLNLVraClYVgv7Io+HrKvS/IDRYxc/wOX2QiqM0jiLJj+blhfPiO+T71Ntb3uh3MLMGSOYO3YjeocBr+wqvPHVXKxGC70jpPG07NQGtDQfBS9BWxHFE59IJdehY57j/Tfnib4opxSp1NQraaGXRjsfBILO43LDl/G/OA1fZQ6RN5aRm9qVkBiphdWzfx+uHM3EYvEWW3BhNfNJPhdMpsUHTe3HaXmTeAjTKYe3nKRYJVXDvDzR5PvYmVG2nEGON4lS59E2IpVv5bHSCLVdg7z4OlofiViMem0Ecz74TKx+HD55CZunCIVdarnUb9+UuZNHsd6vJ61CjzG83ipRKCm8mRVl/pw7351jLgVetmCeG/f0bdHu1A/m8e6bE/BKukZ4ehIzJ4zGy2JBYZHU97+bqzMg+gJN/LI4byqnVxUt0xPTuBwezZaaes4HOhl7zY/j27ZT4vRiQHM9af7SeSIkQDfOO8OCnj2I6vsI2zdsIPHQQbwrrjPI/ygGhYMCq56f0uphceWTkrWWhVvXiaU9j1qLNbKG+H8/ZxDPvi5NffwVos0ZIvnI9AqiincpOHzJ1/pyfnBvPEo5gVlOsaQtnF9X4+pxQqMTe9mP1b07PG7IyJf58MRhfm/dE5tcS3X7FbYE9kDmakN0ptDycTPK1ZRnx3/Ll4tWIC+RjufvPm1F4mHARn0vCxEFRwjNTcehUOJTK45nX/vrab1Hh41k98VLhKRcR5OViVdcbXSFVpK9w2l/6fSfnpvNik6yJbAXp4PvnP/6e3i8WXcebyb9/9fj22hWr75o4f5X+Grx+1zRW7nctz+XdXXFkedbkHlcRFuyCcktJaYwl7jCuxff8c98xscrymkYtR+3D+S/7aRRXGWlSkBidhpfWFS45Erq2i7yZdfKTckfkeJoIpKPWrqjrJU1ogoneSH3EF9VNd3Teuny1BA2vX8OucNOeUUEn716nqvnfmfVnrfY7VVOrkpBblAy+oAPaVIawLqix/lCU41gdzlvl52iqjMQb58ayA3hVBG+/LuSb02nWvZFIkpPs63xh1gNzfhk2ACWHO7FKNMGXjX+htMhJ2hzCec21qZjtIbElnU444rmsimEN2Z/TYwQRKosFPWCPtYwSnzM2LXJ+PhWCt7/u/G/hny8ueaEGAIlfI1efpAvn29LXHxX+mz+nNXmWH4uied5Uxl6o7cYxHQn1m/7lgPJv5PhLidbWUqRtgCdSUlwUSQhNydIBM9+lUeG0iOjlSeX1jopIOhb9aPMr/YcPo5yohNN1PR/GpVcTUn5FUoC/Khhj+WDiCVUVzkJCk4RRxXVCTLcNiWJxSGikKzIJxxdQBQfTx1N9oVjFA189jbxKBrSgbaj37vr+V46eYCfV64i0+xHliKYDF0oxVqhOtAT/pCqrHXaiDLlEuHIJVRZQGSQnPg27bB89gkhN8xsf3QoZb4O3AYtURs20mbn4bumY+7E3MmfglLGMU9dLl4NYpmjB+VCDowcfN12mpUfpmrxNdHoSWjDlKm8OBXblRuOELIVWtbQnPAyN/2NCTw7dKBYLryFgzu/ZMnVzzltVHBMY+Oa20wPwWAowo4fhZAM9RwawRWMPZo0aYdvNSOvsKN1unAooN2rdy9AtyCvkoPnWlU0Lg0nte0YoXtX/LnLpaJJhRPbTUv2dIs/dYyVrUB/tZ4CTwU2gZy6JPHnw6DZ4IH8/vo52iu+JlqbwOnPphDyceVEwwtvDmbTL/vRxx7H268ImUAg3CaSNu9ilcmE2+lDfnYRZcoysUQtV8WxuHEMBw6PItgvmYEZB/nYfxh91VdwK+woHWq0KWeRuUwsGj+Kx8ZPEe3affQ6im9WP07vOo6gBHGp/HFVFLDa1ZpZTT8kODBbqnwJbZZkK6dzwvBy+FOqKKNYm8+Kj78jJMZPtIvPzMjAT6ajQm9Ea67At+hm+0woaum9SPOrwRmHmcaqG/TQH8UTMoe9Tdry3HdfsDe4Fen+SqY1CSayxM6NlpKWR+V00yD7MtPb1KF5j0qi3b1PH4qv7qKv9qDoj5DlDmAdvTD52sBchtxqEr08BAdTS1RNsfzv4/KlU7+W951w+iPCygrFz0y6Popm2qvgiCFdZyCxem/ccjlIxsCU+ug5pJSyQKph4sg5F0fOfXzXfVlj6hNbpqJqwjWq5ifTSFsqpo4qnGOorbWhaNCWR6b9SNWcS9THQ7o2AovOh+5hTmY805EPZ70rjc8KUzrVqzPmLWm3/68wdfwkPpk+Db/SAhRFJTQ2X+WwTwM2Kdry3NVzVKkp5UzdiXr5JrYEwiVNXZYsnc2I4ZKb8L+L/s3vf7G7cukcPx5YQVJgCJe865BRo89dv/f2lFC34gI1itJobqjOgIEjmTtpLmrBAbr6vZ4rrz23nD1za+Bu4sYVAonJE2ne5NDtCvjocwcp0tQhwJ3PoiYdRAPFP0PnTz4i+809hKmvUq3EnzxvJSEuJ4PSl7A7eLRYWbvVeqlVtw4bdEaRaKecPgVDh1GzYRfea9iF8QVprPzxJX5Xp5CiUXLarxi57zLamNSUFHYhUVWLU6o0gq2l9C0qxC2vCj61CdJGiV8NXB3wPrOYNfEnUMvO4qjbid7JR8XHXUg/fm3XlvjcK8TnXWH0pRWM6fABjhQHv9qq0VF1nViPDKMlmPEf/Xm17/9pzcf+/fuZO3cup06dIjs7m3Xr1vH445VR1sLdTZ8+nSVLllBSUkKbNm346quvqFFDCvT5T2k+hBOu06d7Scu3iYvFMw0DmflUCy4c3sCgDQoESdJU/6O8/PoHf3of104c4btf12KtsBCUnyleQP+IGEMxj0ddRCnzsNb5CIvjn+GCbxzDkrbw/IU4vLTBVFhzydQXEyQL4xP/n6nl8aZJw+0oFE5yk2rT7moCF9X+LLI/yxlZNRpEGdk4tpNY6k3v2gOlWyIeOd1q0emzdeLj5mels/zjWZwui+KMT21JV3EHhLyNEHMRkdYcwsgnzGCiVt0qPDp4lEi47gehD7vl+f4k1Ggt7prlTg2hWYV0GfEoVVt1uef2p/es4cOdDs65jbfLxIG6Avr5JTHgWkMs6pVcLiwSd+8CUuPqsbbjU3hlmal7vowbuITJPunv8NDPmMiQJ9oTe9PASMiDWf3ti6xyHyNTLS0WNa1OsvKHk11Rm9EeNR0UZraoz4gXSX3KZfDoeez4UbLjjHRaL6XD3g9vvfEz4cX+1DVswtF9C3Klg7K8GMxH6/OI92ai5Pn8aG7FUx9VClO3zN5LQvlZrOoS5HYD78y6o2b8EBAMjdr6rBZNo3aXDuVqvRCcN44Tmp+Dd5kGxcgs8bpv+S2E1HQvrGoh3VSNOyIOk5cGlUeBVRPHklY12bbjfRppdmFxe/GzfRhJCj9QmVC4VLzIaq5bXBzLqCHqDISEXN96TdEZDaRkmnGpzKhKytBmX8XsHYx3cBn1253Bc/NUkls9pJ+NpIL2ePmGYDXbMOUpKNWViJ8pjUuJUmjZFFxD7rTd8zpLomP4YO4X4v+P7t5E/X0vYpBZ+N3RkC4zpXbjiv2/sig3nJRAaTGXuz3Uz8zkpVrK+164fpg9kv7WX9HIHGJib/6jX9OkdeXo4IEduzm+7QR2nQ2byo3RrSe6SiSDXri77P9n+OTLN/mo9iBREzD1+G/MLWmDr8zC45q7pyasHiU/2RqK2q4e6kRCbhq1PTA8ck44Qkix+/Js+ioUuMmJbcnsGVPFC+Ok18cTlioknMowVavO9FmVZmEPgi9mvok1QdK1XavflJP5NSjQ+dKv6Hfm32E8difa7FhLkqom/XLW8dXguzc4/wQEUnNJXcZV/1gu6ephkenvWq9inUnUKblMbEEJLw+cLLbBbmHe9MlYUtPQW0yimdqM92eju9kmvD1eO3sZxcMcWFpK6/T1vCq89NQuhm9ZwWZdIxQeJ9N1RYxsVTnt82fYP+EVHvH5TvxcrdfG8pQ9gSSVlrYtN/NG+qG7Wi9zx45CnpeO0+jHlKVSxMSdENaxtavGsK3igLiZuoUYi5rQssaEm8OJcKh4STUPsymCvKIJuI2BqHWBFNmyWeCzlBOxWTxeXsEHBUWUoOURy0LKZJWVVy+bieElO5nX9GmU6SbxfHrJlEyPdgrqD6pM4f6n8TDX74cmH1u3buXQoUPEx8fTv3//e8jHnDlzmD17Nt9++y2xsbG8/fbbnD9/nkuXLt0j9vl3n/zDQpiJFmKwxTRKOYxrGcZrfZow5f0vWWOOoYbcyaZ3ut+1sy/KzmDxlwvIr7ASlJshum/eQoF/CE5V5UU+RlHICO/d4kK4ydWCG97RzGr6CmqXnR82XyFGUwWLs4J01xUchmD2yZPwNRTSoNF2VCo7ZUVhpK8zMLL6Mbq7PyTVEUWgv5qjEzvisJq42rIlaqckCs1uHkabxVtY8dGbnEgzcMKrHmWaylKmEQs1LSnUdiQTFaqhfd9B1G749/p784TRW5cZj+JmGqxDJ47wTZg/Q/z+4IbF/HJaxlZrOLfyHmNl2byg20BI60QUMg9VDs8gM/sK8f5fc6YokPO6eGT14pkT2RqLUo4huRjVVTNxKBBSGopu9vEFmtJXf43BPeKo3UzqPZcV5/L5ygFs8C7CJJdjSn4FtzWSWWjJUp2kQmFBVl6OMeMKyHzpcfYUkXt34H2z1/9H7Nu/gwmlPszcu5Hg4LOUNJNCtQ4mjqPoeg6f+nyJ0yPnfI91NG7ZQfzdyd2/E7hTww13Afu158RSfpRv5G3DrgfBpp3ruHp8A/65STS/WoG2pEy0Usd9t7Ymfa5gauakvCiQ8FlWTkeHYdIoxQuRO6Qqdq+qfNn5EWYc+Y0XHAtEErOldDinDCFiO0UIIzxrDeUbw1QCsbPPEcbx5FrI7ziXXcZYzFEB4rys4foFQutnEtas4Faxg+Jr3qTtCbvvgJxLq8cSUVVsa4hwu1GZKtA41GgCDaSU5hOecUP01XDVqCm2ZQT89HZfBir2ilM768Ne5YmXJdO1zStWs68sljSDnPbF2YyaVLm+3IkfPhjGE87NYmBWsjsMc78V1G3cUtTALJ75LRq1BpOyEJtMOm81HjUGhZFx74x74GNUXlJCw9MXcTo1DNx/hF+cVcXK3VDFReQeIcxMut05dyCnPMEEYuExefI98ii3UoFdphIvAlqLNLzqVsjFzCHkDtwKK3Knjty8HKqWXsOlM/L6ih/F202dMp6gFMHuHQpjazDrw4cjHuLfFeYxc/ZMItKTxGqqXGlgpXcvdA4rizs7aNfzXqH0q9+/xZqIgYS70umdLE0H/rsQzoEM3wAu+dQiTXm3+ZqgZ6ljukDNolQaKSN5+ul7tSy5KTf46ItPRQ+TO3GntkjA+uebUPOIhbzacq48GSKKxwWcy6vLJ8Fv45SpeNR8hhW97h2xvx9yUzPQLumIjzKPveW9iffegpfHzfDqL2D3tOC7oZXv39J5cyk5sQ+PXMGIr78Ts5j+DAd3fMEviV9zwNuN7aYoV+fUUb+4Fu+XbiNCYeNK+cvonO1wq9QolTrOFe5lbcN0Zpf8SrjTwTx/X46rGtMipz/XbcHsl5nx8igY4D7J2qatyE5Voyi0iS7AL5/fQOv049h9HOifHUyTEdP+55CPu/5YJruLfAh3FR4ezmuvvcakSZJyXngSISEhrFixgqeeeuo/Pu1SZrLS9rP9lJU6QCFjesdoGqsSGbxVL86zTws4wjNjp7FywSyuFJTim5+N3iqNagko8fLD6h9A+7ga9B5eySD3LvyENgXzUMlM7HfV54StOmeaN+f3gNb0vpbFuze8xGC0k0W/kxkcSYmyEI2+lIYNt4s6D4dVx+U1kVRTFSOrauKVsjmojUoOvdIGb62SCy0bo7dKxONM3XCO+jfmhLY+OYL3wU34Wsupb7/KmUfiKQgOR4mT4Z4U3ussjWH+O7h+7hI/f/cbNr0Lj1wapzXZfEmVBXPa7XM7W6Wm3EEcRfRV/UQX2WG2VY1AFWnDK6cZIcefIZefae67TnQEPWZ7hw3VrKyqIWlwHrl4guQsb4rdRgRD4lzcCFmOAgRO31uXxoA2PjTrIu1ahV7q53smsDHvXTxuLW/JS8hUXxODy/TXT6BwOVkX/DhjL6/myZ33jwXPyk7nmaMptEtNYGjhRk7XtRMQnIrLqeY9y1L671nCa76/kmQPodqsq7f/7tePttK8yMhVIxw0HxO1HwqHgbdn3lv9SEpNYsumpcjTzhJWkEdInhnvHDfK8vsLeAUZTGmEjLwQDdlBAWgaWIiMysHlUpC46zlKFSbUeemoyqSQqbKAWDIaNOfr7Iliku7hsr78rqsvtlGEEL3UIh92G6vxqOkQHwd+icHjYYsshvMpdZHbbtFFD7bI+riNHqpFHiW0imRS53bKuLErmrL0m4rIP4NALHyDcfsEiSFutyB4aHg5/TFbC1BmHMelUKKrVZtx78wWK2spM+PFseE0dzBBU86gM0gE+rc52zE6dUT21FOrsRQQeCd+eHcwAz3bUcpcYoCW7Ok1bFy1C4VLh1VZIrrE3oLGo8LgDMCjtPLqe5JXxsNg0MqV1L6ei0tm5nub9Fy+bV1C+z5SUJwQUtnts4sUImOC70lenTr9vtMjAkZd/Rbd2XJxIkIgbb3eeJexR5Jpn3xGrC5qShSos4+hq9uM0e9M5503JuBz45r4tzkx1Zn7kaQ5elhMWPIZR73C6bV1LTqrWbyvUxW1ueEdSaeCYyz75v17/mbNj4t4LThevFD/VyHWkUSd0svE5hfy3GPjiIyq8qe3Xfv5PM6ev0hASf5twqFXyfG5cV1sQt+KZBDGaw3PPYfcJmPr0JZMfGs5K39pTYRfrkikN8n6csbRjF2dB/5lu+WPODpxOC29f6bEGcZugw/9bZc5rfXhxfo/3zX1Iox0L3lpKDK3C99m7Rk+6a8rorkpN1i4dC4X9elkBmZhUd8ky254vKKcekVBZFkG0TXfC12QkN3jZHfWt/SN3IbdKKd3eDA20Y5eRo+SNnTK78I5xXXxMyCEgK6K74L7bDlyk7RKC14vdYpSxPbM8I9GEl3r3rbb/zjycePGDapVq8aZM2do1KjSGbN9+/bi959++uk992Gz2cSvO598VFTUfxn5EJBXXEH7Lw+Lnveo5CzsXZ1923bxsyUKf08pvQq34lsu2VULMGsNlASFUjvIl2defeOeCs6Bb1fQPGk6GnkJp93V+drUk7Ehm+nSbJlY3v71oIlQk4Ot5q3k+3rhUbhQqSwi8dDpy0VGcXZdnJBoRrewq0zxeZpEmrNmcAOa14rgWLM6WB0GdsfEczisIdd8K/NoNE478aUXiffNxL93b+Y4dZTI/cWSoiDmFP59wX2DD7r8M2YyP0+fysmKMI5r/Eh2+4u7bwE1ZTYGB55iyJi3+fy9r1CpUxknW84NhTc3WqvFnWDM4Q/IyUylht/PhKivU+4K4JBzHMvrx7AvLBZvu5sZlks4vWqzdN9V0u16aqKmGA+ZN0mIoAB4VJvNgEYO2j0+iuPbv2XQnkBxPz5UfRqZ3EW6LpI6p3/DrNCzNGoYRoeFUcaDjHn/7vNP6NU+89sODBVmxqVuZos8luZt1qBUOknOjiXQ0xfn5W0MUB7kO92jbIt4gsWP98BhtZL62WUC7HA8OAeXt5OL6UKVBcK9whn5mjRC+POmVUR+OQPvFA+yP1QzBAgjsbZAKApVkRPkBcpg+qhOYjSWc8ncibpzpZbarmNb8VS8Ir6HZ892pbwslNCsHEKvnicpRBLx6NWBDI3ZTp6jJt8rHhPJkFDeC9QHEhvp4rUzEViVGl63LWakz15R7PWTth5thqxky+pxdLWfYHtZM0Lb52AwSNMspUVeNGmxjipR99rF/xXmvb4AtUqHWVmEVVb52da71fiZ3ZhLM/COC+f5Se+wbc1iOl56U6wWbnA0p8/MneJtBTGvoI7z0mmYMO3uSsXat/vzhHyPmNx5xVWVnY4XsatslCluNe0EDZYcb1cADqsHk+oGltIy1PZbROvBofati9PgED1vZG4VP9gE8aOKHmW/YzB6aFEliqzSCuaXNiUADzvG1SUgvPL9OnvqMC8UF5GliKRt2X5+7juOg7v3cHTJfNFvRFmtHgPHjuHjpZvxcuZIu4siK8aGwThSM1Feu3bP1NDDQjjPO+44Q7KXjmd2ryLsaqIoWLUFhbNc10u8GM2MPM3gcZLW6U6M+mE6JwIFG/Y/n3R7OHgIs2UTV5RCfU8Qzz772gM9/xnvTsWYliJWni0aHYqYaN74QNLUvDl1AgHJEkHLj61Odds52mzNwRLioc52aby2oqKC3w51I0wlEZCTGY8w9Vkp+O9BcW7DZuJOjkArN7HF1Icuhg2CxIx+dSbT0ex1u/VSmJvHotlf4tFrkJvtKN35hMbVou/QYberIJbycpbMn0VqqQn/vCy0N89NIeMlvWEUZ/wvUKopvf3YDStk6HLimZLbDq1/DQqtWZwqWIy8WTxv1u5GzZJ5FFoy8bJ70S6nHTqXDp1HQ1zyAc4b4viy19NojuaBs/JyH2bK58jCeyd8/keO2ubkSCZSQqXjTgjf3/rdHyG0aN5775/vJ/4RVy5cZean6/B1O/FSyRlZM4wvnKEEVuSy+ZeDaE3FKA2hFMl9KHMaMCgrxHHWEC8dr46djHfQ3armWzixaQPx12eiUZRw2R3FrIrBLDZ+xjtRUlWkU64TuzWbH1QXsAeIUj5x0azbcBs6vXCBgH07WuCTXybu4op83Vy2N+XdzlEEywuYM3AKx+oP51xgDdFMR4CwGNUruU4T1VWeHPEstRv2Y8GBjXzg8MUsN4hmOR+GBjEv/aIoGFsmr4r79zXM7PKv1f1/hbVfvM06V2OOqIyizbWASHkJ9ZXZhMhMpBf6cfrAcV6bPYFPp31BpjKEWGcuCalV8KpSQWG134guHs4JTzGtnVb8lRm08HyNPWkYGYYQkrz1LLTGsqZOMEM6x3M9q4C3v99LWhHUxiDqclJxs94axuaj0PnMt8RpBEO4QLxxiMTD5fElXylNGqgUBmqUpotk7VNLR8onjGLqfCkuXsCrP3xPiT6Sl1N3s1EeS5Omm0TiISxOBr9BHN1wjldCLou33VS9C/v8azJg23GeSc+hvT2aIhW0f6YdAcGhJN6cfMkpqlwwgpbNxkeMY5Hh0nsoC5OTF6wjOzAIR1R9uvR8nsbVK1NGBeydMJ72rKCuYTcHJ4ym7fwv6dyiB5u2a9CpbERGXCa3sBGKNv7EXN6Ld4qNc9EhmO0FLLnRiYro+jeJhwyjwptXpowW73fP/lf52a8bX8mexktexlD3aQZaL5D1bUtecNk5UcWf2PAryJUe7HYtVy925qUxH/2ti92kj6TqQmpyKj9/uRGVRk65ohCz3I5ZKGwYQ3GXqlnwxhdofeVsdzamj+o43ZVnRDJy5mKF9BoEAuQ08f5bcwkP8uXF8SP4+e3HGCA/IKaZXnHXZ628Ey6ttBMWlPzebj+wa4lrEcb1C4cpLMwnsChXmER8KLjUPtgjG+HU3MpaCeB4w2C8DxZh1YQgszgIK0whNfU6q6KfEo2eWmuuEBAuWc/fwudJu8gKekwUTD5ll97Ltp06cviXH1EUZGJLv47B4EO/1nHs31qM3WBD7uNDUl4FVZKSJOIREcuM6TP+1rEQMGPlFyTX6IzW5aF7+/b8XlQqjt4Wejyi8dgZ/9qsvWBEyre+G/8VWo+Hwdld2/l+4wbCsqW2Sa5gdd+hHe0HVE6nCG2oya+PJzT1OkE3rtEgVdo4noqPuD1eO/nAr6zXfMoCz2gCZEU0jdzPgu9fZfwz926I/wwN+/Ti7P52NDJuo6HyGrs1MaKR3ti0lSwPeV+s5M2f/SV2lw23qGW2iQJ4tyWS3MOHWHJwJy6tBrNah8JqwWA1c2touELvRVlgCI0jgpFneuFvDaFYk4fT53cOGLScM3qg+kk+dWQz2TGRAG04wbr2lJzOYa5dw9y6M+hsXoYh2090NS1TlXHK/zJ+1Obxn7fwe/O2XGsUifpUvrg21FIVIYuVps/+U/hHKx+HDx8WBaZZWVmE3cxZEDBo0CDxtmvW3B0l/t9Z+Zg16WMWK2vd9TOVx4GvvQRfh/BVSo4mmHR9NIGU8XVXP+I7//UY0qWjh4jaNBIvpVA2DuKV8rF8pF+N0VhEy+Y/4pQreP7kcTQmyTMCl4JcfR5dG2/FR+0RL3K79rUh8EqRWDZ8LCKRD7274FPsR57ZyCnvOlhUlQtO1bIM4l0X6dkzno59pXhlAW/u/JHvFFVxyNREO5P5pnYjGkTGUmE18/jedVzQ1BUrIM84rzGn2/2WmL/Gz1+9w6qMhpxxSc9F2AO1U5XR5+JGBBnIpXqNcGik1pRQ5pc5BdYtp4F6L91l+9jjrI6rY4lU/TjyHoXpeZRHOGhuX4K3Ip98RyybvAcys3EPKlRyOmQl8ePTT9wlFp714x62XCjAGx+EVIjrt9jPTYTLS+muusbmuh2IP7WR6oLYVO1PncJEFkc+KS6wwkI+uHwbM7/8gmmLP2ZjYFPePrObCwoZDRpuw8cnXzwm22W92OJ5jIh9yeyQTxb1HqOi32NbTDscChk1yhwsOG0j1VBB/9elc+TX5WtJSLkkvjmhhlCsFXvoviYBj9zDrpf7MGLk+w988Tj92tM08RJMg9Tst46k85yZLPqhCzVCkrHZNfR8VHKlXPXrChrOn095hYxTsaGUhUVjDwoXCa1VEYC9hT9FTjvCElPulJF20herQ4UySMGrPusYm/EjFTo5pxr64rzZKinN9SXxRhccdh0Nq9al37P/fstOwMGdezix8woyjY1SuSBQlZYdcfTP7cMg2XLC5akcscezQ9lRbO0JDqxupUW6kVA5sWsZJPuJKqrrnKEuG+iCB7kYCKd0eKPzczHy9VF898ksElLSxZFUAXalisLwGKr46MR16F+huMKAS4mkcRKMrtx6vurQWdwc1P79AtfcwTSXJRJjSsJZ6mJdWF8UbifPZqyiPDAAg0HLs08N45dDP7Kg1gCxbTEs9Qc+em5O5TE+cZzdn8wUS/OymDicFeXIS4oxV2uEW+FAZTGgTdlHdmg0bTq0ol+/vx8A1nndfi76etMh+wY/DunPmoVzST18EIXbRX54NdaqOovGYxNkW3l19uf8v4IF702lNCVV1JcJEz6FMVV5V8jVuUNYemd15K1pU2hw8TzNk7OlpNvVq2hcrxGrT+1jaqkWu0xDh9JDDNF+iUFtFT/r1wqHMmrQvRWfP8PeDz+hnWUGCpmLX2y96afZJFZdJxjexa/ULp2v4jqoRGZX49ZYpaqZS4kupwhFWWXr1iNc/zRa0OvxDq1CzyHDqFazuqhZ+uaTpWJkxdPuXajUl5jvHcEeb7doWvbG2eY8onkOl9vJ9qzlhGir4B/alN9VCcg8TnGd3RG1iTKFdF2dutGNd0kUL70xE1mmFdUlqbI5xf8Yo16/t932v6bt8u88+YfBxI+mUmauQz5qcio85Cq8/tI0S+V2EGgrIsBeToDTgq/HJVZM4upHMXT0M6RdScR75dP4qpLI9/gwumI8L8ku0MX4Cy9HzeW3qs2JKM7nsYRDotGV3VbK/hpHeD2yEINGJp74eUc7kJ0gpWUK7RazVs8o62SKtJUjgEJkeauCBFo20zJkwr2TOCO3rmCjpr4oXIuzJ7K6eVci/Cp1ICIB2fMrF7T1kHtcPO28ytwHJCAVpQXM/ex7vjfVEHNLhLpLZ3Uh/Wpk0WOoNI68a2RPwvYnc6ZhB5KrV8Gpuvnhc6kwOHSM1cwSBYgbo2Lwq16GMa8x4adGkeC7E2WZkXbqxegVpWTZa/ONTw8uBNUiuqSMxvnp+JsdqNwa1C6NKBZUezSo0aCSa7is1LNao+XozUyPOooc4jVlLGnbgbErZ4mivkAL9P1qIWh1jJvyNfsDpX59z8J9HO3ak7Hnj5CqsFGnzh4CAqVR2YO04yvZeLA4GXpoDXNVizlurEuf+C9Ruh14BLmhXIbB4aZ79klGd+1GvXCpT33L90Nh19NnzzLUxTLOP+LFoMXHeRgI4jbbosFEaxIocoazt+ZUEjQptAtaKZ43R0qbiURTr1Si85RT7VoaZfYYirwktbuytIDcKr6UhlVa64vHxOpGkSORRHeIlibuRIL1qVIarQuyjobwU1Y/mvuBW226b+bLP4Ev350F5S6cOhVFSqncHEghI92rWegaT7nKJYovo7o0IGdLomif7lCXSqzXI8PfIcMs16D3+GJ3m8U0XgHbv1/KjtNnCctMEcm8cMHKjYylX5vWtO33r6t++ZnZfPXFKjE0ULSfd2qICg5mwLAnaHT6AiaZkUcOH+N4eST9tFnMf3cE/d5ayRlXANVsyfTMqpyEsimVbBk2mOvqOOpZz7GuVd+7MnwEzB07GnleGm6lGpnbKbZhLJGNcXrdnIAoV7C6Q2vkal/6pe5j9sh7g8X+FeYtW8C82A4o3B7ml19k0ONSxWDS5PGEpV0Xd9w3FDXZF9ic2LJMNn/01J9Ov/13QRD5z/pkLqFpN8TjWOrlR3SNqrw45a+rMEIr42Dv7kTmFovJxtc7t+eJsa/R+/QJchXhVHdcZVeHx0m8kUBW2jNolA7Rjj3XMpFneksVwgfBldd7itEI18wtuajTcMPRjDK1pIPDLUfu1NOre0s2bPsFp0WL1uCDSyWd5+oKLe78c2jsJuTuuzdQooBcqweDNwptVcq9bTT2XKWvbDO5bn/21+jFZ/Z9lMg9rD4xBj/vehRYM9idvRpbSDQ2/yB88KVGlb14Is+ztVTFoQoVUbke5i5zsajfYNZ064PxUg7OdJdoTbWml40G7frz/xvBqSA2FUSnt55McHDwf1xw+ub7b6G+GbIjQO4S3C81ONwKSl0qLskCuCEziCfALUvcP4PGZWGJ+iseUZ2k1KNnjGkiPRzQ1vgDP8kHsqB9V9GFtNe5w1S/cQF3SQa/t03h9Yhy1Dq5SHllpzty5qTUimoffAONr4qBjulY0WC0m2med4H2GWeoV3CNOkeP3g59u7MaMGT7SvbrpVjsxtZz/NRxIEbh5P0DLHYbfXetJUFbXyQggx2X+bi7JJb7MwgTLPOOBXD2ZrXjEVUZLzQqpMMTUqrknUhY/RnyD74UNQbHWvYkMzJATMUVoHSqaOW+RI4tn5AeSaJJVcyRd5Fna3C6rSKRUCi1yFQGZArJ0+F+sGCnSF5Bkazi9r8lMhN5Hg0Zbl/qesq5GK/jgrIuL68SpinkNElNpePRc7d3RpPGvsOmgPaocTJAeQW10kyNGocJDZOU8wk0ZLlnBK/5aNj542H6647QX3GQr0P6MyNulHjBvx983UUEOfOJTTNRNSNd3Km3OHyJMFMC6m9/pc4fWisCIUzISuVqYTbpguW2zUyJyylWKExyJWaFFpvDG6tCTZHaG7cwEQEs9zyFWsx0/Wdhdyi58VsUZcVeKKNC8AltTFZ5tnie1oupzYAX/r123f2wbeViju3ZQ4BHgzy4FiatDG9HOdmCC6tHjgIF+QYt/uZy2nKccEcF2zxd71nkBw3sjik/ndU7thOclYry5gRPdlgMrWvXpP9LlSOQf4Wfl63h0o2U2ztXgXgNe/ZxqsRJ3h0dt31HoqY+LRIOci47lraqcl5okMOLp2qINbjPa53FbjNyJCkZXVEBhU1C+aX2M6g9Vp7Zugibx4e6wf4MGTfldgXsyuVENrz/xu2pI5dag1mpRhXUGIfeLGpMDtVsRkKE1PIVKhezWtWnauyD2RYI6P3TDk4GBtMiL5v1T1Y6laZfucg3H83Gu6KEtLAa7FS0wazS8Vz5Jt79orI1+d+N9d8s5Oips2KrTIDQcho9dJiYVfOvsHTlJ7SetUSsKOyrFU2x0cDuR4UU5Tpi22t1tXCaxkjeQXuOb8dWOlbMgXG65diVs3msQ2W8wl9h1+tvEqbeyyZ3H8wCqbhJiuUuLzq2bkhZ7lUOnDhFUKG0vrvlKmwxbXBqpVai3KmlSmgwGo2LjMQLOMtLkAueNM7Kz7bwGkzV6qNVe5jsWSS2Gb9lAI/KNjAjyJssazjzM99GrtJxpnAXV8pOoo9sSk9VB/HpVPhuIKv+VnIVDtaVqBnwLdTKUDF4xlxKjEFEnLrMa0VBNB8SQPUGDx4d8h/VfAjCnevXpbEvAcnJyZw9exZ/f3+io6MZP348M2bMEH09bo3aCoTkznHc/wRir6SRHdsIt9wOcptouoTCLu7mhf1hW/Jp65FhcRr5yRUnlva7uNLBVE6RW0Gh2kihyocKlZHn1TtF4mH3KJhqHk1TawAVXjdYruzLqZgYkXiElVVQ4/wBVBXlXK5eztuhZWLYknBWuS+15dzJHPEkaR6QRrivhT6OaYSUF9KzYi9dT5xFJ+SgKDxE7dh6D/EQLl4D9/zEmZvE4xHzaVZ3H/anym2dWsP6zoN4fNdazmnrs1pVC/f2Vcz/EwKyaM7bfFncUvTcENjxCO8zjJk46U/NxRoMGUdJ+8dI6t2T1kc3ix4jB9r1oShIg1Pp4AA1UBOHKqWEgKqFFFRfR2T5BFGs9Uc43Q6K3MUUyMopUFgoVlgoVViwy+9/0Q302AjxlGI2BnDNJ4rwG1Kp3a30Qd3nkdu3Exb8aTPG45nxPSo/t5hUGR1zhpBQiXjcoBqrnU/zfZ1aYstqxbJrtDRI7Q2vAjdXhzfkpz3bsVwOIskoZ32knFLBb0OYgJL7U6L251p1eCHDipo8zjdoyHcRLci/dgrPtdMioTDL9VTIjZgw4hGtQoUzz19S0f4Rfxgw8LJb2OzpRTflDnE3qBKN2tzYrV7YHdKNhSKQUZWH3aoSvwTINW5kXgLble5H+FspN1gwxHOS7whm35Zm1Cm6SrkujFlzpegBQWchTMtcuv7PhSz+0XlTWKCunTiOLvUgJWH1MfkIZ5ubRvYsqmjO8pu5Ox04Kn4J70e2Q0aCvB/ldptIEoQq05p1G1BWQGhmCnJc5AWFUy0ylNemPlg5WejTz5vxBQ65CZSCqFSJVm5gyqy7g+aiTZki+TB5ayEb8lxaNl40iMSjqdJC7+feEm8n7CG/+WY2q6q2E7/vnLaVgDTBrbSA4vQkZowdid3Pnw51atHzuZeRBUdBtjRZZFWo8DKXU1KciEodh1tppW3iOfzcVdgXVYO9YVUZfKGQ5w5uZ9TQezcBf4QQ3ng6SFojutjuHk2NiquLISIMrpQQmZNEW28dO/zbsFHZlmcTTxNbW/q7/05Mf2MC2vRUAh120TreGRXNxw/hZxKw53vx3/xaCpIjYyj0DRKJhyD6f1FRQtMYaUxegJB4++uudzC630Mpd+N2vMXBU/60jf/rePmjvx/gkNIft6I73Kza+dgV9JP/xt5gLbsOpKNOTyPIYRNfQ3FYFG1rVqPvi2OZ9/4CTM4K8bjeyM9A6dIzedYccV0VNkfbN6wn6cRxHGVFIhlRF+dhCYki1RNGrCyL/o4NYnTAlBwPb9tV7PL8SleepoFfO7LMSZRln2d/nXg6VfjiU9IP38PxaAJ/4KW6iWR3V6Bd5OH1777hzTFvktk0jvPX1jCkQWUr8L8bD00+Tp48SceOleE7EydKpcBnn31WrG68/vrrmEwmRo4cKZqMtW3blm3btv1tsdQ/BWuNJrgp5WD1BqT6RVAzJ5+WN26IpS+BkLgUVjFwS6cqpwb5XHEFc1HlTffgHKJcKlER7vGUEedKZqBS0q7sLO9DlNKfUv8MSuRKnHIZlyKknVL1G1tE4mFTw7AmqdiNCrFknnCjCc6DxSLpaeCbTaOAHB53zsBplTNKtp0Gxy6K1wkh6j5wzbdifsSdyCwuYMjxnVzRNhRthh+znWdxLylU7a8gEJDfRAKyhnPaBvwoEJBt3/Hpo5W95PSrJ5m96jxbbC1vj81OrHOVR5/517PgwvOMP5PI3m6NCE6z0WXPz5QZvNnT+QlsWit2tZvkwrb4x67HFHSOs/JfySmOxaQWSuoesb9uUzpwCsfhfoUnj1CtEqJ4VeL/tWoFcdWi6d6vB1qjnmc+W0iBPJj6uVKLw6NU0ubNhZXH32rl4+8OE+XvwCpzEBRxmejoC2LLIdsTykrHs/zWor3Ysvrxiw9w+4QTLhPyXOQ0HzhJfP8M5z10KnCSoYNJj1Xj1Z1H2BNeTbz/KuWl+LqTaHj+IIn14zAbHRT4NuW89m7x9Z0mSkbKMbor0LvN6F02DB4Hgq7MV6EgWK0n0uhH6K8b6Kr7Tiyb7y0fTqdPzpMwaSANjDvYbH+ck6qqYqVF2Km//uZoVk7vS9st6WT46rgQFSz6ULhVfjQc0Ituj0uVx3dfGcUKY2/ULgc6h4UBJb+KP7/YuLZYURNIrCDwzCgxiS2IHxev4qmRf10p+zt4cuxkvpkzndzziWgNvrhkFuROI73VPyK4mKBS0cghGWN9ETSAQUPn0dnbj7yUFL5a9IM4kixU2Bze4NK3RJj3fmPSS/gG3t1u+jOcO3qK9Rv23Ba3ChqTlo3r0m1Ar3tuGyo4nfpDkXeA+H2WW0WGVZIL9vA9A1TumjeE+ootmhhnMmNrdmFHkkn0CQrOzcBPGI8uKyIx9Tr7TpxCYdTjo9PjcrowWCooN3jTrv0jZBS6SSvKEAlgg6tpVLWmsy6mPalGLbN1bUhY9jXzhzz7l+vqJncgbpmMhkXFjB12L1l5/f25vDb+FcKzU/CT5xFoKaZA58en879nweL/PvJx8cg+lq39SXRvFZAXGEbHFs1EgvqgOJ1wihpieq2M002bEle3A9MN0lrcJOEwDW+a1t2J/p2fYdlveUR5fYla4aS0YAwXk36ibrV699w26cJlVv2wCY/Cgudm9U3t0NHac5yrehdVnNd5qlDONylGbG4V+QFhdGh592uY9M549m/ayd4jZ8Xj6lRWMOeDhXTr2JKWXdrRd9CTIHzdxNdzF5BXXspleQ1iyRKJh4B9zngayVpx3i+d5tmJ+HjXpkVgd3bl/EjyjbVMe2QEryWBnyOaqrmTcZbvxBG0FVtMBa0unCcu+SBXYtvyfZXWdD6ynS6tuvOfwP+aVNtPJ3/As/pvKJZ5cS6gBjcMkVS49cRk5FGGFyUeb9wuPQqXGpNHy49UEXeHPVWJBCukxcmXUkayGj1WTnvqstHzKB651LfzduopDY/n69oBGCzFDFszF6NVTlzHHHQ1JfX12fQ6OLYqUHmc1PTKp1v4VYY53uKkqyavlq2hy97TEvHAg/qLmdToXCm6FHAhK4XhF8+QqoxF6bEzzHWDWV0fLEX1zgjpx3f9wBmRvLgZYL/IwkeH8uvi91iQ3Jg0j1TiH6BL540R3e8aG3xQ7J0wiOCt56VqpFDWHxDNSXc8GSo1NeMOERJ6g9KSEC5e7ChamP8RgmhV4dJgVRgo1RlQU8Hox7pQrd7dguE7MfLbd9gQ3Z/nf/2MwLw80Bh5baVk0iRgxvvfgSsFp8xFbFAKEbUOiMSj2OrN+4en8EFcPn2HSqZGY0dMwhDs4UPVN6S4Q6ny/hXsQurmnBNEWuBYYBFPTJJC/EYvXcT6Ki1EHchbW6bSZWMqO4WgtECQOY1cbuWPChl+CiXBGgNRXn7UCoygfniMSGgexOQqe9ZgauoPY3L5ct7UlZbeP3HQ0YFdiqY3hZlSQq0QFCdgwfRBdPslgSKNjlOx4TgVMjxyPV7xDXhp0jSRiD3x6mIu+lUjypLO4zmbsGj0fDlsCv2dF/n80WF3VT/+q7Qft/DBG/NwaSrEqsMvjTvwSsFyRmb+fPv306q+wjdRA4mxJ9Ht8DHIysG3rAg3CmyRLXEZ3HhuVsYErYhwMX/1rfuHrd3C53O+pKiiRKqACiVzp4Hxk0fi7Xv/Neezr6Yxq9YAFHYbqj2VqdIxMhc7pne7XRWc9s1rfFNtqLgxeOXyat4aXWmxfunoQX5Y/wu2cjPBdwRF3oKg+arVogUDR0st6/ffmieSP+Hz0LhmXZTBMuZX+HHeTzrOjQoLeT3AQaeO9wrjt+5cz0uyaOwKGaOv7+KdEfcfad338/cc+m0dGoeNK/4N2OHTBp3TyqJHLLTv8+d5J/8Uvpo5jZwbyXhXlIoGZHnRVXl78pt/Ol34Z/hmQifabM3GGuwh6Jd99Dl3nCxFFGG56Qz5bTFlXn707tefFj3vrcB/+cM0agb/IK4HFTY9zZttJyxQIpalBSUsXPANLpnttsmicI4ZVBqety/BX5XBrxW9aa3eTajazIH8GDYYOv3la7BWmJk7+0tcwlSezCPq43y03oy/zzkrpFu7VVcYzzLx+3SzN6ts/bD6SQQ7rsBNW207ZEotJ4u2k1R6loyQcLb0GMmsxCxa5Emj+HJZPlc9vxLy2ykKgr0Y8s7HRDtPMiHHyYDn/p4z8797/b7XrvD/pwiNKMVXVkIs6TxeuJuJaSt5J2MRz/IrY/mWt2ULmaT4jOc1ixmqXU4HhbTjuu70xd/hwGhTMdi9WSQemZ5Qtsg6icRD6VLRukRGP1dLNsVIBzo8fadIPALqlN8mHlfzq2LdphKJRxVDET0jrjDV+RLHPLV5KnPLbeIhLEeud0bfQzx2XT7L04mJIvHQe0xMUuU+NPEQoFGr+a3zYJpYzoml/59VdXhm/gqm3GgqEg/Bq+Dd4MPMm/7y3yIeAjrMX4ts/jSccskFRH+5mBfVX/CYfS+ZF2Nwu+X4+ObSuMlmvHWlyOzemG1BpFpiqGKyM002j2mqmTR3XOWn5g35tWkbdp3b+6ePdyE5jyIff9FUzL9AujAEN67UWXw8bRku1w2ReFTzzb5NPCrcBmYcmkSZ04v3Twbw3SdviRfmU9p6tJJLLZcbbmkB2bZsnUg8zApo3KPyffly+Mu8mLSbmjnn6fi7tHNTc168oHmUFbQ8a2Jlr+fFCtNbHfuLkd3Nq9R8IOIhQBAp2ju8SqEjCoOiRCQep51N2aVodnsiZPjwQbeJh4Dx761l+3Od8XVbaHM1DZ3dhcxtpuLEST6cNF7cLQ9tUCp6xNQpl9T3xf6RYrT9JnV1tidKgWORwdICJ1wAVy+61yb6n8Cij74Sk4EFXA2MI8/XSPoVH+zlUqXwSoYf2rCGqJ02UtXVWFe/EwqXQ/R6KIyNZcTYJ3n6iX4iQRJ0IEI7pthRKBKn5Z8tvefxhIuJIAwuMOeJxEOopoV7h/LOzEl/SjwEPD94EgZPOS6VGrXspu4E6GW8eJt47N61nnWx0i6yc8nuu4iHgDot2/LB7Pl89PnXxPcfRF6V6hT5BklTDyo1EXXr3iYeAgQyJBxf4TifTbxO2+ad+a1bPH1STqFyezgbEMArtiCmL777cQSszrGIxKNGmYnXh/65nbYwsloeITn/xlRcIbY8E4tSy4oNkm/GfxXKS4rE8diK8wki8Sgz+mCoV180UXtY4iFU2uNPZt0er335xFaReBg9ZYypSMGk9xLJ6voNG0QC+EeMHjyDhKxHxfPNqDFz6GgvigoLmPPuJ3y64CuxQiEQD0EnqHF78frUsbw2fTwXza05VhBJSnoJp/Kl97BecAb9u7X/y9cgVGrfnjmJmIBIUdQs3HeJvVA8LwXR852Qae2UenxJJUKswu5xtblNPHyt3mTln+ZKnuQ+28SnA1q1N5G5WbQ8vIQxjaL4ueZx5PJs3J4gqvMSmjYvElQKX+2dyJSk5f8o8XhY/K8hH426DGG1ehA/u9qzw9GIQ1512OXfgiv6GFG7IUDImYgglzpc5z3FchS4uOoJ4xHFFiZpPiJELnhuyrAjp7XrPD0dx3mx4CS1NR3YE6IiUy9H7iqnx4Gr+FQpJ7KtNEGRVhpO/noftG47Yboy+kQm8oWtL+vc7WiXdZohp/bdJh7lox4XNRR3QhgVG5NVRK48TBQ3zvRxMb7dg8e334+ArOsymJaFJ1DpemmXAABOgUlEQVSeKeZgbpAoY2ylrGBpDwvPTbx/ANvDoHaPp4ndv49y4ZpwuRSHR0W85gz6PBPXtlbFblGh05XToOkGwhtuZNzEgfhWi2STsj27zFLpsY9mBR9s+xVHcjlfaBty9fLF+z7Wov3XSDZUE2PGRQW5TMugUa+LI2ufvrWYcmWaONpZ25BPaP1dIvEQhL3rS19gZp0iIityKdT58GFGI6aPn0yWIZCWMol85OgkcZ+qVNoJJXrbqFpXiL2uxHsjX2PahrkoLDIqImFejwnglC5kpWaLqCv4d1Cv56Oc8QzA7tZxxVWbTbLON7N2dAx4vBsRVaVU3zsxYdIXHBjzDGq9g7ZX0vAzCQJgJ6r068x4eRT9hk/mvaqJ1DBLhCnMWy22CawyPdMzUkSR8guvDhcza4ST83qaJAD8JyG45uaVl4j3byeIXfVr0CLhOE9u3kby9iCubwzGfVBH7MJlDF63BIOpjIKAUL4bMIbgvn358MMFhFSpSvWGdcTKTNdW7SQS4pGJFZvUonRxQd/wvdRW2rRqHZ/OXyy1WYRpFruRQf17M/K1lx6IBFaxJYsTclq1JKYWjvDggV1v32ZZ6RUK5cEEuPN41iC14+4HobVVVKsaBe0bcbB/Nxa+OI0fBr9MdjMp3v0WBDLUqHZ1iVSpzCyYuxiD0YvFzw9nYtp+Ik02ijQKFlfvxNPfrxXdegWcPXeSIyGSsLJl7vF/2fJ+8413KPQLRmu3UdMjkY59/vGs+vRup9Z/CsJU0oy3poi+HKKPSXgVBr04ktHT/t66s3jBKLT5MlxaD2daD+CkTpq0HEYeL744lrpN48WqUkBxHt9+v5Lsa5VJ4bcwcegXnMtoLRIQP30ZWzc/j4VSsa0nVOQUDiOjXn6eN95/TSQPv/+wgs12OJgfK1bIL2qqk61Q4edxkXBuyQM97+fHDWfY0IHSOSu0R9UVfPXVSn765ofbtxn79jh8XQH8QB8W8QI3vGqJeQea7BRsxQlY1VrOWc9hKr2BXKGhvY90Pja4mknLYx8yN6opPz9iwWXYKHpMqYOaY+j8PjUu1Ceoxj87Zvuw+F/TdskqLqbdgl/RqiwEGeXUC/Ahza+M44ZWBLhy+WL+20QVFlEcoyO7WjC+MjPL3P3Y46nLLOVShih33ftci+pSqvkAFGoGNneT4udDmwvH6HbjR6r2TEPwBMszBZD4Y1V8nBX4a0wMjkngd3tjXpGNJ7Y0i3n7FqJzOyn3lhG9bDlh9Vrc9Rgf79/A584ALDIDIa4sFkRH0rHm3Re/v4Nv5r3FFwWtKBaKv3JwxvnQ0/8qSx771/qRh8Xux5pSL6KQ4NAivpd3JveiHYXaRVCvEkKDpcRTi12DhUmok/SEpgaj5hsa6zfj9sj52DSZz5UNUQSoGBzlw7R+TdBpKts1Pecv43SjJsQnHKbT4S04NUH0nTKJ7T/so1gp3X8jXR76pjtFgzeHR8mW4hF8NkBqJZzYs4G31qZz1Ucama0qy2K3ZpKYOZI57Ci515IJ3qdH6YHLDXLpMuRuVfz82S/y6LeHRILz1fCe/BQ/jNjcQronHhTLqkqHEf0dz/fvQlVeQbFG2N3bRMV81/atadW1UlR7P6xZt5wan85BkyMTNSAZ/pJHgl0fhsdXhybrhtiSGb14KXvTrjAq14FNpqOr+Qzf9Xqebz9fTnJBqsiMqwVXYeiYf84R8dZossyl5vuWndHYy1g+YzJGk40cHwNJkeG0uXhNJOUnqoZzuEkLDrbpRKE2UKxCTNCU80qbnvfc77pvf+L8ldTbWg6xreIw4FFaxCqC0MZQoxcvJA+D536ezbaAHoSeuEJJkZEndWnMmT5K/N3ML17j89pDxJH3F5O+Z8aLUn7NLZxOu873ice45HaRqo6gWC5pR/6I+tYLzK7T/PZUhnjf0z7GoRSckGVUCYziubHSZ/TSpbO8k5DGwRDJ8bhamZnhloscsSjYWKUJEWY7+9vXFgnLv8LSj96l6PQpMSxzt39XLvpUp1HRZYb0CiIzQXKd/XchKynHlWcAixmZXBKVWqNieGP67H9LE7j/8boEXXZzvrUfU56ZK66VrcxnWHdHbsuyj94jJ+EcGodd9E55Z9q791Qnln26FJv8KDXq7BY3KKkpDcm43poB/bpQp1mldcSMaRORpaZJrqQKGY8GXyZA58V3EZFMLthHmlKDctgRwqP/nID+EXPenY/VbRI3FQLZVLkNTJo2RqyqzZu8gIqbrsOChbqxXAmZR8TvSwKC8S3MQ6MNpW/QU8iUGk4Vb+d6yVlRN7ithZmMaoP5rdmj5O/8jGqX6+FxS8/L7r6I5ekY6jasnIL6HzNq+z+JfMyY8S6dU4Pu+pkcNxaDFieCX4IFldkploJkgqmRXEaWXM1qnzK+U89GKXOTXfIoBZZmYjiUwuNCZ2iAXOPNTm0qb7Svh8rp4tVt79Og6yUUajclVm9O/1gXf1sJRpWVp2POct0dzgDPB+htVuYeXEiotRDbqEE0H33vDPuUHT+wSlkNp0zYld5gRb2m1A6rtFb/O8hOvcic5Uf4zSqZwMXKXATUy+VguDTK9pjlHEt6VhqY/bv44uv3SPAFo8fNx5cXkKEOYoJ8JC3PCCmmHlSNPVRvloxGZsfuUXE9pxZRGWNoUqjELptPdd0+nB41001vsEoZJ96nTCOnXqCGt7vG0aR6CC9/+z6bqvZn4I4VVLlxHatPNPqQOEoVxaI/VVNtFvLm+1HLHFLpsvA5Zg+SphNuIeXqOSbO28lp/9o8rfidmaplYlhZ7PuX+fWjbTQvMnDFCzq/JU0x3EJyWgolTz8q7ryutdDS9MMNjN13lkMhUby45xBKueS++U9CuFirfXS8MenuiYw/w/6je1G/NwrvZEgO8uFymCBIEX4jnO1urMZw3lq6WLzt6C0r+VXXQDSlm+VdxrNNO1VqPxxGsT3xT2DuewsweaQF9URUc85FB7N8/lgib5RQ4qPjWFQoLoWcuhn5xBSW4dTKODn5JRo/0psRl8+TrqyC2mPjWXfqn0YHLF3wDVn5xbhUkkup+IoderGa0OeZh/c2eGPZZJbHPk14aTK9E1IZ8VRbomo25UbSFQYnXSRVVZVmpqNs7P0y+WXFLDm1hxPmUlI1gWIb4E4oPQ6inanEOspp7RfK9pJcTmgbiK1QgVh1tybzWbchovhXqJzNeX+h5L3i1DL8hcF3VbsmL1nAbzGPUK6So3N6xJZMmVrOEzcO88XwB/eveG3Sq4SnJ5GvC6bEEk6HzLM0KEj6x4zV74RTJsccpKAkArKDfCkKqUbN5n3o3bXfQ93Psu/m02rmYpH4j5s2lQvhjYh2prCzTVd89JUprwI+e38qlsuXxXFs0TX2vVkc2L6fo2cSBYGWOIUiICz0KtVrHhP/fzWnKqOGSOQr+dwZPl+5XAxJFFDgH0wt/0CeVi4XM5W+dY+gr3IZvm4XS7TtGTF1w0O9lh0/b+bomYtSGOTNce++fTrSsGU8n779GeXyUvSWACZ+NJqPXnkZRX6GpKlTqUVSVd+nJXX82+NxWvmt+CfsFVnYVC42tc7F4xPP5m7vI9fISH77QwLVj+E0JeM7qy9+vndfF/8d/B/5uA++e2siHV0Pd2IryMegeRVvWRmHXO2Icbx+T8aBuSKNfl11FHpXpXXyKV4KmYNS58Jk13H4pyYEVRShVdp5OuYcpXINvZwfY/ZoeePMUqpGW+n8TaUx0Z0YsWUFm24uRrVsiaxp3Z0Q7wdT8f8ZNq2Yyfyr9UhyS0NOfbTZvPF8K4Ii4hiw4zuO6qR5716Wsyzt+fd3uL/9sox9luucDqzHFY2kvVC77Zw//Dg+LhOzvF+m1KzD99oF1FYrCj8XQY+VEqqTSvuHPW24Wlabenk2+qQfpLbyBDa3nlfVM9hqDUN2M59AmOQweqloUOsce/y6Mva7WWhNZohsSLmXCqVHTrzuBq5mJ9DJrKKh0MG8wbw3+F6zNgElhTm8OWU+Q/330Ep/RYx6b/zqWjIXXsPfAcdDs+k//u4L3arRrWiyuwSnt4fyRctp3aSVqBsZ+8MqTnpV5/Gzp5Ddjt379yGYnF0Nj2LV6IdzHr2cdIXsKU8QesFFnpcgRI3EI5PE0trGzRhzMwxNaAl02fUTl9W1CXNlsqN5a7Z/v4HruULLAaoERN/eef9dHNm5nx0H9ou7vDJlJKvbNGXa6o/ofOCMWDo//OrzXEvMxmOzExPgTfND6/FOBUuoB9nnPxIYHsGQE7u5po4ThZ19bRdY1OPPCfOCmQspMwupjDJenfjiXfqYh8EXX0/ng5r9RGL2m7GcZs2lqb8xP0znl9B+aD1mmuYmkB0QQJoy5h5fmDBXBjG2fOL13rzQSJqsuhNfH9nOIpODbEXk7dC1SSFhPNGw9V3v2f0EwL9u/IHPnZFc8pWqHP42F9vr+BMV/WC6rcycLNbNf4WaB7IILy5Dccee1BwqTBXd54884HHJcdlVOF0qHG4VDlTY5ao/SGkrofS4CDEXo3dWulrfCaeXh7JQObnBerIDg3FHN6Jn7+FUi7l/FeG35+OJO2Lmcp0IRo2dJ+rhvg430LVWZaXiTsx++zXkyZm4A2rjNOpvij65q0JWp3oUJYaviA2S2lgXMurgndeMG1eui9oRoc2SE12Nqa9OIDAyhkuT+1LHsJdkazybouWMzTtBospA9JhLGP5gLPevUFZSJrbX3DfFqILOxN/oy9CXhnD10mWatZYmEYU15tNXRqIsL8Itl4vt5lKjD89oHkXvXUVsw6wv34nCUUKpwcHm1tkYFV68G/YsG65mMmLtHkqi9NjHTKJD2y4P9Rz/8vn/X+XjXuz6Yhb6C3eXvoUPiHBBcmlkFKn9xXlwf1MRdocaJXaaBy1Fr8niojuGJ+zvMtV0jSBK8Ny09jYrbGyrpmRLvWfEgz/HPI5wQzY2i4o9W1oTWpCHUu5kSMw55Bonfa0fkSEL5qn0LUz/etY9/h23Fv+ntn/HQb1EBARh6C9dnnpggeL9IOycPv14PkvLGwhpA2JM/diAI7w4ecZdjztw+3ccufm4PS1nWfYQBOTiueOsOrmWc6E1SdA1umvhjbNdoknBBZ65vo14kjhBAzbTGbVD6l1iKkQm9+DdyUJsNSnDIZMIvmAC2YTRwH6BLiVH6Jxxhg/83+KMPBhZhhl7hXRRD+tkJc8ezOjv5ojHtKJmYzRyLfWNV3A0OS+SR2EtPZrdl2nPfPIv3yvH7CoYZRZWqwei1XaneV4oBWqoMq4WvoGVu4Tlqz6lxeyvkDll/P5ETcbOXH/XfU39+mM2xHQQ+/L/FIwON6Mz9zPx+YdPZy0uLeHQ2I5UO26lXKPiaI2qWPR+jF/81V0eLidTrzI4KZtymc/t8vWtFomgAXln1t8Xqd25i8elZ1m7TnQ/sZOJ360Uf7/9qYaMf7dySknAr5t/oMZ776Esk5HVQEmblQIZdTFo3y/i2LiADubTfP8XXjf/BITJoyanEyiXeTM28TvadXueJUd2syuizW0juDvh4ymmii2D2jIZT8U1pWXsn09r3enhM2rXGvbpamOXacUKSRvLeb5oP5DlHy+VqkWCLkEdcM9ET0lZERPXbeJ4cB26Zhxm/oi7tWN/hHABW/T5JKonHKLKBQsKc+XGqlSrYUOVR9gZ3ZwersOMmPgKO39aQUp6BTk2XzIVIWToQynV3D81R+22EWAvItBeSIC9EJ3QZjU6eWHYi3y3eCHHzHUxOGzElmVTuyiF2uZkjBVWsa3wRwgRBdZgKApRkR3oTUFwDOENulKjWgM0w55GbpXx+tipnKjTkBecl+8rxBfC3pYtWo3F5pQqCzeJ961qmFwmp1fXNjRu3+r2e/Pzlg6E+UqRC9lnAsk7EUSF3oh3lRgmTK/0x/j9zel0US/A45Hxpt+bvFM6C53HwyJtd16eupa/g8Uff01OSRFuwSJdKMQ7jPcQZ8Fj66d3p6KwmsSRaqFlpgyJo7+mJzKFmsTS3ZwruYTMbSIjyM6u+GwUMiUv5voysvwsBZ7qpPSYQ6u2f+1t8jD4P/JxHxxavZAS9x3OfcIBVXmhU3ohR8kM3ydJUDQmwpPG63mf0zwjidiKAsplSvooRpBc0Q6lVwK6yNWE2AOIs0YTrHRx3PtpToWH08p5gFcUC7CVqdi3vxXBmfnIZW6ejE7AV2/iufI3Oa6qQ8uCc6z4fOJ9e5zCwjNgz8+c/QcX1IQDvzJnh4NDDmmRiFdamNS2glaP3kssBAIyaPt3HL5JQB61nGFFz8q+6f0W4/k/vM+FsGhOecdjklX2liOc6TQrOk39EjdjXpJaSqvfH8oQ9wYsHh1zGSEt2B4PquJ8NHnpIvkzxpiJ7pKFWunAgZIfGcp2et405YJIdzpxpZfxqzATq2jEjhwz5xvXpFrKFR7fvhqXRoe8SjxR/ldw108kWCYtHiczOjP1Wam18Ff4+avpDMhdgMOjIG/4Sa6uzKRGBRz3L6f/65X6AmFxOjmwCQHXPBTWlNF07en/uJfNg0B43r9M7ChWawSkNFXT7LPfCfS/u/T69u9rWaKoKY5jT1SkE3m5nCtZ18VdYrRflChG/Tu4U7+wu2ZbZI4ivvh4OgqHh7MdfBi86Oh9/27BvFfotux3MR34eNdAnl144B6iHm85x8//JlH/V2i7bQ3XNXF4O0opU929eVB5rMQ6UqjqtNAjrDpPNGj1tz+7wsTRjLRrYnVHgBAW+ZzKScW2K7d1Mk881pN6ze+/w/8rLFkxB+8jv1LrfCnqosqLvcPHw7V6Rq6641CbSjgR0JyjPk1RuRyiVb2Q//JHCILRIEsxPq4S/JyFItkQvryc5eQHhqH0MjCwaw8adb7bSyI/K51PPpjDVk1bSrTSuhFXnExXz34MPmWEFeQTnGfBO9t9Fym6E26VB7lDRkZwCMOmf0IzWwIb7tgwCUR3+cIVYoq5R2mV9BS3nrdTi9LiQVl0nZIQL2Z9uOCe+9/18wpM6nkYjBZxDUm8EEfr2q8Q3+1enVHK1A5U0Z7hnKUL5yKzGFZ4iRNqf5q9KRnI/R1cPnOetT9tx60uIzLqEgF+2SjVZmSqyqqRMK4tmAXejD8S3bm1FT6oZIHgcVOmysR2U/pk1bop1Unjwl4yN8EuBf72j2nc/+8PL/wR/0c+7oPdi6fjqS454N0POS5vpns+wu5IZlzySiYVnBfzTF4ODeaQLAZzstBf9zAodi3xkScJUlnRXorhiQafiAd8tmcioeWZnN1fD3WGTXDpp3/URSKNJbxd/Dw/6LoSU57NN6MaUqPevVbBgnnY4OO/c1Vd64FKyQ+Cbz95i4V5rSgQ3CwFwZwxkdcmjERn+HMtjbCgP7n9Ow7dXNC7mc+Io6J3Yt6XU7gY5MNJ/3jy5ZUmWsIkTrPSk9TOyWXskLfvybIoLshHtbC+WFX4zt6DXFcLlB4dcpUMt6MQV/ZZsJtRaJ3E9szEGCT1PrNcESwxj+OaV9XbJOTW7irckUWKJpYuBzfR+MJRZD7h6BspUNe6Qgyp4qJxJqMlk59d9UDv2Ya3uooJq0nucJKqv0udS+E4ZVDYzU58x863b7fwrb50+eUqHqWHY2+M4vmnH8zG+/8VLJrcjUc2pYk7zfzacgLn/nSPDXyPrd+KfjB+7kI21K/FDwt+kKofDgPvzHz46ocwdXL66gXRzC/bUJ29cdGsnP0q3sVW8TnEf38cg+HuPv2dWDKxM223ZIn9/W3PtGLiW1Ik+otbVrD5H25R3omjyZdZlHiE8+oAMhV3aK48wmSVXIws6Jeygw8GvYL/A4g7HxTCZ3HKrjVsVEVSJpOITrOCczRLyBJ3xA/jv7Jp5zpyN39Kg4u5GO8wrXVrPKTXVXOpfjOeH/0xfj6+bFr6BRd37RTKwqwNHUihVrIQ8LKbiDLnEO7MRaew41J5CC7PwMtaUVl98fbH5udP+9px9HpeEuP+FRLPHWXR5z+xw6e1OOIroH7xVfrFZvPC1I9Esrxl1zpST2/BPy+F8PxS/HMd6HI9IhEV8MmQ4ZxuHcf2lh0INHpJVvmCM6/CIVUObkLw05C5NEQE+/LMy8/w1jtTCUu9LrZRTNWqM/0ON9U570zCnpqG3l5BnaeTUOultOtLOf0Z9/Tce17H7gmv0cnnGzEM8qnq77Im6U1xzV2s7YCPXwN6P/naQ7dgBHy/6Ut83MvQGyXLhn8SBQ4Zrar+QHSNf21d/6D4P/JxH5zauYm9v6zH6GOktm8AfhohnCyXdHchhSjJVpZz1niNurZylmXniu7Wi3xCOa+sRZOcMna6n+aoJ4wmmgKaGc8yyrSeV6rM5PeY2jTwnGai5UOub62BLV8amu0dcZk47wKWFHdmpm64mNfyQd0UccTxTmy/dIrlyQlc0EaIDp0qj51n3cnM6PL38jQspjJ2rvmUfenB/GqJFNsQUTI3E6qcpP/NCsSDLHqDt6/kwE379i7mM3TOL+CkppxTAQ1JUVX2X7UeC40rTlE/J5mRPcYSGSVNjPwZjkxrTivlFc66qtLoA8EZshIp1y6yevanN1OAPQQ3KieseaaoPBcTKNPiOWzqQlpACGn+IVjUlZWG53/6gsDCbIpqNSS0/XnqII3lns+oz/hhvz3w+3fx7QbUVaSy09EIi/c7NClWc87HRa83Kq2ZD57cj8/okWIb4HQnX57+UlKe/0/DgnefousvZ8XdY1kMmN7+lE5tu93+fWpBLj3PJVAoD6KB9TzDMxQkZlwVqx8RPhGMmDDiIXvZgmGSGbfbm2Vt2/HZ59OofTUNa5AH0/zFtG3615M7woVoz/AWVDllx6X3cGbKqwx9ctQd4uzqYoLsPyHOFl77Jyd3cEqmIUlVTZxiESBsDIT/e7uFypGMMrkPvfM38c2gf+0C/HeRmJ3Ga2f2cFrXUPy+SXIGzVNPisdB6/Fm6nv3D5w7fyWBfSveouGlJAKuuW9frIU2RkGcgnN1qtP5+dn3kE4Br78+npDU6xTq/DH4GWjRJp6S/DKOJaeJ2TU+woj0TZh1BkoCQ6kT7MfT46b+rQrgoa1rWP7Lefb6N8Mpl6pFrQrPMqil+q41UxDyLj29l2PF+VhKlXhsWq5Uj+HN/Azyzqfjlrlu5/PcmQHkpVfxwsvP3tW2uJWEK4hshcqOp2ZNhg0dwbyvvxR/JqDIN5BqcVEE1/kFndom8DGSi4czcsCb91SBrXM7EKRKZrfjSUyBR3isNK3y9zI5WQodOXJv8uV+lOEn5v0EBdemxxPj7ktM5q/sT/2Ic1Lwo1tGWlJLzHbV7SwZpUeJXV8iVoCM1nIMpkLx75xKJQH4E2tvj0yuxG3fyTW5iYIiqTKS1DCMQvkFAm0KBjTfSHzcvzfEcCf+j3zcB5+8OYN0U6WBi1utwmKEZL8i8nws2DRugh02fkk5TpDLxib/5nzuepY8cyjB1gJa56SwLKC+WOaa5r0Vb42FiY1fFrUNb9ino1pvwlIofeg6hV6jsV8Omy11GCObJpaux7i3MGmu1PZJyEhmYcJ+ElTeomnYLQimOOPU5Yxre6+985+hMDeNXT8v4XKxL4nWSC44BdPuSvTQ5PP6U3WIrd38oU+kfj8t4UigxIqF13Cr6iDs9OpZz9MoL5HeMR14pOODj2r9MOdlBlukOfYEVxVyG71K1yfuFjB+OHkCqvQ08NjQ+juo2jsV9c1yoa0sENXZZhS6/UnwCeCifxBFWj191y8XLwyuoXri9afE217JqcboITse6Hnt3fgDPsc+orFSUrL/oBhIU8uz6NxwJiaDx0ZVJgFveLYxNY5ZRTdF3++3ERv914Tr/2Us+GQsXb7fKZa2hddzadwknh7w4u3ff3ZwM7PtoeIFd6gjEa+9mX+r+nHLrRO3go0NOtB/zxr679qFW+1h/7hnGPXig128k1KTKHqxt7h7N0WA/utfbl885+3fwBc3x9JDXVnMf8ixdKHt+cnhLRywWbmiqS5qLm4h2plMA0cpNTLTmV+9skwtiHKX+/nRKL41/9VYcGAjy+1K0e9nwLEEAq03RA+KtvHxdO7b4/Zk0+kd31AnMYGIi3bk9sqWRXk0JNQNI6rPRLp37P2Xj1WQkcqC994W7eBzgyOQu1y3g9IEOJQq8oMjCPPWMfKVyQ9tDPZnWLd0LmuP2jkSILWTlG4nTSyJKJsZSAsNEYW8dpnUVlM6XLS9mkqtnBRQlN0hHBXaKgZUCjmDBvX6S2dkIQl32jtviNbuDoWSCqMPfqXSRTwrqhqTXhpNWI04TiQcpiDnBbEd7HLLKLS/zuCed9u/H5wwmrY+q0Qn4scavcP0Gx9S01pMiMvxl4Za5TI5GQo9uXJvCuR+lCq9CKqdhUEnVX6tDjXFjrFi8q4w+p6aXSBOn/0xYHH9N5+hLJCucY39MqnjbobTfygeh4X1xtOUpSehMWWLBn0/PDaU6mnZrH8Aj5uHwf+Rj/tg/Oxp/Njyz1MLVW4Hv557lWZlF0k0xNKr8ZeYFXcnxKpOF6LIt+IK1+GoL5V1q3quMXT9V5hzpNs2D06hXUA6h93hPGuZhUOhpl/R77w57x0+OrqNE8IOXlUDlxBMcXMnVdV5gyZuKxObdiU2MPQvD27mjbPs3vATV8pCuGQLJ9Gl4w6eL0KI56qtsNDN5xwvv37/yY4/gzA2uGL3YhJCq3LG0ET0fLgTBmc5YULpVVlOrEpH27CqdItrLBqXPQiEPuzRGZ1op7gkJjUK47W7nPVpPHoFoRGV44Pbfl1NwrodKOwFyBRuojrm41+tSPyd2yWn7sUKwkvMXLa1YHpAX5qf2Ip3rXKqtpeM3VIKIhg+SBjn/WsIraDD8wfTWXkOrcwuVlgOu2qR7TWFlsVBpOmh6evNUN/czX264DW6fr1ZbFdsfa4tE6c+mKHQ/8v4evmHtFy8AnWxDIe3h4MvPMnolyurZAM2Lxd1FcII6GtXrpOXkyou9GHGMF6a9K8XL8FpNLUwQ1TvX/erj9uWzdvLvhB/t2NgHV794JeHer6Cd0mdmXNQVsjIaKSi3YpKI63vT+3lg1IPpTI/sQ043VfJ4PhH/rLKt+zEbjYVZ5IoxJjfbG8ICHTnUteayTPRdXmsfovbO9z402cpk0k71VFXVjL95b8WMf+TKKgo55V9P3FUHsdzhw+DwoTKqqP15e/wz3WKx/BO2AI9JNbzxdLmSV4Y+mCj2XeOpjouXrj9vSBqzA+KQOelY9jAIQ+UNPt3sP/6BVZs3MjJ4hqU2aX1x6OQ4Yw14oox4qMopVFSJnXSMsWslVsQTPdkKOjQujHtela2SP8VirIzmD17JqG5Uj/KrDWgiYni9ffv9mrZfmg9WCajlAtJuArQzaV7GylmQUD6hYv4rnkML0Uh3yrHMaXNE0xN3c8jNeM4cXAtuIswUkyAp5hgdynh7gpCXXcHZmaGaLhSw4hHLpV7jWVOjJdc5Mm9yZSFUavVeJq278OnMxdSajbjVkmvXyChATYw5uyh0Cq8Zx46RZrxtgxH4x1Deek1eLkBG+d+hsJRRKFvINt792ND2zb3TF39O/g/8nEfjPp0HBtqS7sD4cKhcslRORVC+1kUOk7P+JqnCndQqjAwqMYcUrQRYvlKJlOicgkB3+CxmjCdtogLr1cb0OkddD2yHv8EycuhdmAWPQKTuKjw4cWiD8jRBlLTkgpd9VzT18QiqyQz4a506tkLGBnXnLbV6v7pwbxyaicH9uzlmimSi/ZQrrjuDVUXusz1lBXU0WYQ51dC5wEjCLhpPPQgEBbUz1Z9wKWwUE76NKVULvV4BQS7cgi0FJKqicGkur+yXeOxSrdzlhLu8VDH6E/PGo3+suy9ZsEkWhWtJ1oumYDlefzYperA4Gkrbt/GXF7OJ5NfR1ecKfpReMdaqdI5BbnCI5IEd4k3+flx7CiNp23BJmK7ZwgteHJKA3mix75/Wf5dPWsEnay/EyqXSE2mO5D9Xr3oN2Y25+aeIcLi4VhgIU9MkvIgCorySRn4CIZMSGusovsPkgX//x/w86ZVxH78AfpsySly51OPMGGqJNAtqiin69G9ZCqiqG6/Srd9aQ9c/ci8kcrSZT+IHgp2AtkbG8mieW+hcri50M6LgUukIMCHxfwPR9J95X6xlXD40RCGL9h7VxTBhMxs8uRh4ujlOFXRPY7At9qdl7Rh5MlD76o+1rbeoIdvCCObd72vYPTRzUs5q4+nXdlefur78FNHD4vtezZx8eg6/HKuE1ZQQkCuHX0O5PnHsq9jC5HUVb1WQrNT28Xb2/09pNbQkdyoPS+N+vDfEkILFuhykxmZl57eLVrRtt/fawf/qxbXsnP7OWOrIFUdQq5CchMWIC+0orpcgqxCsrT3slfQR56ByiCMokopxDKXlrgq4Tw5Ysjffg4pFxJYeNPr5okO7Wnd9/6j7D9u+QZ/9Yco5B7sThWBocto1qCy6nV84nM0915HoTOKuh2+pWaFla75R3n7T7J1Tu7bwKmj68BdSETNG2h9LWKbRVjg4q5XEJl990hymkLDFlUnXp76o7iRWzh9AWaVRzQeFN8vwQK+oAxF0QWcajWyuJYMKW2KTKEi0bQTefd6nF79y//X3nnARV3/f/x1e7DhOI4luHKAE0Vx771HjoaaaZrmKm39rWz8HOUoMy0zLUszLbXce2/NgSiKCxBusbnj9vf/+Hy/AqKgpseB8Hk+HgQXp/fxvvf9fl7f93i9wbcboPMLxegZ76Bm+JOboT0OKj6K4Ycv5+BP2RYo08QIviuAIksM3r04XaSXGl2DrrMb2sakCNw0+BZx85B4mxHUTAuv8FwsOvcGLukj0MbnXzSKPw+HgTOmCfXRY3DAFSQJJZio/wAXZTXBk/KQ11IFCLmgGyncq2tKxCBV9RLvxs7tX4eTpy8j3lgFly3+rCdHYVMYB5m/Uk+UjdrSRNQNtKLzkMmPLCItCTIsK9ZPjDO+jZFyz1sg/wLcJPsMIlKTMWXYRwWFo8SlcdfNWFw1ZiCVJ4Be5A0NX8WaoBUH+ff623Twt+UhTChGM/8q6Fk3Cu5SToTlGXKxffaL6CI4xxahEk4I62JNaG9oFSrk8vgw8MXgqy1oeWQfvHLSIZBbEdYnFZ5eXNgxA964eTEMjepeBF/IIN3ghR7tD8HNvXihVFyKhfiu7LI1Qvvpa+Hl7YPNS35HVFIwcsnNzasKhNWqwz5vxZR2aLFDA7uMwZ2v5qFnxz6oSJBaFsFHb8D7JpkKzGBPv7qY9DlnTb7u3GG8kylh04z9r55GgPouK8JV8gCMm1FyYWF+iy4cImyJaI4Fi/8P/vpMtkMoYvUxtsDxaflpcjvE7NSwNQy7RrTFlHe/L/gdSW2+fuU8EoVV2TqqV+w3MbROs2LTneT3tSzX0VIkxrSYHg+ZUz3IwqUfIMFbiCGqmP+UcnwcxLBu29YVwJ1zUOk1CNAa4aV2sLVFxUFSVoeb94M6SEoKOXDFuyryQgxY2LYPqisLN/DyBrHuX3lmHw5lqHFb7IkkQVhBJDg/xRtsT0KYJR3N3X3ZNuVV//sc+3kxiJFnQiThbhZ4Fne0iq6Ljv0e7j4pTZb/OQfh3suJDyXrzFw7YjNqhHJjGE6tXoOG16dCzDfhM8/PsKQRd52vlZWLVtqTmPnqhIfE4IbdP0Nqn8vWlBAyjR4ICFwAQWYGLpzZAj6TAQ+ko6PlMpQOrmNnjygEvtlV0EB6ChYI8Lt1FBIFngXD7wQWCaRaNRx2DWJkDVDNsxUcViNi/Q8gSeiGnDNn4BB5ocObI9AkhrbalqrD6cYNfyPhAAOp2QE4smESqOEQ3UaoQ4MXlftZB9ND+qo4rSvchJPqhCEyPA7hIYnsHTUpbv/3YiSWaMeydQ+vJK+Fpy0HPu65GBnyLzKFUgyRfIHr6YFghDxYmvtDKregtjkBndx8MLF5NzY9cf3cPsT9ewS6dAvSzG7Q272ht3nihs2jYKrs/QTxHKgnykAtaSLqV5OhdT/Odvdp2LD+Bxwx38FZ/3q4Li7MhYoYMxoaz6O+5hpejXkVtepyxW1PkiffceVfnNDdwW2rGTqhDDqhAun84kN5ZBqv0qFhB+wZ+G7I4XlASqr6b6/AiJTNrHtsrkCG+WEjsTx4UEHxmchqRoej21D/KqnnYOAdk4uwesncXUL+WrLliG5VOJGyuBTL0UXD0ElQmGI5ba8JR4dP0LxDYQ58x+yDiMzi44yPGf3e7VQQGajz4Wfgm3k41CsEb3zlHMvp8gapqbjzdl8ExpLCSgbHugXi9YXc4KpRW1diu7wR6yz62r6jgDD7kdEPEhomQ94IFwKjMHDHKkRdiYPZj0HGl0vQvsWTh8aLgxQMHh7ZFCHnbbC5M4j78F0M6T+qSAfZ8FO7ES+uw6Y3+WDuS3c6UM12A40ceZjauFOZbdbkcyXeMB/Bd4wgHnv5RaH3Q46DWQFkBAih9veAVhkK39rtMLDPCAgYHubNXsLWADgcHljRuh3cBdkIMyfDzWEDkeDcRGU5O1G5ll8QIgOrFNwAOBuSxrqhT0WsJgm3s/RQm3KRbiPD0RgY+Hzk8qW4KwqBkVdU4Pk69Ag330WEUIwRkTGIDAp/6LOUacrmNleGhxRTFeyCP2pkJ+Ot6Fz0HVV6U5eLY/FvM1BH9Sd7/ckxuaFVzB4ofLi6l0vvDEI9991INNfHtPrTcVIZCitRKiRNn5OHFuqTmDV8NGt7v+DnIagfcqagqD4upS7GDl5fbLRqx4bvIIxfgk5WLrWsE/ChFgjhnVMLZxwtMK9pL7SOuwo3GxHkXKRIaJKCl6PFEDSB1CMUOVnXEDx7IFYvW4CBL4+BKqSo8+6zQiMfxfDh/y1HkL46GDDQ+KTgs9mv4My2rWh4YgKE/AxkmyKRO2U9lmz6A1ZrJhpX3QGFTFewud3Iqw7zXh4sd0XYpOqFJFkoIrMvo3P2IUyodoQtwBocNAexCVwIN0BpQJRQC79sGzKtntDZ3aG1S6FlBChsTCseYnkeKdajluwOouqFIqZnYQHg03D+7DGsu7AR5wNq4ZKsAdsRkH8Brm2JQ2PtZbT3rodefZ4+bPkg8eokbL12Hpdz05AKHvQiL2gEKpjvK+J7UJREZcZiVsIyNDRyg58ShSqs8O6B3JpNoJK6I8xTgbjV6+GRQopRLZApLKjW8w5EUhtyU+Tge05H7z7cOPgHWTt7LNrn7X4oxTJs+jdFnnd823YEHXJn02zXG+rQfihnw71vUCS7IZOukMi/zjyyJfR5h5iRHZnUHjVOclG9S2080OebQ+Dx+ehwYDNuiGqifupttIi/wIb8FTIlJr5b1Mb7womz2LR1JxiBBTnCYEh1N/Dyzs1sZf6BNwdjwvj/VotUEnEJcTCOHQi3FCA3FPD9cUsRN0wijgfvX8+2DBekO816vF6rKdrUiERZRplSv38HdU8QAVcoOEhULSeQB51ShhSFAuaQCLTpNAKNIkv289jz1zYcPX+W3XDSxWH4I4Zrky8Jct67IxdujhzIHUbI7Wa4MTa4MwwrVBRiGULdvFDTLxANgqpCKhThiiYJV7R3kZSbDrXJwAoKUthu4Atg5Ith5Mvv3Ux4FlxfHoWMMSDMkoiaDjP6hNZB9zpRxaa4yJTXpUt+44qVyTBAmwS+cjHib6Vit1cLmIQSBBjT8EU7OzoNKNmTqDRY8MsbqB+8h90j0gze6Nn+IBtx3ffZbLSzzWN9no5lDWVvptTuXtDKPWG/t6G4IwfVa22CyD2bfczYBMCpxhClFVoXFIWBQpiE2vJDuC7mwYNEh2ycwNgrC8Z7df+HJPdwqPKsGH7tCMwaBzct+p4BiDzPDT0RAS+eB+IMu9BlsXPOvweh4qMEPpqxBox7Nj77aBzSNBrIvu4BuTgBFlsgbvX/FUd2bULtaptgUhAHPO5DYrC7Yb7gXcTzuLoMgc0Kt5R0WK6QOTAOjOZthZ7njf2SKGTmkUKfJ5uEQGI6Sr4NSr4JCmEOFMIsBIgzERPTCPVb//e5Ew+SplNj8V/zEKsKwzmPKBh5hWmIUNttNEk7jwY5AowbMxOuwmyxYM+1CziaegNWhkGg1B1VvRTsnVhV3wD24pOfiukqOAs3Hrf5XbRXhabhpIKumB9nzUFGQjz4Fh14QgfcA43I0QTg7dXrHnrNQ9vWwePYXDQS3ihIsey2N0S7d35nUywEi8mEhIv/IikuERa1PxplinDVg0GnD7mQ6cJZw9Ft7b9seP/ApKLFmBUV1uFxWgdE7eP8Be5EidFg0U5cy9BhVHI2e+c6+sBhiHhprEPkR1+Q0QPFpVtkiPfwxkcrOBOnPf1r4K3ZZMKm81i9bikazf2a7dghpmntfzxZ5M6R3I3PPfw3qnr6YXhUW5R1ZOnw/FFockRbYJ6VFQ6caFYPgQ27o2/3YU9VozH7o/kw84l5G5DlqYK2tgS5PB4MPCGMAsk9ceCBXLgX8cp5EkiUtzgH10dBrObdmRy4seImD3KHhZ3v5MkToKG3EiMat31s9IX167h5u6B1lviavDS8V0H3yo7fl+LjY27QyP0QmqPGohdViGr75J2CzmDBquGoH3qS3S5Ss/wxqPsB9vglvNsZNWTF1zNpFGJcru3BFZWSvSDbikYXsyB8ML9eAsnmuog1N0Ke8gz6mOLZG6UMvgBfBvZBC1Uv9Oo9CJrbN7FszgIIPUNhld8rSmV4qGMPRgOTCjeVJ9B9RqHDtbOg4uMJSH2nOwLdj8HByLDXfzpMntshD75ZIDpg5+FiUiOMH74a7274BOuCh7IzHd68uQx1DMlYoe+Ny9biWyz5DODPY6AUWKAUGKEQZsNPkAk/iQEBCjnqNm2HahEtnXKwia35tqMbkCmxI1PuDr3MG1qpAqmiYGTyfYvUXzTNPIO6ah3em1C0irs8cubwTth2zkS04BrbFWNmRNhnq4emE3+FIjAY62dvQdKd/WAyrrF3BRa5Cu+v/PGRKZbzjtpIkA0HX1QdQocUUrsYnlY+/CwM5NxNRAGnA1PQf/IQ9s7a+uoA1gkyrpUbBv54BpWJpdO7oe3W22w6QF+bD++5a7Hy9iWsEUcgKD0bfS7uZ++u/MT+eOuDCeyfmfPxfJh43EYY51cX76/4AlKzBVdbyNH/J64N2tks/Hwkuv52gr3AHu4ZjLHz96C8RZPW/G84Wh26WdCRQmbVHGrXEOPeW+UUd9wCC3ybBC8N7V9siymJBMWmJiI+LQVJORnQmo3IsNvYaKyBzwkVAytUSGzEo4joIMW7RFDIHQbI7Sa4OaxwYxh48fnwF0kRJPdEdZ8ANAwOfyaTN1JI+dUXS2DlGVhDOjKFWMp3w7ufTCu2NffTSyHIkHqiZtYdfDehabEmjqXJ16v7IDKY8xW6rQvB6CEHsXfmLLxg2wXxvRsoggMOJNXLQ47Ses+rA1AmSKFI5Dp6iI1DvlNpcRgdnrhlbowOC+dDrUnBW/tOwyBKwIJrX6G2hWvLPSn2w1V5H4yYsggfvjcFvrcSYPWoArtfFVhl3FpEjADV8xSo068JGrRw7ntFxcdjODf9NTR249r7jrs3hLHBXUCQ70/LwKyVQnCbD5UjG0F2AxQOG8bUnYUt/u0QlncXe86+Do3VG9/Y+iNbIEZcVjVo5X7wy8vE+7Wvo9vwiXD3cl77UnzcBWw5sAbprMCQI03mDZ1EAa04AHqeosAA6UFkjBGNc88iMvUWJg2YAT//R7fxlkfWLXwbLTL+Rmh+V4zDB3vE7dF17GxcWXYddzP/xe3MK/AKVyFE+QIsRhEk2afQlPmLtVYnaJhAZFjHwd0R9cjXShcBGWIgQ2JC5/HN4ObhiT/GRqPeoRxYfBg4lv/+yPB3RYVEfrpsOMemB4hXRMb7X+JLUyZipZF45cgpuNlT2OjHuzMn4fC2fUVSAL13/IwQrQYZ1Xl4YfXBh2zcnckvE1uh6Z40MAIGu0Z3xpRpi1EeIkhL541Gm/3nIE8ttDE/2iYcg99f7dT348LRU9i0Yw+b6iL24XKxDG/NeOOp68NIpPKyOhE5pjxEBIWz7qGlDUnXbf57Pxc1uzd3pXmjCHQZVHJEY/WCDzE3uSFyxXLUz7iG5R/1Q0Dwkw3UcxZL13TGCyqugP2qugYmDOc6j/L558AGOPI+gbuEi0LkmNxgckzBAa0NxwIbQyvlUk4eVgdaaK7gtTB/tG1TaPh3P8dOHMRHKUCsjxfbqdn99il00f6KAaaLIKX/Bh4PGyRN0arHF1i9aBE8DNmwSKQQioNhUwbCLOZEiNAhwoDePVG3qfOuaVR8lABpa0rZtQo9RQcggB23QmS4We1e7p5h4JduRd34bIiLGUKaKPJAv6gfkSJRoW3WQXS8sgsOvj/OXQ/ELkUryGwm/F/oRbw0+elC8sRfY9POn5EuNiPTzY2NYBCBoRMpoef7PzLsKWHyEGDXwN+shb8pDX7GbHgazegY0R2tWnfG805xqZgL9qqI9xyIqIx2kNwLV5qhAU+8BNX457g/x0hxyzEA7tYX2WmwaRIeMkUMjEIbLHwz6xEglJjgHSBDzej6CAqrVuR1l/74Odou+JW96985pD6mzHo4rVNZ+HrhFHRcvYMzI/NncHjsG/guuAHEWRIMOL+HjX54i/yQYzSxI+xJ8WPIlX/R+tJZVrip//fVY42tnLHRH3ulCQIv2dkpwzdmzUK/7s5vDX1Svl40FdG7d8D7RmE9x9lW/mg25UfUrs7NbHE2385ZgjRjekHBIdm8Vb5eGOtkM6nS4Lu5S6DPzYJDYLlnFOaOKdPHwtP78Y0HSz+ZgkW5bWEmXXVpF7H8q7Hw9PKDK/lpfWuE+aWwUdbY5PqYMmIj+//n//wK6occZyO45Hfx6poYPXBTQbQrJTUJs7f+jWOBTXFXznUOymwMYrQJGO7HR69uAwtf4/flWOLRgH0eec7gWwcwbyzn3/LDvNGIse5CPStXR0K6urYaWkF8IwdGiRxSuxU8mxXhyg5I9LFC4fBAeFUz2oz+b/4vj4KKj2JYNvtljDX/QzrSIHAAel8RLkRwH2qPHBsir+bAagHu5jvN8XyRBR9YGS+Ehkeh17Bp+HTZNCx74SVWCAxPXgfv0xn4Sc75B4zJ+wcffr3ssQJj866fkS4kAkPOCQypAlqRkrWwvr/d7EHEjAkBdjX8LTpWYPgas+BtMCNUrMLgAWMfmqNSESkuFXPK0QJVrBOQK1qP6vzNbIqFcMlRD1elQyElVvohHohs0azIRNrHYTAYcGlQE3jdAjQRArT7s9BsqbJCBpJF/7CSTUGRzX3ly/2wpt5QDDt2Fl7WJDY8zm56DB8WgwCvbPmVbdndO7YP3po0zyVr/Df2PJiJQyFT85AdDoSs2otglWs7WX78+UtU++dntkCZQN6DK8094PvanGfu8HkS/j14HP/sPMq5YN6L45OupDpVQzD49UKn3vJClj4TXy/4sbCo1C5BgJfvExnY3c/8d9/EUqYr2yHXTn8Ky75936XDHon4/Wt7WwR46VmRcSm5Cfw97yDQi4vAWu1C3MoYhvEvflLsnydTiT/7fTWOqaJxy4NLxYjtDKJ1iegvzsD1dD1+C+uAHBEf/iYbxmiOYtLIojOlMnQp+GfFqxhkPgM5ieKDh8OZ1XApVQVtUDj81MkQ2Bl09emHBEkS2n06BZ5O3Duo+CiGxQtfwyuOzfDOscEo5eN0Qy/Y7TzwrwtxztwG1VQ10W/Ee499c8eu+xR/K/tA5LBAclgDm4mPHmmH8N1ybsRyctJt/LllOdKEJmS4ydgUiZ5NkSihYwVGyZXgpIVRaddAadFAYUpnBYaPMQ+BAn8MG/RmpRAYT5OKsTBCiHm2wi4W9x4YNuPZQu5LZ3RHu79vs14KF2fNwLD+RS3gKytkvH3Y/E8hTwEcUgYLRwzGyardMfDf3QUbnQEqvPb71+zP+/uE48152126xp9WL0T0gu8hyOMhIVqK3r8UnSFUWmzavg7CtXNQ7UweGy0jLbJ3GkuQPWhKkRZgV7Ft3WacuXC9YFPPH83eulk9tO9bdMpsWbH19404e4ms0VhQVDqof6enTgV8PmkcVsh6skW191+XXYUhNxfb97eGjxsXfciHGB82a/JrgR/I40TMrF++w1FlNK55cY0CAjJUhkTP+DzUzDbgfZkWPbr0L/HvWLlwEiLytiDawrW6a01u2KyPQK5vJOx3rrPpGgRVx9uLinb7PStUfBTDsdmd0cJ8CjY+cCHSE8HJZpzXDcLpgCqYOfHxoiOfpZ9NwYKIPsjx8QUvx4rQxJuoEZQEvdQPOlZgKB/Zakb8NJR2LfwtGi5FkpcFL4MJKp43Xuw/9rmsyyirVMwO1qCMS8XkMRLssjcq0sXytOw+uB2B06ZCYODhZGd/jFz8eJv2ysSxc8eBmaPhc4MBsaWZ/8oIeDiU8LYkwuHwRq+/V8PDZERCMyl6/+yajf9BFs0ahq5rz7M/H+gTjvGlKIDI+5H0/RREHs8qmKWircPHlR5DXdpNVhKrl6zCrRRd4TwQhpsHMqjf02/yzoB06FhgZKNlJGomhhzvf1q8E+h/4cM3J+A3T854bFDGLnz1PSeEXUWqPgWnTneFu8TIDqK7mByDt0eUPFH9USJk3uolOOwXhUs+3I1ntE6NRU2ro1rVx4sYQ2Ym1i17CQPMx+DNONi17HKE42JmMwi0KWD4fLQaPx3N27SGs6DioxgOTJ2M8Ih1cM+1QqT3w3y/t1GrigQvDRxZouV4PiTiQKqq152w4rhfA0DMh7mlEhAXX4dBHBP9HZp7KRI9/NgUiQlKeGLogDeowHAipw/uwJ0930HVehRaPeJO4L+w/eUGCD9jgTEQCPpjPwKpICzWjfPm270RdImLOC0Z+DIylC9gyD+rUDP5Jts+GloGKY/7WTM+Bo32Z3JurWN7Y9Kkh0ehP+t7sH/+SEQfUbNClUB8YI53bI8pM75DeWPx7G+RYTAUtK4Sa3K+Q4qxbwxDQGiwy9aRcCEOa9ZtKywqtcnQsHZN9Hn52S0G8pk6dio2+nIGga9kb8Vn37n2eNxOuoWN+2agZvhQ9GpbWLPxtCxYuQgaK4NZr47/z6mkdd/PRFjqWjQHl/5J5EuwQdMGvi+0wsjJzh0PQMVHMXz09Ty8eXkldD7V8EXEG5ge6Y+oxjEPiY381AZ5TH4+vO13rPorFgfvjXomBj0x6RcQUi8DR2o3h4ctB4p7EQxvoxH+djf07zn6saPlKeWThfPGodtPB9mfd47tVC46JsorpH308OQOqHmC28yS/VUI0anZ4XS3Pv0cfbuVPMjRFZC6nTOvNIMyzg6rN4MjI4dA7umcLjTDxZ1odSiBrX8hkInAB9vXx7j3f3FpncHTtLEumrMUZpupyDwQEU+KqTPGQeouL9XXXvXtz9BkpnOvfS8NNHna60VG3TsDEjWYPHEWdipagc848Lp5Gz5YxE0Vr4xk67T4Z9aL6ON1GR4iri5uuyQc7lEfonWXF8vEoZzHMCT5U/Ht1X9d/yMafzwfjIhBUoQYVyKiMHLiwhJnS1y5cAJLv92A3V4xyBNyF5P66fHoX12LUe/Ocdq6KGW3cW78eyVyrh2BUncXKl0ufNQ2SNK4zeRmUwl6rubC9pRHX+TXv9MJTfZwuWXS5rp7dBdMnubcXPKzpERkk0dBqnsy87//CmmbPdamCga9/1upthGXRpHn4kUrYOeZCuaBkAiEu0SKCdOfvj03n9vxCdi1ZR+0GdlwkG40noNtAWb4XKSMZxfDV+6Jt96fiNL8bI6dOBeHFE0gtNswUbALU+Zw05QrI598MBV+t66gpeo2Gnul4oZQBkuvv1CnYeFgvGeFio8SWgXbbthRsLkQyB1aQj13pER1xeuvzWTvWHQpSZj/6Vxsl7VCloTra6+WnYzeXhcxdXbl/eA+z+w/thcXDv8Bd/U1BOkyoNCa4aZmCvLzD0JC58aPv3VJZ0JFYcl7PdHi2A0cbVkTE53sYPqsfL9yDqJ+/RmyNOfdZ9klwIUmfoiauhx1a9TF8woRCb/8soltO7+/PTdQ4YMxU8c8UTRj54ZtiE+4gzyLnSs65tngEJiLN3u+F+3o27MNGrSMRmmTmabG6+/9jDN+kawdwlSvYxg7cz4qIzmZ6Zg3fQq8s9Mhqs6DyNMb499b7dTXoOLjEUp42XfTUeP8EYTH5hXYGxOMKgZXfKpgjaI34vw4vweVQY9evON4Z96ich1KpXCk6tTYtPlH2G6egkqnRoDOAG+1HaLMEqaCEs8PFQ/6ADFSFD7IUtVEvZgB6NzWeZNKKZTngVP7jmLHnuNF23Mt7oisWQUDRnFh+bjT53Fg31Gk5+TdF80wF4iWB+HG3UvYQXACAQ+BCm907d0JwdXCXPpvS7lzDWP+tx2XfWrAw2LAe2GXn9qP6Xln1gdT4X7jOkxiKfqNeRMRbZw30ZZAxccTcFedgvVLp6J+3GU2Jyy47/y57BsOvUqCquNHoGtn5xQxFoc+XYc/N/4Ay81TCNClwsPI5WCdAQMeMjxl0PlXgV/ddhjQ69UyHYZ29UY8dm3/CaLEi1DptZBainFye0qENgd8dDbINQx4tuKFhsWXQaaKTAV1g8Y/GPKaMRjYb8wzjXSnUCoaW37biHOXb9zXnstjO2PAt3LmX8VBnmOXAg4BO53CXSZGk8YRaN2j/EQO484cxqQVl5HgFcrW533SRIferxT1yKjoXLlwAvs2rMEJrQcyBR6QMQ78sfQDp74GFR9PyMq572HjzQDccAtFy5SL6JR0BvXSbhX8nlTJq+sIcbFuBAaPX/hMlftb9/6Nayc2wltzE4H6DCg01kduls6GeDLkqsi0TClSFH4wBtVGi44vI7pRc6dHl/7c8it0sXug0CYiUJ8DX7UVEh032Ki0cUgY5AYW/XdGd3gJLe4rLqZQKI9m1eKfkKhOK2zPvQep1eA5RKzgEAl5CA30R/cB3eAXwI2TL8+c3LsJb29MR7J7AAINOszpLETbPi+jomHMzca2NUtwLe4OUg3uSOUpkSwJgNqtaLG1pzUbvw8ORd3mrZz22lR8PIa/Vy3E2qNGHPfjetyFDhvapp/GyAGRSDYbYd37EyJj9axLYj52OYPbkTIk1G+JcRO/KjENQ9rvtm5ZDl7ieQTqNFBqjfBSOyDMKSH0L+Y2S71SgnRP50UmSIW3IsMAP6211CICxE3y0O5VkCVfRqBeD3+tCe5qhjV3Kg7yHmYH8qFVypAjd14ay8HnI8M3qFxEeCiUisS3c79DZk4evORStGrZGI3aPt8ifucfP+D/jsigk/siPCcFi16uioYxXEvu88jZg1txbPcOJOsBtc0Pd0UBSHYLgEkoKfb5PqZshOSpIRaYEcSk4cuFnzm1pICKjxI4tms9Vv5xHvt9omETcFbmzdMu4MVoAQaMefehO/gVK7+A6ux21LyUC1EWr8iGfbWeFzT12sGengyF9g5Uuiz4aayQakmu8+HNl7gdWvyADJUQqf4e0PmHwKt2Gwzu+1qpb5bOqIVwC6gO080zUOqSodLf6wzRF//nyej5vAAe0gNESPH3QroyHGGNe6BHx/60doZCoZQpG5Z9gc/iq7MNBbUzb2Hp5BaoWqdxqQiD3KwMp/19ybeu48YNDdRGL6TwlUiWqdgRHcUhslsRatAg2KKBSqBHkK8d0W3aoGUpzzqi4qMYFr03Ad9bOyBPxKm8ehnX0S/sLkZ/8OUTtWWu/O5t1I09g9BYM/jmR6cPyACpHDb0L0OKQgFzSATadBpR7iaiki6Q84fWwVN9DYH6TPhrzJCTLhDrk6dHSMdQtooPjdINakUAeOFR6NvvjTI1l6JQKJTHpdy/1DaBUSRDw/SrWP7Ji/APCn2qNy3pRhx2r1+F20m5UFu8WWGQJFcVdEuWNoq8DITmqRHI6BAoy0aNGgHo/tI4ePu53i2bio9iOL3/b4z8xwylKQO9Pc5j2tync7yLS4jD3pXvo0FcAvxu2mH2AXuHn6rwhF4ZhqD6ndG3+7Dn9g6fCK2/Nv+E3OtHEKBNYaMc3mobRDmAUclFQ1LZaEgN1G3er9QnlVIoFEpp8O3MSfjG1AEWgQgxaeexYuFbkLuX7C1FouH7/lqB2LOxSM2RIpXxR7JEhRS5Ag5+yVPHnYXUZuaiGVYNVEI9Qvz5aNG1Bxq36obyAhUfJbB28Sz0HTX1kR8wCoVCoVQO5r09Ht8LusPOF6Cj/gSWfPshe+N4PfY09v61FklqM9QWX9wVBiBJHgCDuHgHWHeLEVWMagTZNFCJ01ElUIbOg14qlXROeYaKDwqFQqFQnoBZE8djlVsPdhIuqQHJFHlAI/dlHz+IwGFHkEGHEIsagTw9Ar1MqN+0Edr2efW5jXY7Eyo+KBQKhUJ5Qt4bNxG/e3cvtjMkyK5FoCQT4VW80WXoKASFvUDfVyeID67lg0KhUCiUSsqcZd/CY/I4ZJokCPaxIapNa7TuMaysl1WhoeKDQqFQKJWeD79eVunfA1fycFKLQqFQKBQKpRSh4oNCoVAoFIpLoeKDQqFQKBSKS6Hig0KhUCgUikuh4oNCoVAoFIpLoeKDQqFQKBSKS6Hig0KhUCgUikuh4oNCoVAoFIpLoeKDQqFQKBSKS6Hig0KhUCgUikuh4oNCoVAoFIpLoeKDQqFQKBQKFR8UCoVCoVAqLuVuqi3DMOz37Ozssl4KhUKhUCiUJyR/387fx58r8ZGTk8N+Dw0NLeulUCgUCoVCeYp93MvL65HP4TFPIlFciMPhQEpKCjw8PMDj8ZyuyoioSUpKgqenp1P/bgo9Ds8b9HwoH9DjUD6gx+HZIXKCCI+goCDw+fznK/JBFhwSElKqr0GEBxUfZQ89DuUDehzKB/Q4lA/ocXg2HhfxyId2u1AoFAqFQnEpVHxQKBQKhUJxKZVKfEgkEnz88cfsdwo9DpUdej6UD+hxKB/Q4+Bayl3BKYVCoVAolIpNpYp8UCgUCoVCKXuo+KBQKBQKheJSqPigUCgUCoXiUqj4oFAoFAqF4lIqjfhYsmQJwsPDIZVK0axZM5w6daqsl1Tp+OSTT1jX2vu/ateuXdbLqvAcOnQIvXv3Zl0HyXu+adOmIr8nNecfffQRAgMDIZPJ0KlTJ1y/fr3M1ltZj8PIkSMfOj+6detWZuutiMyePRtNmzZlHbSVSiX69euH+Pj4Is8xmUyYMGEC/Pz84O7ujoEDB0Kj0ZTZmisqlUJ8rFu3DtOmTWPbbM+dO4cGDRqga9eu0Gq1Zb20SkdERARSU1MLvo4cOVLWS6rwGAwG9jNPBHhxzJs3D9988w2WLVuGkydPws3NjT0/yEWY4rrjQCBi4/7zY+3atfQQOJGDBw+ywuLEiRPYvXs3rFYrunTpwh6bfKZOnYp//vkH69evZ59Pxn0MGDCAHgdnw1QCoqOjmQkTJhQ8ttvtTFBQEDN79uwyXVdl4+OPP2YaNGhQ1suo1JBTfuPGjQWPHQ4Ho1KpmC+//LLg/2VmZjISiYRZu3ZtGa2y8h0HwogRI5i+ffuW2ZoqI1qtlj0WBw8eLPjsi0QiZv369QXPuXLlCvuc48ePl+FKKx4VPvJhsVhw9uxZNpR8//wY8vj48eNlurbKCAnnk7BztWrV8NJLLyExMbGsl1SpuXXrFtRqdZHzg8xmIKlJen64ngMHDrDpgFq1amH8+PFIS0srg1VUHrKystjvvr6+7HeyV5BoyP3nA0kNV6lShZ4PTqbCiw+9Xg+73Y6AgIAi/588JhddiusgG9qqVauwY8cOLF26lN34WrduzU5BpJQN+ecAPT/KHpJy+eWXX7B3717MnTuXDfl3796dvX5RSmeC+pQpU9CyZUtERkYWnA9isRje3t5Fnkv3C+dT7qbaUiou5EKaT/369VkxEhYWhj/++AOjR48u07VRKGXN0KFDC36uV68ee45Ur16djYZ07NixTNdWESG1H7GxsbTurIyo8JEPhUIBgUDwULUyeaxSqcpsXRSwdxcvvPACEhIS6NtRRuSfA/T8KH+Q1CS5ftHzw/lMnDgRW7Zswf79+xESElLkfCCp+szMzCLPp/uF86nw4oOE0KKiothQ5v3hNvI4JiamTNdW2cnNzcWNGzfYFk9K2VC1alX2gnv/+ZGdnc12vdDzo2xJTk5maz7o+eE8SK0vER4bN27Evn372M///ZC9QiQSFTkfSCsuqU2j54NzqRRpF9JmO2LECDRp0gTR0dFYtGgR21o1atSosl5apeKdd95hfQ5IqoW0r5HWZxKVGjZsWFkvrcKLvPvvnkmtzfnz59kiO1JIR/Len3/+OWrWrMlejGfOnMkWBRMPBIprjgP5mjVrFuspQcQgEeUzZsxAjRo12LZnivNSLWvWrMHmzZtZr4/8midSZE08bsh3kgImewY5Jp6ennjrrbdY4dG8eXN6GJwJU0lYvHgxU6VKFUYsFrOttydOnCjrJVU6hgwZwgQGBrLHIDg4mH2ckJBQ1suq8Ozfv59tFXzwi7R25rfbzpw5kwkICGBbbDt27MjEx8eX9bIr1XEwGo1Mly5dGH9/f7bVMywsjBkzZgyjVqvLetkViuLef/K1cuXKgufk5eUxb775JuPj48PI5XKmf//+TGpqapmuuyLCI/9xqpqhUCgUCoVCqcw1HxQKhUKhUMoXVHxQKBQKhUJxKVR8UCgUCoVCcSlUfFAoFAqFQnEpVHxQKBQKhUJxKVR8UCgUCoVCcSlUfFAoFAqFQnEpVHxQKBQKhUJxKVR8UCgUCoVCcSlUfFAoFAqFQnEpVHxQKBQKhUJxKVR8UCgUCoVCgSv5f/UKQHByDWOCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ttt in df_useful.TTT:\n",
    "    plt.plot(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7bcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_df(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'n_missing': df.isna().sum(),\n",
    "        '%_missing': (df.isna().mean() * 100).round(2),\n",
    "        'n_unique': df.nunique(),\n",
    "        'top_value': df.mode().iloc[0],  # moda\n",
    "        'top_freq': [df[col].value_counts(dropna=True).iloc[0] if not df[col].value_counts(dropna=True).empty else None for col in df.columns],\n",
    "        'min': [df[col].min() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'max': [df[col].max() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'mean': [df[col].mean() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'std': [df[col].std() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "    })\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d224ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nella precedente sono state eliminate le colonne con Nan, tuttavia alcuni dataset dei sensori METRO hanno dei Nan in city e surface dunque vengono rimossi nel prcedente box\n",
    "\n",
    "categorical = [\n",
    "    'is_weekend'\n",
    "    ]\n",
    "\n",
    "#consiglio, per serie cicliche usare funzioni periodiche tipo seno coseno \n",
    "df_encoded = pd.get_dummies(df_useful\n",
    "                            , columns=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1247ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Salvato: {path}\")\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80bcd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/dataframe_LI-LAPIRA/filtered_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "#codifica ciclica delle features e individuazione del'ora del giorno e della settimana \n",
    "\n",
    "def encode_time_features(df, start_col=\"interval_start\", end_col=\"interval_end\"):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Step 1: Ensure datetime columns are in the correct format first\n",
    "    df[start_col] = pd.to_datetime(df[start_col], utc=True, format=\"mixed\")\n",
    "    df[end_col] = pd.to_datetime(df[end_col], utc=True, format=\"mixed\")\n",
    "\n",
    "    # Step 2: Extract 'month' and 'day' after conversion\n",
    "    df['month'] = df[start_col].dt.month\n",
    "    df['day'] = df[start_col].dt.dayofweek # Note: dayofweek is typically used for cyclical weekly patterns\n",
    "    \n",
    "    # Step 3: Now you can create the cyclical features\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month']/len(df['month'].unique()))\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month']/len(df['month'].unique()))\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day']/len(df['day'].unique()))\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day']/len(df['day'].unique()))\n",
    "\n",
    "\n",
    "    # Ora del giorno (0-23) → ciclo giornaliero\n",
    "    df[\"hour\"] = df[start_col].dt.hour\n",
    "    angle_day_start = 2 * np.pi * df[\"hour\"] / 24\n",
    "    df[\"start_time_sin\"] = np.sin(angle_day_start)\n",
    "    df[\"start_time_cos\"] = np.cos(angle_day_start)\n",
    "\n",
    "    df[\"hour_end\"] = df[end_col].dt.hour\n",
    "    angle_day_end = 2 * np.pi * df[\"hour_end\"] / 24\n",
    "    df[\"end_time_sin\"] = np.sin(angle_day_end)\n",
    "    df[\"end_time_cos\"] = np.cos(angle_day_end)\n",
    "\n",
    "    # Durata in minuti\n",
    "    df[\"duration_minutes\"] = (df[end_col] - df[start_col]).dt.total_seconds() / 60\n",
    "\n",
    "    # Giorno della settimana (0=Mon..6=Sun) → ciclo settimanale\n",
    "    dayofweek = df[start_col].dt.dayofweek\n",
    "    angle_week = 2 * np.pi * dayofweek / 7\n",
    "    df[\"dow_sin\"] = np.sin(angle_week)\n",
    "    df[\"dow_cos\"] = np.cos(angle_week)\n",
    "\n",
    "    # Giorno dell’anno (1-365) → ciclo annuale\n",
    "    dayofyear = df[start_col].dt.dayofyear\n",
    "    angle_year = 2 * np.pi * dayofyear / 365\n",
    "    df[\"doy_sin\"] = np.sin(angle_year)\n",
    "    df[\"doy_cos\"] = np.cos(angle_year)\n",
    "\n",
    "    # Rimuovo colonne temporali e variabili ausiliarie\n",
    "    df = df.drop(columns=[start_col, end_col, \"hour\", \"hour_end\", \"day\", \"month\"])\n",
    "    return df\n",
    "\n",
    "embedding_cols = ['highway_embedding', 'AreaTypeEmbeddings']\n",
    "\n",
    "df_final = encode_time_features(df_encoded)\n",
    "df_final.drop(columns=['type_of_TTT'], inplace=True)\n",
    "for emb_col in embedding_cols:\n",
    "    df_final = spezza_serie_in_colonne(df_final, emb_col, prefix=f'{emb_col}_')\n",
    "df_final.shape\n",
    "\n",
    "# Salvataggio DataFrame finale\n",
    "df_path = os.path.join(exp_dir, f\"dataframe_{sensor_name}\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "save_pkl(df_final, os.path.join(df_path, f\"filtered_dataframe.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f0e301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ttt in df_final.TTT[10:20]:\n",
    "    plt.plot(ttt)\n",
    "    plt.title(\"Esempi di TTT ARPAT\")\n",
    "    plt.xlabel(\"Ora del Giorno\")\n",
    "    plt.ylabel(\"Valore TTT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc56e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (217, 33), (217, 24)\n",
      "Test size: (55, 33), (55, 24)\n",
      "Final shapes:\n",
      "X_train: (217, 33)\n",
      "y_train: (217, 24)\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/X_train_unscaled_LI-LAPIRA.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/y_train_unscaled_LI-LAPIRA.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/X_test_unscaled_LI-LAPIRA.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/y_test_unscaled_LI-LAPIRA.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/X_train.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/y_train.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/X_test.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/y_test.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/scaler_X.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/scaler_y.pkl\n",
      "Scaler salvati.\n",
      "\n",
      "Tutti i file sono stati salvati correttamente.\n",
      "Percorso cartella: /Users/lapotinacci/thesis/Federated_Sys/RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def series_to_2d_array(series, output_dim=24):\n",
    "    arr = np.stack(series.apply(lambda x: np.array(x, dtype=np.float32)))\n",
    "    if arr.shape[1] != output_dim:\n",
    "        raise ValueError(f\"Ogni elemento deve avere {output_dim} valori, trovato {arr.shape[1]}\")\n",
    "    return arr\n",
    "\n",
    " # Separazione delle feature e del target\n",
    "X = df_final.drop(columns=['TTT'])\n",
    "y = df_final['TTT']\n",
    "\n",
    "X_np = X.to_numpy().astype(np.float32)\n",
    "y_np = series_to_2d_array(y, output_dim=24)\n",
    "\n",
    "# Calcolo deviazione standard per ogni serie\n",
    "std_scores = np.std(y_np, axis=1)\n",
    "\n",
    "std_scores_log = np.log1p(std_scores)  # log(1+x) per evitare problemi con valori vicini a 0\n",
    "\n",
    "std_scores_normalized = (std_scores_log - np.min(std_scores_log)) / (np.max(std_scores_log) - np.min(std_scores_log))\n",
    "\n",
    "# Creo bin basati sui quantili\n",
    "bins = np.array([0.0, 0.4, 0.8, 1.0])\n",
    "std_bins = np.digitize(std_scores_normalized, bins)\n",
    "\n",
    "# Primo split: train (80%) vs temp (20%)\n",
    "# Passo anche std_bins per poter stratificare\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_np, y_np,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=std_bins, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test size: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Debug prints\n",
    "print(f\"Final shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "# Scaler per input\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test  = scaler_X.transform(X_test)\n",
    "\n",
    "# Scaler per output (se serve normalizzare anche y)\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test  = scaler_y.transform(y_test)\n",
    "\n",
    "#cartella salvataggio train e test\n",
    "path = os.path.join(exp_dir, \"train_test_data\")\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "#  === Salvataggio dataset e scaler in formato .pkl ===\n",
    "save_pkl(scaler_X.inverse_transform(X_train), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"X_train_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_y.inverse_transform(y_train), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"y_train_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_X.inverse_transform(X_test), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"X_test_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_y.inverse_transform(y_test), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"y_test_unscaled_{sensor_name}.pkl\"))\n",
    "\n",
    "\n",
    "save_pkl(X_train, os.path.join(exp_dir, \"X_train.pkl\"))\n",
    "save_pkl(y_train, os.path.join(exp_dir, \"y_train.pkl\"))\n",
    "save_pkl(X_test, os.path.join(exp_dir, \"X_test.pkl\"))\n",
    "save_pkl(y_test, os.path.join(exp_dir, \"y_test.pkl\"))\n",
    "\n",
    "save_pkl(scaler_X, os.path.join(exp_dir, \"scaler_X.pkl\"))\n",
    "save_pkl(scaler_y, os.path.join(exp_dir, \"scaler_y.pkl\"))\n",
    "\n",
    "print(\"Scaler salvati.\")\n",
    "\n",
    "print(\"\\nTutti i file sono stati salvati correttamente.\")\n",
    "print(f\"Percorso cartella: {os.path.abspath(exp_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2d0d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ricostruite:\n",
      "X_train: (217, 33)\n",
      "y_train: (217, 24)\n",
      "X_test: (55, 33)\n",
      "y_test: (55, 24)\n",
      "\n",
      "Scaler caricati:\n",
      "scaler_X: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "scaler_y: <class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "# === Costruisci i path ===\n",
    "path_X_train = os.path.join(exp_dir, \"X_train.pkl\")\n",
    "path_y_train = os.path.join(exp_dir, \"y_train.pkl\")\n",
    "path_X_test  = os.path.join(exp_dir, \"X_test.pkl\")\n",
    "path_y_test  = os.path.join(exp_dir, \"y_test.pkl\")\n",
    "\n",
    "path_scaler_X = os.path.join(exp_dir, \"scaler_X.pkl\")\n",
    "path_scaler_y = os.path.join(exp_dir, \"scaler_y.pkl\")\n",
    "\n",
    "# === Ricaricamento ===\n",
    "X_train = load_pkl(path_X_train)\n",
    "y_train = load_pkl(path_y_train)\n",
    "X_test  = load_pkl(path_X_test)\n",
    "y_test  = load_pkl(path_y_test)\n",
    "\n",
    "\n",
    "scaler_X = load_pkl(path_scaler_X)\n",
    "scaler_y = load_pkl(path_scaler_y)\n",
    "\n",
    "print(\"Shapes ricostruite:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "print(\"\\nScaler caricati:\")\n",
    "print(\"scaler_X:\", type(scaler_X))\n",
    "print(\"scaler_y:\", type(scaler_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece47aa",
   "metadata": {},
   "source": [
    "# modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08dc75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers # type: ignore\n",
    "from tensorflow.keras.layers import Dropout # type: ignore\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b8b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_plots(y_true, y_pred, output_dir, prefix=\"pred_plot\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    n = len(y_true)\n",
    "    print(f\"Salvo {n} plot in: {output_dir}\")\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        plt.plot(y_true[i], label=\"True\")\n",
    "        plt.plot(y_pred[i], label=\"Pred\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"{prefix}_{i+1}.png\"\n",
    "        path = os.path.join(output_dir, filename)\n",
    "\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Plot salvati correttamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0608b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lapotinacci/thesis/Federated_Sys/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - loss: 1.1283 - mae: 0.8170 - val_loss: 0.9378 - val_mae: 0.6988\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7049 - mae: 0.6369 - val_loss: 0.7233 - val_mae: 0.6281\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.5289 - mae: 0.5516 - val_loss: 0.5823 - val_mae: 0.5693\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4178 - mae: 0.4871 - val_loss: 0.4879 - val_mae: 0.5160\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3657 - mae: 0.4553 - val_loss: 0.4248 - val_mae: 0.4907\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3356 - mae: 0.4439 - val_loss: 0.3693 - val_mae: 0.4642\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3007 - mae: 0.4210 - val_loss: 0.3105 - val_mae: 0.4275\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2594 - mae: 0.3861 - val_loss: 0.2652 - val_mae: 0.3937\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2288 - mae: 0.3598 - val_loss: 0.2398 - val_mae: 0.3764\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2118 - mae: 0.3481 - val_loss: 0.2177 - val_mae: 0.3585\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1939 - mae: 0.3303 - val_loss: 0.2027 - val_mae: 0.3393\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1760 - mae: 0.3085 - val_loss: 0.1878 - val_mae: 0.3210\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1597 - mae: 0.2908 - val_loss: 0.1671 - val_mae: 0.3024\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1420 - mae: 0.2740 - val_loss: 0.1506 - val_mae: 0.2894\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.1308 - mae: 0.2647 - val_loss: 0.1396 - val_mae: 0.2779\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1209 - mae: 0.2535 - val_loss: 0.1319 - val_mae: 0.2685\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1123 - mae: 0.2424 - val_loss: 0.1249 - val_mae: 0.2628\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1034 - mae: 0.2325 - val_loss: 0.1131 - val_mae: 0.2477\n",
      "Epoch 19/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0979 - mae: 0.2223 - val_loss: 0.1052 - val_mae: 0.2345\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0916 - mae: 0.2116 - val_loss: 0.0970 - val_mae: 0.2251\n",
      "Epoch 21/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0856 - mae: 0.2038 - val_loss: 0.0880 - val_mae: 0.2169\n",
      "Epoch 22/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0799 - mae: 0.1973 - val_loss: 0.0833 - val_mae: 0.2108\n",
      "Epoch 23/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0758 - mae: 0.1899 - val_loss: 0.0814 - val_mae: 0.2048\n",
      "Epoch 24/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0727 - mae: 0.1829 - val_loss: 0.0791 - val_mae: 0.1986\n",
      "Epoch 25/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0684 - mae: 0.1749 - val_loss: 0.0731 - val_mae: 0.1937\n",
      "Epoch 26/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0643 - mae: 0.1701 - val_loss: 0.0701 - val_mae: 0.1910\n",
      "Epoch 27/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0618 - mae: 0.1677 - val_loss: 0.0668 - val_mae: 0.1836\n",
      "Epoch 28/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0592 - mae: 0.1652 - val_loss: 0.0608 - val_mae: 0.1730\n",
      "Epoch 29/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0564 - mae: 0.1597 - val_loss: 0.0578 - val_mae: 0.1670\n",
      "Epoch 30/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0530 - mae: 0.1514 - val_loss: 0.0577 - val_mae: 0.1664\n",
      "Epoch 31/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0506 - mae: 0.1484 - val_loss: 0.0554 - val_mae: 0.1591\n",
      "Epoch 32/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0484 - mae: 0.1430 - val_loss: 0.0523 - val_mae: 0.1567\n",
      "Epoch 33/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0460 - mae: 0.1397 - val_loss: 0.0491 - val_mae: 0.1531\n",
      "Epoch 34/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0435 - mae: 0.1357 - val_loss: 0.0498 - val_mae: 0.1524\n",
      "Epoch 35/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0424 - mae: 0.1321 - val_loss: 0.0475 - val_mae: 0.1489\n",
      "Epoch 36/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0397 - mae: 0.1272 - val_loss: 0.0418 - val_mae: 0.1409\n",
      "Epoch 37/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0376 - mae: 0.1249 - val_loss: 0.0393 - val_mae: 0.1375\n",
      "Epoch 38/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0365 - mae: 0.1235 - val_loss: 0.0384 - val_mae: 0.1337\n",
      "Epoch 39/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0339 - mae: 0.1176 - val_loss: 0.0377 - val_mae: 0.1320\n",
      "Epoch 40/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0329 - mae: 0.1174 - val_loss: 0.0367 - val_mae: 0.1303\n",
      "Epoch 41/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0310 - mae: 0.1144 - val_loss: 0.0376 - val_mae: 0.1318\n",
      "Epoch 42/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0298 - mae: 0.1116 - val_loss: 0.0328 - val_mae: 0.1250\n",
      "Epoch 43/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0283 - mae: 0.1090 - val_loss: 0.0295 - val_mae: 0.1188\n",
      "Epoch 44/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0258 - mae: 0.1042 - val_loss: 0.0308 - val_mae: 0.1190\n",
      "Epoch 45/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0257 - mae: 0.1028 - val_loss: 0.0288 - val_mae: 0.1156\n",
      "Epoch 46/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0230 - mae: 0.0985 - val_loss: 0.0269 - val_mae: 0.1139\n",
      "Epoch 47/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0223 - mae: 0.0981 - val_loss: 0.0271 - val_mae: 0.1125\n",
      "Epoch 48/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0213 - mae: 0.0944 - val_loss: 0.0261 - val_mae: 0.1059\n",
      "Epoch 49/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0200 - mae: 0.0912 - val_loss: 0.0243 - val_mae: 0.1043\n",
      "Epoch 50/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0189 - mae: 0.0886 - val_loss: 0.0246 - val_mae: 0.1078\n",
      "Epoch 51/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0176 - mae: 0.0877 - val_loss: 0.0227 - val_mae: 0.1009\n",
      "Epoch 52/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0165 - mae: 0.0842 - val_loss: 0.0206 - val_mae: 0.0981\n",
      "Epoch 53/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0159 - mae: 0.0836 - val_loss: 0.0225 - val_mae: 0.1017\n",
      "Epoch 54/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0158 - mae: 0.0804 - val_loss: 0.0203 - val_mae: 0.0993\n",
      "Epoch 55/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0158 - mae: 0.0840 - val_loss: 0.0174 - val_mae: 0.0916\n",
      "Epoch 56/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0135 - mae: 0.0786 - val_loss: 0.0211 - val_mae: 0.0939\n",
      "Epoch 57/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0149 - mae: 0.0775 - val_loss: 0.0163 - val_mae: 0.0904\n",
      "Epoch 58/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0135 - mae: 0.0787 - val_loss: 0.0154 - val_mae: 0.0869\n",
      "Epoch 59/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0121 - mae: 0.0745 - val_loss: 0.0175 - val_mae: 0.0854\n",
      "Epoch 60/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0132 - mae: 0.0744 - val_loss: 0.0138 - val_mae: 0.0819\n",
      "Epoch 61/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0110 - mae: 0.0714 - val_loss: 0.0137 - val_mae: 0.0852\n",
      "Epoch 62/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0110 - mae: 0.0736 - val_loss: 0.0154 - val_mae: 0.0830\n",
      "Epoch 63/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0694 - val_loss: 0.0137 - val_mae: 0.0764\n",
      "Epoch 64/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0092 - mae: 0.0629 - val_loss: 0.0133 - val_mae: 0.0828\n",
      "Epoch 65/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0681 - val_loss: 0.0128 - val_mae: 0.0760\n",
      "Epoch 66/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0085 - mae: 0.0626 - val_loss: 0.0133 - val_mae: 0.0724\n",
      "Epoch 67/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0079 - mae: 0.0564 - val_loss: 0.0129 - val_mae: 0.0787\n",
      "Epoch 68/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0082 - mae: 0.0625 - val_loss: 0.0100 - val_mae: 0.0671\n",
      "Epoch 69/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0560 - val_loss: 0.0118 - val_mae: 0.0705\n",
      "Epoch 70/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0079 - mae: 0.0575 - val_loss: 0.0103 - val_mae: 0.0686\n",
      "Epoch 71/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0543 - val_loss: 0.0099 - val_mae: 0.0662\n",
      "Epoch 72/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0543 - val_loss: 0.0100 - val_mae: 0.0653\n",
      "Epoch 73/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0069 - mae: 0.0565 - val_loss: 0.0091 - val_mae: 0.0662\n",
      "Epoch 74/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0559 - val_loss: 0.0081 - val_mae: 0.0621\n",
      "Epoch 75/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0527 - val_loss: 0.0086 - val_mae: 0.0619\n",
      "Epoch 76/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0059 - mae: 0.0526 - val_loss: 0.0070 - val_mae: 0.0561\n",
      "Epoch 77/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0052 - mae: 0.0476 - val_loss: 0.0071 - val_mae: 0.0575\n",
      "Epoch 78/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0467 - val_loss: 0.0072 - val_mae: 0.0569\n",
      "Epoch 79/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0049 - mae: 0.0476 - val_loss: 0.0061 - val_mae: 0.0522\n",
      "Epoch 80/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0044 - mae: 0.0445 - val_loss: 0.0067 - val_mae: 0.0570\n",
      "Epoch 81/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0438 - val_loss: 0.0059 - val_mae: 0.0527\n",
      "Epoch 82/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0038 - mae: 0.0422 - val_loss: 0.0052 - val_mae: 0.0475\n",
      "Epoch 83/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0035 - mae: 0.0396 - val_loss: 0.0057 - val_mae: 0.0517\n",
      "Epoch 84/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0036 - mae: 0.0403 - val_loss: 0.0061 - val_mae: 0.0521\n",
      "Epoch 85/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0035 - mae: 0.0393 - val_loss: 0.0055 - val_mae: 0.0491\n",
      "Epoch 86/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0036 - mae: 0.0389 - val_loss: 0.0055 - val_mae: 0.0494\n",
      "Epoch 87/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0033 - mae: 0.0380 - val_loss: 0.0067 - val_mae: 0.0526\n",
      "Epoch 88/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0400 - val_loss: 0.0048 - val_mae: 0.0473\n",
      "Epoch 89/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0391 - val_loss: 0.0044 - val_mae: 0.0458\n",
      "Epoch 90/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0033 - mae: 0.0378 - val_loss: 0.0053 - val_mae: 0.0477\n",
      "Epoch 91/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - mae: 0.0399 - val_loss: 0.0042 - val_mae: 0.0439\n",
      "Epoch 92/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0031 - mae: 0.0370 - val_loss: 0.0045 - val_mae: 0.0452\n",
      "Epoch 93/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0382 - val_loss: 0.0045 - val_mae: 0.0459\n",
      "Epoch 94/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0374 - val_loss: 0.0042 - val_mae: 0.0438\n",
      "Epoch 95/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0029 - mae: 0.0358 - val_loss: 0.0041 - val_mae: 0.0434\n",
      "Epoch 96/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - mae: 0.0355 - val_loss: 0.0041 - val_mae: 0.0445\n",
      "Epoch 97/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0028 - mae: 0.0350 - val_loss: 0.0043 - val_mae: 0.0453\n",
      "Epoch 98/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - mae: 0.0343 - val_loss: 0.0039 - val_mae: 0.0414\n",
      "Epoch 99/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0340 - val_loss: 0.0035 - val_mae: 0.0406\n",
      "Epoch 100/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0024 - mae: 0.0327 - val_loss: 0.0036 - val_mae: 0.0415\n",
      "Epoch 101/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - mae: 0.0336 - val_loss: 0.0031 - val_mae: 0.0394\n",
      "Epoch 102/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0311 - val_loss: 0.0036 - val_mae: 0.0420\n",
      "Epoch 103/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0024 - mae: 0.0332 - val_loss: 0.0032 - val_mae: 0.0416\n",
      "Epoch 104/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0031 - val_mae: 0.0393\n",
      "Epoch 105/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0022 - mae: 0.0313 - val_loss: 0.0029 - val_mae: 0.0379\n",
      "Epoch 106/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0020 - mae: 0.0298 - val_loss: 0.0030 - val_mae: 0.0385\n",
      "Epoch 107/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0028 - val_mae: 0.0378\n",
      "Epoch 108/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0286 - val_loss: 0.0026 - val_mae: 0.0371\n",
      "Epoch 109/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0031 - val_mae: 0.0392\n",
      "Epoch 110/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 0.0027 - val_mae: 0.0385\n",
      "Epoch 111/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0030 - val_mae: 0.0384\n",
      "Epoch 112/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mae: 0.0291 - val_loss: 0.0024 - val_mae: 0.0355\n",
      "Epoch 113/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0022 - val_mae: 0.0340\n",
      "Epoch 114/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0028 - val_mae: 0.0362\n",
      "Epoch 115/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0029 - val_mae: 0.0372\n",
      "Epoch 116/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0293 - val_loss: 0.0024 - val_mae: 0.0346\n",
      "Epoch 117/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0025 - val_mae: 0.0359\n",
      "Epoch 118/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0031 - val_mae: 0.0394\n",
      "Epoch 119/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mae: 0.0292 - val_loss: 0.0028 - val_mae: 0.0388\n",
      "Epoch 120/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0028 - val_mae: 0.0379\n",
      "Epoch 121/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 0.0021 - val_mae: 0.0328\n",
      "Epoch 122/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 0.0022 - val_mae: 0.0340\n",
      "Epoch 123/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 124/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0029 - val_mae: 0.0382\n",
      "Epoch 125/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 0.0021 - val_mae: 0.0329\n",
      "Epoch 126/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0020 - val_mae: 0.0326\n",
      "Epoch 127/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 0.0024 - val_mae: 0.0339\n",
      "Epoch 128/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 0.0024 - val_mae: 0.0358\n",
      "Epoch 129/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0029 - val_mae: 0.0371\n",
      "Epoch 130/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 0.0022 - val_mae: 0.0330\n",
      "Epoch 131/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0265 - val_loss: 0.0024 - val_mae: 0.0349\n",
      "Epoch 132/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 0.0020 - val_mae: 0.0312\n",
      "Epoch 133/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0021 - val_mae: 0.0325\n",
      "Epoch 134/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 0.0022 - val_mae: 0.0328\n",
      "Epoch 135/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 0.0022 - val_mae: 0.0345\n",
      "Epoch 136/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0025 - val_mae: 0.0362\n",
      "Epoch 137/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0022 - val_mae: 0.0343\n",
      "Epoch 138/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0018 - mae: 0.0282 - val_loss: 0.0021 - val_mae: 0.0330\n",
      "Epoch 139/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0022 - val_mae: 0.0340\n",
      "Epoch 140/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 141/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0019 - val_mae: 0.0324\n",
      "Epoch 142/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0022 - val_mae: 0.0344\n",
      "Epoch 143/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0022 - val_mae: 0.0332\n",
      "Epoch 144/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 0.0018 - val_mae: 0.0301\n",
      "Epoch 145/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 0.0016 - val_mae: 0.0282\n",
      "Epoch 146/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 0.0018 - val_mae: 0.0297\n",
      "Epoch 147/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0017 - val_mae: 0.0288\n",
      "Epoch 148/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 0.0019 - val_mae: 0.0287\n",
      "Epoch 149/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0011 - mae: 0.0212 - val_loss: 0.0014 - val_mae: 0.0266\n",
      "Epoch 150/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0230 - val_loss: 0.0017 - val_mae: 0.0282\n",
      "Epoch 151/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0012 - mae: 0.0222 - val_loss: 0.0018 - val_mae: 0.0298\n",
      "Epoch 152/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 0.0016 - val_mae: 0.0272\n",
      "Epoch 153/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 154/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0241 - val_loss: 0.0020 - val_mae: 0.0293\n",
      "Epoch 155/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mae: 0.0220 - val_loss: 0.0018 - val_mae: 0.0290\n",
      "Epoch 156/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 0.0017 - val_mae: 0.0287\n",
      "Epoch 157/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 0.0015 - val_mae: 0.0276\n",
      "Epoch 158/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0018 - val_mae: 0.0284\n",
      "Epoch 159/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 0.0018 - val_mae: 0.0300\n",
      "Epoch 160/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 0.0018 - val_mae: 0.0296\n",
      "Epoch 161/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 0.0017 - val_mae: 0.0293\n",
      "Epoch 162/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0018 - val_mae: 0.0283\n",
      "Epoch 163/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0014 - val_mae: 0.0259\n",
      "Epoch 164/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.9806e-04 - mae: 0.0206 - val_loss: 0.0015 - val_mae: 0.0271\n",
      "Epoch 165/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "Epoch 166/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 0.0017 - val_mae: 0.0298\n",
      "Epoch 167/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 168/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 0.0021 - val_mae: 0.0316\n",
      "Epoch 169/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 0.0015 - val_mae: 0.0280\n",
      "Epoch 170/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 171/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 0.0015 - val_mae: 0.0282\n",
      "Epoch 172/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 173/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0016 - val_mae: 0.0288\n",
      "Epoch 174/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 175/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0017 - val_mae: 0.0291\n",
      "Epoch 176/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 0.0016 - val_mae: 0.0301\n",
      "Epoch 177/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0015 - val_mae: 0.0293\n",
      "Epoch 178/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0021 - val_mae: 0.0318\n",
      "Epoch 179/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 180/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 181/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0016 - val_mae: 0.0283\n",
      "Epoch 182/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0014 - val_mae: 0.0267\n",
      "Epoch 183/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0014 - val_mae: 0.0277\n",
      "Epoch 184/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 0.0017 - val_mae: 0.0294\n",
      "Epoch 185/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 0.0015 - val_mae: 0.0284\n",
      "Epoch 186/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 187/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 188/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0017 - val_mae: 0.0295\n",
      "Epoch 189/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 0.0013 - val_mae: 0.0267\n",
      "Epoch 190/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 8.9576e-04 - mae: 0.0206 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 191/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.2909e-04 - mae: 0.0204 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 192/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.7954e-04 - mae: 0.0209 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 193/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.5992e-04 - mae: 0.0208 - val_loss: 0.0013 - val_mae: 0.0250\n",
      "Epoch 194/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0208 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 195/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.4269e-04 - mae: 0.0194 - val_loss: 0.0014 - val_mae: 0.0254\n",
      "Epoch 196/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mae: 0.0207 - val_loss: 0.0012 - val_mae: 0.0238\n",
      "Epoch 197/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.2719e-04 - mae: 0.0205 - val_loss: 0.0014 - val_mae: 0.0261\n",
      "Epoch 198/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.0258e-04 - mae: 0.0200 - val_loss: 0.0011 - val_mae: 0.0235\n",
      "Epoch 199/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.7641e-04 - mae: 0.0196 - val_loss: 0.0012 - val_mae: 0.0243\n",
      "Epoch 200/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.8991e-04 - mae: 0.0202 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 201/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.0696e-04 - mae: 0.0194 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 202/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.2094e-04 - mae: 0.0204 - val_loss: 0.0014 - val_mae: 0.0256\n",
      "Epoch 203/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.3981e-04 - mae: 0.0190 - val_loss: 0.0015 - val_mae: 0.0258\n",
      "Epoch 204/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.6811e-04 - mae: 0.0202 - val_loss: 0.0015 - val_mae: 0.0262\n",
      "Epoch 205/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 0.0012 - val_mae: 0.0241\n",
      "Epoch 206/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.1074e-04 - mae: 0.0209 - val_loss: 0.0015 - val_mae: 0.0278\n",
      "Epoch 207/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 0.0013 - val_mae: 0.0247\n",
      "Epoch 208/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 0.0012 - val_mae: 0.0244\n",
      "Epoch 209/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 0.0013 - val_mae: 0.0253\n",
      "Epoch 210/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 0.0015 - val_mae: 0.0272\n",
      "Epoch 211/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 212/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0017 - val_mae: 0.0305\n",
      "Epoch 213/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 214/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0014 - val_mae: 0.0273\n",
      "Epoch 215/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0254 - val_loss: 0.0016 - val_mae: 0.0273\n",
      "Epoch 216/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0016 - val_mae: 0.0280\n",
      "Epoch 217/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0016 - val_mae: 0.0275\n",
      "Epoch 218/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 0.0012 - val_mae: 0.0249\n",
      "Epoch 219/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0018 - val_mae: 0.0306\n",
      "Epoch 220/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "Epoch 221/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 222/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.6304e-04 - mae: 0.0225 - val_loss: 0.0016 - val_mae: 0.0295\n",
      "Epoch 223/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 0.0016 - val_mae: 0.0280\n",
      "Epoch 224/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 225/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 0.0016 - val_mae: 0.0289\n",
      "Epoch 226/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0015 - val_mae: 0.0285\n",
      "Epoch 227/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0254 - val_loss: 0.0018 - val_mae: 0.0302\n",
      "Epoch 228/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 0.0016 - val_mae: 0.0296\n",
      "Epoch 229/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0021 - val_mae: 0.0310\n",
      "Epoch 230/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 231/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 0.0016 - val_mae: 0.0285\n",
      "Epoch 232/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 233/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0016 - val_mae: 0.0303\n",
      "Epoch 234/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0016 - val_mae: 0.0295\n",
      "Epoch 235/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0016 - val_mae: 0.0287\n",
      "Epoch 236/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 237/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0016 - val_mae: 0.0275\n",
      "Epoch 238/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 239/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0016 - val_mae: 0.0281\n",
      "Epoch 240/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0017 - val_mae: 0.0297\n",
      "Epoch 241/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0017 - val_mae: 0.0292\n",
      "Epoch 242/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0013 - val_mae: 0.0261\n",
      "Epoch 243/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 244/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 0.0016 - val_mae: 0.0278\n",
      "Epoch 245/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 246/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 0.0019 - val_mae: 0.0319\n",
      "Epoch 247/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0306 - val_loss: 0.0036 - val_mae: 0.0418\n",
      "Epoch 248/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0021 - mae: 0.0332 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 249/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0319 - val_loss: 0.0020 - val_mae: 0.0329\n",
      "Epoch 250/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0019 - mae: 0.0315 - val_loss: 0.0026 - val_mae: 0.0367\n",
      "Epoch 251/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0018 - mae: 0.0307 - val_loss: 0.0017 - val_mae: 0.0311\n",
      "Epoch 252/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 253/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0015 - mae: 0.0282 - val_loss: 0.0022 - val_mae: 0.0325\n",
      "Epoch 254/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0021 - val_mae: 0.0325\n",
      "Epoch 255/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 0.0023 - val_mae: 0.0350\n",
      "Epoch 256/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 257/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0023 - val_mae: 0.0352\n",
      "Epoch 258/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 259/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 0.0020 - val_mae: 0.0320\n",
      "Epoch 260/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0022 - val_mae: 0.0330\n",
      "Epoch 261/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0019 - mae: 0.0313 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 262/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0019 - val_mae: 0.0337\n",
      "Epoch 263/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0019 - val_mae: 0.0313\n",
      "Epoch 264/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0015 - val_mae: 0.0284\n",
      "Epoch 265/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0023 - val_mae: 0.0324\n",
      "Epoch 266/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0018 - val_mae: 0.0307\n",
      "Epoch 267/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0017 - mae: 0.0306 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 268/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 269/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0016 - mae: 0.0305 - val_loss: 0.0019 - val_mae: 0.0334\n",
      "Epoch 270/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0015 - mae: 0.0286 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 271/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 0.0026 - val_mae: 0.0360\n",
      "Epoch 272/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0015 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 273/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0014 - val_mae: 0.0276\n",
      "Epoch 274/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0019 - val_mae: 0.0323\n",
      "Epoch 275/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 276/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 277/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0024 - val_mae: 0.0332\n",
      "Epoch 278/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0013 - mae: 0.0264 - val_loss: 0.0013 - val_mae: 0.0267\n",
      "Epoch 279/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0019 - val_mae: 0.0298\n",
      "Epoch 280/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 0.0056 - val_mae: 0.0412\n",
      "Epoch 281/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0018 - mae: 0.0276 - val_loss: 0.0032 - val_mae: 0.0401\n",
      "Epoch 282/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0022 - val_mae: 0.0351\n",
      "Epoch 283/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0319 - val_loss: 0.0028 - val_mae: 0.0400\n",
      "Epoch 284/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0031 - mae: 0.0388 - val_loss: 0.0025 - val_mae: 0.0369\n",
      "Epoch 285/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0048 - val_mae: 0.0422\n",
      "Epoch 286/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0026 - mae: 0.0356 - val_loss: 0.0044 - val_mae: 0.0382\n",
      "Epoch 287/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 0.0019 - val_mae: 0.0325\n",
      "Epoch 288/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0016 - mae: 0.0297 - val_loss: 0.0021 - val_mae: 0.0342\n",
      "Epoch 289/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0016 - mae: 0.0290 - val_loss: 0.0014 - val_mae: 0.0279\n",
      "Epoch 290/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0013 - mae: 0.0270 - val_loss: 0.0025 - val_mae: 0.0331\n",
      "Epoch 291/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0023 - val_mae: 0.0325\n",
      "Epoch 292/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 0.0018 - val_mae: 0.0289\n",
      "Epoch 293/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 294/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 0.0017 - val_mae: 0.0300\n",
      "Epoch 295/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 0.0013 - val_mae: 0.0266\n",
      "Epoch 296/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0019 - val_mae: 0.0316\n",
      "Epoch 297/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0021 - val_mae: 0.0300\n",
      "Epoch 298/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0014 - val_mae: 0.0256\n",
      "Epoch 299/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 300/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0268\n",
      "Epoch 301/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 302/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0012 - val_mae: 0.0259\n",
      "Epoch 303/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0017 - val_mae: 0.0281\n",
      "Epoch 304/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 305/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.7215e-04 - mae: 0.0230 - val_loss: 0.0018 - val_mae: 0.0298\n",
      "Epoch 306/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.2435e-04 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0242\n",
      "Epoch 307/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.4051e-04 - mae: 0.0207 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 308/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.8510e-04 - mae: 0.0224 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 309/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.3621e-04 - mae: 0.0221 - val_loss: 0.0017 - val_mae: 0.0287\n",
      "Epoch 310/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.9217e-04 - mae: 0.0218 - val_loss: 0.0016 - val_mae: 0.0291\n",
      "Epoch 311/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0012 - mae: 0.0261 - val_loss: 0.0016 - val_mae: 0.0280\n",
      "Epoch 312/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.0088e-04 - mae: 0.0221 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 313/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.8011e-04 - mae: 0.0226 - val_loss: 8.7454e-04 - val_mae: 0.0217\n",
      "Epoch 314/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8.1893e-04 - mae: 0.0207 - val_loss: 0.0012 - val_mae: 0.0243\n",
      "Epoch 315/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.1444e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 316/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.6567e-04 - mae: 0.0199 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 317/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.6948e-04 - mae: 0.0191 - val_loss: 0.0011 - val_mae: 0.0241\n",
      "Epoch 318/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.8269e-04 - mae: 0.0209 - val_loss: 0.0012 - val_mae: 0.0242\n",
      "Epoch 319/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.5078e-04 - mae: 0.0215 - val_loss: 9.2454e-04 - val_mae: 0.0231\n",
      "Epoch 320/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.6811e-04 - mae: 0.0222 - val_loss: 0.0015 - val_mae: 0.0273\n",
      "Epoch 321/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.2539e-04 - mae: 0.0214 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 322/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.9476e-04 - mae: 0.0223 - val_loss: 0.0016 - val_mae: 0.0269\n",
      "Epoch 323/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0223 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 324/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.7260e-04 - mae: 0.0228 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 325/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 0.0015 - val_mae: 0.0277\n",
      "Epoch 326/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 327/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 328/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8.7911e-04 - mae: 0.0217 - val_loss: 0.0012 - val_mae: 0.0241\n",
      "Epoch 329/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.3837e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 330/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 8.0391e-04 - mae: 0.0194 - val_loss: 0.0012 - val_mae: 0.0246\n",
      "Epoch 331/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.3134e-04 - mae: 0.0211 - val_loss: 9.3630e-04 - val_mae: 0.0216\n",
      "Epoch 332/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.2463e-04 - mae: 0.0198 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 333/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0016 - val_mae: 0.0269\n",
      "Epoch 334/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.6887e-04 - mae: 0.0219 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 335/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 0.0016 - val_mae: 0.0277\n",
      "Epoch 336/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0011 - val_mae: 0.0240\n",
      "Epoch 337/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.3827e-04 - mae: 0.0213 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 338/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.0344e-04 - mae: 0.0203 - val_loss: 0.0011 - val_mae: 0.0237\n",
      "Epoch 339/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.5146e-04 - mae: 0.0209 - val_loss: 0.0016 - val_mae: 0.0270\n",
      "Epoch 340/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.8369e-04 - mae: 0.0198 - val_loss: 9.0805e-04 - val_mae: 0.0211\n",
      "Epoch 341/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.0785e-04 - mae: 0.0205 - val_loss: 0.0013 - val_mae: 0.0266\n",
      "Epoch 342/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.5269e-04 - mae: 0.0212 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 343/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.1370e-04 - mae: 0.0194 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 344/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.6136e-04 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 345/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.7900e-04 - mae: 0.0202 - val_loss: 0.0014 - val_mae: 0.0266\n",
      "Epoch 346/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.7584e-04 - mae: 0.0216 - val_loss: 0.0013 - val_mae: 0.0248\n",
      "Epoch 347/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.0035e-04 - mae: 0.0204 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 348/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.7221e-04 - mae: 0.0215 - val_loss: 0.0012 - val_mae: 0.0239\n",
      "Epoch 349/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.3166e-04 - mae: 0.0199 - val_loss: 9.1746e-04 - val_mae: 0.0223\n",
      "Epoch 350/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.0690e-04 - mae: 0.0206 - val_loss: 0.0011 - val_mae: 0.0218\n",
      "Epoch 351/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.5193e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mae: 0.0221\n",
      "Epoch 352/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.1621e-04 - mae: 0.0205 - val_loss: 0.0012 - val_mae: 0.0238\n",
      "Epoch 353/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.4963e-04 - mae: 0.0210 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 354/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.9630e-04 - mae: 0.0216 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 355/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0012 - val_mae: 0.0224\n",
      "Epoch 356/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 0.0012 - val_mae: 0.0238\n",
      "Epoch 357/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 358/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 0.0014 - val_mae: 0.0254\n",
      "Epoch 359/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.4140e-04 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 360/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.3906e-04 - mae: 0.0216 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 361/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.2641e-04 - mae: 0.0205 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 362/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6188e-04 - mae: 0.0197 - val_loss: 0.0012 - val_mae: 0.0251\n",
      "Epoch 363/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1262e-04 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0245\n",
      "Epoch 364/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.3068e-04 - mae: 0.0196 - val_loss: 9.9577e-04 - val_mae: 0.0232\n",
      "Epoch 365/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.7357e-04 - mae: 0.0207 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 366/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.2075e-04 - mae: 0.0195 - val_loss: 0.0010 - val_mae: 0.0229\n",
      "Epoch 367/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.5598e-04 - mae: 0.0192 - val_loss: 9.9755e-04 - val_mae: 0.0216\n",
      "Epoch 368/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.2296e-04 - mae: 0.0178 - val_loss: 9.5159e-04 - val_mae: 0.0212\n",
      "Epoch 369/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.9601e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mae: 0.0242\n",
      "Epoch 370/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.1171e-04 - mae: 0.0197 - val_loss: 0.0010 - val_mae: 0.0232\n",
      "Epoch 371/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.0313e-04 - mae: 0.0199 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 372/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.2391e-04 - mae: 0.0206 - val_loss: 0.0012 - val_mae: 0.0240\n",
      "Epoch 373/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.0140e-04 - mae: 0.0202 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 374/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.0592e-04 - mae: 0.0218 - val_loss: 0.0015 - val_mae: 0.0269\n",
      "Epoch 375/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 8.3881e-04 - mae: 0.0213 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 376/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.0228e-04 - mae: 0.0222 - val_loss: 0.0021 - val_mae: 0.0332\n",
      "Epoch 377/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0267 - val_loss: 0.0018 - val_mae: 0.0309\n",
      "Epoch 378/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011 - mae: 0.0258 - val_loss: 0.0016 - val_mae: 0.0327\n",
      "Epoch 379/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0304 - val_loss: 0.0025 - val_mae: 0.0370\n",
      "Epoch 380/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0326 - val_loss: 0.0042 - val_mae: 0.0506\n",
      "Epoch 381/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0416 - val_loss: 0.0042 - val_mae: 0.0530\n",
      "Epoch 382/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0028 - mae: 0.0420 - val_loss: 0.0042 - val_mae: 0.0511\n",
      "Epoch 383/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0046 - val_mae: 0.0513\n",
      "Epoch 384/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0037 - val_mae: 0.0465\n",
      "Epoch 385/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0038 - mae: 0.0468 - val_loss: 0.0046 - val_mae: 0.0488\n",
      "Epoch 386/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0038 - mae: 0.0458 - val_loss: 0.0028 - val_mae: 0.0413\n",
      "Epoch 387/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0040 - mae: 0.0471 - val_loss: 0.0057 - val_mae: 0.0527\n",
      "Epoch 388/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0052 - mae: 0.0512 - val_loss: 0.0041 - val_mae: 0.0468\n",
      "Epoch 389/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0535 - val_loss: 0.0049 - val_mae: 0.0539\n",
      "Epoch 390/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0560 - val_loss: 0.0088 - val_mae: 0.0664\n",
      "Epoch 391/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0055 - mae: 0.0555 - val_loss: 0.0066 - val_mae: 0.0623\n",
      "Epoch 392/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0057 - mae: 0.0572 - val_loss: 0.0066 - val_mae: 0.0615\n",
      "Epoch 393/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0483\n",
      "Epoch 394/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0441 - val_loss: 0.0031 - val_mae: 0.0430\n",
      "Epoch 395/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0027 - mae: 0.0398 - val_loss: 0.0054 - val_mae: 0.0503\n",
      "Epoch 396/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0369 - val_loss: 0.0028 - val_mae: 0.0368\n",
      "Epoch 397/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0337 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 398/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0321 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 399/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0014 - mae: 0.0287 - val_loss: 0.0016 - val_mae: 0.0296\n",
      "Epoch 400/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 401/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 0.0020 - val_mae: 0.0309\n",
      "Epoch 402/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.8961e-04 - mae: 0.0227 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 403/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 0.0012 - val_mae: 0.0258\n",
      "Epoch 404/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.7949e-04 - mae: 0.0228 - val_loss: 0.0012 - val_mae: 0.0253\n",
      "Epoch 405/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.1537e-04 - mae: 0.0222 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 406/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.9227e-04 - mae: 0.0206 - val_loss: 0.0015 - val_mae: 0.0279\n",
      "Epoch 407/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.3320e-04 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0235\n",
      "Epoch 408/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 7.6750e-04 - mae: 0.0202 - val_loss: 0.0012 - val_mae: 0.0240\n",
      "Epoch 409/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.9186e-04 - mae: 0.0195 - val_loss: 0.0010 - val_mae: 0.0221\n",
      "Epoch 410/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.3804e-04 - mae: 0.0179 - val_loss: 7.6829e-04 - val_mae: 0.0206\n",
      "Epoch 411/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 6.0456e-04 - mae: 0.0178 - val_loss: 9.1723e-04 - val_mae: 0.0221\n",
      "Epoch 412/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8727e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mae: 0.0210\n",
      "Epoch 413/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.3811e-04 - mae: 0.0165 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 414/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.2101e-04 - mae: 0.0192 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 415/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.6292e-04 - mae: 0.0167 - val_loss: 9.7866e-04 - val_mae: 0.0222\n",
      "Epoch 416/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4283e-04 - mae: 0.0175 - val_loss: 0.0015 - val_mae: 0.0263\n",
      "Epoch 417/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.9004e-04 - mae: 0.0190 - val_loss: 0.0014 - val_mae: 0.0255\n",
      "Epoch 418/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.3216e-04 - mae: 0.0181 - val_loss: 7.9379e-04 - val_mae: 0.0201\n",
      "Epoch 419/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0265e-04 - mae: 0.0181 - val_loss: 9.6833e-04 - val_mae: 0.0225\n",
      "Epoch 420/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.5222e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 421/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.2171e-04 - mae: 0.0176 - val_loss: 8.6639e-04 - val_mae: 0.0202\n",
      "Epoch 422/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7977e-04 - mae: 0.0152 - val_loss: 0.0011 - val_mae: 0.0215\n",
      "Epoch 423/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.0328e-04 - mae: 0.0176 - val_loss: 8.0595e-04 - val_mae: 0.0197\n",
      "Epoch 424/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.0649e-04 - mae: 0.0168 - val_loss: 8.6270e-04 - val_mae: 0.0196\n",
      "Epoch 425/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.7743e-04 - mae: 0.0179 - val_loss: 0.0013 - val_mae: 0.0234\n",
      "Epoch 426/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.2133e-04 - mae: 0.0210 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 427/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.3564e-04 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 428/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 429/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0015 - val_mae: 0.0266\n",
      "Epoch 430/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 431/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 0.0024 - val_mae: 0.0338\n",
      "Epoch 432/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 433/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0245 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 434/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 435/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0252 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 436/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 9.7549e-04 - val_mae: 0.0230\n",
      "Epoch 437/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.4182e-04 - mae: 0.0213 - val_loss: 0.0025 - val_mae: 0.0336\n",
      "Epoch 438/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0015 - val_mae: 0.0296\n",
      "Epoch 439/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0021 - val_mae: 0.0324\n",
      "Epoch 440/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 441/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 0.0016 - val_mae: 0.0285\n",
      "Epoch 442/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0243 - val_loss: 0.0014 - val_mae: 0.0269\n",
      "Epoch 443/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0020 - val_mae: 0.0316\n",
      "Epoch 444/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 445/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0024 - val_mae: 0.0356\n",
      "Epoch 446/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 447/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 448/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0240\n",
      "Epoch 449/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 0.0021 - val_mae: 0.0324\n",
      "Epoch 450/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 0.0013 - val_mae: 0.0261\n",
      "Epoch 451/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 0.0014 - val_mae: 0.0262\n",
      "Epoch 452/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.0773e-04 - mae: 0.0216 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "Epoch 453/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.6999e-04 - mae: 0.0225 - val_loss: 0.0014 - val_mae: 0.0260\n",
      "Epoch 454/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.6828e-04 - mae: 0.0202 - val_loss: 8.7525e-04 - val_mae: 0.0225\n",
      "Epoch 455/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.2074e-04 - mae: 0.0198 - val_loss: 0.0016 - val_mae: 0.0257\n",
      "Epoch 456/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7398e-04 - mae: 0.0192 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 457/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.2978e-04 - mae: 0.0197 - val_loss: 0.0014 - val_mae: 0.0263\n",
      "Epoch 458/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.2990e-04 - mae: 0.0216 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 459/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4035e-04 - mae: 0.0202 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 460/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.6411e-04 - mae: 0.0204 - val_loss: 9.9547e-04 - val_mae: 0.0210\n",
      "Epoch 461/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.5038e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 462/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.1848e-04 - mae: 0.0167 - val_loss: 7.5304e-04 - val_mae: 0.0193\n",
      "Epoch 463/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.6928e-04 - mae: 0.0153 - val_loss: 7.0974e-04 - val_mae: 0.0176\n",
      "Epoch 464/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.0757e-04 - mae: 0.0145 - val_loss: 7.8834e-04 - val_mae: 0.0200\n",
      "Epoch 465/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.8477e-04 - mae: 0.0153 - val_loss: 8.9733e-04 - val_mae: 0.0200\n",
      "Epoch 466/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.2412e-04 - mae: 0.0155 - val_loss: 8.9421e-04 - val_mae: 0.0201\n",
      "Epoch 467/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0460e-04 - mae: 0.0168 - val_loss: 7.5157e-04 - val_mae: 0.0200\n",
      "Epoch 468/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.6852e-04 - mae: 0.0174 - val_loss: 0.0013 - val_mae: 0.0251\n",
      "Epoch 469/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 8.0845e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 470/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.7707e-04 - mae: 0.0223 - val_loss: 0.0013 - val_mae: 0.0263\n",
      "Epoch 471/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 472/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0258 - val_loss: 9.6510e-04 - val_mae: 0.0233\n",
      "Epoch 473/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.7760e-04 - mae: 0.0210 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 474/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0237 - val_loss: 0.0015 - val_mae: 0.0269\n",
      "Epoch 475/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 9.9510e-04 - val_mae: 0.0237\n",
      "Epoch 476/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.8233e-04 - mae: 0.0210 - val_loss: 8.7623e-04 - val_mae: 0.0207\n",
      "Epoch 477/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.8469e-04 - mae: 0.0188 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 478/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.6972e-04 - mae: 0.0198 - val_loss: 0.0013 - val_mae: 0.0256\n",
      "Epoch 479/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8.3550e-04 - mae: 0.0212 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 480/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.4610e-04 - mae: 0.0203 - val_loss: 9.0159e-04 - val_mae: 0.0208\n",
      "Epoch 481/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.3301e-04 - mae: 0.0190 - val_loss: 0.0017 - val_mae: 0.0285\n",
      "Epoch 482/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0015 - val_mae: 0.0278\n",
      "Epoch 483/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 0.0023 - val_mae: 0.0319\n",
      "Epoch 484/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0015 - val_mae: 0.0272\n",
      "Epoch 485/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0021 - val_mae: 0.0320\n",
      "Epoch 486/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 487/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 488/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0305 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 489/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0014 - mae: 0.0274 - val_loss: 0.0020 - val_mae: 0.0318\n",
      "Epoch 490/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0017 - mae: 0.0303 - val_loss: 0.0019 - val_mae: 0.0312\n",
      "Epoch 491/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0302 - val_loss: 0.0027 - val_mae: 0.0372\n",
      "Epoch 492/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0033 - val_mae: 0.0395\n",
      "Epoch 493/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0025 - mae: 0.0350 - val_loss: 0.0026 - val_mae: 0.0394\n",
      "Epoch 494/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0026 - mae: 0.0377 - val_loss: 0.0044 - val_mae: 0.0444\n",
      "Epoch 495/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0049 - mae: 0.0472 - val_loss: 0.0030 - val_mae: 0.0378\n",
      "Epoch 496/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0409 - val_loss: 0.0052 - val_mae: 0.0477\n",
      "Epoch 497/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0066 - mae: 0.0505 - val_loss: 0.0036 - val_mae: 0.0426\n",
      "Epoch 498/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0497 - val_loss: 0.0046 - val_mae: 0.0460\n",
      "Epoch 499/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0515 - val_loss: 0.0055 - val_mae: 0.0519\n",
      "Epoch 500/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mae: 0.0548 - val_loss: 0.0034 - val_mae: 0.0448\n",
      "Epoch 501/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0037 - mae: 0.0448 - val_loss: 0.0032 - val_mae: 0.0395\n",
      "Epoch 502/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0383 - val_loss: 0.0054 - val_mae: 0.0536\n",
      "Epoch 503/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0066 - val_mae: 0.0595\n",
      "Epoch 504/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0055 - mae: 0.0536 - val_loss: 0.0068 - val_mae: 0.0632\n",
      "Epoch 505/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0051 - mae: 0.0535 - val_loss: 0.0046 - val_mae: 0.0515\n",
      "Epoch 506/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0041 - val_mae: 0.0473\n",
      "Epoch 507/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0042 - mae: 0.0467 - val_loss: 0.0047 - val_mae: 0.0487\n",
      "Epoch 508/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0449 - val_loss: 0.0035 - val_mae: 0.0423\n",
      "Epoch 509/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0034 - val_mae: 0.0446\n",
      "Epoch 510/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0029 - mae: 0.0401 - val_loss: 0.0025 - val_mae: 0.0379\n",
      "Epoch 511/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0361 - val_loss: 0.0041 - val_mae: 0.0468\n",
      "Epoch 512/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0026 - val_mae: 0.0381\n",
      "Epoch 513/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0346 - val_loss: 0.0025 - val_mae: 0.0372\n",
      "Epoch 514/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0360 - val_loss: 0.0030 - val_mae: 0.0376\n",
      "Epoch 515/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0020 - mae: 0.0322 - val_loss: 0.0025 - val_mae: 0.0352\n",
      "Epoch 516/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0301 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 517/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0280 - val_loss: 0.0023 - val_mae: 0.0340\n",
      "Epoch 518/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 519/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0293 - val_loss: 0.0015 - val_mae: 0.0281\n",
      "Epoch 520/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 0.0022 - val_mae: 0.0328\n",
      "Epoch 521/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0280 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 522/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0245 - val_loss: 0.0018 - val_mae: 0.0303\n",
      "Epoch 523/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 9.4433e-04 - val_mae: 0.0233\n",
      "Epoch 524/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.4346e-04 - mae: 0.0205 - val_loss: 0.0011 - val_mae: 0.0231\n",
      "Epoch 525/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.8548e-04 - mae: 0.0201 - val_loss: 0.0010 - val_mae: 0.0227\n",
      "Epoch 526/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.4211e-04 - mae: 0.0192 - val_loss: 0.0012 - val_mae: 0.0246\n",
      "Epoch 527/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 8.2249e-04 - val_mae: 0.0214\n",
      "Epoch 528/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.5776e-04 - mae: 0.0221 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 529/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 8.2107e-04 - mae: 0.0209 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 530/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.8586e-04 - mae: 0.0221 - val_loss: 0.0014 - val_mae: 0.0261\n",
      "Epoch 531/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.2879e-04 - mae: 0.0218 - val_loss: 0.0012 - val_mae: 0.0250\n",
      "Epoch 532/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.0012 - val_mae: 0.0232\n",
      "Epoch 533/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.4831e-04 - mae: 0.0200 - val_loss: 9.8637e-04 - val_mae: 0.0212\n",
      "Epoch 534/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.5987e-04 - mae: 0.0191 - val_loss: 8.3404e-04 - val_mae: 0.0200\n",
      "Epoch 535/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.7391e-04 - mae: 0.0177 - val_loss: 8.6707e-04 - val_mae: 0.0223\n",
      "Epoch 536/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.0801e-04 - mae: 0.0192 - val_loss: 7.6646e-04 - val_mae: 0.0203\n",
      "Epoch 537/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.6046e-04 - mae: 0.0181 - val_loss: 7.5837e-04 - val_mae: 0.0190\n",
      "Epoch 538/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.8278e-04 - mae: 0.0180 - val_loss: 0.0013 - val_mae: 0.0229\n",
      "Epoch 539/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.6585e-04 - mae: 0.0179 - val_loss: 9.2164e-04 - val_mae: 0.0209\n",
      "Epoch 540/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.4329e-04 - mae: 0.0170 - val_loss: 7.9497e-04 - val_mae: 0.0200\n",
      "Epoch 541/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0204e-04 - mae: 0.0185 - val_loss: 7.0755e-04 - val_mae: 0.0196\n",
      "Epoch 542/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.7431e-04 - mae: 0.0169 - val_loss: 6.7950e-04 - val_mae: 0.0184\n",
      "Epoch 543/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.4494e-04 - mae: 0.0166 - val_loss: 7.7835e-04 - val_mae: 0.0202\n",
      "Epoch 544/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6932e-04 - mae: 0.0169 - val_loss: 8.2862e-04 - val_mae: 0.0197\n",
      "Epoch 545/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 5.8940e-04 - mae: 0.0170 - val_loss: 6.6593e-04 - val_mae: 0.0185\n",
      "Epoch 546/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 8.5631e-04 - mae: 0.0187 - val_loss: 8.8335e-04 - val_mae: 0.0199\n",
      "Epoch 547/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.7437e-04 - mae: 0.0192 - val_loss: 9.4422e-04 - val_mae: 0.0210\n",
      "Epoch 548/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.4047e-04 - mae: 0.0189 - val_loss: 8.1744e-04 - val_mae: 0.0205\n",
      "Epoch 549/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 9.9305e-04 - val_mae: 0.0214\n",
      "Epoch 550/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.7894e-04 - mae: 0.0191 - val_loss: 9.2819e-04 - val_mae: 0.0212\n",
      "Epoch 551/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.1594e-04 - mae: 0.0188 - val_loss: 6.3243e-04 - val_mae: 0.0191\n",
      "Epoch 552/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0514e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 553/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.0989e-04 - mae: 0.0195 - val_loss: 8.2756e-04 - val_mae: 0.0202\n",
      "Epoch 554/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.1747e-04 - mae: 0.0203 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 555/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.8681e-04 - mae: 0.0197 - val_loss: 8.5717e-04 - val_mae: 0.0208\n",
      "Epoch 556/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.4884e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 557/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.8875e-04 - mae: 0.0218 - val_loss: 8.9211e-04 - val_mae: 0.0215\n",
      "Epoch 558/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.4383e-04 - mae: 0.0212 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 559/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 560/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 0.0014 - val_mae: 0.0270\n",
      "Epoch 561/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.7140e-04 - mae: 0.0218 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 562/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.6824e-04 - mae: 0.0237 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 563/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.1453e-04 - mae: 0.0222 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 564/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.3176e-04 - mae: 0.0238 - val_loss: 9.1959e-04 - val_mae: 0.0231\n",
      "Epoch 565/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.0609e-04 - mae: 0.0211 - val_loss: 0.0010 - val_mae: 0.0245\n",
      "Epoch 566/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.3611e-04 - mae: 0.0210 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 567/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 9.0384e-04 - mae: 0.0212 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 568/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.5377e-04 - mae: 0.0222 - val_loss: 0.0014 - val_mae: 0.0274\n",
      "Epoch 569/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 0.0012 - val_mae: 0.0270\n",
      "Epoch 570/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.9915e-04 - mae: 0.0238 - val_loss: 0.0016 - val_mae: 0.0303\n",
      "Epoch 571/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0012 - mae: 0.0260 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 572/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0012 - mae: 0.0265 - val_loss: 0.0019 - val_mae: 0.0308\n",
      "Epoch 573/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0011 - mae: 0.0246 - val_loss: 0.0020 - val_mae: 0.0313\n",
      "Epoch 574/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0017 - val_mae: 0.0287\n",
      "Epoch 575/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.1144e-04 - mae: 0.0213 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 576/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.1171e-04 - mae: 0.0185 - val_loss: 8.0797e-04 - val_mae: 0.0210\n",
      "Epoch 577/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8988e-04 - mae: 0.0177 - val_loss: 0.0010 - val_mae: 0.0209\n",
      "Epoch 578/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.6831e-04 - mae: 0.0170 - val_loss: 8.2588e-04 - val_mae: 0.0197\n",
      "Epoch 579/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 5.6296e-04 - mae: 0.0170 - val_loss: 5.5514e-04 - val_mae: 0.0171\n",
      "Epoch 580/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.1329e-04 - mae: 0.0162 - val_loss: 9.4460e-04 - val_mae: 0.0210\n",
      "Epoch 581/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1774e-04 - mae: 0.0167 - val_loss: 7.3245e-04 - val_mae: 0.0198\n",
      "Epoch 582/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.5993e-04 - mae: 0.0172 - val_loss: 8.2275e-04 - val_mae: 0.0216\n",
      "Epoch 583/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.7550e-04 - mae: 0.0181 - val_loss: 0.0012 - val_mae: 0.0236\n",
      "Epoch 584/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.7907e-04 - mae: 0.0177 - val_loss: 8.0998e-04 - val_mae: 0.0214\n",
      "Epoch 585/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.3795e-04 - mae: 0.0186 - val_loss: 0.0012 - val_mae: 0.0241\n",
      "Epoch 586/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.8255e-04 - mae: 0.0190 - val_loss: 9.6804e-04 - val_mae: 0.0223\n",
      "Epoch 587/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.5401e-04 - mae: 0.0184 - val_loss: 6.7495e-04 - val_mae: 0.0193\n",
      "Epoch 588/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.9378e-04 - mae: 0.0178 - val_loss: 7.4364e-04 - val_mae: 0.0193\n",
      "Epoch 589/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.8807e-04 - mae: 0.0175 - val_loss: 6.3427e-04 - val_mae: 0.0170\n",
      "Epoch 590/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.9128e-04 - mae: 0.0141 - val_loss: 6.7092e-04 - val_mae: 0.0184\n",
      "Epoch 591/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.8284e-04 - mae: 0.0158 - val_loss: 8.1596e-04 - val_mae: 0.0193\n",
      "Epoch 592/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.9933e-04 - mae: 0.0179 - val_loss: 6.5191e-04 - val_mae: 0.0183\n",
      "Epoch 593/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4773e-04 - mae: 0.0163 - val_loss: 6.6493e-04 - val_mae: 0.0168\n",
      "Epoch 594/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.1010e-04 - mae: 0.0140 - val_loss: 9.3851e-04 - val_mae: 0.0192\n",
      "Epoch 595/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 4.5410e-04 - mae: 0.0151 - val_loss: 6.1526e-04 - val_mae: 0.0171\n",
      "Epoch 596/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.5154e-04 - mae: 0.0149 - val_loss: 7.4296e-04 - val_mae: 0.0180\n",
      "Epoch 597/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.0203e-04 - mae: 0.0143 - val_loss: 6.3974e-04 - val_mae: 0.0180\n",
      "Epoch 598/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7341e-04 - mae: 0.0136 - val_loss: 5.7959e-04 - val_mae: 0.0177\n",
      "Epoch 599/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.8927e-04 - mae: 0.0144 - val_loss: 8.9464e-04 - val_mae: 0.0193\n",
      "Epoch 600/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7894e-04 - mae: 0.0141 - val_loss: 6.6378e-04 - val_mae: 0.0189\n",
      "Epoch 601/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 5.6624e-04 - mae: 0.0179 - val_loss: 6.7947e-04 - val_mae: 0.0198\n",
      "Epoch 602/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.0397e-04 - mae: 0.0187 - val_loss: 7.5602e-04 - val_mae: 0.0200\n",
      "Epoch 603/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.7332e-04 - mae: 0.0177 - val_loss: 6.9013e-04 - val_mae: 0.0181\n",
      "Epoch 604/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.6277e-04 - mae: 0.0158 - val_loss: 9.6078e-04 - val_mae: 0.0204\n",
      "Epoch 605/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0127e-04 - mae: 0.0157 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 606/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.8211e-04 - mae: 0.0181 - val_loss: 6.3571e-04 - val_mae: 0.0177\n",
      "Epoch 607/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.2579e-04 - mae: 0.0176 - val_loss: 8.4766e-04 - val_mae: 0.0204\n",
      "Epoch 608/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.0975e-04 - mae: 0.0183 - val_loss: 8.0825e-04 - val_mae: 0.0206\n",
      "Epoch 609/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.4568e-04 - mae: 0.0185 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 610/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.0431e-04 - mae: 0.0188 - val_loss: 9.5023e-04 - val_mae: 0.0213\n",
      "Epoch 611/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.5234e-04 - mae: 0.0199 - val_loss: 0.0014 - val_mae: 0.0262\n",
      "Epoch 612/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 0.0013 - val_mae: 0.0273\n",
      "Epoch 613/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0017 - val_mae: 0.0290\n",
      "Epoch 614/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 615/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 616/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.8775e-04 - mae: 0.0235 - val_loss: 0.0014 - val_mae: 0.0275\n",
      "Epoch 617/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.0842e-04 - mae: 0.0215 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 618/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0274 - val_loss: 0.0021 - val_mae: 0.0362\n",
      "Epoch 619/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0293 - val_loss: 0.0029 - val_mae: 0.0442\n",
      "Epoch 620/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0029 - val_mae: 0.0405\n",
      "Epoch 621/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0308 - val_loss: 0.0023 - val_mae: 0.0384\n",
      "Epoch 622/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0333 - val_loss: 0.0020 - val_mae: 0.0365\n",
      "Epoch 623/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0330 - val_loss: 0.0026 - val_mae: 0.0400\n",
      "Epoch 624/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0388\n",
      "Epoch 625/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0323 - val_loss: 0.0023 - val_mae: 0.0358\n",
      "Epoch 626/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0015 - mae: 0.0303 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 627/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0018 - mae: 0.0327 - val_loss: 0.0027 - val_mae: 0.0387\n",
      "Epoch 628/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0311 - val_loss: 0.0033 - val_mae: 0.0430\n",
      "Epoch 629/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0032 - mae: 0.0407 - val_loss: 0.0052 - val_mae: 0.0545\n",
      "Epoch 630/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0503 - val_loss: 0.0044 - val_mae: 0.0501\n",
      "Epoch 631/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - mae: 0.0498 - val_loss: 0.0057 - val_mae: 0.0561\n",
      "Epoch 632/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - mae: 0.0490 - val_loss: 0.0074 - val_mae: 0.0601\n",
      "Epoch 633/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0052 - mae: 0.0524 - val_loss: 0.0093 - val_mae: 0.0715\n",
      "Epoch 634/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0061 - mae: 0.0566 - val_loss: 0.0054 - val_mae: 0.0590\n",
      "Epoch 635/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0050 - mae: 0.0542 - val_loss: 0.0082 - val_mae: 0.0636\n",
      "Epoch 636/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - mae: 0.0537 - val_loss: 0.0054 - val_mae: 0.0544\n",
      "Epoch 637/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0051 - mae: 0.0534 - val_loss: 0.0037 - val_mae: 0.0438\n",
      "Epoch 638/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0055 - mae: 0.0516 - val_loss: 0.0040 - val_mae: 0.0457\n",
      "Epoch 639/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0533 - val_loss: 0.0028 - val_mae: 0.0403\n",
      "Epoch 640/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0406 - val_loss: 0.0042 - val_mae: 0.0471\n",
      "Epoch 641/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0034 - mae: 0.0448 - val_loss: 0.0043 - val_mae: 0.0478\n",
      "Epoch 642/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0041 - mae: 0.0454 - val_loss: 0.0044 - val_mae: 0.0499\n",
      "Epoch 643/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.0024 - val_mae: 0.0380\n",
      "Epoch 644/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0023 - mae: 0.0367 - val_loss: 0.0036 - val_mae: 0.0443\n",
      "Epoch 645/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0390 - val_loss: 0.0022 - val_mae: 0.0361\n",
      "Epoch 646/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0023 - mae: 0.0353 - val_loss: 0.0043 - val_mae: 0.0450\n",
      "Epoch 647/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0025 - mae: 0.0386 - val_loss: 0.0030 - val_mae: 0.0410\n",
      "Epoch 648/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0391 - val_loss: 0.0030 - val_mae: 0.0415\n",
      "Epoch 649/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0024 - mae: 0.0372 - val_loss: 0.0033 - val_mae: 0.0427\n",
      "Epoch 650/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0036 - val_mae: 0.0460\n",
      "Epoch 651/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0028 - mae: 0.0392 - val_loss: 0.0043 - val_mae: 0.0458\n",
      "Epoch 652/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0426 - val_loss: 0.0031 - val_mae: 0.0430\n",
      "Epoch 653/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0024 - mae: 0.0376 - val_loss: 0.0043 - val_mae: 0.0481\n",
      "Epoch 654/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 655/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0373 - val_loss: 0.0026 - val_mae: 0.0388\n",
      "Epoch 656/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - mae: 0.0371 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 657/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0022 - mae: 0.0352 - val_loss: 0.0028 - val_mae: 0.0393\n",
      "Epoch 658/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0023 - mae: 0.0363 - val_loss: 0.0025 - val_mae: 0.0360\n",
      "Epoch 659/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0029 - val_mae: 0.0420\n",
      "Epoch 660/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0020 - mae: 0.0342 - val_loss: 0.0027 - val_mae: 0.0391\n",
      "Epoch 661/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0025 - mae: 0.0374 - val_loss: 0.0034 - val_mae: 0.0434\n",
      "Epoch 662/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0035 - val_mae: 0.0423\n",
      "Epoch 663/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - mae: 0.0446 - val_loss: 0.0032 - val_mae: 0.0398\n",
      "Epoch 664/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0035 - mae: 0.0427 - val_loss: 0.0030 - val_mae: 0.0423\n",
      "Epoch 665/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0423 - val_loss: 0.0031 - val_mae: 0.0416\n",
      "Epoch 666/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0032 - mae: 0.0421 - val_loss: 0.0034 - val_mae: 0.0437\n",
      "Epoch 667/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0037 - mae: 0.0451 - val_loss: 0.0030 - val_mae: 0.0395\n",
      "Epoch 668/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0390 - val_loss: 0.0024 - val_mae: 0.0381\n",
      "Epoch 669/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0377 - val_loss: 0.0028 - val_mae: 0.0396\n",
      "Epoch 670/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0023 - mae: 0.0353 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 671/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0024 - mae: 0.0344 - val_loss: 0.0037 - val_mae: 0.0428\n",
      "Epoch 672/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0024 - mae: 0.0357 - val_loss: 0.0030 - val_mae: 0.0392\n",
      "Epoch 673/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0030 - mae: 0.0388 - val_loss: 0.0024 - val_mae: 0.0367\n",
      "Epoch 674/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0026 - val_mae: 0.0387\n",
      "Epoch 675/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0022 - mae: 0.0351 - val_loss: 0.0021 - val_mae: 0.0356\n",
      "Epoch 676/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0023 - mae: 0.0356 - val_loss: 0.0031 - val_mae: 0.0380\n",
      "Epoch 677/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0025 - mae: 0.0346 - val_loss: 0.0040 - val_mae: 0.0421\n",
      "Epoch 678/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0387 - val_loss: 0.0028 - val_mae: 0.0399\n",
      "Epoch 679/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0025 - mae: 0.0380 - val_loss: 0.0025 - val_mae: 0.0376\n",
      "Epoch 679: early stopping\n",
      "Restoring model weights from the end of the best epoch: 579.\n"
     ]
    }
   ],
   "source": [
    "# Definizione modello DNN\n",
    "def build_model(input_shape: tuple, output_shape: tuple):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation = \"relu\", input_shape=input_shape),\n",
    "        Dropout(0.0),\n",
    "        layers.Dense(output_shape, 'linear')\n",
    "    ])\n",
    "    model.compile(\n",
    "    optimizer=optimizers.AdamW(learning_rate=0.01, weight_decay=0.2072),\n",
    "    loss= 'mse',\n",
    "    metrics=['mae'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',      # metrica da monitorare, es. val_loss o val_mae\n",
    "    patience=100,             # numero di epoche senza miglioramento prima di fermare\n",
    "    restore_best_weights=True,  # ripristina i pesi migliori trovati\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Training del modello\n",
    "model = build_model((X_test.shape[1],), y_test.shape[1])\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    callbacks = [early_stop],\n",
    "    validation_split = 0.2,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "'''print(\"y_train min/max:\", y_train_np.min(), y_train_np.max())\n",
    "print(\"y_pred min/max (scaled):\", y_pred.min(), y_pred.max())\n",
    "y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
    "print(\"y_pred_rescaled min/max:\", y_pred_rescaled.min(), y_pred_rescaled.max())'''\n",
    "\n",
    "if not os.path.exists(os.path.join(exp_dir, \"model\")):\n",
    "    os.makedirs(os.path.join(exp_dir, \"model\"))\n",
    "    model.save(os.path.join(exp_dir, \"model\", f\"{sensor_name}_model.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b6149cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{exp_dir}/model/NO2_{sensor_name}_model.keras') if os.path.exists(f'{exp_dir}/model/NO2_{sensor_name}_model.keras') else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105abd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai losses da tutti i folds\n",
    "train_losses = history.history['loss']\n",
    "val_losses   = history.history['val_loss']\n",
    "\n",
    "train_losses = train_losses\n",
    "val_losses = val_losses\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "\n",
    "# Training loss\n",
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "# Validation loss\n",
    "plt.plot(val_losses, color='red', label='Validation Loss')\n",
    "\n",
    "\n",
    "# Dettagli grafico\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.savefig(f'{exp_dir}/loss_plot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1f8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_n_series(y_pred, y_test, n_series=10, title=\"Confronto Serie Predette vs Reali\"):\n",
    "    \"\"\"\n",
    "    Plotta le prime n_series serie reali e predette per un confronto diretto.\n",
    "\n",
    "    Args:\n",
    "        y_pred (np.ndarray): Predizioni del modello (shape: num_samples x seq_len).\n",
    "        y_test (np.ndarray): Serie reali (shape: num_samples x seq_len).\n",
    "        n_series (int): Numero di serie da plottare.\n",
    "        title (str): Titolo del grafico.\n",
    "    \"\"\"\n",
    "\n",
    "    # Limitiamo a n_series per evitare problemi\n",
    "    n = min(n_series, y_pred.shape[0], y_test.shape[0])\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.plot(\n",
    "            y_test[i], \n",
    "            linewidth=1.8, \n",
    "            alpha=0.5, \n",
    "            label=f\"Reale {i+1}\" if i == 0 else \"\",\n",
    "            color = 'blue'\n",
    "        )\n",
    "        plt.plot(\n",
    "            y_pred[i], \n",
    "            linewidth=1.2, \n",
    "            linestyle=\"--\", \n",
    "            alpha=0.9, \n",
    "            label=f\"Predetto {i+1}\" if i == 0 else \"\",\n",
    "            color = 'orange'\n",
    "        )\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Time Step\", fontsize=12)\n",
    "    plt.ylabel(\"Valore\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ddfb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_diagnosis_gradient(y_pred, y_test, save_path: str,  tolerance:float =0.05, max_samples_heatmap=50, scatter_sample_ratio=0.5, tol_auto = True):\n",
    "    \"\"\"\n",
    "    Dashboard diagnostica con tolleranza AUTO-ADATTIVA alla scala dei dati.\n",
    "    \n",
    "    Args:\n",
    "        tolerance (float): \n",
    "            - Se None: La tolleranza viene calcolata automaticamente come il 5% del range dei dati (Max-Min).\n",
    "            - Se float: Valore assoluto (es. 0.5).\n",
    "        tol_auto (bool): Se True, usa la tolleranza automatica basata sul range dei dati, altrimenti usa il valore manuale fornito \n",
    "        col parametro tolerance.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test_flat = y_test.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # AUTOMAZIONE TOLLERANZA\n",
    "    # ---------------------------------------------------------\n",
    "    if tol_auto:\n",
    "        data_range = y_test_flat.max() - y_test_flat.min()\n",
    "        # Impostiamo la tolleranza al 5% del range totale (regolabile)\n",
    "        tolerance = data_range * tolerance \n",
    "        tol_label = f\"Auto (5% Range: ±{tolerance:.2f})\"\n",
    "    else:\n",
    "        tol_label = f\"Manuale (±{tolerance})\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(22, 8))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. HEATMAP (SX)\n",
    "    # -----------------------------\n",
    "    errors = np.abs(y_test - y_pred)\n",
    "    errors_subset = errors[:max_samples_heatmap]\n",
    "    \n",
    "    # Adattiamo anche la scala colori della heatmap alla tolleranza\n",
    "    # Tutto ciò che è oltre 3 volte la tolleranza è \"errore massimo\" visivo\n",
    "    sns.heatmap(errors_subset, cmap=\"plasma\", ax=axes[0], \n",
    "                vmax=tolerance * 3,\n",
    "                cbar_kws={'label': 'Errore Assoluto'})\n",
    "    \n",
    "    axes[0].set_title(f\"Heatmap Errori (Primi {max_samples_heatmap} campioni)\", fontsize=16)\n",
    "    axes[0].set_xlabel(\"Time Step\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Indice Campione\", fontsize=12)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. SCATTER CON SFONDO GRADIENTE (DX)\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Campionamento dati\n",
    "    if scatter_sample_ratio < 1.0:\n",
    "        mask = np.random.rand(len(y_test_flat)) < scatter_sample_ratio\n",
    "        sample_test = y_test_flat[mask]\n",
    "        sample_pred = y_pred_flat[mask]\n",
    "    else:\n",
    "        sample_test = y_test_flat\n",
    "        sample_pred = y_pred_flat\n",
    "\n",
    "    # Calcolo limiti grafico\n",
    "    min_val = min(y_test_flat.min(), y_pred_flat.min())\n",
    "    max_val = max(y_test_flat.max(), y_pred_flat.max())\n",
    "    padding = (max_val - min_val) * 0.05\n",
    "    plot_min = min_val - padding\n",
    "    plot_max = max_val + padding\n",
    "\n",
    "    # --- SFONDO GRADIENTE ---\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.linspace(plot_min, plot_max, 200),\n",
    "        np.linspace(plot_min, plot_max, 200)\n",
    "    )\n",
    "    grid_z = np.abs(grid_y - grid_x)\n",
    "\n",
    "    im = axes[1].imshow(\n",
    "        grid_z, \n",
    "        extent=(plot_min, plot_max, plot_min, plot_max), \n",
    "        origin='lower', \n",
    "        cmap='RdYlGn_r', \n",
    "        alpha=0.4, \n",
    "        vmax=tolerance * 4, # Il rosso satura a 4x della tolleranza\n",
    "        aspect='auto'\n",
    "    )\n",
    "\n",
    "    # --- PUNTI BLU ---\n",
    "    axes[1].scatter(\n",
    "        sample_test, \n",
    "        sample_pred, \n",
    "        alpha=0.6, \n",
    "        s=15, \n",
    "        color='royalblue', \n",
    "        edgecolors='white', \n",
    "        linewidth=0.3,\n",
    "        label='Campioni'\n",
    "    )\n",
    "\n",
    "    axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n",
    "\n",
    "    # Metriche\n",
    "    within_tol = np.mean(np.abs(y_test_flat - y_pred_flat) <= tolerance) * 100\n",
    "\n",
    "    axes[1].set_title(\n",
    "        f\"Bontà delle previsioni con {tol_label}\\nValori nel range di Tolleranza: {within_tol:.1f}%\", \n",
    "        fontsize=16\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Valore Reale\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Valore Predetto\", fontsize=12)\n",
    "    axes[1].set_xlim(plot_min, plot_max)\n",
    "    axes[1].set_ylim(plot_min, plot_max)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=axes[1], pad=0.02)\n",
    "    cbar.set_label('Gravità Errore (Distanza da diagonale)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{exp_dir}/{save_path}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00d6ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/vnvjtlb516n5mswtv7rf58b80000gn/T/ipykernel_1850/2011710758.py:96: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k--\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)\n",
    "y_test_np = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "plot_diagnosis_gradient(y_pred, y_test_np, save_path='pred_quality', max_samples_heatmap=10, scatter_sample_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ca8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo 55 plot in: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/TEST\n",
      "Plot salvati correttamente.\n"
     ]
    }
   ],
   "source": [
    "save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/TEST', prefix=\"pred_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5d0ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.0814\n",
      "Test RMSE: 0.1219\n",
      "Test MAPE: 0.68%\n",
      "Test R2: 0.9994\n",
      "Valore medio del test set: 13.7463\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/evaluation_log.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_and_log(y_true, y_pred, log_path=\"log.json\"):\n",
    "    # --- Metriche ---\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput=\"uniform_average\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"uniform_average\"))\n",
    "\n",
    "    mask = y_true != 0\n",
    "    mape = float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0)\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred, multioutput=\"uniform_average\")\n",
    "\n",
    "    # Valore medio del test set\n",
    "    v_mean = float(np.mean(y_true))\n",
    "\n",
    "    # --- Stampa ---\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAPE: {mape:.2f}%\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Valore medio del test set: {v_mean:.4f}\")\n",
    "\n",
    "    # --- Salvataggio log ---\n",
    "    log_data = {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2,\n",
    "        \"test_mean_value\": v_mean\n",
    "    }\n",
    "\n",
    "    with open(log_path, \"w\") as f:\n",
    "        json.dump(log_data, f, indent=4)\n",
    "\n",
    "    print(f\"\\nLog salvato in: {log_path}\")\n",
    "evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/evaluation_log.json\")\n",
    "# Impostazioni pandas per visualizzare tutti i dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031eff0",
   "metadata": {},
   "source": [
    "# globale e federato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd226e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed = tf.keras.models.load_model('/Users/lapotinacci/thesis/Federated_Sys/app/custom/models/fed_model_Arpat.keras')\n",
    "\n",
    "model  = [fed]\n",
    "model_name = [\"federated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8f66133",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = f'{exp_dir}/model/{sensor_name}_fed_model.keras'\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27698951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "--- federated ---\n",
      "Test MAE: 3.3171\n",
      "Test RMSE: 4.8845\n",
      "Test MAPE: 26.00%\n",
      "Test R2: 0.2644\n",
      "Valore medio del test set: 13.7463\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/federated_evaluation_log.json\n",
      "Salvo 55 plot in: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/federated/TEST\n",
      "Plot salvati correttamente.\n",
      "\n",
      "\n",
      "Epoch 1/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - loss: 0.6518 - mae: 0.6172 - mse: 0.6518\n",
      "Epoch 1: val_loss improved from None to 0.55543, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.6280 - mae: 0.6063 - mse: 0.6280 - val_loss: 0.5554 - val_mae: 0.5452 - val_mse: 0.5554\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4265 - mae: 0.4955 - mse: 0.4265\n",
      "Epoch 2: val_loss improved from 0.55543 to 0.31141, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3920 - mae: 0.4748 - mse: 0.3920 - val_loss: 0.3114 - val_mae: 0.4129 - val_mse: 0.3114\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2450 - mae: 0.3714 - mse: 0.2450\n",
      "Epoch 3: val_loss improved from 0.31141 to 0.21815, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2476 - mae: 0.3745 - mse: 0.2476 - val_loss: 0.2181 - val_mae: 0.3528 - val_mse: 0.2181\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1994 - mae: 0.3293 - mse: 0.1994\n",
      "Epoch 4: val_loss improved from 0.21815 to 0.18194, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1968 - mae: 0.3299 - mse: 0.1968 - val_loss: 0.1819 - val_mae: 0.3298 - val_mse: 0.1819\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1595 - mae: 0.3057 - mse: 0.1595\n",
      "Epoch 5: val_loss improved from 0.18194 to 0.15480, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1620 - mae: 0.3055 - mse: 0.1620 - val_loss: 0.1548 - val_mae: 0.2983 - val_mse: 0.1548\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1368 - mae: 0.2785 - mse: 0.1368\n",
      "Epoch 6: val_loss improved from 0.15480 to 0.14066, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1318 - mae: 0.2728 - mse: 0.1318 - val_loss: 0.1407 - val_mae: 0.2804 - val_mse: 0.1407\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1178 - mae: 0.2566 - mse: 0.1178\n",
      "Epoch 7: val_loss improved from 0.14066 to 0.13377, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1126 - mae: 0.2510 - mse: 0.1126 - val_loss: 0.1338 - val_mae: 0.2781 - val_mse: 0.1338\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1033 - mae: 0.2426 - mse: 0.1033\n",
      "Epoch 8: val_loss improved from 0.13377 to 0.11493, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1010 - mae: 0.2390 - mse: 0.1010 - val_loss: 0.1149 - val_mae: 0.2557 - val_mse: 0.1149\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0837 - mae: 0.2130 - mse: 0.0837\n",
      "Epoch 9: val_loss improved from 0.11493 to 0.09634, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0837 - mae: 0.2120 - mse: 0.0837 - val_loss: 0.0963 - val_mae: 0.2344 - val_mse: 0.0963\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0686 - mae: 0.1888 - mse: 0.0686\n",
      "Epoch 10: val_loss improved from 0.09634 to 0.07373, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0709 - mae: 0.1918 - mse: 0.0709 - val_loss: 0.0737 - val_mae: 0.2026 - val_mse: 0.0737\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0579 - mae: 0.1777 - mse: 0.0579\n",
      "Epoch 11: val_loss improved from 0.07373 to 0.05478, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0615 - mae: 0.1809 - mse: 0.0615 - val_loss: 0.0548 - val_mae: 0.1710 - val_mse: 0.0548\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0569 - mae: 0.1756 - mse: 0.0569\n",
      "Epoch 12: val_loss improved from 0.05478 to 0.04548, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0548 - mae: 0.1698 - mse: 0.0548 - val_loss: 0.0455 - val_mae: 0.1550 - val_mse: 0.0455\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0457 - mae: 0.1559 - mse: 0.0457\n",
      "Epoch 13: val_loss improved from 0.04548 to 0.04106, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0445 - mae: 0.1535 - mse: 0.0445 - val_loss: 0.0411 - val_mae: 0.1529 - val_mse: 0.0411\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0420 - mae: 0.1490 - mse: 0.0420\n",
      "Epoch 14: val_loss improved from 0.04106 to 0.03729, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0414 - mae: 0.1480 - mse: 0.0414 - val_loss: 0.0373 - val_mae: 0.1441 - val_mse: 0.0373\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0349 - mae: 0.1355 - mse: 0.0349\n",
      "Epoch 15: val_loss improved from 0.03729 to 0.03603, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0365 - mae: 0.1372 - mse: 0.0365 - val_loss: 0.0360 - val_mae: 0.1391 - val_mse: 0.0360\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0359 - mae: 0.1340 - mse: 0.0359\n",
      "Epoch 16: val_loss improved from 0.03603 to 0.02928, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0334 - mae: 0.1294 - mse: 0.0334 - val_loss: 0.0293 - val_mae: 0.1244 - val_mse: 0.0293\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0288 - mae: 0.1189 - mse: 0.0288\n",
      "Epoch 17: val_loss improved from 0.02928 to 0.02829, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0281 - mae: 0.1169 - mse: 0.0281 - val_loss: 0.0283 - val_mae: 0.1222 - val_mse: 0.0283\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0252 - mae: 0.1121 - mse: 0.0252\n",
      "Epoch 18: val_loss improved from 0.02829 to 0.02576, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0255 - mae: 0.1132 - mse: 0.0255 - val_loss: 0.0258 - val_mae: 0.1140 - val_mse: 0.0258\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0232 - mae: 0.1071 - mse: 0.0232\n",
      "Epoch 19: val_loss improved from 0.02576 to 0.02172, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0228 - mae: 0.1062 - mse: 0.0228 - val_loss: 0.0217 - val_mae: 0.1037 - val_mse: 0.0217\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0202 - mae: 0.0982 - mse: 0.0202\n",
      "Epoch 20: val_loss improved from 0.02172 to 0.01969, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0194 - mae: 0.0961 - mse: 0.0194 - val_loss: 0.0197 - val_mae: 0.0995 - val_mse: 0.0197\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0193 - mae: 0.0974 - mse: 0.0193\n",
      "Epoch 21: val_loss improved from 0.01969 to 0.01683, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0185 - mae: 0.0947 - mse: 0.0185 - val_loss: 0.0168 - val_mae: 0.0922 - val_mse: 0.0168\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0167 - mae: 0.0892 - mse: 0.0167\n",
      "Epoch 22: val_loss improved from 0.01683 to 0.01591, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0154 - mae: 0.0857 - mse: 0.0154 - val_loss: 0.0159 - val_mae: 0.0876 - val_mse: 0.0159\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - mae: 0.0809 - mse: 0.0137\n",
      "Epoch 23: val_loss improved from 0.01591 to 0.01448, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0151 - mae: 0.0841 - mse: 0.0151 - val_loss: 0.0145 - val_mae: 0.0829 - val_mse: 0.0145\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0129 - mae: 0.0770 - mse: 0.0129\n",
      "Epoch 24: val_loss improved from 0.01448 to 0.01278, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0126 - mae: 0.0758 - mse: 0.0126 - val_loss: 0.0128 - val_mae: 0.0788 - val_mse: 0.0128\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0136 - mae: 0.0788 - mse: 0.0136\n",
      "Epoch 25: val_loss improved from 0.01278 to 0.01098, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0129 - mae: 0.0773 - mse: 0.0129 - val_loss: 0.0110 - val_mae: 0.0743 - val_mse: 0.0110\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0101 - mae: 0.0701 - mse: 0.0101\n",
      "Epoch 26: val_loss did not improve from 0.01098\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0102 - mae: 0.0703 - mse: 0.0102 - val_loss: 0.0114 - val_mae: 0.0732 - val_mse: 0.0114\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0111 - mae: 0.0728 - mse: 0.0111\n",
      "Epoch 27: val_loss improved from 0.01098 to 0.00995, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0103 - mae: 0.0693 - mse: 0.0103 - val_loss: 0.0099 - val_mae: 0.0690 - val_mse: 0.0099\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0083 - mae: 0.0628 - mse: 0.0083\n",
      "Epoch 28: val_loss improved from 0.00995 to 0.00869, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0084 - mae: 0.0628 - mse: 0.0084 - val_loss: 0.0087 - val_mae: 0.0647 - val_mse: 0.0087\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0081 - mae: 0.0617 - mse: 0.0081\n",
      "Epoch 29: val_loss improved from 0.00869 to 0.00844, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0077 - mae: 0.0599 - mse: 0.0077 - val_loss: 0.0084 - val_mae: 0.0623 - val_mse: 0.0084\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0071 - mae: 0.0567 - mse: 0.0071\n",
      "Epoch 30: val_loss improved from 0.00844 to 0.00780, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mae: 0.0555 - mse: 0.0067 - val_loss: 0.0078 - val_mae: 0.0593 - val_mse: 0.0078\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0057 - mae: 0.0508 - mse: 0.0057\n",
      "Epoch 31: val_loss improved from 0.00780 to 0.00679, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0061 - mae: 0.0527 - mse: 0.0061 - val_loss: 0.0068 - val_mae: 0.0574 - val_mse: 0.0068\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0050 - mae: 0.0487 - mse: 0.0050\n",
      "Epoch 32: val_loss improved from 0.00679 to 0.00585, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - mae: 0.0513 - mse: 0.0056 - val_loss: 0.0059 - val_mae: 0.0549 - val_mse: 0.0059\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - mae: 0.0524 - mse: 0.0056\n",
      "Epoch 33: val_loss improved from 0.00585 to 0.00566, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0053 - mae: 0.0510 - mse: 0.0053 - val_loss: 0.0057 - val_mae: 0.0523 - val_mse: 0.0057\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - mae: 0.0470 - mse: 0.0049\n",
      "Epoch 34: val_loss improved from 0.00566 to 0.00542, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0048 - mae: 0.0471 - mse: 0.0048 - val_loss: 0.0054 - val_mae: 0.0512 - val_mse: 0.0054\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0046 - mae: 0.0459 - mse: 0.0046\n",
      "Epoch 35: val_loss improved from 0.00542 to 0.00448, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0044 - mae: 0.0451 - mse: 0.0044 - val_loss: 0.0045 - val_mae: 0.0483 - val_mse: 0.0045\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041 - mae: 0.0448 - mse: 0.0041\n",
      "Epoch 36: val_loss improved from 0.00448 to 0.00442, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0041 - mae: 0.0445 - mse: 0.0041 - val_loss: 0.0044 - val_mae: 0.0466 - val_mse: 0.0044\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0037 - mae: 0.0417 - mse: 0.0037\n",
      "Epoch 37: val_loss did not improve from 0.00442\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mae: 0.0413 - mse: 0.0037 - val_loss: 0.0046 - val_mae: 0.0468 - val_mse: 0.0046\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0040 - mae: 0.0427 - mse: 0.0040\n",
      "Epoch 38: val_loss improved from 0.00442 to 0.00412, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0034 - mae: 0.0398 - mse: 0.0034 - val_loss: 0.0041 - val_mae: 0.0457 - val_mse: 0.0041\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0405 - mse: 0.0034\n",
      "Epoch 39: val_loss improved from 0.00412 to 0.00388, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0032 - mae: 0.0394 - mse: 0.0032 - val_loss: 0.0039 - val_mae: 0.0440 - val_mse: 0.0039\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0365 - mse: 0.0029\n",
      "Epoch 40: val_loss improved from 0.00388 to 0.00350, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0030 - mae: 0.0372 - mse: 0.0030 - val_loss: 0.0035 - val_mae: 0.0418 - val_mse: 0.0035\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0026 - mae: 0.0354 - mse: 0.0026\n",
      "Epoch 41: val_loss improved from 0.00350 to 0.00335, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0027 - mae: 0.0356 - mse: 0.0027 - val_loss: 0.0034 - val_mae: 0.0402 - val_mse: 0.0034\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0357 - mse: 0.0028\n",
      "Epoch 42: val_loss did not improve from 0.00335\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0026 - mae: 0.0346 - mse: 0.0026 - val_loss: 0.0034 - val_mae: 0.0399 - val_mse: 0.0034\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0023 - mae: 0.0327 - mse: 0.0023\n",
      "Epoch 43: val_loss improved from 0.00335 to 0.00303, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0333 - mse: 0.0024 - val_loss: 0.0030 - val_mae: 0.0381 - val_mse: 0.0030\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mae: 0.0321 - mse: 0.0021\n",
      "Epoch 44: val_loss improved from 0.00303 to 0.00277, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0325 - mse: 0.0022 - val_loss: 0.0028 - val_mae: 0.0368 - val_mse: 0.0028\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0323 - mse: 0.0022\n",
      "Epoch 45: val_loss improved from 0.00277 to 0.00259, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0021 - mae: 0.0315 - mse: 0.0021 - val_loss: 0.0026 - val_mae: 0.0357 - val_mse: 0.0026\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0298 - mse: 0.0019\n",
      "Epoch 46: val_loss improved from 0.00259 to 0.00238, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0308 - mse: 0.0020 - val_loss: 0.0024 - val_mae: 0.0342 - val_mse: 0.0024\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0292 - mse: 0.0018\n",
      "Epoch 47: val_loss did not improve from 0.00238\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0019 - mae: 0.0293 - mse: 0.0019 - val_loss: 0.0025 - val_mae: 0.0343 - val_mse: 0.0025\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0289 - mse: 0.0017\n",
      "Epoch 48: val_loss did not improve from 0.00238\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0018 - mae: 0.0291 - mse: 0.0018 - val_loss: 0.0024 - val_mae: 0.0341 - val_mse: 0.0024\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0276 - mse: 0.0017\n",
      "Epoch 49: val_loss improved from 0.00238 to 0.00228, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0276 - mse: 0.0017 - val_loss: 0.0023 - val_mae: 0.0343 - val_mse: 0.0023\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0278 - mse: 0.0015\n",
      "Epoch 50: val_loss improved from 0.00228 to 0.00211, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0281 - mse: 0.0016 - val_loss: 0.0021 - val_mae: 0.0328 - val_mse: 0.0021\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0252 - mse: 0.0013\n",
      "Epoch 51: val_loss did not improve from 0.00211\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0015 - mae: 0.0269 - mse: 0.0015 - val_loss: 0.0022 - val_mae: 0.0328 - val_mse: 0.0022\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0260 - mse: 0.0014\n",
      "Epoch 52: val_loss improved from 0.00211 to 0.00210, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0260 - mse: 0.0014 - val_loss: 0.0021 - val_mae: 0.0319 - val_mse: 0.0021\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0268 - mse: 0.0015\n",
      "Epoch 53: val_loss improved from 0.00210 to 0.00194, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0261 - mse: 0.0014 - val_loss: 0.0019 - val_mae: 0.0302 - val_mse: 0.0019\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0011 - mae: 0.0233 - mse: 0.0011\n",
      "Epoch 54: val_loss improved from 0.00194 to 0.00181, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0242 - mse: 0.0013 - val_loss: 0.0018 - val_mae: 0.0298 - val_mse: 0.0018\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0230 - mse: 0.0010\n",
      "Epoch 55: val_loss improved from 0.00181 to 0.00167, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0239 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0291 - val_mse: 0.0017\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0223 - mse: 0.0010\n",
      "Epoch 56: val_loss did not improve from 0.00167\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0012 - mae: 0.0236 - mse: 0.0012 - val_loss: 0.0017 - val_mae: 0.0296 - val_mse: 0.0017\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0011 - mae: 0.0230 - mse: 0.0011\n",
      "Epoch 57: val_loss improved from 0.00167 to 0.00164, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0228 - mse: 0.0011 - val_loss: 0.0016 - val_mae: 0.0291 - val_mse: 0.0016\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0010 - mae: 0.0218 - mse: 0.0010\n",
      "Epoch 58: val_loss improved from 0.00164 to 0.00150, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0011 - mae: 0.0227 - mse: 0.0011 - val_loss: 0.0015 - val_mae: 0.0277 - val_mse: 0.0015\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5780e-04 - mae: 0.0215 - mse: 9.5780e-04\n",
      "Epoch 59: val_loss did not improve from 0.00150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0010 - mae: 0.0223 - mse: 0.0010 - val_loss: 0.0015 - val_mae: 0.0274 - val_mse: 0.0015\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0010 - mae: 0.0224 - mse: 0.0010\n",
      "Epoch 60: val_loss did not improve from 0.00150\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.4574e-04 - mae: 0.0215 - mse: 9.4574e-04 - val_loss: 0.0015 - val_mae: 0.0278 - val_mse: 0.0015\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.2719e-04 - mae: 0.0213 - mse: 9.2719e-04\n",
      "Epoch 61: val_loss improved from 0.00150 to 0.00140, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.2822e-04 - mae: 0.0213 - mse: 9.2822e-04 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0014\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0358e-04 - mae: 0.0213 - mse: 9.0358e-04\n",
      "Epoch 62: val_loss improved from 0.00140 to 0.00137, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.8819e-04 - mae: 0.0210 - mse: 8.8819e-04 - val_loss: 0.0014 - val_mae: 0.0266 - val_mse: 0.0014\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2883e-04 - mae: 0.0195 - mse: 7.2883e-04\n",
      "Epoch 63: val_loss did not improve from 0.00137\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.5911e-04 - mae: 0.0203 - mse: 8.5911e-04 - val_loss: 0.0014 - val_mae: 0.0267 - val_mse: 0.0014\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9539e-04 - mae: 0.0200 - mse: 7.9539e-04\n",
      "Epoch 64: val_loss improved from 0.00137 to 0.00133, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.9685e-04 - mae: 0.0200 - mse: 7.9685e-04 - val_loss: 0.0013 - val_mae: 0.0261 - val_mse: 0.0013\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5796e-04 - mae: 0.0197 - mse: 7.5796e-04\n",
      "Epoch 65: val_loss improved from 0.00133 to 0.00124, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.6502e-04 - mae: 0.0201 - mse: 8.6502e-04 - val_loss: 0.0012 - val_mae: 0.0251 - val_mse: 0.0012\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.3094e-04 - mae: 0.0189 - mse: 7.3094e-04\n",
      "Epoch 66: val_loss improved from 0.00124 to 0.00120, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.9497e-04 - mae: 0.0194 - mse: 7.9497e-04 - val_loss: 0.0012 - val_mae: 0.0247 - val_mse: 0.0012\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5683e-04 - mae: 0.0198 - mse: 8.5683e-04\n",
      "Epoch 67: val_loss improved from 0.00120 to 0.00118, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.2431e-04 - mae: 0.0198 - mse: 8.2431e-04 - val_loss: 0.0012 - val_mae: 0.0247 - val_mse: 0.0012\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3817e-04 - mae: 0.0194 - mse: 7.3817e-04\n",
      "Epoch 68: val_loss did not improve from 0.00118\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3616e-04 - mae: 0.0191 - mse: 7.3616e-04 - val_loss: 0.0012 - val_mae: 0.0247 - val_mse: 0.0012\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4431e-04 - mae: 0.0191 - mse: 7.4431e-04\n",
      "Epoch 69: val_loss improved from 0.00118 to 0.00107, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.2270e-04 - mae: 0.0187 - mse: 7.2270e-04 - val_loss: 0.0011 - val_mae: 0.0237 - val_mse: 0.0011\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2924e-04 - mae: 0.0177 - mse: 6.2924e-04\n",
      "Epoch 70: val_loss improved from 0.00107 to 0.00106, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.3731e-04 - mae: 0.0189 - mse: 7.3731e-04 - val_loss: 0.0011 - val_mae: 0.0229 - val_mse: 0.0011\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2505e-04 - mae: 0.0175 - mse: 6.2505e-04\n",
      "Epoch 71: val_loss did not improve from 0.00106\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4825e-04 - mae: 0.0176 - mse: 6.4825e-04 - val_loss: 0.0012 - val_mae: 0.0240 - val_mse: 0.0012\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3549e-04 - mae: 0.0186 - mse: 7.3549e-04\n",
      "Epoch 72: val_loss did not improve from 0.00106\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.4094e-04 - mae: 0.0187 - mse: 7.4094e-04 - val_loss: 0.0011 - val_mae: 0.0235 - val_mse: 0.0011\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2090e-04 - mae: 0.0188 - mse: 7.2090e-04\n",
      "Epoch 73: val_loss did not improve from 0.00106\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.3512e-04 - mae: 0.0190 - mse: 7.3512e-04 - val_loss: 0.0011 - val_mae: 0.0232 - val_mse: 0.0011\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7056e-04 - mae: 0.0178 - mse: 6.7056e-04\n",
      "Epoch 74: val_loss did not improve from 0.00106\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.6358e-04 - mae: 0.0181 - mse: 6.6358e-04 - val_loss: 0.0011 - val_mae: 0.0233 - val_mse: 0.0011\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1024e-04 - mae: 0.0173 - mse: 6.1024e-04\n",
      "Epoch 75: val_loss did not improve from 0.00106\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1075e-04 - mae: 0.0171 - mse: 6.1075e-04 - val_loss: 0.0011 - val_mae: 0.0241 - val_mse: 0.0011\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5751e-04 - mae: 0.0200 - mse: 8.5751e-04\n",
      "Epoch 76: val_loss did not improve from 0.00106\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.5623e-04 - mae: 0.0189 - mse: 7.5623e-04 - val_loss: 0.0011 - val_mae: 0.0228 - val_mse: 0.0011\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9665e-04 - mae: 0.0170 - mse: 5.9665e-04\n",
      "Epoch 77: val_loss improved from 0.00106 to 0.00100, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9324e-04 - mae: 0.0170 - mse: 5.9324e-04 - val_loss: 9.9731e-04 - val_mae: 0.0221 - val_mse: 9.9731e-04\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8940e-04 - mae: 0.0171 - mse: 5.8940e-04\n",
      "Epoch 78: val_loss improved from 0.00100 to 0.00100, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.3944e-04 - mae: 0.0165 - mse: 5.3944e-04 - val_loss: 9.9639e-04 - val_mae: 0.0218 - val_mse: 9.9639e-04\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6358e-04 - mae: 0.0163 - mse: 5.6358e-04\n",
      "Epoch 79: val_loss did not improve from 0.00100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0352e-04 - mae: 0.0168 - mse: 6.0352e-04 - val_loss: 0.0010 - val_mae: 0.0221 - val_mse: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3323e-04 - mae: 0.0160 - mse: 5.3323e-04\n",
      "Epoch 80: val_loss improved from 0.00100 to 0.00098, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5872e-04 - mae: 0.0162 - mse: 5.5872e-04 - val_loss: 9.7759e-04 - val_mae: 0.0215 - val_mse: 9.7759e-04\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8085e-04 - mae: 0.0152 - mse: 4.8085e-04\n",
      "Epoch 81: val_loss improved from 0.00098 to 0.00095, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.0038e-04 - mae: 0.0155 - mse: 5.0038e-04 - val_loss: 9.5347e-04 - val_mae: 0.0211 - val_mse: 9.5347e-04\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.1952e-04 - mae: 0.0155 - mse: 5.1952e-04\n",
      "Epoch 82: val_loss did not improve from 0.00095\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8975e-04 - mae: 0.0154 - mse: 4.8975e-04 - val_loss: 0.0010 - val_mae: 0.0215 - val_mse: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0436e-04 - mae: 0.0155 - mse: 5.0436e-04\n",
      "Epoch 83: val_loss improved from 0.00095 to 0.00094, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7625e-04 - mae: 0.0152 - mse: 4.7625e-04 - val_loss: 9.4450e-04 - val_mae: 0.0207 - val_mse: 9.4450e-04\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7595e-04 - mae: 0.0148 - mse: 4.7595e-04\n",
      "Epoch 84: val_loss improved from 0.00094 to 0.00092, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.4764e-04 - mae: 0.0145 - mse: 4.4764e-04 - val_loss: 9.1667e-04 - val_mae: 0.0204 - val_mse: 9.1667e-04\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8312e-04 - mae: 0.0149 - mse: 4.8312e-04\n",
      "Epoch 85: val_loss did not improve from 0.00092\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.5615e-04 - mae: 0.0146 - mse: 4.5615e-04 - val_loss: 9.5397e-04 - val_mae: 0.0209 - val_mse: 9.5397e-04\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1496e-04 - mae: 0.0139 - mse: 4.1496e-04\n",
      "Epoch 86: val_loss did not improve from 0.00092\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.5166e-04 - mae: 0.0144 - mse: 4.5166e-04 - val_loss: 9.2476e-04 - val_mae: 0.0205 - val_mse: 9.2476e-04\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5218e-04 - mae: 0.0144 - mse: 4.5218e-04\n",
      "Epoch 87: val_loss did not improve from 0.00092\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.1072e-04 - mae: 0.0139 - mse: 4.1072e-04 - val_loss: 9.1947e-04 - val_mae: 0.0202 - val_mse: 9.1947e-04\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1881e-04 - mae: 0.0138 - mse: 4.1881e-04\n",
      "Epoch 88: val_loss did not improve from 0.00092\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1728e-04 - mae: 0.0139 - mse: 4.1728e-04 - val_loss: 9.3016e-04 - val_mae: 0.0203 - val_mse: 9.3016e-04\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0285e-04 - mae: 0.0139 - mse: 4.0285e-04\n",
      "Epoch 89: val_loss improved from 0.00092 to 0.00089, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.9681e-04 - mae: 0.0138 - mse: 3.9681e-04 - val_loss: 8.9128e-04 - val_mae: 0.0198 - val_mse: 8.9128e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9234e-04 - mae: 0.0135 - mse: 3.9234e-04\n",
      "Epoch 90: val_loss improved from 0.00089 to 0.00087, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.2444e-04 - mae: 0.0137 - mse: 4.2444e-04 - val_loss: 8.6700e-04 - val_mae: 0.0194 - val_mse: 8.6700e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3737e-04 - mae: 0.0135 - mse: 4.3737e-04\n",
      "Epoch 91: val_loss did not improve from 0.00087\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.1004e-04 - mae: 0.0135 - mse: 4.1004e-04 - val_loss: 8.7812e-04 - val_mae: 0.0196 - val_mse: 8.7812e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6301e-04 - mae: 0.0131 - mse: 3.6301e-04\n",
      "Epoch 92: val_loss improved from 0.00087 to 0.00083, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.8334e-04 - mae: 0.0135 - mse: 3.8334e-04 - val_loss: 8.3425e-04 - val_mae: 0.0188 - val_mse: 8.3425e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7517e-04 - mae: 0.0131 - mse: 3.7517e-04\n",
      "Epoch 93: val_loss improved from 0.00083 to 0.00083, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.6007e-04 - mae: 0.0130 - mse: 3.6007e-04 - val_loss: 8.2732e-04 - val_mae: 0.0186 - val_mse: 8.2732e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4368e-04 - mae: 0.0139 - mse: 4.4368e-04\n",
      "Epoch 94: val_loss did not improve from 0.00083\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8283e-04 - mae: 0.0131 - mse: 3.8283e-04 - val_loss: 8.4164e-04 - val_mae: 0.0189 - val_mse: 8.4164e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4633e-04 - mae: 0.0128 - mse: 3.4633e-04\n",
      "Epoch 95: val_loss improved from 0.00083 to 0.00081, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.5551e-04 - mae: 0.0130 - mse: 3.5551e-04 - val_loss: 8.0612e-04 - val_mae: 0.0186 - val_mse: 8.0612e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3501e-04 - mae: 0.0127 - mse: 3.3501e-04\n",
      "Epoch 96: val_loss improved from 0.00081 to 0.00078, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.3675e-04 - mae: 0.0127 - mse: 3.3675e-04 - val_loss: 7.7722e-04 - val_mae: 0.0185 - val_mse: 7.7722e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3025e-04 - mae: 0.0122 - mse: 3.3025e-04\n",
      "Epoch 97: val_loss improved from 0.00078 to 0.00077, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3644e-04 - mae: 0.0124 - mse: 3.3644e-04 - val_loss: 7.6595e-04 - val_mae: 0.0183 - val_mse: 7.6595e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4868e-04 - mae: 0.0127 - mse: 3.4868e-04\n",
      "Epoch 98: val_loss improved from 0.00077 to 0.00076, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.3524e-04 - mae: 0.0125 - mse: 3.3524e-04 - val_loss: 7.6449e-04 - val_mae: 0.0177 - val_mse: 7.6449e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9122e-04 - mae: 0.0115 - mse: 2.9122e-04\n",
      "Epoch 99: val_loss did not improve from 0.00076\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0840e-04 - mae: 0.0118 - mse: 3.0840e-04 - val_loss: 7.7638e-04 - val_mae: 0.0181 - val_mse: 7.7638e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2441e-04 - mae: 0.0109 - mse: 2.2441e-04\n",
      "Epoch 100: val_loss improved from 0.00076 to 0.00076, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1592e-04 - mae: 0.0121 - mse: 3.1592e-04 - val_loss: 7.5817e-04 - val_mae: 0.0176 - val_mse: 7.5817e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2486e-04 - mae: 0.0120 - mse: 3.2486e-04\n",
      "Epoch 101: val_loss did not improve from 0.00076\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.0206e-04 - mae: 0.0119 - mse: 3.0206e-04 - val_loss: 7.6377e-04 - val_mae: 0.0178 - val_mse: 7.6377e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0603e-04 - mae: 0.0117 - mse: 3.0603e-04\n",
      "Epoch 102: val_loss did not improve from 0.00076\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9451e-04 - mae: 0.0116 - mse: 2.9451e-04 - val_loss: 7.7297e-04 - val_mae: 0.0181 - val_mse: 7.7297e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2383e-04 - mae: 0.0124 - mse: 3.2383e-04\n",
      "Epoch 103: val_loss improved from 0.00076 to 0.00074, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2002e-04 - mae: 0.0122 - mse: 3.2002e-04 - val_loss: 7.3837e-04 - val_mae: 0.0174 - val_mse: 7.3837e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6057e-04 - mae: 0.0111 - mse: 2.6057e-04\n",
      "Epoch 104: val_loss did not improve from 0.00074\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8290e-04 - mae: 0.0113 - mse: 2.8290e-04 - val_loss: 7.7910e-04 - val_mae: 0.0180 - val_mse: 7.7910e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2253e-04 - mae: 0.0121 - mse: 3.2253e-04\n",
      "Epoch 105: val_loss did not improve from 0.00074\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.2618e-04 - mae: 0.0119 - mse: 3.2618e-04 - val_loss: 8.0683e-04 - val_mae: 0.0184 - val_mse: 8.0683e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7767e-04 - mae: 0.0114 - mse: 2.7767e-04\n",
      "Epoch 106: val_loss did not improve from 0.00074\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1097e-04 - mae: 0.0118 - mse: 3.1097e-04 - val_loss: 7.5051e-04 - val_mae: 0.0175 - val_mse: 7.5051e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9011e-04 - mae: 0.0115 - mse: 2.9011e-04\n",
      "Epoch 107: val_loss improved from 0.00074 to 0.00072, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.8455e-04 - mae: 0.0114 - mse: 2.8455e-04 - val_loss: 7.1678e-04 - val_mae: 0.0172 - val_mse: 7.1678e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8624e-04 - mae: 0.0113 - mse: 2.8624e-04\n",
      "Epoch 108: val_loss improved from 0.00072 to 0.00070, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0643e-04 - mae: 0.0117 - mse: 3.0643e-04 - val_loss: 6.9590e-04 - val_mae: 0.0170 - val_mse: 6.9590e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5599e-04 - mae: 0.0109 - mse: 2.5599e-04\n",
      "Epoch 109: val_loss did not improve from 0.00070\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7464e-04 - mae: 0.0114 - mse: 2.7464e-04 - val_loss: 6.9870e-04 - val_mae: 0.0172 - val_mse: 6.9870e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7837e-04 - mae: 0.0115 - mse: 2.7837e-04\n",
      "Epoch 110: val_loss did not improve from 0.00070\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.9081e-04 - mae: 0.0115 - mse: 2.9081e-04 - val_loss: 7.2021e-04 - val_mae: 0.0176 - val_mse: 7.2021e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7900e-04 - mae: 0.0113 - mse: 2.7900e-04\n",
      "Epoch 111: val_loss improved from 0.00070 to 0.00069, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.7597e-04 - mae: 0.0115 - mse: 2.7597e-04 - val_loss: 6.9132e-04 - val_mae: 0.0172 - val_mse: 6.9132e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6486e-04 - mae: 0.0108 - mse: 2.6486e-04\n",
      "Epoch 112: val_loss improved from 0.00069 to 0.00068, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6191e-04 - mae: 0.0110 - mse: 2.6191e-04 - val_loss: 6.7798e-04 - val_mae: 0.0168 - val_mse: 6.7798e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1551e-04 - mae: 0.0104 - mse: 2.1551e-04\n",
      "Epoch 113: val_loss did not improve from 0.00068\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5336e-04 - mae: 0.0108 - mse: 2.5336e-04 - val_loss: 6.8940e-04 - val_mae: 0.0170 - val_mse: 6.8940e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5453e-04 - mae: 0.0110 - mse: 2.5453e-04\n",
      "Epoch 114: val_loss improved from 0.00068 to 0.00065, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.5148e-04 - mae: 0.0109 - mse: 2.5148e-04 - val_loss: 6.4765e-04 - val_mae: 0.0162 - val_mse: 6.4765e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3116e-04 - mae: 0.0102 - mse: 2.3116e-04\n",
      "Epoch 115: val_loss did not improve from 0.00065\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3542e-04 - mae: 0.0104 - mse: 2.3542e-04 - val_loss: 6.5008e-04 - val_mae: 0.0160 - val_mse: 6.5008e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5384e-04 - mae: 0.0105 - mse: 2.5384e-04\n",
      "Epoch 116: val_loss did not improve from 0.00065\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3130e-04 - mae: 0.0102 - mse: 2.3130e-04 - val_loss: 6.8985e-04 - val_mae: 0.0165 - val_mse: 6.8985e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4694e-04 - mae: 0.0107 - mse: 2.4694e-04\n",
      "Epoch 117: val_loss did not improve from 0.00065\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4027e-04 - mae: 0.0105 - mse: 2.4027e-04 - val_loss: 6.4808e-04 - val_mae: 0.0158 - val_mse: 6.4808e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2729e-04 - mae: 0.0101 - mse: 2.2729e-04\n",
      "Epoch 118: val_loss improved from 0.00065 to 0.00064, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.1932e-04 - mae: 0.0100 - mse: 2.1932e-04 - val_loss: 6.3896e-04 - val_mae: 0.0158 - val_mse: 6.3896e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2749e-04 - mae: 0.0099 - mse: 2.2749e-04\n",
      "Epoch 119: val_loss did not improve from 0.00064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.2178e-04 - mae: 0.0101 - mse: 2.2178e-04 - val_loss: 6.4942e-04 - val_mae: 0.0161 - val_mse: 6.4942e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1659e-04 - mae: 0.0100 - mse: 2.1659e-04\n",
      "Epoch 120: val_loss did not improve from 0.00064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1665e-04 - mae: 0.0101 - mse: 2.1665e-04 - val_loss: 6.4891e-04 - val_mae: 0.0160 - val_mse: 6.4891e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3510e-04 - mae: 0.0101 - mse: 2.3510e-04\n",
      "Epoch 121: val_loss did not improve from 0.00064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1676e-04 - mae: 0.0099 - mse: 2.1676e-04 - val_loss: 6.5753e-04 - val_mae: 0.0160 - val_mse: 6.5753e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5010e-04 - mae: 0.0103 - mse: 2.5010e-04\n",
      "Epoch 122: val_loss did not improve from 0.00064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2465e-04 - mae: 0.0101 - mse: 2.2465e-04 - val_loss: 6.5518e-04 - val_mae: 0.0158 - val_mse: 6.5518e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1793e-04 - mae: 0.0099 - mse: 2.1793e-04\n",
      "Epoch 123: val_loss did not improve from 0.00064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1249e-04 - mae: 0.0098 - mse: 2.1249e-04 - val_loss: 6.5800e-04 - val_mae: 0.0157 - val_mse: 6.5800e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2416e-04 - mae: 0.0099 - mse: 2.2416e-04\n",
      "Epoch 124: val_loss did not improve from 0.00064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0182e-04 - mae: 0.0096 - mse: 2.0182e-04 - val_loss: 6.4573e-04 - val_mae: 0.0157 - val_mse: 6.4573e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1911e-04 - mae: 0.0097 - mse: 2.1911e-04\n",
      "Epoch 125: val_loss improved from 0.00064 to 0.00061, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.9771e-04 - mae: 0.0095 - mse: 1.9771e-04 - val_loss: 6.1459e-04 - val_mae: 0.0155 - val_mse: 6.1459e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1498e-04 - mae: 0.0097 - mse: 2.1498e-04\n",
      "Epoch 126: val_loss did not improve from 0.00061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9125e-04 - mae: 0.0094 - mse: 1.9125e-04 - val_loss: 6.1640e-04 - val_mae: 0.0152 - val_mse: 6.1640e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1049e-04 - mae: 0.0094 - mse: 2.1049e-04\n",
      "Epoch 127: val_loss did not improve from 0.00061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8669e-04 - mae: 0.0091 - mse: 1.8669e-04 - val_loss: 6.4870e-04 - val_mae: 0.0155 - val_mse: 6.4870e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9096e-04 - mae: 0.0092 - mse: 1.9096e-04\n",
      "Epoch 128: val_loss did not improve from 0.00061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8420e-04 - mae: 0.0091 - mse: 1.8420e-04 - val_loss: 6.3740e-04 - val_mae: 0.0151 - val_mse: 6.3740e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7951e-04 - mae: 0.0089 - mse: 1.7951e-04\n",
      "Epoch 129: val_loss did not improve from 0.00061\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8423e-04 - mae: 0.0089 - mse: 1.8423e-04 - val_loss: 6.2175e-04 - val_mae: 0.0149 - val_mse: 6.2175e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8791e-04 - mae: 0.0088 - mse: 1.8791e-04\n",
      "Epoch 130: val_loss improved from 0.00061 to 0.00061, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7928e-04 - mae: 0.0088 - mse: 1.7928e-04 - val_loss: 6.1323e-04 - val_mae: 0.0149 - val_mse: 6.1323e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8536e-04 - mae: 0.0090 - mse: 1.8536e-04\n",
      "Epoch 131: val_loss improved from 0.00061 to 0.00061, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7545e-04 - mae: 0.0087 - mse: 1.7545e-04 - val_loss: 6.0920e-04 - val_mae: 0.0148 - val_mse: 6.0920e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8070e-04 - mae: 0.0086 - mse: 1.8070e-04\n",
      "Epoch 132: val_loss improved from 0.00061 to 0.00060, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.7544e-04 - mae: 0.0085 - mse: 1.7544e-04 - val_loss: 5.9552e-04 - val_mae: 0.0147 - val_mse: 5.9552e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6308e-04 - mae: 0.0083 - mse: 1.6308e-04\n",
      "Epoch 133: val_loss did not improve from 0.00060\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7038e-04 - mae: 0.0085 - mse: 1.7038e-04 - val_loss: 5.9609e-04 - val_mae: 0.0146 - val_mse: 5.9609e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5621e-04 - mae: 0.0084 - mse: 1.5621e-04\n",
      "Epoch 134: val_loss did not improve from 0.00060\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6652e-04 - mae: 0.0085 - mse: 1.6652e-04 - val_loss: 6.0172e-04 - val_mae: 0.0146 - val_mse: 6.0172e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2957e-04 - mae: 0.0076 - mse: 1.2957e-04\n",
      "Epoch 135: val_loss improved from 0.00060 to 0.00059, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6595e-04 - mae: 0.0084 - mse: 1.6595e-04 - val_loss: 5.8506e-04 - val_mae: 0.0144 - val_mse: 5.8506e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8201e-04 - mae: 0.0085 - mse: 1.8201e-04\n",
      "Epoch 136: val_loss improved from 0.00059 to 0.00057, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6546e-04 - mae: 0.0084 - mse: 1.6546e-04 - val_loss: 5.7413e-04 - val_mae: 0.0144 - val_mse: 5.7413e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6324e-04 - mae: 0.0087 - mse: 1.6324e-04\n",
      "Epoch 137: val_loss did not improve from 0.00057\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7996e-04 - mae: 0.0088 - mse: 1.7996e-04 - val_loss: 5.8369e-04 - val_mae: 0.0144 - val_mse: 5.8369e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7518e-04 - mae: 0.0087 - mse: 1.7518e-04\n",
      "Epoch 138: val_loss did not improve from 0.00057\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6565e-04 - mae: 0.0086 - mse: 1.6565e-04 - val_loss: 5.8993e-04 - val_mae: 0.0144 - val_mse: 5.8993e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7943e-04 - mae: 0.0088 - mse: 1.7943e-04\n",
      "Epoch 139: val_loss did not improve from 0.00057\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7715e-04 - mae: 0.0087 - mse: 1.7715e-04 - val_loss: 5.8709e-04 - val_mae: 0.0144 - val_mse: 5.8709e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6017e-04 - mae: 0.0087 - mse: 1.6017e-04\n",
      "Epoch 140: val_loss improved from 0.00057 to 0.00057, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7074e-04 - mae: 0.0087 - mse: 1.7074e-04 - val_loss: 5.7145e-04 - val_mae: 0.0142 - val_mse: 5.7145e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4814e-04 - mae: 0.0084 - mse: 1.4814e-04\n",
      "Epoch 141: val_loss improved from 0.00057 to 0.00055, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6799e-04 - mae: 0.0087 - mse: 1.6799e-04 - val_loss: 5.5093e-04 - val_mae: 0.0142 - val_mse: 5.5093e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7647e-04 - mae: 0.0087 - mse: 1.7647e-04\n",
      "Epoch 142: val_loss improved from 0.00055 to 0.00055, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6024e-04 - mae: 0.0085 - mse: 1.6024e-04 - val_loss: 5.4800e-04 - val_mae: 0.0140 - val_mse: 5.4800e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3787e-04 - mae: 0.0080 - mse: 1.3787e-04\n",
      "Epoch 143: val_loss did not improve from 0.00055\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.5484e-04 - mae: 0.0083 - mse: 1.5484e-04 - val_loss: 5.6082e-04 - val_mae: 0.0142 - val_mse: 5.6082e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3718e-04 - mae: 0.0080 - mse: 1.3718e-04\n",
      "Epoch 144: val_loss improved from 0.00055 to 0.00054, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5609e-04 - mae: 0.0083 - mse: 1.5609e-04 - val_loss: 5.3865e-04 - val_mae: 0.0140 - val_mse: 5.3865e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5972e-04 - mae: 0.0086 - mse: 1.5972e-04\n",
      "Epoch 145: val_loss improved from 0.00054 to 0.00052, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4761e-04 - mae: 0.0083 - mse: 1.4761e-04 - val_loss: 5.2365e-04 - val_mae: 0.0139 - val_mse: 5.2365e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5234e-04 - mae: 0.0083 - mse: 1.5234e-04\n",
      "Epoch 146: val_loss did not improve from 0.00052\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5671e-04 - mae: 0.0083 - mse: 1.5671e-04 - val_loss: 5.3624e-04 - val_mae: 0.0139 - val_mse: 5.3624e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3560e-04 - mae: 0.0080 - mse: 1.3560e-04\n",
      "Epoch 147: val_loss did not improve from 0.00052\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5036e-04 - mae: 0.0082 - mse: 1.5036e-04 - val_loss: 5.4700e-04 - val_mae: 0.0139 - val_mse: 5.4700e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4897e-04 - mae: 0.0080 - mse: 1.4897e-04\n",
      "Epoch 148: val_loss did not improve from 0.00052\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3978e-04 - mae: 0.0079 - mse: 1.3978e-04 - val_loss: 5.3735e-04 - val_mae: 0.0137 - val_mse: 5.3735e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6210e-04 - mae: 0.0082 - mse: 1.6210e-04\n",
      "Epoch 149: val_loss improved from 0.00052 to 0.00052, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4586e-04 - mae: 0.0080 - mse: 1.4586e-04 - val_loss: 5.2156e-04 - val_mae: 0.0134 - val_mse: 5.2156e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1561e-04 - mae: 0.0075 - mse: 1.1561e-04\n",
      "Epoch 150: val_loss did not improve from 0.00052\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3445e-04 - mae: 0.0077 - mse: 1.3445e-04 - val_loss: 5.2741e-04 - val_mae: 0.0136 - val_mse: 5.2741e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6142e-04 - mae: 0.0082 - mse: 1.6142e-04\n",
      "Epoch 151: val_loss did not improve from 0.00052\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4481e-04 - mae: 0.0080 - mse: 1.4481e-04 - val_loss: 5.2441e-04 - val_mae: 0.0135 - val_mse: 5.2441e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2249e-04 - mae: 0.0075 - mse: 1.2249e-04\n",
      "Epoch 152: val_loss did not improve from 0.00052\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3349e-04 - mae: 0.0077 - mse: 1.3349e-04 - val_loss: 5.3143e-04 - val_mae: 0.0137 - val_mse: 5.3143e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2327e-04 - mae: 0.0076 - mse: 1.2327e-04\n",
      "Epoch 153: val_loss improved from 0.00052 to 0.00052, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4079e-04 - mae: 0.0078 - mse: 1.4079e-04 - val_loss: 5.2001e-04 - val_mae: 0.0135 - val_mse: 5.2001e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2184e-04 - mae: 0.0075 - mse: 1.2184e-04\n",
      "Epoch 154: val_loss improved from 0.00052 to 0.00051, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2801e-04 - mae: 0.0076 - mse: 1.2801e-04 - val_loss: 5.0824e-04 - val_mae: 0.0134 - val_mse: 5.0824e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1428e-04 - mae: 0.0074 - mse: 1.1428e-04\n",
      "Epoch 155: val_loss improved from 0.00051 to 0.00050, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2971e-04 - mae: 0.0076 - mse: 1.2971e-04 - val_loss: 4.9618e-04 - val_mae: 0.0133 - val_mse: 4.9618e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1272e-04 - mae: 0.0072 - mse: 1.1272e-04\n",
      "Epoch 156: val_loss improved from 0.00050 to 0.00048, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3096e-04 - mae: 0.0076 - mse: 1.3096e-04 - val_loss: 4.8452e-04 - val_mae: 0.0133 - val_mse: 4.8452e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1421e-04 - mae: 0.0072 - mse: 1.1421e-04\n",
      "Epoch 157: val_loss improved from 0.00048 to 0.00047, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2859e-04 - mae: 0.0075 - mse: 1.2859e-04 - val_loss: 4.7476e-04 - val_mae: 0.0131 - val_mse: 4.7476e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0485e-04 - mae: 0.0072 - mse: 1.0485e-04\n",
      "Epoch 158: val_loss improved from 0.00047 to 0.00047, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2601e-04 - mae: 0.0076 - mse: 1.2601e-04 - val_loss: 4.7257e-04 - val_mae: 0.0131 - val_mse: 4.7257e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2992e-04 - mae: 0.0077 - mse: 1.2992e-04\n",
      "Epoch 159: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2016e-04 - mae: 0.0075 - mse: 1.2016e-04 - val_loss: 4.7340e-04 - val_mae: 0.0130 - val_mse: 4.7340e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3461e-04 - mae: 0.0076 - mse: 1.3461e-04\n",
      "Epoch 160: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2387e-04 - mae: 0.0075 - mse: 1.2387e-04 - val_loss: 4.7627e-04 - val_mae: 0.0130 - val_mse: 4.7627e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0412e-04 - mae: 0.0070 - mse: 1.0412e-04\n",
      "Epoch 161: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1940e-04 - mae: 0.0074 - mse: 1.1940e-04 - val_loss: 4.8017e-04 - val_mae: 0.0130 - val_mse: 4.8017e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1424e-04 - mae: 0.0072 - mse: 1.1424e-04\n",
      "Epoch 162: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2467e-04 - mae: 0.0073 - mse: 1.2467e-04 - val_loss: 4.8501e-04 - val_mae: 0.0131 - val_mse: 4.8501e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2163e-04 - mae: 0.0072 - mse: 1.2163e-04\n",
      "Epoch 163: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3096e-04 - mae: 0.0074 - mse: 1.3096e-04 - val_loss: 4.9188e-04 - val_mae: 0.0132 - val_mse: 4.9188e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2758e-04 - mae: 0.0073 - mse: 1.2758e-04\n",
      "Epoch 164: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2548e-04 - mae: 0.0074 - mse: 1.2548e-04 - val_loss: 4.9076e-04 - val_mae: 0.0131 - val_mse: 4.9076e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2204e-04 - mae: 0.0074 - mse: 1.2204e-04\n",
      "Epoch 165: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1977e-04 - mae: 0.0074 - mse: 1.1977e-04 - val_loss: 4.7698e-04 - val_mae: 0.0129 - val_mse: 4.7698e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1399e-04 - mae: 0.0071 - mse: 1.1399e-04\n",
      "Epoch 166: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2049e-04 - mae: 0.0072 - mse: 1.2049e-04 - val_loss: 4.7876e-04 - val_mae: 0.0128 - val_mse: 4.7876e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2470e-04 - mae: 0.0072 - mse: 1.2470e-04\n",
      "Epoch 167: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1781e-04 - mae: 0.0071 - mse: 1.1781e-04 - val_loss: 4.8248e-04 - val_mae: 0.0128 - val_mse: 4.8248e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0177e-04 - mae: 0.0068 - mse: 1.0177e-04\n",
      "Epoch 168: val_loss improved from 0.00047 to 0.00046, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1147e-04 - mae: 0.0071 - mse: 1.1147e-04 - val_loss: 4.6432e-04 - val_mae: 0.0126 - val_mse: 4.6432e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6515e-05 - mae: 0.0068 - mse: 9.6515e-05\n",
      "Epoch 169: val_loss improved from 0.00046 to 0.00045, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0787e-04 - mae: 0.0069 - mse: 1.0787e-04 - val_loss: 4.5330e-04 - val_mae: 0.0125 - val_mse: 4.5330e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0409e-04 - mae: 0.0070 - mse: 1.0409e-04\n",
      "Epoch 170: val_loss improved from 0.00045 to 0.00045, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.0727e-04 - mae: 0.0069 - mse: 1.0727e-04 - val_loss: 4.5099e-04 - val_mae: 0.0125 - val_mse: 4.5099e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1659e-04 - mae: 0.0071 - mse: 1.1659e-04\n",
      "Epoch 171: val_loss did not improve from 0.00045\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0789e-04 - mae: 0.0070 - mse: 1.0789e-04 - val_loss: 4.5659e-04 - val_mae: 0.0125 - val_mse: 4.5659e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7615e-05 - mae: 0.0067 - mse: 9.7615e-05\n",
      "Epoch 172: val_loss did not improve from 0.00045\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0395e-04 - mae: 0.0068 - mse: 1.0395e-04 - val_loss: 4.5538e-04 - val_mae: 0.0124 - val_mse: 4.5538e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0344e-04 - mae: 0.0067 - mse: 1.0344e-04\n",
      "Epoch 173: val_loss improved from 0.00045 to 0.00045, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0316e-04 - mae: 0.0067 - mse: 1.0316e-04 - val_loss: 4.4894e-04 - val_mae: 0.0123 - val_mse: 4.4894e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2788e-05 - mae: 0.0066 - mse: 9.2788e-05\n",
      "Epoch 174: val_loss did not improve from 0.00045\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0306e-04 - mae: 0.0066 - mse: 1.0306e-04 - val_loss: 4.5282e-04 - val_mae: 0.0123 - val_mse: 4.5282e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9394e-05 - mae: 0.0066 - mse: 9.9394e-05\n",
      "Epoch 175: val_loss improved from 0.00045 to 0.00044, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.9092e-05 - mae: 0.0067 - mse: 9.9092e-05 - val_loss: 4.3806e-04 - val_mae: 0.0121 - val_mse: 4.3806e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0120e-04 - mae: 0.0065 - mse: 1.0120e-04\n",
      "Epoch 176: val_loss improved from 0.00044 to 0.00044, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0042e-04 - mae: 0.0067 - mse: 1.0042e-04 - val_loss: 4.3763e-04 - val_mae: 0.0122 - val_mse: 4.3763e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0868e-04 - mae: 0.0068 - mse: 1.0868e-04\n",
      "Epoch 177: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.9532e-05 - mae: 0.0067 - mse: 9.9532e-05 - val_loss: 4.5804e-04 - val_mae: 0.0124 - val_mse: 4.5804e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0936e-04 - mae: 0.0069 - mse: 1.0936e-04\n",
      "Epoch 178: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.8402e-05 - mae: 0.0066 - mse: 9.8402e-05 - val_loss: 4.5766e-04 - val_mae: 0.0122 - val_mse: 4.5766e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2330e-05 - mae: 0.0063 - mse: 8.2330e-05\n",
      "Epoch 179: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.5091e-05 - mae: 0.0064 - mse: 9.5091e-05 - val_loss: 4.4096e-04 - val_mae: 0.0121 - val_mse: 4.4096e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4630e-05 - mae: 0.0065 - mse: 9.4630e-05\n",
      "Epoch 180: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.4596e-05 - mae: 0.0065 - mse: 9.4596e-05 - val_loss: 4.4125e-04 - val_mae: 0.0120 - val_mse: 4.4125e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6310e-05 - mae: 0.0064 - mse: 9.6310e-05\n",
      "Epoch 181: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3668e-05 - mae: 0.0064 - mse: 9.3668e-05 - val_loss: 4.5901e-04 - val_mae: 0.0123 - val_mse: 4.5901e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0361e-04 - mae: 0.0067 - mse: 1.0361e-04\n",
      "Epoch 182: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.1508e-05 - mae: 0.0064 - mse: 9.1508e-05 - val_loss: 4.5534e-04 - val_mae: 0.0121 - val_mse: 4.5534e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0259e-04 - mae: 0.0065 - mse: 1.0259e-04\n",
      "Epoch 183: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.9693e-05 - mae: 0.0062 - mse: 8.9693e-05 - val_loss: 4.4971e-04 - val_mae: 0.0121 - val_mse: 4.4971e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8055e-05 - mae: 0.0064 - mse: 9.8055e-05\n",
      "Epoch 184: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.9075e-05 - mae: 0.0062 - mse: 8.9075e-05 - val_loss: 4.5084e-04 - val_mae: 0.0120 - val_mse: 4.5084e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9111e-05 - mae: 0.0065 - mse: 9.9111e-05\n",
      "Epoch 185: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.8118e-05 - mae: 0.0062 - mse: 8.8118e-05 - val_loss: 4.5022e-04 - val_mae: 0.0120 - val_mse: 4.5022e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1579e-05 - mae: 0.0062 - mse: 9.1579e-05\n",
      "Epoch 186: val_loss did not improve from 0.00044\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.9225e-05 - mae: 0.0062 - mse: 8.9225e-05 - val_loss: 4.4065e-04 - val_mae: 0.0119 - val_mse: 4.4065e-04\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9950e-05 - mae: 0.0055 - mse: 5.9950e-05\n",
      "Epoch 187: val_loss improved from 0.00044 to 0.00044, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.8441e-05 - mae: 0.0061 - mse: 8.8441e-05 - val_loss: 4.3641e-04 - val_mae: 0.0119 - val_mse: 4.3641e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6599e-05 - mae: 0.0063 - mse: 9.6599e-05\n",
      "Epoch 188: val_loss improved from 0.00044 to 0.00043, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.4685e-05 - mae: 0.0060 - mse: 8.4685e-05 - val_loss: 4.3095e-04 - val_mae: 0.0118 - val_mse: 4.3095e-04\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5831e-05 - mae: 0.0062 - mse: 9.5831e-05\n",
      "Epoch 189: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.8845e-05 - mae: 0.0061 - mse: 8.8845e-05 - val_loss: 4.3199e-04 - val_mae: 0.0118 - val_mse: 4.3199e-04\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2897e-05 - mae: 0.0061 - mse: 9.2897e-05\n",
      "Epoch 190: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.4098e-05 - mae: 0.0060 - mse: 8.4098e-05 - val_loss: 4.3727e-04 - val_mae: 0.0118 - val_mse: 4.3727e-04\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8762e-05 - mae: 0.0060 - mse: 8.8762e-05\n",
      "Epoch 191: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.3573e-05 - mae: 0.0060 - mse: 8.3573e-05 - val_loss: 4.3587e-04 - val_mae: 0.0118 - val_mse: 4.3587e-04\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9628e-05 - mae: 0.0059 - mse: 7.9628e-05\n",
      "Epoch 192: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.5669e-05 - mae: 0.0060 - mse: 8.5669e-05 - val_loss: 4.3919e-04 - val_mae: 0.0118 - val_mse: 4.3919e-04\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0783e-05 - mae: 0.0060 - mse: 9.0783e-05\n",
      "Epoch 193: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.1874e-05 - mae: 0.0059 - mse: 8.1874e-05 - val_loss: 4.4506e-04 - val_mae: 0.0118 - val_mse: 4.4506e-04\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5028e-05 - mae: 0.0055 - mse: 7.5028e-05\n",
      "Epoch 194: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.5964e-05 - mae: 0.0059 - mse: 8.5964e-05 - val_loss: 4.4607e-04 - val_mae: 0.0119 - val_mse: 4.4607e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8128e-05 - mae: 0.0057 - mse: 6.8128e-05\n",
      "Epoch 195: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.2496e-05 - mae: 0.0059 - mse: 8.2496e-05 - val_loss: 4.3592e-04 - val_mae: 0.0117 - val_mse: 4.3592e-04\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.8591e-05 - mae: 0.0057 - mse: 7.8591e-05\n",
      "Epoch 196: val_loss improved from 0.00043 to 0.00043, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.0573e-05 - mae: 0.0058 - mse: 8.0573e-05 - val_loss: 4.2757e-04 - val_mae: 0.0116 - val_mse: 4.2757e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.8441e-05 - mae: 0.0060 - mse: 8.8441e-05\n",
      "Epoch 197: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.1052e-05 - mae: 0.0059 - mse: 8.1052e-05 - val_loss: 4.2947e-04 - val_mae: 0.0117 - val_mse: 4.2947e-04\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0819e-05 - mae: 0.0060 - mse: 8.0819e-05\n",
      "Epoch 198: val_loss did not improve from 0.00043\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.2004e-05 - mae: 0.0059 - mse: 8.2004e-05 - val_loss: 4.2760e-04 - val_mae: 0.0115 - val_mse: 4.2760e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3066e-05 - mae: 0.0055 - mse: 6.3066e-05\n",
      "Epoch 199: val_loss improved from 0.00043 to 0.00043, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.9486e-05 - mae: 0.0057 - mse: 7.9486e-05 - val_loss: 4.2613e-04 - val_mae: 0.0115 - val_mse: 4.2613e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0810e-05 - mae: 0.0061 - mse: 9.0810e-05\n",
      "Epoch 200: val_loss improved from 0.00043 to 0.00042, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.2048e-05 - mae: 0.0059 - mse: 8.2048e-05 - val_loss: 4.2232e-04 - val_mae: 0.0116 - val_mse: 4.2232e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1997e-05 - mae: 0.0058 - mse: 8.1997e-05\n",
      "Epoch 201: val_loss did not improve from 0.00042\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.8093e-05 - mae: 0.0058 - mse: 7.8093e-05 - val_loss: 4.2444e-04 - val_mae: 0.0116 - val_mse: 4.2444e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7841e-05 - mae: 0.0060 - mse: 8.7841e-05\n",
      "Epoch 202: val_loss did not improve from 0.00042\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.6836e-05 - mae: 0.0057 - mse: 7.6836e-05 - val_loss: 4.3029e-04 - val_mae: 0.0116 - val_mse: 4.3029e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0558e-05 - mae: 0.0058 - mse: 8.0558e-05\n",
      "Epoch 203: val_loss did not improve from 0.00042\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.7335e-05 - mae: 0.0057 - mse: 7.7335e-05 - val_loss: 4.2498e-04 - val_mae: 0.0116 - val_mse: 4.2498e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.2150e-05 - mae: 0.0055 - mse: 6.2150e-05\n",
      "Epoch 204: val_loss improved from 0.00042 to 0.00042, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.7324e-05 - mae: 0.0058 - mse: 7.7324e-05 - val_loss: 4.2222e-04 - val_mae: 0.0115 - val_mse: 4.2222e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6621e-05 - mae: 0.0056 - mse: 7.6621e-05\n",
      "Epoch 205: val_loss improved from 0.00042 to 0.00042, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.6317e-05 - mae: 0.0057 - mse: 7.6317e-05 - val_loss: 4.2046e-04 - val_mae: 0.0115 - val_mse: 4.2046e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0223e-05 - mae: 0.0059 - mse: 8.0223e-05\n",
      "Epoch 206: val_loss improved from 0.00042 to 0.00041, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.6304e-05 - mae: 0.0058 - mse: 7.6304e-05 - val_loss: 4.1113e-04 - val_mae: 0.0114 - val_mse: 4.1113e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8016e-05 - mae: 0.0054 - mse: 6.8016e-05\n",
      "Epoch 207: val_loss improved from 0.00041 to 0.00041, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.3518e-05 - mae: 0.0056 - mse: 7.3518e-05 - val_loss: 4.0785e-04 - val_mae: 0.0113 - val_mse: 4.0785e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4867e-05 - mae: 0.0056 - mse: 7.4867e-05\n",
      "Epoch 208: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3657e-05 - mae: 0.0057 - mse: 7.3657e-05 - val_loss: 4.2042e-04 - val_mae: 0.0113 - val_mse: 4.2042e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6538e-05 - mae: 0.0053 - mse: 6.6538e-05\n",
      "Epoch 209: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3676e-05 - mae: 0.0056 - mse: 7.3676e-05 - val_loss: 4.2798e-04 - val_mae: 0.0114 - val_mse: 4.2798e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4236e-05 - mae: 0.0059 - mse: 8.4236e-05\n",
      "Epoch 210: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.4138e-05 - mae: 0.0056 - mse: 7.4138e-05 - val_loss: 4.2095e-04 - val_mae: 0.0115 - val_mse: 4.2095e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0040e-05 - mae: 0.0058 - mse: 7.0040e-05\n",
      "Epoch 211: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.6965e-05 - mae: 0.0058 - mse: 7.6965e-05 - val_loss: 4.0987e-04 - val_mae: 0.0113 - val_mse: 4.0987e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5046e-05 - mae: 0.0056 - mse: 7.5046e-05\n",
      "Epoch 212: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.5460e-05 - mae: 0.0057 - mse: 7.5460e-05 - val_loss: 4.1220e-04 - val_mae: 0.0113 - val_mse: 4.1220e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8307e-05 - mae: 0.0053 - mse: 5.8307e-05\n",
      "Epoch 213: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.1788e-05 - mae: 0.0055 - mse: 7.1788e-05 - val_loss: 4.1595e-04 - val_mae: 0.0114 - val_mse: 4.1595e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3283e-05 - mae: 0.0053 - mse: 6.3283e-05\n",
      "Epoch 214: val_loss improved from 0.00041 to 0.00040, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.3500e-05 - mae: 0.0055 - mse: 7.3500e-05 - val_loss: 4.0007e-04 - val_mae: 0.0113 - val_mse: 4.0007e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6738e-05 - mae: 0.0057 - mse: 7.6738e-05\n",
      "Epoch 215: val_loss improved from 0.00040 to 0.00039, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.3652e-05 - mae: 0.0056 - mse: 7.3652e-05 - val_loss: 3.9070e-04 - val_mae: 0.0111 - val_mse: 3.9070e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9326e-05 - mae: 0.0057 - mse: 7.9326e-05\n",
      "Epoch 216: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0680e-05 - mae: 0.0055 - mse: 7.0680e-05 - val_loss: 3.9782e-04 - val_mae: 0.0111 - val_mse: 3.9782e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9268e-05 - mae: 0.0057 - mse: 6.9268e-05\n",
      "Epoch 217: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.3876e-05 - mae: 0.0057 - mse: 7.3876e-05 - val_loss: 3.9851e-04 - val_mae: 0.0111 - val_mse: 3.9851e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4075e-05 - mae: 0.0057 - mse: 7.4075e-05\n",
      "Epoch 218: val_loss improved from 0.00039 to 0.00039, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.9991e-05 - mae: 0.0056 - mse: 6.9991e-05 - val_loss: 3.8844e-04 - val_mae: 0.0109 - val_mse: 3.8844e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2550e-05 - mae: 0.0057 - mse: 7.2550e-05\n",
      "Epoch 219: val_loss improved from 0.00039 to 0.00039, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.8980e-05 - mae: 0.0055 - mse: 6.8980e-05 - val_loss: 3.8664e-04 - val_mae: 0.0108 - val_mse: 3.8664e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0477e-05 - mae: 0.0055 - mse: 7.0477e-05\n",
      "Epoch 220: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.6687e-05 - mae: 0.0054 - mse: 6.6687e-05 - val_loss: 3.9056e-04 - val_mae: 0.0109 - val_mse: 3.9056e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9199e-05 - mae: 0.0055 - mse: 6.9199e-05\n",
      "Epoch 221: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.8050e-05 - mae: 0.0054 - mse: 6.8050e-05 - val_loss: 3.9558e-04 - val_mae: 0.0110 - val_mse: 3.9558e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6325e-05 - mae: 0.0052 - mse: 5.6325e-05\n",
      "Epoch 222: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.6183e-05 - mae: 0.0054 - mse: 6.6183e-05 - val_loss: 3.9521e-04 - val_mae: 0.0109 - val_mse: 3.9521e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.5099e-05 - mae: 0.0051 - mse: 5.5099e-05\n",
      "Epoch 223: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4275e-05 - mae: 0.0053 - mse: 6.4275e-05 - val_loss: 3.8769e-04 - val_mae: 0.0108 - val_mse: 3.8769e-04\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2581e-05 - mae: 0.0056 - mse: 7.2581e-05\n",
      "Epoch 224: val_loss improved from 0.00039 to 0.00038, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.6559e-05 - mae: 0.0054 - mse: 6.6559e-05 - val_loss: 3.7964e-04 - val_mae: 0.0107 - val_mse: 3.7964e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2799e-05 - mae: 0.0056 - mse: 7.2799e-05\n",
      "Epoch 225: val_loss improved from 0.00038 to 0.00038, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.3269e-05 - mae: 0.0053 - mse: 6.3269e-05 - val_loss: 3.7953e-04 - val_mae: 0.0105 - val_mse: 3.7953e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5928e-05 - mae: 0.0052 - mse: 5.5928e-05\n",
      "Epoch 226: val_loss improved from 0.00038 to 0.00038, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.3350e-05 - mae: 0.0053 - mse: 6.3350e-05 - val_loss: 3.7736e-04 - val_mae: 0.0106 - val_mse: 3.7736e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6052e-05 - mae: 0.0053 - mse: 6.6052e-05\n",
      "Epoch 227: val_loss improved from 0.00038 to 0.00037, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1752e-05 - mae: 0.0052 - mse: 6.1752e-05 - val_loss: 3.7400e-04 - val_mae: 0.0106 - val_mse: 3.7400e-04\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5657e-05 - mae: 0.0053 - mse: 6.5657e-05\n",
      "Epoch 228: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0817e-05 - mae: 0.0051 - mse: 6.0817e-05 - val_loss: 3.7921e-04 - val_mae: 0.0106 - val_mse: 3.7921e-04\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0583e-05 - mae: 0.0051 - mse: 6.0583e-05\n",
      "Epoch 229: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.9790e-05 - mae: 0.0051 - mse: 5.9790e-05 - val_loss: 3.8373e-04 - val_mae: 0.0106 - val_mse: 3.8373e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0943e-05 - mae: 0.0051 - mse: 6.0943e-05\n",
      "Epoch 230: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.9954e-05 - mae: 0.0051 - mse: 5.9954e-05 - val_loss: 3.8552e-04 - val_mae: 0.0107 - val_mse: 3.8552e-04\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5472e-05 - mae: 0.0053 - mse: 6.5472e-05\n",
      "Epoch 231: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8916e-05 - mae: 0.0050 - mse: 5.8916e-05 - val_loss: 3.9403e-04 - val_mae: 0.0107 - val_mse: 3.9403e-04\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6767e-05 - mae: 0.0051 - mse: 5.6767e-05\n",
      "Epoch 232: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1115e-05 - mae: 0.0051 - mse: 6.1115e-05 - val_loss: 3.8745e-04 - val_mae: 0.0106 - val_mse: 3.8745e-04\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7893e-05 - mae: 0.0052 - mse: 6.7893e-05\n",
      "Epoch 233: val_loss improved from 0.00037 to 0.00037, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.0484e-05 - mae: 0.0050 - mse: 6.0484e-05 - val_loss: 3.7090e-04 - val_mae: 0.0105 - val_mse: 3.7090e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.1829e-05 - mae: 0.0050 - mse: 6.1829e-05\n",
      "Epoch 234: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.8383e-05 - mae: 0.0050 - mse: 5.8383e-05 - val_loss: 3.7648e-04 - val_mae: 0.0104 - val_mse: 3.7648e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3310e-05 - mae: 0.0045 - mse: 4.3310e-05\n",
      "Epoch 235: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.8077e-05 - mae: 0.0049 - mse: 5.8077e-05 - val_loss: 3.8327e-04 - val_mae: 0.0104 - val_mse: 3.8327e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3320e-05 - mae: 0.0047 - mse: 5.3320e-05\n",
      "Epoch 236: val_loss improved from 0.00037 to 0.00037, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.6924e-05 - mae: 0.0049 - mse: 5.6924e-05 - val_loss: 3.7008e-04 - val_mae: 0.0103 - val_mse: 3.7008e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1713e-05 - mae: 0.0049 - mse: 5.1713e-05\n",
      "Epoch 237: val_loss improved from 0.00037 to 0.00036, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.6782e-05 - mae: 0.0050 - mse: 5.6782e-05 - val_loss: 3.6439e-04 - val_mae: 0.0103 - val_mse: 3.6439e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3816e-05 - mae: 0.0048 - mse: 5.3816e-05\n",
      "Epoch 238: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6990e-05 - mae: 0.0049 - mse: 5.6990e-05 - val_loss: 3.7062e-04 - val_mae: 0.0103 - val_mse: 3.7062e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6045e-05 - mae: 0.0049 - mse: 5.6045e-05\n",
      "Epoch 239: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.5749e-05 - mae: 0.0049 - mse: 5.5749e-05 - val_loss: 3.7454e-04 - val_mae: 0.0104 - val_mse: 3.7454e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1847e-05 - mae: 0.0051 - mse: 6.1847e-05\n",
      "Epoch 240: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6652e-05 - mae: 0.0050 - mse: 5.6652e-05 - val_loss: 3.6760e-04 - val_mae: 0.0103 - val_mse: 3.6760e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8017e-05 - mae: 0.0049 - mse: 5.8017e-05\n",
      "Epoch 241: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4970e-05 - mae: 0.0049 - mse: 5.4970e-05 - val_loss: 3.6644e-04 - val_mae: 0.0102 - val_mse: 3.6644e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5979e-05 - mae: 0.0048 - mse: 5.5979e-05\n",
      "Epoch 242: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3743e-05 - mae: 0.0048 - mse: 5.3743e-05 - val_loss: 3.7117e-04 - val_mae: 0.0102 - val_mse: 3.7117e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6217e-05 - mae: 0.0049 - mse: 5.6217e-05\n",
      "Epoch 243: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.4527e-05 - mae: 0.0048 - mse: 5.4527e-05 - val_loss: 3.7019e-04 - val_mae: 0.0101 - val_mse: 3.7019e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3631e-05 - mae: 0.0046 - mse: 4.3631e-05\n",
      "Epoch 244: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.4182e-05 - mae: 0.0048 - mse: 5.4182e-05 - val_loss: 3.6652e-04 - val_mae: 0.0101 - val_mse: 3.6652e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1276e-05 - mae: 0.0046 - mse: 5.1276e-05\n",
      "Epoch 245: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 5.3283e-05 - mae: 0.0048 - mse: 5.3283e-05 - val_loss: 3.6864e-04 - val_mae: 0.0102 - val_mse: 3.6864e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.7889e-05 - mae: 0.0050 - mse: 5.7889e-05\n",
      "Epoch 246: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.6410e-05 - mae: 0.0049 - mse: 5.6410e-05 - val_loss: 3.6646e-04 - val_mae: 0.0101 - val_mse: 3.6646e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6544e-05 - mae: 0.0048 - mse: 5.6544e-05\n",
      "Epoch 247: val_loss improved from 0.00036 to 0.00036, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.3977e-05 - mae: 0.0047 - mse: 5.3977e-05 - val_loss: 3.6263e-04 - val_mae: 0.0101 - val_mse: 3.6263e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3900e-05 - mae: 0.0046 - mse: 5.3900e-05\n",
      "Epoch 248: val_loss improved from 0.00036 to 0.00036, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.4119e-05 - mae: 0.0048 - mse: 5.4119e-05 - val_loss: 3.6162e-04 - val_mae: 0.0101 - val_mse: 3.6162e-04\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9917e-05 - mae: 0.0046 - mse: 4.9917e-05\n",
      "Epoch 249: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1766e-05 - mae: 0.0047 - mse: 5.1766e-05 - val_loss: 3.6307e-04 - val_mae: 0.0101 - val_mse: 3.6307e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5643e-05 - mae: 0.0048 - mse: 5.5643e-05\n",
      "Epoch 250: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1703e-05 - mae: 0.0047 - mse: 5.1703e-05 - val_loss: 3.6954e-04 - val_mae: 0.0101 - val_mse: 3.6954e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.7251e-05 - mae: 0.0048 - mse: 5.7251e-05\n",
      "Epoch 251: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0709e-05 - mae: 0.0046 - mse: 5.0709e-05 - val_loss: 3.7412e-04 - val_mae: 0.0102 - val_mse: 3.7412e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.2969e-05 - mae: 0.0046 - mse: 5.2969e-05\n",
      "Epoch 252: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1806e-05 - mae: 0.0047 - mse: 5.1806e-05 - val_loss: 3.7116e-04 - val_mae: 0.0101 - val_mse: 3.7116e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9000e-05 - mae: 0.0043 - mse: 3.9000e-05\n",
      "Epoch 253: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0558e-05 - mae: 0.0046 - mse: 5.0558e-05 - val_loss: 3.6201e-04 - val_mae: 0.0100 - val_mse: 3.6201e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9513e-05 - mae: 0.0043 - mse: 4.9513e-05\n",
      "Epoch 254: val_loss improved from 0.00036 to 0.00036, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.0411e-05 - mae: 0.0046 - mse: 5.0411e-05 - val_loss: 3.5758e-04 - val_mae: 0.0100 - val_mse: 3.5758e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.2088e-05 - mae: 0.0044 - mse: 4.2088e-05\n",
      "Epoch 255: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1136e-05 - mae: 0.0046 - mse: 5.1136e-05 - val_loss: 3.6430e-04 - val_mae: 0.0100 - val_mse: 3.6430e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2713e-05 - mae: 0.0045 - mse: 4.2713e-05\n",
      "Epoch 256: val_loss did not improve from 0.00036\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8268e-05 - mae: 0.0045 - mse: 4.8268e-05 - val_loss: 3.6116e-04 - val_mae: 0.0099 - val_mse: 3.6116e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2044e-05 - mae: 0.0043 - mse: 4.2044e-05\n",
      "Epoch 257: val_loss improved from 0.00036 to 0.00035, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.9430e-05 - mae: 0.0046 - mse: 4.9430e-05 - val_loss: 3.5474e-04 - val_mae: 0.0099 - val_mse: 3.5474e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1088e-05 - mae: 0.0043 - mse: 4.1088e-05\n",
      "Epoch 258: val_loss improved from 0.00035 to 0.00035, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.8728e-05 - mae: 0.0045 - mse: 4.8728e-05 - val_loss: 3.5149e-04 - val_mae: 0.0099 - val_mse: 3.5149e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5169e-05 - mae: 0.0044 - mse: 4.5169e-05\n",
      "Epoch 259: val_loss improved from 0.00035 to 0.00035, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9612e-05 - mae: 0.0046 - mse: 4.9612e-05 - val_loss: 3.4749e-04 - val_mae: 0.0098 - val_mse: 3.4749e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3262e-05 - mae: 0.0047 - mse: 5.3262e-05\n",
      "Epoch 260: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.0201e-05 - mae: 0.0046 - mse: 5.0201e-05 - val_loss: 3.5035e-04 - val_mae: 0.0098 - val_mse: 3.5035e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4369e-05 - mae: 0.0048 - mse: 5.4369e-05\n",
      "Epoch 261: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9000e-05 - mae: 0.0046 - mse: 4.9000e-05 - val_loss: 3.5333e-04 - val_mae: 0.0098 - val_mse: 3.5333e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1278e-05 - mae: 0.0046 - mse: 5.1278e-05\n",
      "Epoch 262: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.7326e-05 - mae: 0.0045 - mse: 4.7326e-05 - val_loss: 3.5155e-04 - val_mae: 0.0098 - val_mse: 3.5155e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3158e-05 - mae: 0.0047 - mse: 5.3158e-05\n",
      "Epoch 263: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.6490e-05 - mae: 0.0044 - mse: 4.6490e-05 - val_loss: 3.4880e-04 - val_mae: 0.0097 - val_mse: 3.4880e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5824e-05 - mae: 0.0043 - mse: 4.5824e-05\n",
      "Epoch 264: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.6186e-05 - mae: 0.0045 - mse: 4.6186e-05 - val_loss: 3.5294e-04 - val_mae: 0.0097 - val_mse: 3.5294e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7722e-05 - mae: 0.0044 - mse: 4.7722e-05\n",
      "Epoch 265: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.5186e-05 - mae: 0.0044 - mse: 4.5186e-05 - val_loss: 3.6326e-04 - val_mae: 0.0099 - val_mse: 3.6326e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6516e-05 - mae: 0.0043 - mse: 4.6516e-05\n",
      "Epoch 266: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.6021e-05 - mae: 0.0044 - mse: 4.6021e-05 - val_loss: 3.5880e-04 - val_mae: 0.0098 - val_mse: 3.5880e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5863e-05 - mae: 0.0042 - mse: 4.5863e-05\n",
      "Epoch 267: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4514e-05 - mae: 0.0043 - mse: 4.4514e-05 - val_loss: 3.4882e-04 - val_mae: 0.0097 - val_mse: 3.4882e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9286e-05 - mae: 0.0042 - mse: 3.9286e-05\n",
      "Epoch 268: val_loss improved from 0.00035 to 0.00035, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.5559e-05 - mae: 0.0043 - mse: 4.5559e-05 - val_loss: 3.4730e-04 - val_mae: 0.0097 - val_mse: 3.4730e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5698e-05 - mae: 0.0043 - mse: 4.5698e-05\n",
      "Epoch 269: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5423e-05 - mae: 0.0043 - mse: 4.5423e-05 - val_loss: 3.4769e-04 - val_mae: 0.0097 - val_mse: 3.4769e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8291e-05 - mae: 0.0044 - mse: 4.8291e-05\n",
      "Epoch 270: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.5095e-05 - mae: 0.0044 - mse: 4.5095e-05 - val_loss: 3.5343e-04 - val_mae: 0.0098 - val_mse: 3.5343e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6203e-05 - mae: 0.0043 - mse: 4.6203e-05\n",
      "Epoch 271: val_loss did not improve from 0.00035\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6881e-05 - mae: 0.0044 - mse: 4.6881e-05 - val_loss: 3.5228e-04 - val_mae: 0.0097 - val_mse: 3.5228e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7469e-05 - mae: 0.0044 - mse: 4.7469e-05\n",
      "Epoch 272: val_loss improved from 0.00035 to 0.00034, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.5398e-05 - mae: 0.0044 - mse: 4.5398e-05 - val_loss: 3.4215e-04 - val_mae: 0.0095 - val_mse: 3.4215e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8067e-05 - mae: 0.0045 - mse: 4.8067e-05\n",
      "Epoch 273: val_loss improved from 0.00034 to 0.00034, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.5238e-05 - mae: 0.0044 - mse: 4.5238e-05 - val_loss: 3.3522e-04 - val_mae: 0.0094 - val_mse: 3.3522e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5071e-05 - mae: 0.0042 - mse: 4.5071e-05\n",
      "Epoch 274: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3893e-05 - mae: 0.0043 - mse: 4.3893e-05 - val_loss: 3.4485e-04 - val_mae: 0.0095 - val_mse: 3.4485e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5318e-05 - mae: 0.0040 - mse: 3.5318e-05\n",
      "Epoch 275: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2646e-05 - mae: 0.0042 - mse: 4.2646e-05 - val_loss: 3.5012e-04 - val_mae: 0.0095 - val_mse: 3.5012e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2364e-05 - mae: 0.0040 - mse: 4.2364e-05\n",
      "Epoch 276: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.3382e-05 - mae: 0.0042 - mse: 4.3382e-05 - val_loss: 3.4878e-04 - val_mae: 0.0094 - val_mse: 3.4878e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7024e-05 - mae: 0.0041 - mse: 3.7024e-05\n",
      "Epoch 277: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3401e-05 - mae: 0.0042 - mse: 4.3401e-05 - val_loss: 3.4667e-04 - val_mae: 0.0094 - val_mse: 3.4667e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6542e-05 - mae: 0.0043 - mse: 4.6542e-05\n",
      "Epoch 278: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2881e-05 - mae: 0.0042 - mse: 4.2881e-05 - val_loss: 3.3770e-04 - val_mae: 0.0094 - val_mse: 3.3770e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7106e-05 - mae: 0.0043 - mse: 4.7106e-05\n",
      "Epoch 279: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.2547e-05 - mae: 0.0042 - mse: 4.2547e-05 - val_loss: 3.4267e-04 - val_mae: 0.0094 - val_mse: 3.4267e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3979e-05 - mae: 0.0043 - mse: 4.3979e-05\n",
      "Epoch 280: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1478e-05 - mae: 0.0042 - mse: 4.1478e-05 - val_loss: 3.4406e-04 - val_mae: 0.0094 - val_mse: 3.4406e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5475e-05 - mae: 0.0040 - mse: 3.5475e-05\n",
      "Epoch 281: val_loss improved from 0.00034 to 0.00033, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.1757e-05 - mae: 0.0042 - mse: 4.1757e-05 - val_loss: 3.3492e-04 - val_mae: 0.0094 - val_mse: 3.3492e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5226e-05 - mae: 0.0043 - mse: 4.5226e-05\n",
      "Epoch 282: val_loss improved from 0.00033 to 0.00033, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.1582e-05 - mae: 0.0042 - mse: 4.1582e-05 - val_loss: 3.3165e-04 - val_mae: 0.0094 - val_mse: 3.3165e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2355e-05 - mae: 0.0042 - mse: 4.2355e-05\n",
      "Epoch 283: val_loss did not improve from 0.00033\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.1248e-05 - mae: 0.0042 - mse: 4.1248e-05 - val_loss: 3.3476e-04 - val_mae: 0.0094 - val_mse: 3.3476e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3905e-05 - mae: 0.0040 - mse: 3.3905e-05\n",
      "Epoch 284: val_loss did not improve from 0.00033\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2700e-05 - mae: 0.0043 - mse: 4.2700e-05 - val_loss: 3.3545e-04 - val_mae: 0.0094 - val_mse: 3.3545e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3222e-05 - mae: 0.0042 - mse: 4.3222e-05\n",
      "Epoch 285: val_loss improved from 0.00033 to 0.00033, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.0794e-05 - mae: 0.0042 - mse: 4.0794e-05 - val_loss: 3.2936e-04 - val_mae: 0.0093 - val_mse: 3.2936e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5688e-05 - mae: 0.0041 - mse: 3.5688e-05\n",
      "Epoch 286: val_loss improved from 0.00033 to 0.00033, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.4276e-05 - mae: 0.0043 - mse: 4.4276e-05 - val_loss: 3.2841e-04 - val_mae: 0.0093 - val_mse: 3.2841e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7648e-05 - mae: 0.0045 - mse: 4.7648e-05\n",
      "Epoch 287: val_loss did not improve from 0.00033\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5833e-05 - mae: 0.0045 - mse: 4.5833e-05 - val_loss: 3.2885e-04 - val_mae: 0.0093 - val_mse: 3.2885e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2168e-05 - mae: 0.0040 - mse: 3.2168e-05\n",
      "Epoch 288: val_loss improved from 0.00033 to 0.00033, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.5065e-05 - mae: 0.0044 - mse: 4.5065e-05 - val_loss: 3.2516e-04 - val_mae: 0.0092 - val_mse: 3.2516e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5194e-05 - mae: 0.0044 - mse: 4.5194e-05\n",
      "Epoch 289: val_loss improved from 0.00033 to 0.00032, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.2878e-05 - mae: 0.0044 - mse: 4.2878e-05 - val_loss: 3.2167e-04 - val_mae: 0.0092 - val_mse: 3.2167e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8412e-05 - mae: 0.0045 - mse: 4.8412e-05\n",
      "Epoch 290: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.4073e-05 - mae: 0.0044 - mse: 4.4073e-05 - val_loss: 3.3520e-04 - val_mae: 0.0094 - val_mse: 3.3520e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1216e-05 - mae: 0.0048 - mse: 5.1216e-05\n",
      "Epoch 291: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5058e-05 - mae: 0.0045 - mse: 4.5058e-05 - val_loss: 3.3519e-04 - val_mae: 0.0093 - val_mse: 3.3519e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2405e-05 - mae: 0.0042 - mse: 4.2405e-05\n",
      "Epoch 292: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.2919e-05 - mae: 0.0044 - mse: 4.2919e-05 - val_loss: 3.2903e-04 - val_mae: 0.0092 - val_mse: 3.2903e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.5639e-05 - mae: 0.0045 - mse: 4.5639e-05\n",
      "Epoch 293: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.3374e-05 - mae: 0.0044 - mse: 4.3374e-05 - val_loss: 3.3013e-04 - val_mae: 0.0092 - val_mse: 3.3013e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6420e-05 - mae: 0.0039 - mse: 3.6420e-05\n",
      "Epoch 294: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.2239e-05 - mae: 0.0043 - mse: 4.2239e-05 - val_loss: 3.3425e-04 - val_mae: 0.0093 - val_mse: 3.3425e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1731e-05 - mae: 0.0042 - mse: 4.1731e-05\n",
      "Epoch 295: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.2788e-05 - mae: 0.0043 - mse: 4.2788e-05 - val_loss: 3.3105e-04 - val_mae: 0.0092 - val_mse: 3.3105e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1356e-05 - mae: 0.0042 - mse: 4.1356e-05\n",
      "Epoch 296: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8702e-05 - mae: 0.0041 - mse: 3.8702e-05 - val_loss: 3.3637e-04 - val_mae: 0.0093 - val_mse: 3.3637e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0802e-05 - mae: 0.0045 - mse: 5.0802e-05\n",
      "Epoch 297: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.6447e-05 - mae: 0.0044 - mse: 4.6447e-05 - val_loss: 3.4743e-04 - val_mae: 0.0095 - val_mse: 3.4743e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3010e-05 - mae: 0.0048 - mse: 5.3010e-05\n",
      "Epoch 298: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.7055e-05 - mae: 0.0046 - mse: 4.7055e-05 - val_loss: 3.3490e-04 - val_mae: 0.0091 - val_mse: 3.3490e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.2166e-05 - mae: 0.0041 - mse: 4.2166e-05\n",
      "Epoch 299: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9048e-05 - mae: 0.0040 - mse: 3.9048e-05 - val_loss: 3.3515e-04 - val_mae: 0.0091 - val_mse: 3.3515e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9838e-05 - mae: 0.0039 - mse: 3.9838e-05\n",
      "Epoch 300: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.1819e-05 - mae: 0.0041 - mse: 4.1819e-05 - val_loss: 3.3717e-04 - val_mae: 0.0092 - val_mse: 3.3717e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0635e-05 - mae: 0.0040 - mse: 4.0635e-05\n",
      "Epoch 301: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.9402e-05 - mae: 0.0040 - mse: 3.9402e-05 - val_loss: 3.2880e-04 - val_mae: 0.0090 - val_mse: 3.2880e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0212e-05 - mae: 0.0040 - mse: 4.0212e-05\n",
      "Epoch 302: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7464e-05 - mae: 0.0040 - mse: 3.7464e-05 - val_loss: 3.3532e-04 - val_mae: 0.0091 - val_mse: 3.3532e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1533e-05 - mae: 0.0039 - mse: 3.1533e-05\n",
      "Epoch 303: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.8269e-05 - mae: 0.0040 - mse: 3.8269e-05 - val_loss: 3.3325e-04 - val_mae: 0.0090 - val_mse: 3.3325e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2467e-05 - mae: 0.0042 - mse: 4.2467e-05\n",
      "Epoch 304: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.7417e-05 - mae: 0.0040 - mse: 3.7417e-05 - val_loss: 3.2679e-04 - val_mae: 0.0090 - val_mse: 3.2679e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6277e-05 - mae: 0.0038 - mse: 3.6277e-05\n",
      "Epoch 305: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6893e-05 - mae: 0.0039 - mse: 3.6893e-05 - val_loss: 3.2710e-04 - val_mae: 0.0090 - val_mse: 3.2710e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7480e-05 - mae: 0.0036 - mse: 2.7480e-05\n",
      "Epoch 306: val_loss improved from 0.00032 to 0.00032, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.6626e-05 - mae: 0.0039 - mse: 3.6626e-05 - val_loss: 3.1832e-04 - val_mae: 0.0089 - val_mse: 3.1832e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8091e-05 - mae: 0.0040 - mse: 3.8091e-05\n",
      "Epoch 307: val_loss improved from 0.00032 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.6258e-05 - mae: 0.0040 - mse: 3.6258e-05 - val_loss: 3.1483e-04 - val_mae: 0.0088 - val_mse: 3.1483e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6570e-05 - mae: 0.0036 - mse: 2.6570e-05\n",
      "Epoch 308: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5876e-05 - mae: 0.0039 - mse: 3.5876e-05 - val_loss: 3.2227e-04 - val_mae: 0.0088 - val_mse: 3.2227e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5502e-05 - mae: 0.0038 - mse: 3.5502e-05\n",
      "Epoch 309: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6204e-05 - mae: 0.0039 - mse: 3.6204e-05 - val_loss: 3.2635e-04 - val_mae: 0.0088 - val_mse: 3.2635e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8693e-05 - mae: 0.0037 - mse: 2.8693e-05\n",
      "Epoch 310: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4926e-05 - mae: 0.0038 - mse: 3.4926e-05 - val_loss: 3.2282e-04 - val_mae: 0.0089 - val_mse: 3.2282e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4346e-05 - mae: 0.0038 - mse: 3.4346e-05\n",
      "Epoch 311: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5647e-05 - mae: 0.0039 - mse: 3.5647e-05 - val_loss: 3.1618e-04 - val_mae: 0.0088 - val_mse: 3.1618e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6032e-05 - mae: 0.0038 - mse: 3.6032e-05\n",
      "Epoch 312: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.4788e-05 - mae: 0.0038 - mse: 3.4788e-05 - val_loss: 3.2052e-04 - val_mae: 0.0089 - val_mse: 3.2052e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6604e-05 - mae: 0.0035 - mse: 2.6604e-05\n",
      "Epoch 313: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4894e-05 - mae: 0.0038 - mse: 3.4894e-05 - val_loss: 3.2076e-04 - val_mae: 0.0088 - val_mse: 3.2076e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7315e-05 - mae: 0.0035 - mse: 2.7315e-05\n",
      "Epoch 314: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3111e-05 - mae: 0.0037 - mse: 3.3111e-05 - val_loss: 3.1694e-04 - val_mae: 0.0087 - val_mse: 3.1694e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6180e-05 - mae: 0.0038 - mse: 3.6180e-05\n",
      "Epoch 315: val_loss improved from 0.00031 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.5315e-05 - mae: 0.0038 - mse: 3.5315e-05 - val_loss: 3.1367e-04 - val_mae: 0.0087 - val_mse: 3.1367e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3270e-05 - mae: 0.0036 - mse: 3.3270e-05\n",
      "Epoch 316: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4749e-05 - mae: 0.0038 - mse: 3.4749e-05 - val_loss: 3.2235e-04 - val_mae: 0.0088 - val_mse: 3.2235e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0940e-05 - mae: 0.0038 - mse: 3.0940e-05\n",
      "Epoch 317: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.4700e-05 - mae: 0.0038 - mse: 3.4700e-05 - val_loss: 3.2678e-04 - val_mae: 0.0089 - val_mse: 3.2678e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.4656e-05 - mae: 0.0038 - mse: 3.4656e-05\n",
      "Epoch 318: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3651e-05 - mae: 0.0038 - mse: 3.3651e-05 - val_loss: 3.1526e-04 - val_mae: 0.0088 - val_mse: 3.1526e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6936e-05 - mae: 0.0039 - mse: 3.6936e-05\n",
      "Epoch 319: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.6581e-05 - mae: 0.0040 - mse: 3.6581e-05 - val_loss: 3.1462e-04 - val_mae: 0.0087 - val_mse: 3.1462e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9166e-05 - mae: 0.0037 - mse: 2.9166e-05\n",
      "Epoch 320: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3329e-05 - mae: 0.0038 - mse: 3.3329e-05 - val_loss: 3.2551e-04 - val_mae: 0.0088 - val_mse: 3.2551e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.7119e-05 - mae: 0.0040 - mse: 3.7119e-05\n",
      "Epoch 321: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.3081e-05 - mae: 0.0038 - mse: 3.3081e-05 - val_loss: 3.2319e-04 - val_mae: 0.0088 - val_mse: 3.2319e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.6141e-05 - mae: 0.0039 - mse: 3.6141e-05\n",
      "Epoch 322: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4906e-05 - mae: 0.0039 - mse: 3.4906e-05 - val_loss: 3.1742e-04 - val_mae: 0.0087 - val_mse: 3.1742e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1562e-05 - mae: 0.0036 - mse: 3.1562e-05\n",
      "Epoch 323: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3916e-05 - mae: 0.0038 - mse: 3.3916e-05 - val_loss: 3.1640e-04 - val_mae: 0.0087 - val_mse: 3.1640e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5879e-05 - mae: 0.0039 - mse: 3.5879e-05\n",
      "Epoch 324: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3815e-05 - mae: 0.0038 - mse: 3.3815e-05 - val_loss: 3.1880e-04 - val_mae: 0.0087 - val_mse: 3.1880e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2579e-05 - mae: 0.0036 - mse: 3.2579e-05\n",
      "Epoch 325: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3546e-05 - mae: 0.0038 - mse: 3.3546e-05 - val_loss: 3.2049e-04 - val_mae: 0.0087 - val_mse: 3.2049e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2984e-05 - mae: 0.0038 - mse: 3.2984e-05\n",
      "Epoch 326: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.3349e-05 - mae: 0.0038 - mse: 3.3349e-05 - val_loss: 3.1944e-04 - val_mae: 0.0086 - val_mse: 3.1944e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6966e-05 - mae: 0.0036 - mse: 2.6966e-05\n",
      "Epoch 327: val_loss improved from 0.00031 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.2007e-05 - mae: 0.0037 - mse: 3.2007e-05 - val_loss: 3.1145e-04 - val_mae: 0.0086 - val_mse: 3.1145e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5012e-05 - mae: 0.0038 - mse: 3.5012e-05\n",
      "Epoch 328: val_loss improved from 0.00031 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.4059e-05 - mae: 0.0038 - mse: 3.4059e-05 - val_loss: 3.1062e-04 - val_mae: 0.0087 - val_mse: 3.1062e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6396e-05 - mae: 0.0040 - mse: 3.6396e-05\n",
      "Epoch 329: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.3276e-05 - mae: 0.0039 - mse: 3.3276e-05 - val_loss: 3.1833e-04 - val_mae: 0.0087 - val_mse: 3.1833e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 3.3436e-05 - mae: 0.0037 - mse: 3.3436e-05\n",
      "Epoch 330: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.2262e-05 - mae: 0.0037 - mse: 3.2262e-05 - val_loss: 3.2235e-04 - val_mae: 0.0087 - val_mse: 3.2235e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.2084e-05 - mae: 0.0037 - mse: 3.2084e-05\n",
      "Epoch 331: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.1275e-05 - mae: 0.0037 - mse: 3.1275e-05 - val_loss: 3.1678e-04 - val_mae: 0.0085 - val_mse: 3.1678e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0872e-05 - mae: 0.0035 - mse: 3.0872e-05\n",
      "Epoch 332: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9806e-05 - mae: 0.0035 - mse: 2.9806e-05 - val_loss: 3.1501e-04 - val_mae: 0.0085 - val_mse: 3.1501e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9359e-05 - mae: 0.0035 - mse: 2.9359e-05\n",
      "Epoch 333: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0707e-05 - mae: 0.0036 - mse: 3.0707e-05 - val_loss: 3.1772e-04 - val_mae: 0.0085 - val_mse: 3.1772e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4979e-05 - mae: 0.0035 - mse: 2.4979e-05\n",
      "Epoch 334: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0067e-05 - mae: 0.0036 - mse: 3.0067e-05 - val_loss: 3.2092e-04 - val_mae: 0.0085 - val_mse: 3.2092e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3230e-05 - mae: 0.0037 - mse: 3.3230e-05\n",
      "Epoch 335: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0135e-05 - mae: 0.0035 - mse: 3.0135e-05 - val_loss: 3.1692e-04 - val_mae: 0.0085 - val_mse: 3.1692e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4229e-05 - mae: 0.0034 - mse: 2.4229e-05\n",
      "Epoch 336: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0264e-05 - mae: 0.0036 - mse: 3.0264e-05 - val_loss: 3.1233e-04 - val_mae: 0.0085 - val_mse: 3.1233e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0242e-05 - mae: 0.0035 - mse: 3.0242e-05\n",
      "Epoch 337: val_loss improved from 0.00031 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.9512e-05 - mae: 0.0035 - mse: 2.9512e-05 - val_loss: 3.0961e-04 - val_mae: 0.0084 - val_mse: 3.0961e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5372e-05 - mae: 0.0034 - mse: 2.5372e-05\n",
      "Epoch 338: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9275e-05 - mae: 0.0035 - mse: 2.9275e-05 - val_loss: 3.1253e-04 - val_mae: 0.0085 - val_mse: 3.1253e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0132e-05 - mae: 0.0035 - mse: 3.0132e-05\n",
      "Epoch 339: val_loss did not improve from 0.00031\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.9018e-05 - mae: 0.0035 - mse: 2.9018e-05 - val_loss: 3.1235e-04 - val_mae: 0.0085 - val_mse: 3.1235e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8828e-05 - mae: 0.0035 - mse: 2.8828e-05\n",
      "Epoch 340: val_loss improved from 0.00031 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.8596e-05 - mae: 0.0035 - mse: 2.8596e-05 - val_loss: 3.0826e-04 - val_mae: 0.0084 - val_mse: 3.0826e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1033e-05 - mae: 0.0036 - mse: 3.1033e-05\n",
      "Epoch 341: val_loss improved from 0.00031 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.9408e-05 - mae: 0.0036 - mse: 2.9408e-05 - val_loss: 3.0430e-04 - val_mae: 0.0084 - val_mse: 3.0430e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0484e-05 - mae: 0.0035 - mse: 3.0484e-05\n",
      "Epoch 342: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9665e-05 - mae: 0.0035 - mse: 2.9665e-05 - val_loss: 3.0867e-04 - val_mae: 0.0084 - val_mse: 3.0867e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8437e-05 - mae: 0.0034 - mse: 2.8437e-05\n",
      "Epoch 343: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8715e-05 - mae: 0.0035 - mse: 2.8715e-05 - val_loss: 3.1386e-04 - val_mae: 0.0084 - val_mse: 3.1386e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.0023e-05 - mae: 0.0035 - mse: 3.0023e-05\n",
      "Epoch 344: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9995e-05 - mae: 0.0036 - mse: 2.9995e-05 - val_loss: 3.1069e-04 - val_mae: 0.0084 - val_mse: 3.1069e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1511e-05 - mae: 0.0037 - mse: 3.1511e-05\n",
      "Epoch 345: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.8846e-05 - mae: 0.0035 - mse: 2.8846e-05 - val_loss: 3.1234e-04 - val_mae: 0.0084 - val_mse: 3.1234e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0194e-05 - mae: 0.0036 - mse: 3.0194e-05\n",
      "Epoch 346: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.9027e-05 - mae: 0.0035 - mse: 2.9027e-05 - val_loss: 3.1807e-04 - val_mae: 0.0084 - val_mse: 3.1807e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4793e-05 - mae: 0.0034 - mse: 2.4793e-05\n",
      "Epoch 347: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.8230e-05 - mae: 0.0034 - mse: 2.8230e-05 - val_loss: 3.1298e-04 - val_mae: 0.0083 - val_mse: 3.1298e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0509e-05 - mae: 0.0035 - mse: 3.0509e-05\n",
      "Epoch 348: val_loss improved from 0.00030 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.7838e-05 - mae: 0.0034 - mse: 2.7838e-05 - val_loss: 3.0268e-04 - val_mae: 0.0083 - val_mse: 3.0268e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7479e-05 - mae: 0.0034 - mse: 2.7479e-05\n",
      "Epoch 349: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.7899e-05 - mae: 0.0035 - mse: 2.7899e-05 - val_loss: 3.0481e-04 - val_mae: 0.0083 - val_mse: 3.0481e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0530e-05 - mae: 0.0035 - mse: 3.0530e-05\n",
      "Epoch 350: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.7911e-05 - mae: 0.0034 - mse: 2.7911e-05 - val_loss: 3.0757e-04 - val_mae: 0.0083 - val_mse: 3.0757e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2448e-05 - mae: 0.0032 - mse: 2.2448e-05\n",
      "Epoch 351: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.8034e-05 - mae: 0.0034 - mse: 2.8034e-05 - val_loss: 3.0378e-04 - val_mae: 0.0083 - val_mse: 3.0378e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8129e-05 - mae: 0.0034 - mse: 2.8129e-05\n",
      "Epoch 352: val_loss improved from 0.00030 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.7525e-05 - mae: 0.0034 - mse: 2.7525e-05 - val_loss: 3.0063e-04 - val_mae: 0.0082 - val_mse: 3.0063e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6258e-05 - mae: 0.0033 - mse: 2.6258e-05\n",
      "Epoch 353: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.7406e-05 - mae: 0.0034 - mse: 2.7406e-05 - val_loss: 3.0335e-04 - val_mae: 0.0082 - val_mse: 3.0335e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.9653e-05 - mae: 0.0035 - mse: 2.9653e-05\n",
      "Epoch 354: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.6447e-05 - mae: 0.0033 - mse: 2.6447e-05 - val_loss: 3.0942e-04 - val_mae: 0.0083 - val_mse: 3.0942e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9625e-05 - mae: 0.0035 - mse: 2.9625e-05\n",
      "Epoch 355: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.7290e-05 - mae: 0.0034 - mse: 2.7290e-05 - val_loss: 3.0827e-04 - val_mae: 0.0083 - val_mse: 3.0827e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6248e-05 - mae: 0.0033 - mse: 2.6248e-05\n",
      "Epoch 356: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6564e-05 - mae: 0.0033 - mse: 2.6564e-05 - val_loss: 3.0731e-04 - val_mae: 0.0082 - val_mse: 3.0731e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8134e-05 - mae: 0.0034 - mse: 2.8134e-05\n",
      "Epoch 357: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7177e-05 - mae: 0.0034 - mse: 2.7177e-05 - val_loss: 3.0702e-04 - val_mae: 0.0082 - val_mse: 3.0702e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1721e-05 - mae: 0.0032 - mse: 2.1721e-05\n",
      "Epoch 358: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.6541e-05 - mae: 0.0033 - mse: 2.6541e-05 - val_loss: 3.0811e-04 - val_mae: 0.0082 - val_mse: 3.0811e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7052e-05 - mae: 0.0032 - mse: 2.7052e-05\n",
      "Epoch 359: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5868e-05 - mae: 0.0032 - mse: 2.5868e-05 - val_loss: 3.0649e-04 - val_mae: 0.0081 - val_mse: 3.0649e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5325e-05 - mae: 0.0031 - mse: 2.5325e-05\n",
      "Epoch 360: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5564e-05 - mae: 0.0032 - mse: 2.5564e-05 - val_loss: 3.0866e-04 - val_mae: 0.0081 - val_mse: 3.0866e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3912e-05 - mae: 0.0033 - mse: 2.3912e-05\n",
      "Epoch 361: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6320e-05 - mae: 0.0033 - mse: 2.6320e-05 - val_loss: 3.0627e-04 - val_mae: 0.0081 - val_mse: 3.0627e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7084e-05 - mae: 0.0033 - mse: 2.7084e-05\n",
      "Epoch 362: val_loss improved from 0.00030 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.6472e-05 - mae: 0.0033 - mse: 2.6472e-05 - val_loss: 2.9705e-04 - val_mae: 0.0080 - val_mse: 2.9705e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2999e-05 - mae: 0.0033 - mse: 2.2999e-05\n",
      "Epoch 363: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6374e-05 - mae: 0.0034 - mse: 2.6374e-05 - val_loss: 2.9855e-04 - val_mae: 0.0080 - val_mse: 2.9855e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8173e-05 - mae: 0.0034 - mse: 2.8173e-05\n",
      "Epoch 364: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5602e-05 - mae: 0.0033 - mse: 2.5602e-05 - val_loss: 2.9894e-04 - val_mae: 0.0080 - val_mse: 2.9894e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6213e-05 - mae: 0.0032 - mse: 2.6213e-05\n",
      "Epoch 365: val_loss improved from 0.00030 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 2.5653e-05 - mae: 0.0033 - mse: 2.5653e-05 - val_loss: 2.9584e-04 - val_mae: 0.0079 - val_mse: 2.9584e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.5409e-05 - mae: 0.0032 - mse: 2.5409e-05\n",
      "Epoch 366: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5067e-05 - mae: 0.0032 - mse: 2.5067e-05 - val_loss: 3.0269e-04 - val_mae: 0.0080 - val_mse: 3.0269e-04\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0672e-05 - mae: 0.0031 - mse: 2.0672e-05\n",
      "Epoch 367: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5257e-05 - mae: 0.0032 - mse: 2.5257e-05 - val_loss: 3.0785e-04 - val_mae: 0.0080 - val_mse: 3.0785e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6495e-05 - mae: 0.0033 - mse: 2.6495e-05\n",
      "Epoch 368: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.5334e-05 - mae: 0.0032 - mse: 2.5334e-05 - val_loss: 3.0289e-04 - val_mae: 0.0080 - val_mse: 3.0289e-04\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7693e-05 - mae: 0.0034 - mse: 2.7693e-05\n",
      "Epoch 369: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4150e-05 - mae: 0.0032 - mse: 2.4150e-05 - val_loss: 3.0256e-04 - val_mae: 0.0080 - val_mse: 3.0256e-04\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7879e-05 - mae: 0.0034 - mse: 2.7879e-05\n",
      "Epoch 370: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5055e-05 - mae: 0.0032 - mse: 2.5055e-05 - val_loss: 3.0719e-04 - val_mae: 0.0080 - val_mse: 3.0719e-04\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7170e-05 - mae: 0.0033 - mse: 2.7170e-05\n",
      "Epoch 371: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4882e-05 - mae: 0.0032 - mse: 2.4882e-05 - val_loss: 3.0889e-04 - val_mae: 0.0080 - val_mse: 3.0889e-04\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4044e-05 - mae: 0.0031 - mse: 2.4044e-05\n",
      "Epoch 372: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4483e-05 - mae: 0.0032 - mse: 2.4483e-05 - val_loss: 3.0637e-04 - val_mae: 0.0080 - val_mse: 3.0637e-04\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6662e-05 - mae: 0.0033 - mse: 2.6662e-05\n",
      "Epoch 373: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4695e-05 - mae: 0.0032 - mse: 2.4695e-05 - val_loss: 3.0630e-04 - val_mae: 0.0080 - val_mse: 3.0630e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0498e-05 - mae: 0.0030 - mse: 2.0498e-05\n",
      "Epoch 374: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4504e-05 - mae: 0.0032 - mse: 2.4504e-05 - val_loss: 2.9990e-04 - val_mae: 0.0080 - val_mse: 2.9990e-04\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7179e-05 - mae: 0.0033 - mse: 2.7179e-05\n",
      "Epoch 375: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4993e-05 - mae: 0.0032 - mse: 2.4993e-05 - val_loss: 2.9955e-04 - val_mae: 0.0080 - val_mse: 2.9955e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6368e-05 - mae: 0.0032 - mse: 2.6368e-05\n",
      "Epoch 376: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4062e-05 - mae: 0.0031 - mse: 2.4062e-05 - val_loss: 3.0951e-04 - val_mae: 0.0081 - val_mse: 3.0951e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9901e-05 - mae: 0.0030 - mse: 1.9901e-05\n",
      "Epoch 377: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4489e-05 - mae: 0.0031 - mse: 2.4489e-05 - val_loss: 3.0464e-04 - val_mae: 0.0080 - val_mse: 3.0464e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9835e-05 - mae: 0.0031 - mse: 1.9835e-05\n",
      "Epoch 378: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4496e-05 - mae: 0.0032 - mse: 2.4496e-05 - val_loss: 2.9921e-04 - val_mae: 0.0079 - val_mse: 2.9921e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2151e-05 - mae: 0.0029 - mse: 2.2151e-05\n",
      "Epoch 379: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.3945e-05 - mae: 0.0031 - mse: 2.3945e-05 - val_loss: 3.0093e-04 - val_mae: 0.0079 - val_mse: 3.0093e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9688e-05 - mae: 0.0031 - mse: 1.9688e-05\n",
      "Epoch 380: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3388e-05 - mae: 0.0032 - mse: 2.3388e-05 - val_loss: 2.9889e-04 - val_mae: 0.0079 - val_mse: 2.9889e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4479e-05 - mae: 0.0032 - mse: 2.4479e-05\n",
      "Epoch 381: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4190e-05 - mae: 0.0032 - mse: 2.4190e-05 - val_loss: 2.9953e-04 - val_mae: 0.0079 - val_mse: 2.9953e-04\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5605e-05 - mae: 0.0033 - mse: 2.5605e-05\n",
      "Epoch 382: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.3513e-05 - mae: 0.0032 - mse: 2.3513e-05 - val_loss: 3.0356e-04 - val_mae: 0.0078 - val_mse: 3.0356e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9791e-05 - mae: 0.0030 - mse: 1.9791e-05\n",
      "Epoch 383: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.2908e-05 - mae: 0.0031 - mse: 2.2908e-05 - val_loss: 3.0239e-04 - val_mae: 0.0079 - val_mse: 3.0239e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4384e-05 - mae: 0.0032 - mse: 2.4384e-05\n",
      "Epoch 384: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2946e-05 - mae: 0.0031 - mse: 2.2946e-05 - val_loss: 2.9961e-04 - val_mae: 0.0079 - val_mse: 2.9961e-04\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5518e-05 - mae: 0.0033 - mse: 2.5518e-05\n",
      "Epoch 385: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3008e-05 - mae: 0.0031 - mse: 2.3008e-05 - val_loss: 3.0273e-04 - val_mae: 0.0079 - val_mse: 3.0273e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5838e-05 - mae: 0.0033 - mse: 2.5838e-05\n",
      "Epoch 386: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2981e-05 - mae: 0.0031 - mse: 2.2981e-05 - val_loss: 3.0658e-04 - val_mae: 0.0078 - val_mse: 3.0658e-04\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5252e-05 - mae: 0.0032 - mse: 2.5252e-05\n",
      "Epoch 387: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2183e-05 - mae: 0.0030 - mse: 2.2183e-05 - val_loss: 3.0573e-04 - val_mae: 0.0078 - val_mse: 3.0573e-04\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0287e-05 - mae: 0.0028 - mse: 2.0287e-05\n",
      "Epoch 388: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2569e-05 - mae: 0.0030 - mse: 2.2569e-05 - val_loss: 3.0231e-04 - val_mae: 0.0078 - val_mse: 3.0231e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0606e-05 - mae: 0.0028 - mse: 2.0606e-05\n",
      "Epoch 389: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2304e-05 - mae: 0.0030 - mse: 2.2304e-05 - val_loss: 3.0286e-04 - val_mae: 0.0078 - val_mse: 3.0286e-04\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3367e-05 - mae: 0.0030 - mse: 2.3367e-05\n",
      "Epoch 390: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1926e-05 - mae: 0.0030 - mse: 2.1926e-05 - val_loss: 3.0652e-04 - val_mae: 0.0079 - val_mse: 3.0652e-04\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1144e-05 - mae: 0.0029 - mse: 2.1144e-05\n",
      "Epoch 391: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2414e-05 - mae: 0.0030 - mse: 2.2414e-05 - val_loss: 3.0654e-04 - val_mae: 0.0079 - val_mse: 3.0654e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9650e-05 - mae: 0.0030 - mse: 1.9650e-05\n",
      "Epoch 392: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2275e-05 - mae: 0.0030 - mse: 2.2275e-05 - val_loss: 3.0160e-04 - val_mae: 0.0078 - val_mse: 3.0160e-04\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4726e-05 - mae: 0.0031 - mse: 2.4726e-05\n",
      "Epoch 393: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2492e-05 - mae: 0.0030 - mse: 2.2492e-05 - val_loss: 2.9770e-04 - val_mae: 0.0077 - val_mse: 2.9770e-04\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3499e-05 - mae: 0.0030 - mse: 2.3499e-05\n",
      "Epoch 394: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2265e-05 - mae: 0.0030 - mse: 2.2265e-05 - val_loss: 3.0169e-04 - val_mae: 0.0078 - val_mse: 3.0169e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.3635e-05 - mae: 0.0031 - mse: 2.3635e-05\n",
      "Epoch 395: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2141e-05 - mae: 0.0031 - mse: 2.2141e-05 - val_loss: 3.0561e-04 - val_mae: 0.0078 - val_mse: 3.0561e-04\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1866e-05 - mae: 0.0029 - mse: 2.1866e-05\n",
      "Epoch 396: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1928e-05 - mae: 0.0030 - mse: 2.1928e-05 - val_loss: 3.0648e-04 - val_mae: 0.0078 - val_mse: 3.0648e-04\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9274e-05 - mae: 0.0030 - mse: 1.9274e-05\n",
      "Epoch 397: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2611e-05 - mae: 0.0031 - mse: 2.2611e-05 - val_loss: 3.0447e-04 - val_mae: 0.0078 - val_mse: 3.0447e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1752e-05 - mae: 0.0030 - mse: 2.1752e-05\n",
      "Epoch 398: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2261e-05 - mae: 0.0031 - mse: 2.2261e-05 - val_loss: 3.0624e-04 - val_mae: 0.0079 - val_mse: 3.0624e-04\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6666e-05 - mae: 0.0033 - mse: 2.6666e-05\n",
      "Epoch 399: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3648e-05 - mae: 0.0032 - mse: 2.3648e-05 - val_loss: 3.0574e-04 - val_mae: 0.0079 - val_mse: 3.0574e-04\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4586e-05 - mae: 0.0032 - mse: 2.4586e-05\n",
      "Epoch 400: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3241e-05 - mae: 0.0031 - mse: 2.3241e-05 - val_loss: 3.0378e-04 - val_mae: 0.0078 - val_mse: 3.0378e-04\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4059e-05 - mae: 0.0032 - mse: 2.4059e-05\n",
      "Epoch 401: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.1823e-05 - mae: 0.0030 - mse: 2.1823e-05 - val_loss: 3.0354e-04 - val_mae: 0.0078 - val_mse: 3.0354e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8740e-05 - mae: 0.0029 - mse: 1.8740e-05\n",
      "Epoch 402: val_loss did not improve from 0.00030\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.2951e-05 - mae: 0.0031 - mse: 2.2951e-05 - val_loss: 2.9881e-04 - val_mae: 0.0077 - val_mse: 2.9881e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3585e-05 - mae: 0.0031 - mse: 2.3585e-05\n",
      "Epoch 403: val_loss improved from 0.00030 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.1997e-05 - mae: 0.0030 - mse: 2.1997e-05 - val_loss: 2.9253e-04 - val_mae: 0.0077 - val_mse: 2.9253e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0814e-05 - mae: 0.0029 - mse: 2.0814e-05\n",
      "Epoch 404: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1636e-05 - mae: 0.0031 - mse: 2.1636e-05 - val_loss: 3.0046e-04 - val_mae: 0.0077 - val_mse: 3.0046e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9414e-05 - mae: 0.0030 - mse: 1.9414e-05\n",
      "Epoch 405: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2140e-05 - mae: 0.0031 - mse: 2.2140e-05 - val_loss: 3.0632e-04 - val_mae: 0.0078 - val_mse: 3.0632e-04\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2380e-05 - mae: 0.0030 - mse: 2.2380e-05\n",
      "Epoch 406: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1175e-05 - mae: 0.0030 - mse: 2.1175e-05 - val_loss: 3.0041e-04 - val_mae: 0.0077 - val_mse: 3.0041e-04\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8972e-05 - mae: 0.0030 - mse: 1.8972e-05\n",
      "Epoch 407: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1518e-05 - mae: 0.0030 - mse: 2.1518e-05 - val_loss: 2.9785e-04 - val_mae: 0.0076 - val_mse: 2.9785e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1498e-05 - mae: 0.0029 - mse: 2.1498e-05\n",
      "Epoch 408: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0875e-05 - mae: 0.0030 - mse: 2.0875e-05 - val_loss: 2.9639e-04 - val_mae: 0.0077 - val_mse: 2.9639e-04\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1765e-05 - mae: 0.0030 - mse: 2.1765e-05\n",
      "Epoch 409: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1765e-05 - mae: 0.0031 - mse: 2.1765e-05 - val_loss: 2.9700e-04 - val_mae: 0.0076 - val_mse: 2.9700e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2286e-05 - mae: 0.0030 - mse: 2.2286e-05\n",
      "Epoch 410: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1839e-05 - mae: 0.0030 - mse: 2.1839e-05 - val_loss: 3.0350e-04 - val_mae: 0.0077 - val_mse: 3.0350e-04\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1896e-05 - mae: 0.0030 - mse: 2.1896e-05\n",
      "Epoch 411: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2017e-05 - mae: 0.0031 - mse: 2.2017e-05 - val_loss: 2.9920e-04 - val_mae: 0.0077 - val_mse: 2.9920e-04\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9615e-05 - mae: 0.0029 - mse: 1.9615e-05\n",
      "Epoch 412: val_loss improved from 0.00029 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.2218e-05 - mae: 0.0031 - mse: 2.2218e-05 - val_loss: 2.9056e-04 - val_mae: 0.0076 - val_mse: 2.9056e-04\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1130e-05 - mae: 0.0029 - mse: 2.1130e-05\n",
      "Epoch 413: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1371e-05 - mae: 0.0030 - mse: 2.1371e-05 - val_loss: 2.9746e-04 - val_mae: 0.0077 - val_mse: 2.9746e-04\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4874e-05 - mae: 0.0032 - mse: 2.4874e-05\n",
      "Epoch 414: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2552e-05 - mae: 0.0031 - mse: 2.2552e-05 - val_loss: 3.0459e-04 - val_mae: 0.0078 - val_mse: 3.0459e-04\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3999e-05 - mae: 0.0032 - mse: 2.3999e-05\n",
      "Epoch 415: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2795e-05 - mae: 0.0031 - mse: 2.2795e-05 - val_loss: 3.0704e-04 - val_mae: 0.0078 - val_mse: 3.0704e-04\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1230e-05 - mae: 0.0029 - mse: 2.1230e-05\n",
      "Epoch 416: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1131e-05 - mae: 0.0029 - mse: 2.1131e-05 - val_loss: 3.0663e-04 - val_mae: 0.0077 - val_mse: 3.0663e-04\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1262e-05 - mae: 0.0029 - mse: 2.1262e-05\n",
      "Epoch 417: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9962e-05 - mae: 0.0029 - mse: 1.9962e-05 - val_loss: 3.0593e-04 - val_mae: 0.0077 - val_mse: 3.0593e-04\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3406e-05 - mae: 0.0031 - mse: 2.3406e-05\n",
      "Epoch 418: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.1621e-05 - mae: 0.0030 - mse: 2.1621e-05 - val_loss: 3.0816e-04 - val_mae: 0.0078 - val_mse: 3.0816e-04\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3001e-05 - mae: 0.0031 - mse: 2.3001e-05\n",
      "Epoch 419: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0992e-05 - mae: 0.0030 - mse: 2.0992e-05 - val_loss: 3.0603e-04 - val_mae: 0.0077 - val_mse: 3.0603e-04\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7062e-05 - mae: 0.0028 - mse: 1.7062e-05\n",
      "Epoch 420: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0384e-05 - mae: 0.0029 - mse: 2.0384e-05 - val_loss: 3.0002e-04 - val_mae: 0.0076 - val_mse: 3.0002e-04\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1081e-05 - mae: 0.0028 - mse: 2.1081e-05\n",
      "Epoch 421: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9751e-05 - mae: 0.0029 - mse: 1.9751e-05 - val_loss: 2.9746e-04 - val_mae: 0.0076 - val_mse: 2.9746e-04\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6254e-05 - mae: 0.0026 - mse: 1.6254e-05\n",
      "Epoch 422: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0581e-05 - mae: 0.0029 - mse: 2.0581e-05 - val_loss: 3.0032e-04 - val_mae: 0.0076 - val_mse: 3.0032e-04\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0407e-05 - mae: 0.0028 - mse: 2.0407e-05\n",
      "Epoch 423: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9128e-05 - mae: 0.0028 - mse: 1.9128e-05 - val_loss: 3.0096e-04 - val_mae: 0.0077 - val_mse: 3.0096e-04\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0346e-05 - mae: 0.0029 - mse: 2.0346e-05\n",
      "Epoch 424: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9594e-05 - mae: 0.0029 - mse: 1.9594e-05 - val_loss: 2.9878e-04 - val_mae: 0.0076 - val_mse: 2.9878e-04\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0453e-05 - mae: 0.0029 - mse: 2.0453e-05\n",
      "Epoch 425: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9596e-05 - mae: 0.0028 - mse: 1.9596e-05 - val_loss: 2.9580e-04 - val_mae: 0.0076 - val_mse: 2.9580e-04\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6720e-05 - mae: 0.0028 - mse: 1.6720e-05\n",
      "Epoch 426: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9115e-05 - mae: 0.0028 - mse: 1.9115e-05 - val_loss: 2.9595e-04 - val_mae: 0.0076 - val_mse: 2.9595e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1653e-05 - mae: 0.0029 - mse: 2.1653e-05\n",
      "Epoch 427: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9320e-05 - mae: 0.0028 - mse: 1.9320e-05 - val_loss: 2.9981e-04 - val_mae: 0.0076 - val_mse: 2.9981e-04\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1880e-05 - mae: 0.0029 - mse: 2.1880e-05\n",
      "Epoch 428: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9700e-05 - mae: 0.0028 - mse: 1.9700e-05 - val_loss: 2.9971e-04 - val_mae: 0.0075 - val_mse: 2.9971e-04\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7293e-05 - mae: 0.0028 - mse: 1.7293e-05\n",
      "Epoch 429: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8749e-05 - mae: 0.0028 - mse: 1.8749e-05 - val_loss: 2.9926e-04 - val_mae: 0.0076 - val_mse: 2.9926e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1699e-05 - mae: 0.0030 - mse: 2.1699e-05\n",
      "Epoch 430: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9653e-05 - mae: 0.0028 - mse: 1.9653e-05 - val_loss: 2.9929e-04 - val_mae: 0.0076 - val_mse: 2.9929e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0947e-05 - mae: 0.0028 - mse: 2.0947e-05\n",
      "Epoch 431: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9751e-05 - mae: 0.0028 - mse: 1.9751e-05 - val_loss: 2.9959e-04 - val_mae: 0.0076 - val_mse: 2.9959e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3547e-05 - mae: 0.0025 - mse: 1.3547e-05\n",
      "Epoch 432: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9643e-05 - mae: 0.0028 - mse: 1.9643e-05 - val_loss: 2.9799e-04 - val_mae: 0.0075 - val_mse: 2.9799e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7573e-05 - mae: 0.0027 - mse: 1.7573e-05\n",
      "Epoch 433: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8776e-05 - mae: 0.0028 - mse: 1.8776e-05 - val_loss: 2.9641e-04 - val_mae: 0.0075 - val_mse: 2.9641e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8239e-05 - mae: 0.0027 - mse: 1.8239e-05\n",
      "Epoch 434: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9161e-05 - mae: 0.0028 - mse: 1.9161e-05 - val_loss: 2.9877e-04 - val_mae: 0.0075 - val_mse: 2.9877e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0302e-05 - mae: 0.0029 - mse: 2.0302e-05\n",
      "Epoch 435: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9041e-05 - mae: 0.0029 - mse: 1.9041e-05 - val_loss: 2.9713e-04 - val_mae: 0.0075 - val_mse: 2.9713e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9620e-05 - mae: 0.0028 - mse: 1.9620e-05\n",
      "Epoch 436: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8602e-05 - mae: 0.0028 - mse: 1.8602e-05 - val_loss: 2.9598e-04 - val_mae: 0.0075 - val_mse: 2.9598e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1236e-05 - mae: 0.0030 - mse: 2.1236e-05\n",
      "Epoch 437: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9498e-05 - mae: 0.0029 - mse: 1.9498e-05 - val_loss: 2.9918e-04 - val_mae: 0.0076 - val_mse: 2.9918e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8496e-05 - mae: 0.0027 - mse: 1.8496e-05\n",
      "Epoch 438: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8745e-05 - mae: 0.0028 - mse: 1.8745e-05 - val_loss: 2.9640e-04 - val_mae: 0.0075 - val_mse: 2.9640e-04\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9128e-05 - mae: 0.0028 - mse: 1.9128e-05\n",
      "Epoch 439: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9175e-05 - mae: 0.0028 - mse: 1.9175e-05 - val_loss: 2.9773e-04 - val_mae: 0.0075 - val_mse: 2.9773e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6177e-05 - mae: 0.0027 - mse: 1.6177e-05\n",
      "Epoch 440: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0512e-05 - mae: 0.0029 - mse: 2.0512e-05 - val_loss: 2.9793e-04 - val_mae: 0.0075 - val_mse: 2.9793e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7535e-05 - mae: 0.0028 - mse: 1.7535e-05\n",
      "Epoch 441: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9415e-05 - mae: 0.0029 - mse: 1.9415e-05 - val_loss: 2.9259e-04 - val_mae: 0.0074 - val_mse: 2.9259e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9818e-05 - mae: 0.0028 - mse: 1.9818e-05\n",
      "Epoch 442: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9746e-05 - mae: 0.0029 - mse: 1.9746e-05 - val_loss: 2.9631e-04 - val_mae: 0.0076 - val_mse: 2.9631e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0915e-05 - mae: 0.0029 - mse: 2.0915e-05\n",
      "Epoch 443: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9936e-05 - mae: 0.0029 - mse: 1.9936e-05 - val_loss: 2.9925e-04 - val_mae: 0.0075 - val_mse: 2.9925e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0801e-05 - mae: 0.0030 - mse: 2.0801e-05\n",
      "Epoch 444: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0382e-05 - mae: 0.0030 - mse: 2.0382e-05 - val_loss: 2.9781e-04 - val_mae: 0.0075 - val_mse: 2.9781e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6468e-05 - mae: 0.0028 - mse: 1.6468e-05\n",
      "Epoch 445: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9351e-05 - mae: 0.0030 - mse: 1.9351e-05 - val_loss: 2.9612e-04 - val_mae: 0.0075 - val_mse: 2.9612e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9258e-05 - mae: 0.0029 - mse: 1.9258e-05\n",
      "Epoch 446: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9200e-05 - mae: 0.0029 - mse: 1.9200e-05 - val_loss: 2.9324e-04 - val_mae: 0.0075 - val_mse: 2.9324e-04\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8657e-05 - mae: 0.0030 - mse: 1.8657e-05\n",
      "Epoch 447: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9352e-05 - mae: 0.0029 - mse: 1.9352e-05 - val_loss: 2.9267e-04 - val_mae: 0.0075 - val_mse: 2.9267e-04\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0469e-05 - mae: 0.0030 - mse: 2.0469e-05\n",
      "Epoch 448: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9225e-05 - mae: 0.0029 - mse: 1.9225e-05 - val_loss: 2.9606e-04 - val_mae: 0.0075 - val_mse: 2.9606e-04\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8857e-05 - mae: 0.0029 - mse: 1.8857e-05\n",
      "Epoch 449: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8997e-05 - mae: 0.0029 - mse: 1.8997e-05 - val_loss: 2.9667e-04 - val_mae: 0.0075 - val_mse: 2.9667e-04\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0963e-05 - mae: 0.0030 - mse: 2.0963e-05\n",
      "Epoch 450: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9699e-05 - mae: 0.0030 - mse: 1.9699e-05 - val_loss: 2.9445e-04 - val_mae: 0.0075 - val_mse: 2.9445e-04\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7265e-05 - mae: 0.0029 - mse: 1.7265e-05\n",
      "Epoch 451: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9953e-05 - mae: 0.0029 - mse: 1.9953e-05 - val_loss: 2.9811e-04 - val_mae: 0.0075 - val_mse: 2.9811e-04\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8208e-05 - mae: 0.0028 - mse: 1.8208e-05\n",
      "Epoch 452: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8350e-05 - mae: 0.0028 - mse: 1.8350e-05 - val_loss: 2.9702e-04 - val_mae: 0.0074 - val_mse: 2.9702e-04\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8558e-05 - mae: 0.0028 - mse: 1.8558e-05\n",
      "Epoch 453: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8739e-05 - mae: 0.0029 - mse: 1.8739e-05 - val_loss: 2.9536e-04 - val_mae: 0.0074 - val_mse: 2.9536e-04\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8817e-05 - mae: 0.0028 - mse: 1.8817e-05\n",
      "Epoch 454: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8743e-05 - mae: 0.0028 - mse: 1.8743e-05 - val_loss: 2.9414e-04 - val_mae: 0.0074 - val_mse: 2.9414e-04\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9127e-05 - mae: 0.0029 - mse: 1.9127e-05\n",
      "Epoch 455: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7980e-05 - mae: 0.0028 - mse: 1.7980e-05 - val_loss: 2.9505e-04 - val_mae: 0.0074 - val_mse: 2.9505e-04\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8076e-05 - mae: 0.0028 - mse: 1.8076e-05\n",
      "Epoch 456: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8369e-05 - mae: 0.0028 - mse: 1.8369e-05 - val_loss: 3.0143e-04 - val_mae: 0.0074 - val_mse: 3.0143e-04\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9548e-05 - mae: 0.0029 - mse: 1.9548e-05\n",
      "Epoch 457: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8102e-05 - mae: 0.0028 - mse: 1.8102e-05 - val_loss: 3.0257e-04 - val_mae: 0.0075 - val_mse: 3.0257e-04\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9956e-05 - mae: 0.0029 - mse: 1.9956e-05\n",
      "Epoch 458: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9043e-05 - mae: 0.0029 - mse: 1.9043e-05 - val_loss: 2.9775e-04 - val_mae: 0.0074 - val_mse: 2.9775e-04\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8413e-05 - mae: 0.0028 - mse: 1.8413e-05\n",
      "Epoch 459: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.7472e-05 - mae: 0.0028 - mse: 1.7472e-05 - val_loss: 2.9509e-04 - val_mae: 0.0074 - val_mse: 2.9509e-04\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6369e-05 - mae: 0.0027 - mse: 1.6369e-05\n",
      "Epoch 460: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9789e-05 - mae: 0.0029 - mse: 1.9789e-05 - val_loss: 2.9368e-04 - val_mae: 0.0074 - val_mse: 2.9368e-04\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7708e-05 - mae: 0.0027 - mse: 1.7708e-05\n",
      "Epoch 461: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8550e-05 - mae: 0.0028 - mse: 1.8550e-05 - val_loss: 2.9262e-04 - val_mae: 0.0074 - val_mse: 2.9262e-04\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7272e-05 - mae: 0.0026 - mse: 1.7272e-05\n",
      "Epoch 462: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8057e-05 - mae: 0.0028 - mse: 1.8057e-05 - val_loss: 2.9833e-04 - val_mae: 0.0074 - val_mse: 2.9833e-04\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8766e-05 - mae: 0.0029 - mse: 1.8766e-05\n",
      "Epoch 463: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7947e-05 - mae: 0.0028 - mse: 1.7947e-05 - val_loss: 2.9541e-04 - val_mae: 0.0074 - val_mse: 2.9541e-04\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5427e-05 - mae: 0.0027 - mse: 1.5427e-05\n",
      "Epoch 464: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8390e-05 - mae: 0.0028 - mse: 1.8390e-05 - val_loss: 2.9209e-04 - val_mae: 0.0073 - val_mse: 2.9209e-04\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7933e-05 - mae: 0.0027 - mse: 1.7933e-05\n",
      "Epoch 465: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7531e-05 - mae: 0.0027 - mse: 1.7531e-05 - val_loss: 2.9387e-04 - val_mae: 0.0073 - val_mse: 2.9387e-04\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6617e-05 - mae: 0.0026 - mse: 1.6617e-05\n",
      "Epoch 466: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7111e-05 - mae: 0.0027 - mse: 1.7111e-05 - val_loss: 2.9446e-04 - val_mae: 0.0073 - val_mse: 2.9446e-04\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7004e-05 - mae: 0.0026 - mse: 1.7004e-05\n",
      "Epoch 467: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6581e-05 - mae: 0.0027 - mse: 1.6581e-05 - val_loss: 2.9481e-04 - val_mae: 0.0073 - val_mse: 2.9481e-04\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5364e-05 - mae: 0.0026 - mse: 1.5364e-05\n",
      "Epoch 468: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7517e-05 - mae: 0.0027 - mse: 1.7517e-05 - val_loss: 2.9585e-04 - val_mae: 0.0073 - val_mse: 2.9585e-04\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7402e-05 - mae: 0.0027 - mse: 1.7402e-05\n",
      "Epoch 469: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7679e-05 - mae: 0.0028 - mse: 1.7679e-05 - val_loss: 2.9280e-04 - val_mae: 0.0073 - val_mse: 2.9280e-04\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5918e-05 - mae: 0.0027 - mse: 1.5918e-05\n",
      "Epoch 470: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7031e-05 - mae: 0.0027 - mse: 1.7031e-05 - val_loss: 2.9556e-04 - val_mae: 0.0073 - val_mse: 2.9556e-04\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9210e-05 - mae: 0.0028 - mse: 1.9210e-05\n",
      "Epoch 471: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7851e-05 - mae: 0.0028 - mse: 1.7851e-05 - val_loss: 2.9563e-04 - val_mae: 0.0073 - val_mse: 2.9563e-04\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7096e-05 - mae: 0.0027 - mse: 1.7096e-05\n",
      "Epoch 472: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7080e-05 - mae: 0.0027 - mse: 1.7080e-05 - val_loss: 2.9476e-04 - val_mae: 0.0073 - val_mse: 2.9476e-04\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8224e-05 - mae: 0.0028 - mse: 1.8224e-05\n",
      "Epoch 473: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6462e-05 - mae: 0.0027 - mse: 1.6462e-05 - val_loss: 2.9862e-04 - val_mae: 0.0073 - val_mse: 2.9862e-04\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5637e-05 - mae: 0.0025 - mse: 1.5637e-05\n",
      "Epoch 474: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6673e-05 - mae: 0.0027 - mse: 1.6673e-05 - val_loss: 2.9588e-04 - val_mae: 0.0073 - val_mse: 2.9588e-04\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9146e-05 - mae: 0.0029 - mse: 1.9146e-05\n",
      "Epoch 475: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7887e-05 - mae: 0.0028 - mse: 1.7887e-05 - val_loss: 2.9520e-04 - val_mae: 0.0071 - val_mse: 2.9520e-04\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7027e-05 - mae: 0.0026 - mse: 1.7027e-05\n",
      "Epoch 476: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6199e-05 - mae: 0.0026 - mse: 1.6199e-05 - val_loss: 2.9771e-04 - val_mae: 0.0072 - val_mse: 2.9771e-04\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6178e-05 - mae: 0.0026 - mse: 1.6178e-05\n",
      "Epoch 477: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6338e-05 - mae: 0.0026 - mse: 1.6338e-05 - val_loss: 2.9574e-04 - val_mae: 0.0073 - val_mse: 2.9574e-04\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9226e-05 - mae: 0.0028 - mse: 1.9226e-05\n",
      "Epoch 478: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7397e-05 - mae: 0.0028 - mse: 1.7397e-05 - val_loss: 2.9742e-04 - val_mae: 0.0073 - val_mse: 2.9742e-04\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8206e-05 - mae: 0.0028 - mse: 1.8206e-05\n",
      "Epoch 479: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6624e-05 - mae: 0.0027 - mse: 1.6624e-05 - val_loss: 2.9845e-04 - val_mae: 0.0074 - val_mse: 2.9845e-04\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9110e-05 - mae: 0.0029 - mse: 1.9110e-05\n",
      "Epoch 480: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7375e-05 - mae: 0.0028 - mse: 1.7375e-05 - val_loss: 2.9474e-04 - val_mae: 0.0073 - val_mse: 2.9474e-04\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8706e-05 - mae: 0.0028 - mse: 1.8706e-05\n",
      "Epoch 481: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7320e-05 - mae: 0.0028 - mse: 1.7320e-05 - val_loss: 2.9477e-04 - val_mae: 0.0072 - val_mse: 2.9477e-04\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6167e-05 - mae: 0.0026 - mse: 1.6167e-05\n",
      "Epoch 482: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6455e-05 - mae: 0.0026 - mse: 1.6455e-05 - val_loss: 2.9757e-04 - val_mae: 0.0073 - val_mse: 2.9757e-04\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3874e-05 - mae: 0.0025 - mse: 1.3874e-05\n",
      "Epoch 483: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6495e-05 - mae: 0.0026 - mse: 1.6495e-05 - val_loss: 2.9247e-04 - val_mae: 0.0072 - val_mse: 2.9247e-04\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7511e-05 - mae: 0.0027 - mse: 1.7511e-05\n",
      "Epoch 484: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6345e-05 - mae: 0.0026 - mse: 1.6345e-05 - val_loss: 2.9581e-04 - val_mae: 0.0072 - val_mse: 2.9581e-04\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7155e-05 - mae: 0.0026 - mse: 1.7155e-05\n",
      "Epoch 485: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5898e-05 - mae: 0.0026 - mse: 1.5898e-05 - val_loss: 3.0031e-04 - val_mae: 0.0073 - val_mse: 3.0031e-04\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6162e-05 - mae: 0.0026 - mse: 1.6162e-05\n",
      "Epoch 486: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6076e-05 - mae: 0.0026 - mse: 1.6076e-05 - val_loss: 2.9134e-04 - val_mae: 0.0072 - val_mse: 2.9134e-04\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6816e-05 - mae: 0.0026 - mse: 1.6816e-05\n",
      "Epoch 487: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6045e-05 - mae: 0.0026 - mse: 1.6045e-05 - val_loss: 2.9350e-04 - val_mae: 0.0072 - val_mse: 2.9350e-04\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3573e-05 - mae: 0.0025 - mse: 1.3573e-05\n",
      "Epoch 488: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6065e-05 - mae: 0.0026 - mse: 1.6065e-05 - val_loss: 2.9491e-04 - val_mae: 0.0072 - val_mse: 2.9491e-04\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5909e-05 - mae: 0.0026 - mse: 1.5909e-05\n",
      "Epoch 489: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6013e-05 - mae: 0.0026 - mse: 1.6013e-05 - val_loss: 2.9099e-04 - val_mae: 0.0072 - val_mse: 2.9099e-04\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3974e-05 - mae: 0.0026 - mse: 1.3974e-05\n",
      "Epoch 490: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5887e-05 - mae: 0.0026 - mse: 1.5887e-05 - val_loss: 2.9333e-04 - val_mae: 0.0072 - val_mse: 2.9333e-04\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3314e-05 - mae: 0.0024 - mse: 1.3314e-05\n",
      "Epoch 491: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6174e-05 - mae: 0.0026 - mse: 1.6174e-05 - val_loss: 2.9221e-04 - val_mae: 0.0072 - val_mse: 2.9221e-04\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6611e-05 - mae: 0.0027 - mse: 1.6611e-05\n",
      "Epoch 492: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6132e-05 - mae: 0.0027 - mse: 1.6132e-05 - val_loss: 2.9346e-04 - val_mae: 0.0072 - val_mse: 2.9346e-04\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2535e-05 - mae: 0.0025 - mse: 1.2535e-05\n",
      "Epoch 493: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6461e-05 - mae: 0.0027 - mse: 1.6461e-05 - val_loss: 2.9249e-04 - val_mae: 0.0071 - val_mse: 2.9249e-04\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6997e-05 - mae: 0.0027 - mse: 1.6997e-05\n",
      "Epoch 494: val_loss improved from 0.00029 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5624e-05 - mae: 0.0026 - mse: 1.5624e-05 - val_loss: 2.9035e-04 - val_mae: 0.0072 - val_mse: 2.9035e-04\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6805e-05 - mae: 0.0027 - mse: 1.6805e-05\n",
      "Epoch 495: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7227e-05 - mae: 0.0028 - mse: 1.7227e-05 - val_loss: 2.9283e-04 - val_mae: 0.0071 - val_mse: 2.9283e-04\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3744e-05 - mae: 0.0026 - mse: 1.3744e-05\n",
      "Epoch 496: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6136e-05 - mae: 0.0027 - mse: 1.6136e-05 - val_loss: 2.9633e-04 - val_mae: 0.0072 - val_mse: 2.9633e-04\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6668e-05 - mae: 0.0027 - mse: 1.6668e-05\n",
      "Epoch 497: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5591e-05 - mae: 0.0026 - mse: 1.5591e-05 - val_loss: 2.9479e-04 - val_mae: 0.0072 - val_mse: 2.9479e-04\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5324e-05 - mae: 0.0026 - mse: 1.5324e-05\n",
      "Epoch 498: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6224e-05 - mae: 0.0027 - mse: 1.6224e-05 - val_loss: 2.9989e-04 - val_mae: 0.0073 - val_mse: 2.9989e-04\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8556e-05 - mae: 0.0029 - mse: 1.8556e-05\n",
      "Epoch 499: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7290e-05 - mae: 0.0028 - mse: 1.7290e-05 - val_loss: 2.9779e-04 - val_mae: 0.0071 - val_mse: 2.9779e-04\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3665e-05 - mae: 0.0025 - mse: 1.3665e-05\n",
      "Epoch 500: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5445e-05 - mae: 0.0026 - mse: 1.5445e-05 - val_loss: 2.9528e-04 - val_mae: 0.0071 - val_mse: 2.9528e-04\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6146e-05 - mae: 0.0026 - mse: 1.6146e-05\n",
      "Epoch 501: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5649e-05 - mae: 0.0026 - mse: 1.5649e-05 - val_loss: 3.0092e-04 - val_mae: 0.0074 - val_mse: 3.0092e-04\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0466e-05 - mae: 0.0031 - mse: 2.0466e-05\n",
      "Epoch 502: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.8019e-05 - mae: 0.0029 - mse: 1.8019e-05 - val_loss: 2.9515e-04 - val_mae: 0.0072 - val_mse: 2.9515e-04\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5569e-05 - mae: 0.0027 - mse: 1.5569e-05\n",
      "Epoch 503: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6834e-05 - mae: 0.0027 - mse: 1.6834e-05 - val_loss: 2.9370e-04 - val_mae: 0.0071 - val_mse: 2.9370e-04\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5506e-05 - mae: 0.0025 - mse: 1.5506e-05\n",
      "Epoch 504: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4974e-05 - mae: 0.0026 - mse: 1.4974e-05 - val_loss: 2.9718e-04 - val_mae: 0.0071 - val_mse: 2.9718e-04\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5461e-05 - mae: 0.0026 - mse: 1.5461e-05\n",
      "Epoch 505: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4383e-05 - mae: 0.0025 - mse: 1.4383e-05 - val_loss: 2.9756e-04 - val_mae: 0.0070 - val_mse: 2.9756e-04\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5139e-05 - mae: 0.0025 - mse: 1.5139e-05\n",
      "Epoch 506: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4021e-05 - mae: 0.0024 - mse: 1.4021e-05 - val_loss: 2.9565e-04 - val_mae: 0.0071 - val_mse: 2.9565e-04\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5213e-05 - mae: 0.0025 - mse: 1.5213e-05\n",
      "Epoch 507: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4323e-05 - mae: 0.0025 - mse: 1.4323e-05 - val_loss: 2.9412e-04 - val_mae: 0.0070 - val_mse: 2.9412e-04\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1692e-05 - mae: 0.0023 - mse: 1.1692e-05\n",
      "Epoch 508: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4243e-05 - mae: 0.0024 - mse: 1.4243e-05 - val_loss: 2.9400e-04 - val_mae: 0.0071 - val_mse: 2.9400e-04\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6235e-05 - mae: 0.0027 - mse: 1.6235e-05\n",
      "Epoch 509: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5224e-05 - mae: 0.0026 - mse: 1.5224e-05 - val_loss: 2.9473e-04 - val_mae: 0.0071 - val_mse: 2.9473e-04\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5199e-05 - mae: 0.0025 - mse: 1.5199e-05\n",
      "Epoch 510: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4671e-05 - mae: 0.0025 - mse: 1.4671e-05 - val_loss: 2.9806e-04 - val_mae: 0.0071 - val_mse: 2.9806e-04\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1654e-05 - mae: 0.0024 - mse: 1.1654e-05\n",
      "Epoch 511: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.4511e-05 - mae: 0.0025 - mse: 1.4511e-05 - val_loss: 2.9710e-04 - val_mae: 0.0070 - val_mse: 2.9710e-04\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1362e-05 - mae: 0.0023 - mse: 1.1362e-05\n",
      "Epoch 512: val_loss improved from 0.00029 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4720e-05 - mae: 0.0025 - mse: 1.4720e-05 - val_loss: 2.8896e-04 - val_mae: 0.0070 - val_mse: 2.8896e-04\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5317e-05 - mae: 0.0026 - mse: 1.5317e-05\n",
      "Epoch 513: val_loss improved from 0.00029 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.4748e-05 - mae: 0.0026 - mse: 1.4748e-05 - val_loss: 2.8658e-04 - val_mae: 0.0069 - val_mse: 2.8658e-04\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4364e-05 - mae: 0.0025 - mse: 1.4364e-05\n",
      "Epoch 514: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4128e-05 - mae: 0.0025 - mse: 1.4128e-05 - val_loss: 2.9497e-04 - val_mae: 0.0070 - val_mse: 2.9497e-04\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3734e-05 - mae: 0.0024 - mse: 1.3734e-05\n",
      "Epoch 515: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.3997e-05 - mae: 0.0025 - mse: 1.3997e-05 - val_loss: 2.9505e-04 - val_mae: 0.0070 - val_mse: 2.9505e-04\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4843e-05 - mae: 0.0025 - mse: 1.4843e-05\n",
      "Epoch 516: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4098e-05 - mae: 0.0025 - mse: 1.4098e-05 - val_loss: 2.9249e-04 - val_mae: 0.0070 - val_mse: 2.9249e-04\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2863e-05 - mae: 0.0025 - mse: 1.2863e-05\n",
      "Epoch 517: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4267e-05 - mae: 0.0025 - mse: 1.4267e-05 - val_loss: 2.9310e-04 - val_mae: 0.0070 - val_mse: 2.9310e-04\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3922e-05 - mae: 0.0024 - mse: 1.3922e-05\n",
      "Epoch 518: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3730e-05 - mae: 0.0024 - mse: 1.3730e-05 - val_loss: 2.9247e-04 - val_mae: 0.0070 - val_mse: 2.9247e-04\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5086e-05 - mae: 0.0026 - mse: 1.5086e-05\n",
      "Epoch 519: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3866e-05 - mae: 0.0025 - mse: 1.3866e-05 - val_loss: 2.9466e-04 - val_mae: 0.0070 - val_mse: 2.9466e-04\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1169e-05 - mae: 0.0023 - mse: 1.1169e-05\n",
      "Epoch 520: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4451e-05 - mae: 0.0025 - mse: 1.4451e-05 - val_loss: 2.9412e-04 - val_mae: 0.0069 - val_mse: 2.9412e-04\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3359e-05 - mae: 0.0024 - mse: 1.3359e-05\n",
      "Epoch 521: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3683e-05 - mae: 0.0024 - mse: 1.3683e-05 - val_loss: 2.9486e-04 - val_mae: 0.0070 - val_mse: 2.9486e-04\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0438e-05 - mae: 0.0022 - mse: 1.0438e-05\n",
      "Epoch 522: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4105e-05 - mae: 0.0025 - mse: 1.4105e-05 - val_loss: 2.9279e-04 - val_mae: 0.0070 - val_mse: 2.9279e-04\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4553e-05 - mae: 0.0026 - mse: 1.4553e-05\n",
      "Epoch 523: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5064e-05 - mae: 0.0026 - mse: 1.5064e-05 - val_loss: 2.9486e-04 - val_mae: 0.0070 - val_mse: 2.9486e-04\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4895e-05 - mae: 0.0026 - mse: 1.4895e-05\n",
      "Epoch 524: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5009e-05 - mae: 0.0026 - mse: 1.5009e-05 - val_loss: 2.9870e-04 - val_mae: 0.0070 - val_mse: 2.9870e-04\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3832e-05 - mae: 0.0026 - mse: 1.3832e-05\n",
      "Epoch 525: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6683e-05 - mae: 0.0028 - mse: 1.6683e-05 - val_loss: 2.9227e-04 - val_mae: 0.0071 - val_mse: 2.9227e-04\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6026e-05 - mae: 0.0027 - mse: 1.6026e-05\n",
      "Epoch 526: val_loss improved from 0.00029 to 0.00028, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7311e-05 - mae: 0.0028 - mse: 1.7311e-05 - val_loss: 2.8409e-04 - val_mae: 0.0070 - val_mse: 2.8409e-04\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3810e-05 - mae: 0.0026 - mse: 1.3810e-05\n",
      "Epoch 527: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6969e-05 - mae: 0.0028 - mse: 1.6969e-05 - val_loss: 2.8930e-04 - val_mae: 0.0070 - val_mse: 2.8930e-04\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5443e-05 - mae: 0.0027 - mse: 1.5443e-05\n",
      "Epoch 528: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6329e-05 - mae: 0.0028 - mse: 1.6329e-05 - val_loss: 2.9301e-04 - val_mae: 0.0070 - val_mse: 2.9301e-04\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4668e-05 - mae: 0.0027 - mse: 1.4668e-05\n",
      "Epoch 529: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5931e-05 - mae: 0.0027 - mse: 1.5931e-05 - val_loss: 2.9626e-04 - val_mae: 0.0070 - val_mse: 2.9626e-04\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6374e-05 - mae: 0.0027 - mse: 1.6374e-05\n",
      "Epoch 530: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5739e-05 - mae: 0.0026 - mse: 1.5739e-05 - val_loss: 2.9586e-04 - val_mae: 0.0071 - val_mse: 2.9586e-04\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4606e-05 - mae: 0.0027 - mse: 1.4606e-05\n",
      "Epoch 531: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6189e-05 - mae: 0.0028 - mse: 1.6189e-05 - val_loss: 2.9810e-04 - val_mae: 0.0071 - val_mse: 2.9810e-04\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6777e-05 - mae: 0.0028 - mse: 1.6777e-05\n",
      "Epoch 532: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6282e-05 - mae: 0.0028 - mse: 1.6282e-05 - val_loss: 3.0976e-04 - val_mae: 0.0072 - val_mse: 3.0976e-04\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7776e-05 - mae: 0.0028 - mse: 1.7776e-05\n",
      "Epoch 533: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6882e-05 - mae: 0.0028 - mse: 1.6882e-05 - val_loss: 3.0339e-04 - val_mae: 0.0070 - val_mse: 3.0339e-04\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6160e-05 - mae: 0.0027 - mse: 1.6160e-05\n",
      "Epoch 534: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4953e-05 - mae: 0.0026 - mse: 1.4953e-05 - val_loss: 2.9772e-04 - val_mae: 0.0070 - val_mse: 2.9772e-04\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4356e-05 - mae: 0.0025 - mse: 1.4356e-05\n",
      "Epoch 535: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4558e-05 - mae: 0.0025 - mse: 1.4558e-05 - val_loss: 2.9317e-04 - val_mae: 0.0070 - val_mse: 2.9317e-04\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5950e-05 - mae: 0.0026 - mse: 1.5950e-05\n",
      "Epoch 536: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4748e-05 - mae: 0.0026 - mse: 1.4748e-05 - val_loss: 2.9820e-04 - val_mae: 0.0070 - val_mse: 2.9820e-04\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5551e-05 - mae: 0.0026 - mse: 1.5551e-05\n",
      "Epoch 537: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3813e-05 - mae: 0.0025 - mse: 1.3813e-05 - val_loss: 3.0528e-04 - val_mae: 0.0070 - val_mse: 3.0528e-04\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5060e-05 - mae: 0.0026 - mse: 1.5060e-05\n",
      "Epoch 538: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3766e-05 - mae: 0.0025 - mse: 1.3766e-05 - val_loss: 2.9887e-04 - val_mae: 0.0069 - val_mse: 2.9887e-04\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2238e-05 - mae: 0.0024 - mse: 1.2238e-05\n",
      "Epoch 539: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3927e-05 - mae: 0.0025 - mse: 1.3927e-05 - val_loss: 2.9536e-04 - val_mae: 0.0069 - val_mse: 2.9536e-04\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4306e-05 - mae: 0.0025 - mse: 1.4306e-05\n",
      "Epoch 540: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4093e-05 - mae: 0.0025 - mse: 1.4093e-05 - val_loss: 2.9233e-04 - val_mae: 0.0068 - val_mse: 2.9233e-04\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4697e-05 - mae: 0.0025 - mse: 1.4697e-05\n",
      "Epoch 541: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3308e-05 - mae: 0.0024 - mse: 1.3308e-05 - val_loss: 2.9646e-04 - val_mae: 0.0069 - val_mse: 2.9646e-04\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5244e-05 - mae: 0.0026 - mse: 1.5244e-05\n",
      "Epoch 542: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3232e-05 - mae: 0.0024 - mse: 1.3232e-05 - val_loss: 2.9793e-04 - val_mae: 0.0069 - val_mse: 2.9793e-04\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2890e-05 - mae: 0.0023 - mse: 1.2890e-05\n",
      "Epoch 543: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2984e-05 - mae: 0.0024 - mse: 1.2984e-05 - val_loss: 2.9824e-04 - val_mae: 0.0069 - val_mse: 2.9824e-04\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2229e-05 - mae: 0.0023 - mse: 1.2229e-05\n",
      "Epoch 544: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.2828e-05 - mae: 0.0024 - mse: 1.2828e-05 - val_loss: 2.9674e-04 - val_mae: 0.0069 - val_mse: 2.9674e-04\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2547e-05 - mae: 0.0023 - mse: 1.2547e-05\n",
      "Epoch 545: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2738e-05 - mae: 0.0023 - mse: 1.2738e-05 - val_loss: 2.9880e-04 - val_mae: 0.0069 - val_mse: 2.9880e-04\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3298e-05 - mae: 0.0023 - mse: 1.3298e-05\n",
      "Epoch 546: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2245e-05 - mae: 0.0023 - mse: 1.2245e-05 - val_loss: 3.0048e-04 - val_mae: 0.0069 - val_mse: 3.0048e-04\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2476e-05 - mae: 0.0023 - mse: 1.2476e-05\n",
      "Epoch 547: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2408e-05 - mae: 0.0023 - mse: 1.2408e-05 - val_loss: 2.9627e-04 - val_mae: 0.0068 - val_mse: 2.9627e-04\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2671e-05 - mae: 0.0023 - mse: 1.2671e-05\n",
      "Epoch 548: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2543e-05 - mae: 0.0023 - mse: 1.2543e-05 - val_loss: 2.9398e-04 - val_mae: 0.0068 - val_mse: 2.9398e-04\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2508e-05 - mae: 0.0023 - mse: 1.2508e-05\n",
      "Epoch 549: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2733e-05 - mae: 0.0023 - mse: 1.2733e-05 - val_loss: 2.9669e-04 - val_mae: 0.0068 - val_mse: 2.9669e-04\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2163e-05 - mae: 0.0024 - mse: 1.2163e-05\n",
      "Epoch 550: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2757e-05 - mae: 0.0023 - mse: 1.2757e-05 - val_loss: 2.9633e-04 - val_mae: 0.0069 - val_mse: 2.9633e-04\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4136e-05 - mae: 0.0024 - mse: 1.4136e-05\n",
      "Epoch 551: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3094e-05 - mae: 0.0024 - mse: 1.3094e-05 - val_loss: 2.9527e-04 - val_mae: 0.0069 - val_mse: 2.9527e-04\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5721e-05 - mae: 0.0025 - mse: 1.5721e-05\n",
      "Epoch 552: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.3829e-05 - mae: 0.0024 - mse: 1.3829e-05 - val_loss: 2.9627e-04 - val_mae: 0.0068 - val_mse: 2.9627e-04\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2646e-05 - mae: 0.0023 - mse: 1.2646e-05\n",
      "Epoch 553: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2238e-05 - mae: 0.0023 - mse: 1.2238e-05 - val_loss: 2.9833e-04 - val_mae: 0.0068 - val_mse: 2.9833e-04\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7453e-06 - mae: 0.0021 - mse: 9.7453e-06\n",
      "Epoch 554: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2546e-05 - mae: 0.0023 - mse: 1.2546e-05 - val_loss: 2.9846e-04 - val_mae: 0.0068 - val_mse: 2.9846e-04\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3451e-05 - mae: 0.0024 - mse: 1.3451e-05\n",
      "Epoch 555: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2339e-05 - mae: 0.0023 - mse: 1.2339e-05 - val_loss: 2.9610e-04 - val_mae: 0.0069 - val_mse: 2.9610e-04\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3475e-05 - mae: 0.0024 - mse: 1.3475e-05\n",
      "Epoch 556: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2302e-05 - mae: 0.0023 - mse: 1.2302e-05 - val_loss: 2.9604e-04 - val_mae: 0.0068 - val_mse: 2.9604e-04\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1005e-05 - mae: 0.0022 - mse: 1.1005e-05\n",
      "Epoch 557: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2448e-05 - mae: 0.0023 - mse: 1.2448e-05 - val_loss: 2.9720e-04 - val_mae: 0.0068 - val_mse: 2.9720e-04\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1194e-05 - mae: 0.0021 - mse: 1.1194e-05\n",
      "Epoch 558: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1887e-05 - mae: 0.0022 - mse: 1.1887e-05 - val_loss: 2.9447e-04 - val_mae: 0.0068 - val_mse: 2.9447e-04\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0815e-05 - mae: 0.0023 - mse: 1.0815e-05\n",
      "Epoch 559: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1988e-05 - mae: 0.0023 - mse: 1.1988e-05 - val_loss: 2.9471e-04 - val_mae: 0.0067 - val_mse: 2.9471e-04\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2438e-05 - mae: 0.0023 - mse: 1.2438e-05\n",
      "Epoch 560: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2044e-05 - mae: 0.0023 - mse: 1.2044e-05 - val_loss: 2.9401e-04 - val_mae: 0.0067 - val_mse: 2.9401e-04\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2324e-05 - mae: 0.0023 - mse: 1.2324e-05\n",
      "Epoch 561: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1991e-05 - mae: 0.0023 - mse: 1.1991e-05 - val_loss: 2.9623e-04 - val_mae: 0.0068 - val_mse: 2.9623e-04\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6709e-06 - mae: 0.0021 - mse: 9.6709e-06\n",
      "Epoch 562: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1449e-05 - mae: 0.0022 - mse: 1.1449e-05 - val_loss: 2.9851e-04 - val_mae: 0.0068 - val_mse: 2.9851e-04\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2863e-05 - mae: 0.0023 - mse: 1.2863e-05\n",
      "Epoch 563: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2375e-05 - mae: 0.0023 - mse: 1.2375e-05 - val_loss: 3.0101e-04 - val_mae: 0.0068 - val_mse: 3.0101e-04\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1829e-05 - mae: 0.0022 - mse: 1.1829e-05\n",
      "Epoch 564: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2619e-05 - mae: 0.0023 - mse: 1.2619e-05 - val_loss: 3.0154e-04 - val_mae: 0.0068 - val_mse: 3.0154e-04\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2231e-05 - mae: 0.0022 - mse: 1.2231e-05\n",
      "Epoch 565: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.2147e-05 - mae: 0.0023 - mse: 1.2147e-05 - val_loss: 2.9798e-04 - val_mae: 0.0068 - val_mse: 2.9798e-04\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1172e-05 - mae: 0.0023 - mse: 1.1172e-05\n",
      "Epoch 566: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2362e-05 - mae: 0.0023 - mse: 1.2362e-05 - val_loss: 3.0331e-04 - val_mae: 0.0069 - val_mse: 3.0331e-04\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3817e-05 - mae: 0.0025 - mse: 1.3817e-05\n",
      "Epoch 567: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2576e-05 - mae: 0.0024 - mse: 1.2576e-05 - val_loss: 3.0358e-04 - val_mae: 0.0068 - val_mse: 3.0358e-04\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0513e-05 - mae: 0.0022 - mse: 1.0513e-05\n",
      "Epoch 568: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2103e-05 - mae: 0.0023 - mse: 1.2103e-05 - val_loss: 3.0049e-04 - val_mae: 0.0068 - val_mse: 3.0049e-04\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1365e-05 - mae: 0.0023 - mse: 1.1365e-05\n",
      "Epoch 569: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2004e-05 - mae: 0.0023 - mse: 1.2004e-05 - val_loss: 3.0258e-04 - val_mae: 0.0068 - val_mse: 3.0258e-04\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2187e-05 - mae: 0.0023 - mse: 1.2187e-05\n",
      "Epoch 570: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1951e-05 - mae: 0.0023 - mse: 1.1951e-05 - val_loss: 2.9864e-04 - val_mae: 0.0068 - val_mse: 2.9864e-04\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1546e-05 - mae: 0.0022 - mse: 1.1546e-05\n",
      "Epoch 571: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1966e-05 - mae: 0.0023 - mse: 1.1966e-05 - val_loss: 2.9718e-04 - val_mae: 0.0068 - val_mse: 2.9718e-04\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1795e-05 - mae: 0.0022 - mse: 1.1795e-05\n",
      "Epoch 572: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2590e-05 - mae: 0.0023 - mse: 1.2590e-05 - val_loss: 3.0449e-04 - val_mae: 0.0068 - val_mse: 3.0449e-04\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2702e-05 - mae: 0.0023 - mse: 1.2702e-05\n",
      "Epoch 573: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2564e-05 - mae: 0.0024 - mse: 1.2564e-05 - val_loss: 3.0368e-04 - val_mae: 0.0068 - val_mse: 3.0368e-04\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3145e-05 - mae: 0.0024 - mse: 1.3145e-05\n",
      "Epoch 574: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2652e-05 - mae: 0.0023 - mse: 1.2652e-05 - val_loss: 3.0188e-04 - val_mae: 0.0068 - val_mse: 3.0188e-04\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2562e-05 - mae: 0.0024 - mse: 1.2562e-05\n",
      "Epoch 575: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2506e-05 - mae: 0.0024 - mse: 1.2506e-05 - val_loss: 3.0373e-04 - val_mae: 0.0068 - val_mse: 3.0373e-04\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1059e-05 - mae: 0.0023 - mse: 1.1059e-05\n",
      "Epoch 576: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2297e-05 - mae: 0.0024 - mse: 1.2297e-05 - val_loss: 3.0126e-04 - val_mae: 0.0067 - val_mse: 3.0126e-04\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3176e-05 - mae: 0.0024 - mse: 1.3176e-05\n",
      "Epoch 577: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2056e-05 - mae: 0.0023 - mse: 1.2056e-05 - val_loss: 3.0050e-04 - val_mae: 0.0068 - val_mse: 3.0050e-04\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0987e-05 - mae: 0.0022 - mse: 1.0987e-05\n",
      "Epoch 578: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1562e-05 - mae: 0.0023 - mse: 1.1562e-05 - val_loss: 3.0327e-04 - val_mae: 0.0068 - val_mse: 3.0327e-04\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5477e-06 - mae: 0.0022 - mse: 9.5477e-06\n",
      "Epoch 579: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1992e-05 - mae: 0.0023 - mse: 1.1992e-05 - val_loss: 2.9767e-04 - val_mae: 0.0067 - val_mse: 2.9767e-04\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.8573e-06 - mae: 0.0022 - mse: 9.8573e-06\n",
      "Epoch 580: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0957e-05 - mae: 0.0022 - mse: 1.0957e-05 - val_loss: 2.9860e-04 - val_mae: 0.0067 - val_mse: 2.9860e-04\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2919e-05 - mae: 0.0023 - mse: 1.2919e-05\n",
      "Epoch 581: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2434e-05 - mae: 0.0023 - mse: 1.2434e-05 - val_loss: 3.0802e-04 - val_mae: 0.0067 - val_mse: 3.0802e-04\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1834e-05 - mae: 0.0023 - mse: 1.1834e-05\n",
      "Epoch 582: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1736e-05 - mae: 0.0023 - mse: 1.1736e-05 - val_loss: 3.0858e-04 - val_mae: 0.0068 - val_mse: 3.0858e-04\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3925e-06 - mae: 0.0021 - mse: 9.3925e-06\n",
      "Epoch 583: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1645e-05 - mae: 0.0023 - mse: 1.1645e-05 - val_loss: 3.0071e-04 - val_mae: 0.0067 - val_mse: 3.0071e-04\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7979e-06 - mae: 0.0022 - mse: 9.7979e-06\n",
      "Epoch 584: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1554e-05 - mae: 0.0023 - mse: 1.1554e-05 - val_loss: 2.9756e-04 - val_mae: 0.0067 - val_mse: 2.9756e-04\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0912e-05 - mae: 0.0022 - mse: 1.0912e-05\n",
      "Epoch 585: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1750e-05 - mae: 0.0023 - mse: 1.1750e-05 - val_loss: 2.9616e-04 - val_mae: 0.0066 - val_mse: 2.9616e-04\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0921e-05 - mae: 0.0022 - mse: 1.0921e-05\n",
      "Epoch 586: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1166e-05 - mae: 0.0022 - mse: 1.1166e-05 - val_loss: 2.9845e-04 - val_mae: 0.0067 - val_mse: 2.9845e-04\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1625e-05 - mae: 0.0023 - mse: 1.1625e-05\n",
      "Epoch 587: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1441e-05 - mae: 0.0023 - mse: 1.1441e-05 - val_loss: 3.0373e-04 - val_mae: 0.0067 - val_mse: 3.0373e-04\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2371e-05 - mae: 0.0023 - mse: 1.2371e-05\n",
      "Epoch 588: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1442e-05 - mae: 0.0022 - mse: 1.1442e-05 - val_loss: 3.0115e-04 - val_mae: 0.0066 - val_mse: 3.0115e-04\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1879e-05 - mae: 0.0023 - mse: 1.1879e-05\n",
      "Epoch 589: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0761e-05 - mae: 0.0022 - mse: 1.0761e-05 - val_loss: 2.9767e-04 - val_mae: 0.0067 - val_mse: 2.9767e-04\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1185e-05 - mae: 0.0022 - mse: 1.1185e-05\n",
      "Epoch 590: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1090e-05 - mae: 0.0022 - mse: 1.1090e-05 - val_loss: 3.0125e-04 - val_mae: 0.0067 - val_mse: 3.0125e-04\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1467e-05 - mae: 0.0022 - mse: 1.1467e-05\n",
      "Epoch 591: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1317e-05 - mae: 0.0022 - mse: 1.1317e-05 - val_loss: 3.0345e-04 - val_mae: 0.0066 - val_mse: 3.0345e-04\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1983e-05 - mae: 0.0023 - mse: 1.1983e-05\n",
      "Epoch 592: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1129e-05 - mae: 0.0022 - mse: 1.1129e-05 - val_loss: 3.0440e-04 - val_mae: 0.0066 - val_mse: 3.0440e-04\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4571e-06 - mae: 0.0021 - mse: 9.4571e-06\n",
      "Epoch 593: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1620e-05 - mae: 0.0023 - mse: 1.1620e-05 - val_loss: 3.0383e-04 - val_mae: 0.0067 - val_mse: 3.0383e-04\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1817e-05 - mae: 0.0023 - mse: 1.1817e-05\n",
      "Epoch 594: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1210e-05 - mae: 0.0023 - mse: 1.1210e-05 - val_loss: 2.9930e-04 - val_mae: 0.0066 - val_mse: 2.9930e-04\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5923e-06 - mae: 0.0021 - mse: 9.5923e-06\n",
      "Epoch 595: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0960e-05 - mae: 0.0022 - mse: 1.0960e-05 - val_loss: 2.9830e-04 - val_mae: 0.0066 - val_mse: 2.9830e-04\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1685e-05 - mae: 0.0022 - mse: 1.1685e-05\n",
      "Epoch 596: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1347e-05 - mae: 0.0022 - mse: 1.1347e-05 - val_loss: 2.9934e-04 - val_mae: 0.0065 - val_mse: 2.9934e-04\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2137e-05 - mae: 0.0023 - mse: 1.2137e-05\n",
      "Epoch 597: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1393e-05 - mae: 0.0022 - mse: 1.1393e-05 - val_loss: 3.0008e-04 - val_mae: 0.0065 - val_mse: 3.0008e-04\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7115e-06 - mae: 0.0020 - mse: 8.7115e-06\n",
      "Epoch 598: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0990e-05 - mae: 0.0022 - mse: 1.0990e-05 - val_loss: 2.9592e-04 - val_mae: 0.0066 - val_mse: 2.9592e-04\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0519e-05 - mae: 0.0021 - mse: 1.0519e-05\n",
      "Epoch 599: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0663e-05 - mae: 0.0022 - mse: 1.0663e-05 - val_loss: 2.9946e-04 - val_mae: 0.0067 - val_mse: 2.9946e-04\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1135e-05 - mae: 0.0023 - mse: 1.1135e-05\n",
      "Epoch 600: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1721e-05 - mae: 0.0023 - mse: 1.1721e-05 - val_loss: 3.0537e-04 - val_mae: 0.0067 - val_mse: 3.0537e-04\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0961e-05 - mae: 0.0023 - mse: 1.0961e-05\n",
      "Epoch 601: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1407e-05 - mae: 0.0023 - mse: 1.1407e-05 - val_loss: 3.0000e-04 - val_mae: 0.0066 - val_mse: 3.0000e-04\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1607e-05 - mae: 0.0023 - mse: 1.1607e-05\n",
      "Epoch 602: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1118e-05 - mae: 0.0022 - mse: 1.1118e-05 - val_loss: 3.0103e-04 - val_mae: 0.0065 - val_mse: 3.0103e-04\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1414e-05 - mae: 0.0022 - mse: 1.1414e-05\n",
      "Epoch 603: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0826e-05 - mae: 0.0022 - mse: 1.0826e-05 - val_loss: 3.0576e-04 - val_mae: 0.0066 - val_mse: 3.0576e-04\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1021e-05 - mae: 0.0022 - mse: 1.1021e-05\n",
      "Epoch 604: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0551e-05 - mae: 0.0022 - mse: 1.0551e-05 - val_loss: 3.0378e-04 - val_mae: 0.0066 - val_mse: 3.0378e-04\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0386e-05 - mae: 0.0022 - mse: 1.0386e-05\n",
      "Epoch 605: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0767e-05 - mae: 0.0022 - mse: 1.0767e-05 - val_loss: 3.0459e-04 - val_mae: 0.0066 - val_mse: 3.0459e-04\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0120e-05 - mae: 0.0021 - mse: 1.0120e-05\n",
      "Epoch 606: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0906e-05 - mae: 0.0022 - mse: 1.0906e-05 - val_loss: 3.0294e-04 - val_mae: 0.0066 - val_mse: 3.0294e-04\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0826e-05 - mae: 0.0022 - mse: 1.0826e-05\n",
      "Epoch 607: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1097e-05 - mae: 0.0022 - mse: 1.1097e-05 - val_loss: 3.0279e-04 - val_mae: 0.0066 - val_mse: 3.0279e-04\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1530e-05 - mae: 0.0023 - mse: 1.1530e-05\n",
      "Epoch 608: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0925e-05 - mae: 0.0023 - mse: 1.0925e-05 - val_loss: 3.0666e-04 - val_mae: 0.0067 - val_mse: 3.0666e-04\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1538e-05 - mae: 0.0023 - mse: 1.1538e-05\n",
      "Epoch 609: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2385e-05 - mae: 0.0023 - mse: 1.2385e-05 - val_loss: 3.0714e-04 - val_mae: 0.0067 - val_mse: 3.0714e-04\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2331e-05 - mae: 0.0024 - mse: 1.2331e-05\n",
      "Epoch 610: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2964e-05 - mae: 0.0024 - mse: 1.2964e-05 - val_loss: 3.0200e-04 - val_mae: 0.0066 - val_mse: 3.0200e-04\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2877e-05 - mae: 0.0025 - mse: 1.2877e-05\n",
      "Epoch 611: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3567e-05 - mae: 0.0025 - mse: 1.3567e-05 - val_loss: 3.0554e-04 - val_mae: 0.0068 - val_mse: 3.0554e-04\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3938e-05 - mae: 0.0025 - mse: 1.3938e-05\n",
      "Epoch 612: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5496e-05 - mae: 0.0026 - mse: 1.5496e-05 - val_loss: 3.0664e-04 - val_mae: 0.0068 - val_mse: 3.0664e-04\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6349e-05 - mae: 0.0027 - mse: 1.6349e-05\n",
      "Epoch 613: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6120e-05 - mae: 0.0027 - mse: 1.6120e-05 - val_loss: 3.0722e-04 - val_mae: 0.0069 - val_mse: 3.0722e-04\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7161e-05 - mae: 0.0028 - mse: 1.7161e-05\n",
      "Epoch 614: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6299e-05 - mae: 0.0028 - mse: 1.6299e-05 - val_loss: 3.0645e-04 - val_mae: 0.0068 - val_mse: 3.0645e-04\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6136e-05 - mae: 0.0027 - mse: 1.6136e-05\n",
      "Epoch 615: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.6230e-05 - mae: 0.0027 - mse: 1.6230e-05 - val_loss: 3.0819e-04 - val_mae: 0.0067 - val_mse: 3.0819e-04\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4680e-05 - mae: 0.0025 - mse: 1.4680e-05\n",
      "Epoch 616: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5610e-05 - mae: 0.0027 - mse: 1.5610e-05 - val_loss: 3.0872e-04 - val_mae: 0.0067 - val_mse: 3.0872e-04\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2193e-05 - mae: 0.0023 - mse: 1.2193e-05\n",
      "Epoch 617: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3783e-05 - mae: 0.0025 - mse: 1.3783e-05 - val_loss: 3.0914e-04 - val_mae: 0.0067 - val_mse: 3.0914e-04\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2288e-05 - mae: 0.0023 - mse: 1.2288e-05\n",
      "Epoch 618: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2100e-05 - mae: 0.0024 - mse: 1.2100e-05 - val_loss: 3.0823e-04 - val_mae: 0.0068 - val_mse: 3.0823e-04\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2695e-05 - mae: 0.0025 - mse: 1.2695e-05\n",
      "Epoch 619: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4476e-05 - mae: 0.0026 - mse: 1.4476e-05 - val_loss: 3.0357e-04 - val_mae: 0.0068 - val_mse: 3.0357e-04\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3735e-05 - mae: 0.0025 - mse: 1.3735e-05\n",
      "Epoch 620: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3210e-05 - mae: 0.0025 - mse: 1.3210e-05 - val_loss: 3.0598e-04 - val_mae: 0.0068 - val_mse: 3.0598e-04\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2270e-05 - mae: 0.0023 - mse: 1.2270e-05\n",
      "Epoch 621: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2635e-05 - mae: 0.0024 - mse: 1.2635e-05 - val_loss: 3.0991e-04 - val_mae: 0.0067 - val_mse: 3.0991e-04\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3275e-05 - mae: 0.0024 - mse: 1.3275e-05\n",
      "Epoch 622: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2787e-05 - mae: 0.0024 - mse: 1.2787e-05 - val_loss: 3.1458e-04 - val_mae: 0.0069 - val_mse: 3.1458e-04\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8529e-05 - mae: 0.0028 - mse: 1.8529e-05\n",
      "Epoch 623: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6790e-05 - mae: 0.0027 - mse: 1.6790e-05 - val_loss: 3.0777e-04 - val_mae: 0.0068 - val_mse: 3.0777e-04\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4034e-05 - mae: 0.0025 - mse: 1.4034e-05\n",
      "Epoch 624: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3325e-05 - mae: 0.0025 - mse: 1.3325e-05 - val_loss: 3.0606e-04 - val_mae: 0.0068 - val_mse: 3.0606e-04\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4061e-05 - mae: 0.0026 - mse: 1.4061e-05\n",
      "Epoch 625: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2832e-05 - mae: 0.0025 - mse: 1.2832e-05 - val_loss: 3.0892e-04 - val_mae: 0.0070 - val_mse: 3.0892e-04\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3893e-05 - mae: 0.0026 - mse: 1.3893e-05\n",
      "Epoch 626: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3509e-05 - mae: 0.0026 - mse: 1.3509e-05 - val_loss: 3.1309e-04 - val_mae: 0.0069 - val_mse: 3.1309e-04\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4581e-05 - mae: 0.0027 - mse: 1.4581e-05\n",
      "Epoch 627: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2983e-05 - mae: 0.0025 - mse: 1.2983e-05 - val_loss: 3.1579e-04 - val_mae: 0.0067 - val_mse: 3.1579e-04\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4117e-05 - mae: 0.0026 - mse: 1.4117e-05\n",
      "Epoch 628: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2177e-05 - mae: 0.0024 - mse: 1.2177e-05 - val_loss: 3.0992e-04 - val_mae: 0.0068 - val_mse: 3.0992e-04\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3801e-05 - mae: 0.0026 - mse: 1.3801e-05\n",
      "Epoch 629: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.2190e-05 - mae: 0.0024 - mse: 1.2190e-05 - val_loss: 3.0416e-04 - val_mae: 0.0066 - val_mse: 3.0416e-04\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1843e-05 - mae: 0.0023 - mse: 1.1843e-05\n",
      "Epoch 630: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1742e-05 - mae: 0.0023 - mse: 1.1742e-05 - val_loss: 3.0669e-04 - val_mae: 0.0068 - val_mse: 3.0669e-04\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1187e-05 - mae: 0.0023 - mse: 1.1187e-05\n",
      "Epoch 631: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2309e-05 - mae: 0.0024 - mse: 1.2309e-05 - val_loss: 3.0471e-04 - val_mae: 0.0066 - val_mse: 3.0471e-04\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0675e-05 - mae: 0.0022 - mse: 1.0675e-05\n",
      "Epoch 632: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1754e-05 - mae: 0.0023 - mse: 1.1754e-05 - val_loss: 3.1022e-04 - val_mae: 0.0066 - val_mse: 3.1022e-04\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0796e-05 - mae: 0.0022 - mse: 1.0796e-05\n",
      "Epoch 633: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3984e-05 - mae: 0.0025 - mse: 1.3984e-05 - val_loss: 3.1163e-04 - val_mae: 0.0067 - val_mse: 3.1163e-04\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2691e-05 - mae: 0.0024 - mse: 1.2691e-05\n",
      "Epoch 634: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4647e-05 - mae: 0.0026 - mse: 1.4647e-05 - val_loss: 3.1188e-04 - val_mae: 0.0067 - val_mse: 3.1188e-04\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5036e-05 - mae: 0.0025 - mse: 1.5036e-05\n",
      "Epoch 635: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4754e-05 - mae: 0.0025 - mse: 1.4754e-05 - val_loss: 3.1137e-04 - val_mae: 0.0067 - val_mse: 3.1137e-04\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4000e-05 - mae: 0.0025 - mse: 1.4000e-05\n",
      "Epoch 636: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4473e-05 - mae: 0.0026 - mse: 1.4473e-05 - val_loss: 3.1240e-04 - val_mae: 0.0067 - val_mse: 3.1240e-04\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3823e-05 - mae: 0.0026 - mse: 1.3823e-05\n",
      "Epoch 637: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5891e-05 - mae: 0.0027 - mse: 1.5891e-05 - val_loss: 3.0920e-04 - val_mae: 0.0067 - val_mse: 3.0920e-04\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3399e-05 - mae: 0.0026 - mse: 1.3399e-05\n",
      "Epoch 638: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5047e-05 - mae: 0.0027 - mse: 1.5047e-05 - val_loss: 3.0567e-04 - val_mae: 0.0068 - val_mse: 3.0567e-04\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4134e-05 - mae: 0.0027 - mse: 1.4134e-05\n",
      "Epoch 639: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4680e-05 - mae: 0.0027 - mse: 1.4680e-05 - val_loss: 3.1055e-04 - val_mae: 0.0068 - val_mse: 3.1055e-04\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5317e-05 - mae: 0.0027 - mse: 1.5317e-05\n",
      "Epoch 640: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6417e-05 - mae: 0.0028 - mse: 1.6417e-05 - val_loss: 3.1018e-04 - val_mae: 0.0067 - val_mse: 3.1018e-04\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5724e-05 - mae: 0.0026 - mse: 1.5724e-05\n",
      "Epoch 641: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6152e-05 - mae: 0.0027 - mse: 1.6152e-05 - val_loss: 3.1575e-04 - val_mae: 0.0068 - val_mse: 3.1575e-04\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4996e-05 - mae: 0.0027 - mse: 1.4996e-05\n",
      "Epoch 642: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5840e-05 - mae: 0.0028 - mse: 1.5840e-05 - val_loss: 3.1402e-04 - val_mae: 0.0070 - val_mse: 3.1402e-04\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6076e-05 - mae: 0.0030 - mse: 1.6076e-05\n",
      "Epoch 643: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6621e-05 - mae: 0.0030 - mse: 1.6621e-05 - val_loss: 3.0972e-04 - val_mae: 0.0072 - val_mse: 3.0972e-04\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6298e-05 - mae: 0.0030 - mse: 1.6298e-05\n",
      "Epoch 644: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5270e-05 - mae: 0.0029 - mse: 1.5270e-05 - val_loss: 3.1862e-04 - val_mae: 0.0068 - val_mse: 3.1862e-04\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5018e-05 - mae: 0.0026 - mse: 1.5018e-05\n",
      "Epoch 645: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4870e-05 - mae: 0.0026 - mse: 1.4870e-05 - val_loss: 3.2292e-04 - val_mae: 0.0070 - val_mse: 3.2292e-04\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5135e-05 - mae: 0.0027 - mse: 1.5135e-05\n",
      "Epoch 646: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.4889e-05 - mae: 0.0027 - mse: 1.4889e-05 - val_loss: 3.1210e-04 - val_mae: 0.0066 - val_mse: 3.1210e-04\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3167e-05 - mae: 0.0025 - mse: 1.3167e-05\n",
      "Epoch 647: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3517e-05 - mae: 0.0025 - mse: 1.3517e-05 - val_loss: 3.1263e-04 - val_mae: 0.0066 - val_mse: 3.1263e-04\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1935e-05 - mae: 0.0024 - mse: 1.1935e-05\n",
      "Epoch 648: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3175e-05 - mae: 0.0025 - mse: 1.3175e-05 - val_loss: 3.1366e-04 - val_mae: 0.0065 - val_mse: 3.1366e-04\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2332e-05 - mae: 0.0024 - mse: 1.2332e-05\n",
      "Epoch 649: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2034e-05 - mae: 0.0023 - mse: 1.2034e-05 - val_loss: 3.2348e-04 - val_mae: 0.0068 - val_mse: 3.2348e-04\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6432e-05 - mae: 0.0028 - mse: 1.6432e-05\n",
      "Epoch 650: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5093e-05 - mae: 0.0026 - mse: 1.5093e-05 - val_loss: 3.1283e-04 - val_mae: 0.0066 - val_mse: 3.1283e-04\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2802e-05 - mae: 0.0025 - mse: 1.2802e-05\n",
      "Epoch 651: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2364e-05 - mae: 0.0024 - mse: 1.2364e-05 - val_loss: 3.1279e-04 - val_mae: 0.0066 - val_mse: 3.1279e-04\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1005e-05 - mae: 0.0022 - mse: 1.1005e-05\n",
      "Epoch 652: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1462e-05 - mae: 0.0023 - mse: 1.1462e-05 - val_loss: 3.2060e-04 - val_mae: 0.0067 - val_mse: 3.2060e-04\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1038e-05 - mae: 0.0022 - mse: 1.1038e-05\n",
      "Epoch 653: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1371e-05 - mae: 0.0023 - mse: 1.1371e-05 - val_loss: 3.2045e-04 - val_mae: 0.0067 - val_mse: 3.2045e-04\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4805e-06 - mae: 0.0022 - mse: 9.4805e-06\n",
      "Epoch 654: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1191e-05 - mae: 0.0023 - mse: 1.1191e-05 - val_loss: 3.1646e-04 - val_mae: 0.0067 - val_mse: 3.1646e-04\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3067e-05 - mae: 0.0024 - mse: 1.3067e-05\n",
      "Epoch 655: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3191e-05 - mae: 0.0024 - mse: 1.3191e-05 - val_loss: 3.1392e-04 - val_mae: 0.0066 - val_mse: 3.1392e-04\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1175e-05 - mae: 0.0023 - mse: 1.1175e-05\n",
      "Epoch 656: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1398e-05 - mae: 0.0023 - mse: 1.1398e-05 - val_loss: 3.1773e-04 - val_mae: 0.0066 - val_mse: 3.1773e-04\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0800e-05 - mae: 0.0023 - mse: 1.0800e-05\n",
      "Epoch 657: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1768e-05 - mae: 0.0023 - mse: 1.1768e-05 - val_loss: 3.1593e-04 - val_mae: 0.0065 - val_mse: 3.1593e-04\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1079e-05 - mae: 0.0022 - mse: 1.1079e-05\n",
      "Epoch 658: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1245e-05 - mae: 0.0023 - mse: 1.1245e-05 - val_loss: 3.1310e-04 - val_mae: 0.0066 - val_mse: 3.1310e-04\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1693e-05 - mae: 0.0024 - mse: 1.1693e-05\n",
      "Epoch 659: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1471e-05 - mae: 0.0024 - mse: 1.1471e-05 - val_loss: 3.1584e-04 - val_mae: 0.0065 - val_mse: 3.1584e-04\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0397e-05 - mae: 0.0022 - mse: 1.0397e-05\n",
      "Epoch 660: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0210e-05 - mae: 0.0022 - mse: 1.0210e-05 - val_loss: 3.1299e-04 - val_mae: 0.0065 - val_mse: 3.1299e-04\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0538e-05 - mae: 0.0023 - mse: 1.0538e-05\n",
      "Epoch 661: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0542e-05 - mae: 0.0022 - mse: 1.0542e-05 - val_loss: 3.1360e-04 - val_mae: 0.0065 - val_mse: 3.1360e-04\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.5667e-06 - mae: 0.0021 - mse: 9.5667e-06\n",
      "Epoch 662: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.0318e-05 - mae: 0.0022 - mse: 1.0318e-05 - val_loss: 3.1275e-04 - val_mae: 0.0065 - val_mse: 3.1275e-04\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0064e-05 - mae: 0.0022 - mse: 1.0064e-05\n",
      "Epoch 663: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0457e-05 - mae: 0.0022 - mse: 1.0457e-05 - val_loss: 3.1222e-04 - val_mae: 0.0065 - val_mse: 3.1222e-04\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5773e-06 - mae: 0.0020 - mse: 8.5773e-06\n",
      "Epoch 664: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0098e-05 - mae: 0.0022 - mse: 1.0098e-05 - val_loss: 3.1388e-04 - val_mae: 0.0064 - val_mse: 3.1388e-04\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5521e-06 - mae: 0.0022 - mse: 9.5521e-06\n",
      "Epoch 665: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0238e-05 - mae: 0.0022 - mse: 1.0238e-05 - val_loss: 3.1262e-04 - val_mae: 0.0065 - val_mse: 3.1262e-04\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0601e-05 - mae: 0.0023 - mse: 1.0601e-05\n",
      "Epoch 666: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0782e-05 - mae: 0.0023 - mse: 1.0782e-05 - val_loss: 3.1254e-04 - val_mae: 0.0065 - val_mse: 3.1254e-04\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1050e-05 - mae: 0.0023 - mse: 1.1050e-05\n",
      "Epoch 667: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0061e-05 - mae: 0.0022 - mse: 1.0061e-05 - val_loss: 3.1136e-04 - val_mae: 0.0065 - val_mse: 3.1136e-04\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1798e-06 - mae: 0.0021 - mse: 9.1798e-06\n",
      "Epoch 668: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.6760e-06 - mae: 0.0022 - mse: 9.6760e-06 - val_loss: 3.1404e-04 - val_mae: 0.0064 - val_mse: 3.1404e-04\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0381e-05 - mae: 0.0022 - mse: 1.0381e-05\n",
      "Epoch 669: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.4742e-06 - mae: 0.0021 - mse: 9.4742e-06 - val_loss: 3.1645e-04 - val_mae: 0.0064 - val_mse: 3.1645e-04\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4026e-06 - mae: 0.0021 - mse: 9.4026e-06\n",
      "Epoch 670: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.4058e-06 - mae: 0.0021 - mse: 9.4058e-06 - val_loss: 3.1283e-04 - val_mae: 0.0065 - val_mse: 3.1283e-04\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9205e-06 - mae: 0.0020 - mse: 7.9205e-06\n",
      "Epoch 671: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.1172e-06 - mae: 0.0021 - mse: 9.1172e-06 - val_loss: 3.1299e-04 - val_mae: 0.0065 - val_mse: 3.1299e-04\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0397e-05 - mae: 0.0023 - mse: 1.0397e-05\n",
      "Epoch 672: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.8664e-06 - mae: 0.0022 - mse: 9.8664e-06 - val_loss: 3.1352e-04 - val_mae: 0.0064 - val_mse: 3.1352e-04\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2034e-06 - mae: 0.0021 - mse: 9.2034e-06\n",
      "Epoch 673: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.2943e-06 - mae: 0.0021 - mse: 9.2943e-06 - val_loss: 3.1924e-04 - val_mae: 0.0064 - val_mse: 3.1924e-04\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0840e-06 - mae: 0.0020 - mse: 9.0840e-06\n",
      "Epoch 674: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.1579e-06 - mae: 0.0020 - mse: 9.1579e-06 - val_loss: 3.1622e-04 - val_mae: 0.0064 - val_mse: 3.1622e-04\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4671e-06 - mae: 0.0019 - mse: 7.4671e-06\n",
      "Epoch 675: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.7668e-06 - mae: 0.0020 - mse: 8.7668e-06 - val_loss: 3.1343e-04 - val_mae: 0.0064 - val_mse: 3.1343e-04\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2568e-06 - mae: 0.0020 - mse: 9.2568e-06\n",
      "Epoch 676: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.0796e-06 - mae: 0.0020 - mse: 9.0796e-06 - val_loss: 3.1820e-04 - val_mae: 0.0065 - val_mse: 3.1820e-04\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9739e-06 - mae: 0.0022 - mse: 9.9739e-06\n",
      "Epoch 677: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.1205e-06 - mae: 0.0020 - mse: 9.1205e-06 - val_loss: 3.1453e-04 - val_mae: 0.0064 - val_mse: 3.1453e-04\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9477e-06 - mae: 0.0020 - mse: 8.9477e-06\n",
      "Epoch 678: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.2589e-06 - mae: 0.0021 - mse: 9.2589e-06 - val_loss: 3.1599e-04 - val_mae: 0.0064 - val_mse: 3.1599e-04\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.1911e-06 - mae: 0.0020 - mse: 9.1911e-06\n",
      "Epoch 679: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.9376e-06 - mae: 0.0020 - mse: 8.9376e-06 - val_loss: 3.2100e-04 - val_mae: 0.0064 - val_mse: 3.2100e-04\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7234e-06 - mae: 0.0020 - mse: 8.7234e-06\n",
      "Epoch 680: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.1935e-06 - mae: 0.0020 - mse: 9.1935e-06 - val_loss: 3.2221e-04 - val_mae: 0.0065 - val_mse: 3.2221e-04\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8268e-06 - mae: 0.0020 - mse: 8.8268e-06\n",
      "Epoch 681: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.8948e-06 - mae: 0.0020 - mse: 8.8948e-06 - val_loss: 3.2023e-04 - val_mae: 0.0065 - val_mse: 3.2023e-04\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0967e-05 - mae: 0.0022 - mse: 1.0967e-05\n",
      "Epoch 682: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0199e-05 - mae: 0.0021 - mse: 1.0199e-05 - val_loss: 3.1663e-04 - val_mae: 0.0066 - val_mse: 3.1663e-04\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1233e-05 - mae: 0.0023 - mse: 1.1233e-05\n",
      "Epoch 683: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0205e-05 - mae: 0.0022 - mse: 1.0205e-05 - val_loss: 3.1684e-04 - val_mae: 0.0065 - val_mse: 3.1684e-04\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.9687e-06 - mae: 0.0021 - mse: 9.9687e-06\n",
      "Epoch 684: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 9.5544e-06 - mae: 0.0021 - mse: 9.5544e-06 - val_loss: 3.2125e-04 - val_mae: 0.0065 - val_mse: 3.2125e-04\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0368e-05 - mae: 0.0022 - mse: 1.0368e-05\n",
      "Epoch 685: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0200e-05 - mae: 0.0022 - mse: 1.0200e-05 - val_loss: 3.1984e-04 - val_mae: 0.0064 - val_mse: 3.1984e-04\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0273e-05 - mae: 0.0021 - mse: 1.0273e-05\n",
      "Epoch 686: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0222e-05 - mae: 0.0022 - mse: 1.0222e-05 - val_loss: 3.1394e-04 - val_mae: 0.0063 - val_mse: 3.1394e-04\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0251e-06 - mae: 0.0020 - mse: 8.0251e-06\n",
      "Epoch 687: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9.3394e-06 - mae: 0.0021 - mse: 9.3394e-06 - val_loss: 3.1487e-04 - val_mae: 0.0064 - val_mse: 3.1487e-04\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0931e-05 - mae: 0.0022 - mse: 1.0931e-05\n",
      "Epoch 688: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0814e-05 - mae: 0.0022 - mse: 1.0814e-05 - val_loss: 3.1876e-04 - val_mae: 0.0064 - val_mse: 3.1876e-04\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4268e-06 - mae: 0.0021 - mse: 9.4268e-06\n",
      "Epoch 689: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0183e-05 - mae: 0.0022 - mse: 1.0183e-05 - val_loss: 3.1897e-04 - val_mae: 0.0065 - val_mse: 3.1897e-04\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2396e-05 - mae: 0.0023 - mse: 1.2396e-05\n",
      "Epoch 690: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1506e-05 - mae: 0.0023 - mse: 1.1506e-05 - val_loss: 3.1570e-04 - val_mae: 0.0064 - val_mse: 3.1570e-04\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0900e-06 - mae: 0.0021 - mse: 9.0900e-06\n",
      "Epoch 691: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.6332e-06 - mae: 0.0021 - mse: 9.6332e-06 - val_loss: 3.1528e-04 - val_mae: 0.0064 - val_mse: 3.1528e-04\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0133e-05 - mae: 0.0022 - mse: 1.0133e-05\n",
      "Epoch 692: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 1.0582e-05 - mae: 0.0022 - mse: 1.0582e-05 - val_loss: 3.1487e-04 - val_mae: 0.0063 - val_mse: 3.1487e-04\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.8593e-06 - mae: 0.0019 - mse: 7.8593e-06\n",
      "Epoch 693: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.4220e-06 - mae: 0.0021 - mse: 9.4220e-06 - val_loss: 3.1332e-04 - val_mae: 0.0063 - val_mse: 3.1332e-04\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0695e-05 - mae: 0.0023 - mse: 1.0695e-05\n",
      "Epoch 694: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.6719e-06 - mae: 0.0022 - mse: 9.6719e-06 - val_loss: 3.1717e-04 - val_mae: 0.0065 - val_mse: 3.1717e-04\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0704e-05 - mae: 0.0022 - mse: 1.0704e-05\n",
      "Epoch 695: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.7404e-06 - mae: 0.0021 - mse: 9.7404e-06 - val_loss: 3.1715e-04 - val_mae: 0.0064 - val_mse: 3.1715e-04\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4192e-06 - mae: 0.0021 - mse: 9.4192e-06\n",
      "Epoch 696: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.4029e-06 - mae: 0.0021 - mse: 9.4029e-06 - val_loss: 3.1560e-04 - val_mae: 0.0063 - val_mse: 3.1560e-04\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6262e-06 - mae: 0.0020 - mse: 8.6262e-06\n",
      "Epoch 697: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.2476e-06 - mae: 0.0020 - mse: 8.2476e-06 - val_loss: 3.2081e-04 - val_mae: 0.0065 - val_mse: 3.2081e-04\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.9264e-06 - mae: 0.0022 - mse: 9.9264e-06\n",
      "Epoch 698: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.0275e-06 - mae: 0.0021 - mse: 9.0275e-06 - val_loss: 3.1318e-04 - val_mae: 0.0062 - val_mse: 3.1318e-04\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6750e-06 - mae: 0.0019 - mse: 7.6750e-06\n",
      "Epoch 699: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.4275e-06 - mae: 0.0019 - mse: 8.4275e-06 - val_loss: 3.1417e-04 - val_mae: 0.0063 - val_mse: 3.1417e-04\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5098e-06 - mae: 0.0020 - mse: 8.5098e-06\n",
      "Epoch 700: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.3078e-06 - mae: 0.0020 - mse: 8.3078e-06 - val_loss: 3.2038e-04 - val_mae: 0.0064 - val_mse: 3.2038e-04\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8090e-06 - mae: 0.0020 - mse: 8.8090e-06\n",
      "Epoch 701: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.8654e-06 - mae: 0.0020 - mse: 8.8654e-06 - val_loss: 3.0996e-04 - val_mae: 0.0063 - val_mse: 3.0996e-04\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7761e-06 - mae: 0.0019 - mse: 6.7761e-06\n",
      "Epoch 702: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.4514e-06 - mae: 0.0020 - mse: 8.4514e-06 - val_loss: 3.0953e-04 - val_mae: 0.0062 - val_mse: 3.0953e-04\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0796e-06 - mae: 0.0020 - mse: 9.0796e-06\n",
      "Epoch 703: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.4170e-06 - mae: 0.0019 - mse: 8.4170e-06 - val_loss: 3.1857e-04 - val_mae: 0.0063 - val_mse: 3.1857e-04\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7217e-06 - mae: 0.0021 - mse: 8.7217e-06\n",
      "Epoch 704: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.8760e-06 - mae: 0.0020 - mse: 8.8760e-06 - val_loss: 3.1425e-04 - val_mae: 0.0063 - val_mse: 3.1425e-04\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9.0377e-06 - mae: 0.0021 - mse: 9.0377e-06\n",
      "Epoch 705: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.9195e-06 - mae: 0.0021 - mse: 8.9195e-06 - val_loss: 3.1661e-04 - val_mae: 0.0063 - val_mse: 3.1661e-04\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.8286e-06 - mae: 0.0020 - mse: 8.8286e-06\n",
      "Epoch 706: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.6619e-06 - mae: 0.0020 - mse: 8.6619e-06 - val_loss: 3.1906e-04 - val_mae: 0.0063 - val_mse: 3.1906e-04\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7113e-06 - mae: 0.0021 - mse: 9.7113e-06\n",
      "Epoch 707: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.1749e-06 - mae: 0.0020 - mse: 9.1749e-06 - val_loss: 3.1392e-04 - val_mae: 0.0064 - val_mse: 3.1392e-04\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0079e-05 - mae: 0.0022 - mse: 1.0079e-05\n",
      "Epoch 708: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1133e-05 - mae: 0.0022 - mse: 1.1133e-05 - val_loss: 3.1647e-04 - val_mae: 0.0065 - val_mse: 3.1647e-04\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2174e-05 - mae: 0.0024 - mse: 1.2174e-05\n",
      "Epoch 709: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0936e-05 - mae: 0.0023 - mse: 1.0936e-05 - val_loss: 3.2154e-04 - val_mae: 0.0066 - val_mse: 3.2154e-04\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3080e-05 - mae: 0.0024 - mse: 1.3080e-05\n",
      "Epoch 710: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2512e-05 - mae: 0.0023 - mse: 1.2512e-05 - val_loss: 3.2245e-04 - val_mae: 0.0065 - val_mse: 3.2245e-04\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4947e-05 - mae: 0.0026 - mse: 1.4947e-05\n",
      "Epoch 711: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2924e-05 - mae: 0.0024 - mse: 1.2924e-05 - val_loss: 3.2299e-04 - val_mae: 0.0066 - val_mse: 3.2299e-04\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3129e-05 - mae: 0.0025 - mse: 1.3129e-05\n",
      "Epoch 712: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1884e-05 - mae: 0.0024 - mse: 1.1884e-05 - val_loss: 3.1688e-04 - val_mae: 0.0065 - val_mse: 3.1688e-04\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3315e-05 - mae: 0.0025 - mse: 1.3315e-05\n",
      "Epoch 713: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2334e-05 - mae: 0.0024 - mse: 1.2334e-05 - val_loss: 3.2067e-04 - val_mae: 0.0065 - val_mse: 3.2067e-04\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.7726e-06 - mae: 0.0022 - mse: 9.7726e-06\n",
      "Epoch 714: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0920e-05 - mae: 0.0022 - mse: 1.0920e-05 - val_loss: 3.1457e-04 - val_mae: 0.0064 - val_mse: 3.1457e-04\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2185e-05 - mae: 0.0023 - mse: 1.2185e-05\n",
      "Epoch 715: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1730e-05 - mae: 0.0023 - mse: 1.1730e-05 - val_loss: 3.1686e-04 - val_mae: 0.0064 - val_mse: 3.1686e-04\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0950e-05 - mae: 0.0022 - mse: 1.0950e-05\n",
      "Epoch 716: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1197e-05 - mae: 0.0023 - mse: 1.1197e-05 - val_loss: 3.2152e-04 - val_mae: 0.0066 - val_mse: 3.2152e-04\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2314e-05 - mae: 0.0024 - mse: 1.2314e-05\n",
      "Epoch 717: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2449e-05 - mae: 0.0024 - mse: 1.2449e-05 - val_loss: 3.2661e-04 - val_mae: 0.0069 - val_mse: 3.2661e-04\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7110e-05 - mae: 0.0029 - mse: 1.7110e-05\n",
      "Epoch 718: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5921e-05 - mae: 0.0027 - mse: 1.5921e-05 - val_loss: 3.2470e-04 - val_mae: 0.0068 - val_mse: 3.2470e-04\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9240e-05 - mae: 0.0031 - mse: 1.9240e-05\n",
      "Epoch 719: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8060e-05 - mae: 0.0029 - mse: 1.8060e-05 - val_loss: 3.2838e-04 - val_mae: 0.0071 - val_mse: 3.2838e-04\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3898e-05 - mae: 0.0034 - mse: 2.3898e-05\n",
      "Epoch 720: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9785e-05 - mae: 0.0030 - mse: 1.9785e-05 - val_loss: 3.2779e-04 - val_mae: 0.0069 - val_mse: 3.2779e-04\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8397e-05 - mae: 0.0029 - mse: 1.8397e-05\n",
      "Epoch 721: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6755e-05 - mae: 0.0028 - mse: 1.6755e-05 - val_loss: 3.2827e-04 - val_mae: 0.0071 - val_mse: 3.2827e-04\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3932e-05 - mae: 0.0034 - mse: 2.3932e-05\n",
      "Epoch 722: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0448e-05 - mae: 0.0031 - mse: 2.0448e-05 - val_loss: 3.2014e-04 - val_mae: 0.0068 - val_mse: 3.2014e-04\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8229e-05 - mae: 0.0029 - mse: 1.8229e-05\n",
      "Epoch 723: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7472e-05 - mae: 0.0029 - mse: 1.7472e-05 - val_loss: 3.1859e-04 - val_mae: 0.0068 - val_mse: 3.1859e-04\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8180e-05 - mae: 0.0028 - mse: 1.8180e-05\n",
      "Epoch 724: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6691e-05 - mae: 0.0027 - mse: 1.6691e-05 - val_loss: 3.1390e-04 - val_mae: 0.0064 - val_mse: 3.1390e-04\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1534e-05 - mae: 0.0023 - mse: 1.1534e-05\n",
      "Epoch 725: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3454e-05 - mae: 0.0025 - mse: 1.3454e-05 - val_loss: 3.2544e-04 - val_mae: 0.0067 - val_mse: 3.2544e-04\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3193e-05 - mae: 0.0032 - mse: 2.3193e-05\n",
      "Epoch 726: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0305e-05 - mae: 0.0029 - mse: 2.0305e-05 - val_loss: 3.1458e-04 - val_mae: 0.0066 - val_mse: 3.1458e-04\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7530e-05 - mae: 0.0028 - mse: 1.7530e-05\n",
      "Epoch 727: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7359e-05 - mae: 0.0028 - mse: 1.7359e-05 - val_loss: 3.1768e-04 - val_mae: 0.0064 - val_mse: 3.1768e-04\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1953e-05 - mae: 0.0024 - mse: 1.1953e-05\n",
      "Epoch 728: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3926e-05 - mae: 0.0025 - mse: 1.3926e-05 - val_loss: 3.1783e-04 - val_mae: 0.0064 - val_mse: 3.1783e-04\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0852e-05 - mae: 0.0023 - mse: 1.0852e-05\n",
      "Epoch 729: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2436e-05 - mae: 0.0025 - mse: 1.2436e-05 - val_loss: 3.2701e-04 - val_mae: 0.0069 - val_mse: 3.2701e-04\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9734e-05 - mae: 0.0030 - mse: 1.9734e-05\n",
      "Epoch 730: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8268e-05 - mae: 0.0029 - mse: 1.8268e-05 - val_loss: 3.1585e-04 - val_mae: 0.0065 - val_mse: 3.1585e-04\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3621e-05 - mae: 0.0026 - mse: 1.3621e-05\n",
      "Epoch 731: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3204e-05 - mae: 0.0026 - mse: 1.3204e-05 - val_loss: 3.1270e-04 - val_mae: 0.0066 - val_mse: 3.1270e-04\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5580e-05 - mae: 0.0029 - mse: 1.5580e-05\n",
      "Epoch 732: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3396e-05 - mae: 0.0027 - mse: 1.3396e-05 - val_loss: 3.2505e-04 - val_mae: 0.0066 - val_mse: 3.2505e-04\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1297e-05 - mae: 0.0025 - mse: 1.1297e-05\n",
      "Epoch 733: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1679e-05 - mae: 0.0025 - mse: 1.1679e-05 - val_loss: 3.1544e-04 - val_mae: 0.0066 - val_mse: 3.1544e-04\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3019e-05 - mae: 0.0026 - mse: 1.3019e-05\n",
      "Epoch 734: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2752e-05 - mae: 0.0025 - mse: 1.2752e-05 - val_loss: 3.1667e-04 - val_mae: 0.0064 - val_mse: 3.1667e-04\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3028e-05 - mae: 0.0025 - mse: 1.3028e-05\n",
      "Epoch 735: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2169e-05 - mae: 0.0024 - mse: 1.2169e-05 - val_loss: 3.2292e-04 - val_mae: 0.0066 - val_mse: 3.2292e-04\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0551e-05 - mae: 0.0023 - mse: 1.0551e-05\n",
      "Epoch 736: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.1253e-05 - mae: 0.0023 - mse: 1.1253e-05 - val_loss: 3.2031e-04 - val_mae: 0.0066 - val_mse: 3.2031e-04\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4000e-05 - mae: 0.0026 - mse: 1.4000e-05\n",
      "Epoch 737: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.2930e-05 - mae: 0.0025 - mse: 1.2930e-05 - val_loss: 3.2337e-04 - val_mae: 0.0066 - val_mse: 3.2337e-04\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3923e-05 - mae: 0.0026 - mse: 1.3923e-05\n",
      "Epoch 738: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3264e-05 - mae: 0.0026 - mse: 1.3264e-05 - val_loss: 3.1808e-04 - val_mae: 0.0064 - val_mse: 3.1808e-04\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6539e-05 - mae: 0.0027 - mse: 1.6539e-05\n",
      "Epoch 739: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5755e-05 - mae: 0.0026 - mse: 1.5755e-05 - val_loss: 3.2302e-04 - val_mae: 0.0067 - val_mse: 3.2302e-04\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8563e-05 - mae: 0.0028 - mse: 1.8563e-05\n",
      "Epoch 740: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8959e-05 - mae: 0.0029 - mse: 1.8959e-05 - val_loss: 3.2918e-04 - val_mae: 0.0069 - val_mse: 3.2918e-04\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6276e-05 - mae: 0.0037 - mse: 3.6276e-05\n",
      "Epoch 741: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1367e-05 - mae: 0.0035 - mse: 3.1367e-05 - val_loss: 3.3126e-04 - val_mae: 0.0070 - val_mse: 3.3126e-04\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7998e-05 - mae: 0.0033 - mse: 2.7998e-05\n",
      "Epoch 742: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.5188e-05 - mae: 0.0032 - mse: 2.5188e-05 - val_loss: 3.2033e-04 - val_mae: 0.0068 - val_mse: 3.2033e-04\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0964e-05 - mae: 0.0030 - mse: 2.0964e-05\n",
      "Epoch 743: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.9754e-05 - mae: 0.0030 - mse: 1.9754e-05 - val_loss: 3.2493e-04 - val_mae: 0.0073 - val_mse: 3.2493e-04\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.4685e-05 - mae: 0.0035 - mse: 2.4685e-05\n",
      "Epoch 744: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2558e-05 - mae: 0.0033 - mse: 2.2558e-05 - val_loss: 3.2909e-04 - val_mae: 0.0073 - val_mse: 3.2909e-04\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3055e-05 - mae: 0.0040 - mse: 3.3055e-05\n",
      "Epoch 745: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6798e-05 - mae: 0.0035 - mse: 2.6798e-05 - val_loss: 3.2571e-04 - val_mae: 0.0072 - val_mse: 3.2571e-04\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3668e-05 - mae: 0.0035 - mse: 2.3668e-05\n",
      "Epoch 746: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0361e-05 - mae: 0.0032 - mse: 2.0361e-05 - val_loss: 3.2860e-04 - val_mae: 0.0069 - val_mse: 3.2860e-04\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2520e-05 - mae: 0.0034 - mse: 2.2520e-05\n",
      "Epoch 747: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9455e-05 - mae: 0.0031 - mse: 1.9455e-05 - val_loss: 3.2457e-04 - val_mae: 0.0068 - val_mse: 3.2457e-04\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6659e-05 - mae: 0.0030 - mse: 1.6659e-05\n",
      "Epoch 748: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5749e-05 - mae: 0.0029 - mse: 1.5749e-05 - val_loss: 3.1777e-04 - val_mae: 0.0064 - val_mse: 3.1777e-04\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7831e-05 - mae: 0.0029 - mse: 1.7831e-05\n",
      "Epoch 749: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6171e-05 - mae: 0.0028 - mse: 1.6171e-05 - val_loss: 3.1912e-04 - val_mae: 0.0066 - val_mse: 3.1912e-04\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9235e-05 - mae: 0.0030 - mse: 1.9235e-05\n",
      "Epoch 750: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6622e-05 - mae: 0.0028 - mse: 1.6622e-05 - val_loss: 3.1883e-04 - val_mae: 0.0064 - val_mse: 3.1883e-04\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5598e-05 - mae: 0.0026 - mse: 1.5598e-05\n",
      "Epoch 751: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4583e-05 - mae: 0.0025 - mse: 1.4583e-05 - val_loss: 3.3041e-04 - val_mae: 0.0068 - val_mse: 3.3041e-04\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4963e-05 - mae: 0.0033 - mse: 2.4963e-05\n",
      "Epoch 752: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1546e-05 - mae: 0.0030 - mse: 2.1546e-05 - val_loss: 3.2070e-04 - val_mae: 0.0066 - val_mse: 3.2070e-04\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3479e-05 - mae: 0.0031 - mse: 2.3479e-05\n",
      "Epoch 753: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.0298e-05 - mae: 0.0029 - mse: 2.0298e-05 - val_loss: 3.2260e-04 - val_mae: 0.0068 - val_mse: 3.2260e-04\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2183e-05 - mae: 0.0031 - mse: 2.2183e-05\n",
      "Epoch 754: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0407e-05 - mae: 0.0030 - mse: 2.0407e-05 - val_loss: 3.2409e-04 - val_mae: 0.0068 - val_mse: 3.2409e-04\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5604e-05 - mae: 0.0033 - mse: 2.5604e-05\n",
      "Epoch 755: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.2838e-05 - mae: 0.0031 - mse: 2.2838e-05 - val_loss: 3.3910e-04 - val_mae: 0.0070 - val_mse: 3.3910e-04\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5727e-05 - mae: 0.0034 - mse: 2.5727e-05\n",
      "Epoch 756: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1769e-05 - mae: 0.0031 - mse: 2.1769e-05 - val_loss: 3.2255e-04 - val_mae: 0.0067 - val_mse: 3.2255e-04\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8455e-05 - mae: 0.0030 - mse: 1.8455e-05\n",
      "Epoch 757: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7006e-05 - mae: 0.0029 - mse: 1.7006e-05 - val_loss: 3.2269e-04 - val_mae: 0.0069 - val_mse: 3.2269e-04\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.2415e-05 - mae: 0.0033 - mse: 2.2415e-05\n",
      "Epoch 758: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9084e-05 - mae: 0.0030 - mse: 1.9084e-05 - val_loss: 3.3201e-04 - val_mae: 0.0069 - val_mse: 3.3201e-04\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8898e-05 - mae: 0.0031 - mse: 1.8898e-05\n",
      "Epoch 759: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7435e-05 - mae: 0.0029 - mse: 1.7435e-05 - val_loss: 3.2841e-04 - val_mae: 0.0072 - val_mse: 3.2841e-04\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4147e-05 - mae: 0.0035 - mse: 2.4147e-05\n",
      "Epoch 760: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1267e-05 - mae: 0.0033 - mse: 2.1267e-05 - val_loss: 3.2977e-04 - val_mae: 0.0071 - val_mse: 3.2977e-04\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6050e-05 - mae: 0.0036 - mse: 2.6050e-05\n",
      "Epoch 761: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.2419e-05 - mae: 0.0033 - mse: 2.2419e-05 - val_loss: 3.2656e-04 - val_mae: 0.0069 - val_mse: 3.2656e-04\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3333e-05 - mae: 0.0033 - mse: 2.3333e-05\n",
      "Epoch 762: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9922e-05 - mae: 0.0031 - mse: 1.9922e-05 - val_loss: 3.1770e-04 - val_mae: 0.0065 - val_mse: 3.1770e-04\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9039e-05 - mae: 0.0029 - mse: 1.9039e-05\n",
      "Epoch 763: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7056e-05 - mae: 0.0028 - mse: 1.7056e-05 - val_loss: 3.1992e-04 - val_mae: 0.0066 - val_mse: 3.1992e-04\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7273e-05 - mae: 0.0027 - mse: 1.7273e-05\n",
      "Epoch 764: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6660e-05 - mae: 0.0027 - mse: 1.6660e-05 - val_loss: 3.1682e-04 - val_mae: 0.0064 - val_mse: 3.1682e-04\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4085e-05 - mae: 0.0024 - mse: 1.4085e-05\n",
      "Epoch 765: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.6052e-05 - mae: 0.0026 - mse: 1.6052e-05 - val_loss: 3.3045e-04 - val_mae: 0.0070 - val_mse: 3.3045e-04\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6425e-05 - mae: 0.0036 - mse: 3.6425e-05\n",
      "Epoch 766: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2921e-05 - mae: 0.0034 - mse: 3.2921e-05 - val_loss: 3.2282e-04 - val_mae: 0.0067 - val_mse: 3.2282e-04\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7162e-05 - mae: 0.0032 - mse: 2.7162e-05\n",
      "Epoch 767: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.7594e-05 - mae: 0.0033 - mse: 2.7594e-05 - val_loss: 3.3877e-04 - val_mae: 0.0072 - val_mse: 3.3877e-04\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1041e-05 - mae: 0.0041 - mse: 4.1041e-05\n",
      "Epoch 768: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6293e-05 - mae: 0.0038 - mse: 3.6293e-05 - val_loss: 3.2732e-04 - val_mae: 0.0073 - val_mse: 3.2732e-04\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3268e-05 - mae: 0.0040 - mse: 3.3268e-05\n",
      "Epoch 769: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.9214e-05 - mae: 0.0037 - mse: 2.9214e-05 - val_loss: 3.3820e-04 - val_mae: 0.0077 - val_mse: 3.3820e-04\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9925e-05 - mae: 0.0045 - mse: 3.9925e-05\n",
      "Epoch 770: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2119e-05 - mae: 0.0039 - mse: 3.2119e-05 - val_loss: 3.3982e-04 - val_mae: 0.0074 - val_mse: 3.3982e-04\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1054e-05 - mae: 0.0040 - mse: 4.1054e-05\n",
      "Epoch 771: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.4959e-05 - mae: 0.0038 - mse: 3.4959e-05 - val_loss: 3.2344e-04 - val_mae: 0.0072 - val_mse: 3.2344e-04\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2025e-05 - mae: 0.0042 - mse: 4.2025e-05\n",
      "Epoch 772: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6392e-05 - mae: 0.0039 - mse: 3.6392e-05 - val_loss: 3.2221e-04 - val_mae: 0.0068 - val_mse: 3.2221e-04\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1805e-05 - mae: 0.0032 - mse: 2.1805e-05\n",
      "Epoch 773: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.2522e-05 - mae: 0.0033 - mse: 2.2522e-05 - val_loss: 3.1979e-04 - val_mae: 0.0067 - val_mse: 3.1979e-04\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0141e-05 - mae: 0.0031 - mse: 2.0141e-05\n",
      "Epoch 774: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.9585e-05 - mae: 0.0031 - mse: 1.9585e-05 - val_loss: 3.2117e-04 - val_mae: 0.0066 - val_mse: 3.2117e-04\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7793e-05 - mae: 0.0029 - mse: 1.7793e-05\n",
      "Epoch 775: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.8734e-05 - mae: 0.0030 - mse: 1.8734e-05 - val_loss: 3.3058e-04 - val_mae: 0.0069 - val_mse: 3.3058e-04\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.8186e-05 - mae: 0.0030 - mse: 1.8186e-05\n",
      "Epoch 776: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.0094e-05 - mae: 0.0031 - mse: 2.0094e-05 - val_loss: 3.2250e-04 - val_mae: 0.0068 - val_mse: 3.2250e-04\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6583e-05 - mae: 0.0035 - mse: 2.6583e-05\n",
      "Epoch 777: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.4042e-05 - mae: 0.0033 - mse: 2.4042e-05 - val_loss: 3.4033e-04 - val_mae: 0.0070 - val_mse: 3.4033e-04\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4416e-05 - mae: 0.0033 - mse: 2.4416e-05\n",
      "Epoch 778: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.2513e-05 - mae: 0.0032 - mse: 2.2513e-05 - val_loss: 3.1627e-04 - val_mae: 0.0068 - val_mse: 3.1627e-04\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5471e-05 - mae: 0.0032 - mse: 2.5471e-05\n",
      "Epoch 779: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.3451e-05 - mae: 0.0032 - mse: 2.3451e-05 - val_loss: 3.0591e-04 - val_mae: 0.0069 - val_mse: 3.0591e-04\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3108e-05 - mae: 0.0034 - mse: 2.3108e-05\n",
      "Epoch 780: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 2.4850e-05 - mae: 0.0035 - mse: 2.4850e-05 - val_loss: 3.3009e-04 - val_mae: 0.0075 - val_mse: 3.3009e-04\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7965e-05 - mae: 0.0040 - mse: 3.7965e-05\n",
      "Epoch 781: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.7274e-05 - mae: 0.0040 - mse: 3.7274e-05 - val_loss: 3.4401e-04 - val_mae: 0.0079 - val_mse: 3.4401e-04\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5799e-05 - mae: 0.0049 - mse: 5.5799e-05\n",
      "Epoch 782: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.8158e-05 - mae: 0.0045 - mse: 4.8158e-05 - val_loss: 3.2736e-04 - val_mae: 0.0075 - val_mse: 3.2736e-04\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0665e-05 - mae: 0.0043 - mse: 4.0665e-05\n",
      "Epoch 783: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6658e-05 - mae: 0.0041 - mse: 3.6658e-05 - val_loss: 3.4301e-04 - val_mae: 0.0077 - val_mse: 3.4301e-04\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0885e-05 - mae: 0.0043 - mse: 4.0885e-05\n",
      "Epoch 784: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.4811e-05 - mae: 0.0040 - mse: 3.4811e-05 - val_loss: 3.3866e-04 - val_mae: 0.0074 - val_mse: 3.3866e-04\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1309e-05 - mae: 0.0041 - mse: 4.1309e-05\n",
      "Epoch 785: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.4412e-05 - mae: 0.0038 - mse: 3.4412e-05 - val_loss: 3.2749e-04 - val_mae: 0.0074 - val_mse: 3.2749e-04\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.3523e-05 - mae: 0.0039 - mse: 3.3523e-05\n",
      "Epoch 786: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.0222e-05 - mae: 0.0037 - mse: 3.0222e-05 - val_loss: 3.3488e-04 - val_mae: 0.0070 - val_mse: 3.3488e-04\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9767e-05 - mae: 0.0037 - mse: 2.9767e-05\n",
      "Epoch 787: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7583e-05 - mae: 0.0036 - mse: 2.7583e-05 - val_loss: 3.2957e-04 - val_mae: 0.0070 - val_mse: 3.2957e-04\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8308e-05 - mae: 0.0036 - mse: 2.8308e-05\n",
      "Epoch 788: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6103e-05 - mae: 0.0035 - mse: 2.6103e-05 - val_loss: 3.2370e-04 - val_mae: 0.0069 - val_mse: 3.2370e-04\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5409e-05 - mae: 0.0034 - mse: 2.5409e-05\n",
      "Epoch 789: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.3834e-05 - mae: 0.0034 - mse: 2.3834e-05 - val_loss: 3.1721e-04 - val_mae: 0.0072 - val_mse: 3.1721e-04\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4822e-05 - mae: 0.0036 - mse: 2.4822e-05\n",
      "Epoch 790: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1961e-05 - mae: 0.0033 - mse: 2.1961e-05 - val_loss: 3.1580e-04 - val_mae: 0.0069 - val_mse: 3.1580e-04\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3828e-05 - mae: 0.0034 - mse: 2.3828e-05\n",
      "Epoch 791: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1100e-05 - mae: 0.0032 - mse: 2.1100e-05 - val_loss: 3.3776e-04 - val_mae: 0.0071 - val_mse: 3.3776e-04\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4059e-05 - mae: 0.0034 - mse: 2.4059e-05\n",
      "Epoch 792: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1057e-05 - mae: 0.0032 - mse: 2.1057e-05 - val_loss: 3.1082e-04 - val_mae: 0.0067 - val_mse: 3.1082e-04\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9037e-05 - mae: 0.0031 - mse: 1.9037e-05\n",
      "Epoch 793: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.7637e-05 - mae: 0.0030 - mse: 1.7637e-05 - val_loss: 3.1825e-04 - val_mae: 0.0070 - val_mse: 3.1825e-04\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0211e-05 - mae: 0.0031 - mse: 2.0211e-05\n",
      "Epoch 794: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.8569e-05 - mae: 0.0031 - mse: 1.8569e-05 - val_loss: 3.2226e-04 - val_mae: 0.0066 - val_mse: 3.2226e-04\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9311e-05 - mae: 0.0030 - mse: 1.9311e-05\n",
      "Epoch 795: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8828e-05 - mae: 0.0030 - mse: 1.8828e-05 - val_loss: 3.2631e-04 - val_mae: 0.0071 - val_mse: 3.2631e-04\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3172e-05 - mae: 0.0035 - mse: 2.3172e-05\n",
      "Epoch 796: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1314e-05 - mae: 0.0033 - mse: 2.1314e-05 - val_loss: 3.2237e-04 - val_mae: 0.0071 - val_mse: 3.2237e-04\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1536e-05 - mae: 0.0039 - mse: 3.1536e-05\n",
      "Epoch 797: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7368e-05 - mae: 0.0036 - mse: 2.7368e-05 - val_loss: 3.2465e-04 - val_mae: 0.0076 - val_mse: 3.2465e-04\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3449e-05 - mae: 0.0041 - mse: 3.3449e-05\n",
      "Epoch 798: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7625e-05 - mae: 0.0037 - mse: 2.7625e-05 - val_loss: 3.2922e-04 - val_mae: 0.0071 - val_mse: 3.2922e-04\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5614e-05 - mae: 0.0036 - mse: 2.5614e-05\n",
      "Epoch 799: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2562e-05 - mae: 0.0034 - mse: 2.2562e-05 - val_loss: 3.2969e-04 - val_mae: 0.0071 - val_mse: 3.2969e-04\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4932e-05 - mae: 0.0036 - mse: 2.4932e-05\n",
      "Epoch 800: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1794e-05 - mae: 0.0034 - mse: 2.1794e-05 - val_loss: 3.2174e-04 - val_mae: 0.0070 - val_mse: 3.2174e-04\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5859e-05 - mae: 0.0036 - mse: 2.5859e-05\n",
      "Epoch 801: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2366e-05 - mae: 0.0034 - mse: 2.2366e-05 - val_loss: 3.2625e-04 - val_mae: 0.0071 - val_mse: 3.2625e-04\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3463e-05 - mae: 0.0034 - mse: 2.3463e-05\n",
      "Epoch 802: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1660e-05 - mae: 0.0033 - mse: 2.1660e-05 - val_loss: 3.2528e-04 - val_mae: 0.0069 - val_mse: 3.2528e-04\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.1846e-05 - mae: 0.0037 - mse: 3.1846e-05\n",
      "Epoch 803: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8837e-05 - mae: 0.0036 - mse: 2.8837e-05 - val_loss: 3.3729e-04 - val_mae: 0.0073 - val_mse: 3.3729e-04\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5383e-05 - mae: 0.0038 - mse: 3.5383e-05\n",
      "Epoch 804: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.3648e-05 - mae: 0.0037 - mse: 3.3648e-05 - val_loss: 3.2799e-04 - val_mae: 0.0071 - val_mse: 3.2799e-04\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3031e-05 - mae: 0.0039 - mse: 4.3031e-05\n",
      "Epoch 805: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.9396e-05 - mae: 0.0038 - mse: 3.9396e-05 - val_loss: 3.4252e-04 - val_mae: 0.0075 - val_mse: 3.4252e-04\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6041e-05 - mae: 0.0048 - mse: 6.6041e-05\n",
      "Epoch 806: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3221e-05 - mae: 0.0042 - mse: 5.3221e-05 - val_loss: 3.2796e-04 - val_mae: 0.0070 - val_mse: 3.2796e-04\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1888e-05 - mae: 0.0042 - mse: 5.1888e-05\n",
      "Epoch 807: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.3818e-05 - mae: 0.0039 - mse: 4.3818e-05 - val_loss: 3.4307e-04 - val_mae: 0.0077 - val_mse: 3.4307e-04\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3019e-05 - mae: 0.0041 - mse: 4.3019e-05\n",
      "Epoch 808: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 4.1735e-05 - mae: 0.0041 - mse: 4.1735e-05 - val_loss: 3.4410e-04 - val_mae: 0.0077 - val_mse: 3.4410e-04\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2949e-05 - mae: 0.0050 - mse: 6.2949e-05\n",
      "Epoch 809: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9655e-05 - mae: 0.0049 - mse: 5.9655e-05 - val_loss: 3.5531e-04 - val_mae: 0.0086 - val_mse: 3.5531e-04\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1426e-04 - mae: 0.0067 - mse: 1.1426e-04\n",
      "Epoch 810: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.8640e-05 - mae: 0.0057 - mse: 8.8640e-05 - val_loss: 3.5167e-04 - val_mae: 0.0082 - val_mse: 3.5167e-04\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3942e-05 - mae: 0.0053 - mse: 6.3942e-05\n",
      "Epoch 811: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3245e-05 - mae: 0.0048 - mse: 5.3245e-05 - val_loss: 3.5688e-04 - val_mae: 0.0085 - val_mse: 3.5688e-04\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0923e-05 - mae: 0.0054 - mse: 6.0923e-05\n",
      "Epoch 812: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9543e-05 - mae: 0.0047 - mse: 4.9543e-05 - val_loss: 3.3913e-04 - val_mae: 0.0081 - val_mse: 3.3913e-04\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0505e-05 - mae: 0.0051 - mse: 5.0505e-05\n",
      "Epoch 813: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1999e-05 - mae: 0.0046 - mse: 4.1999e-05 - val_loss: 3.3022e-04 - val_mae: 0.0077 - val_mse: 3.3022e-04\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.1056e-05 - mae: 0.0045 - mse: 4.1056e-05\n",
      "Epoch 814: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.6002e-05 - mae: 0.0042 - mse: 3.6002e-05 - val_loss: 3.2706e-04 - val_mae: 0.0072 - val_mse: 3.2706e-04\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0825e-05 - mae: 0.0041 - mse: 4.0825e-05\n",
      "Epoch 815: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7010e-05 - mae: 0.0039 - mse: 3.7010e-05 - val_loss: 3.3227e-04 - val_mae: 0.0072 - val_mse: 3.3227e-04\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8268e-05 - mae: 0.0039 - mse: 3.8268e-05\n",
      "Epoch 816: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6929e-05 - mae: 0.0038 - mse: 3.6929e-05 - val_loss: 3.1842e-04 - val_mae: 0.0069 - val_mse: 3.1842e-04\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6487e-05 - mae: 0.0038 - mse: 3.6487e-05\n",
      "Epoch 817: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.9279e-05 - mae: 0.0042 - mse: 4.9279e-05 - val_loss: 3.6510e-04 - val_mae: 0.0084 - val_mse: 3.6510e-04\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5613e-04 - mae: 0.0067 - mse: 1.5613e-04\n",
      "Epoch 818: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2440e-04 - mae: 0.0059 - mse: 1.2440e-04 - val_loss: 3.4413e-04 - val_mae: 0.0081 - val_mse: 3.4413e-04\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.0038e-05 - mae: 0.0059 - mse: 9.0038e-05\n",
      "Epoch 819: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.4456e-05 - mae: 0.0053 - mse: 7.4456e-05 - val_loss: 3.4306e-04 - val_mae: 0.0083 - val_mse: 3.4306e-04\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4349e-05 - mae: 0.0052 - mse: 6.4349e-05\n",
      "Epoch 820: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.9512e-05 - mae: 0.0049 - mse: 5.9512e-05 - val_loss: 3.4593e-04 - val_mae: 0.0081 - val_mse: 3.4593e-04\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9417e-05 - mae: 0.0057 - mse: 6.9417e-05\n",
      "Epoch 821: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.8411e-05 - mae: 0.0051 - mse: 5.8411e-05 - val_loss: 3.4941e-04 - val_mae: 0.0078 - val_mse: 3.4941e-04\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8749e-05 - mae: 0.0045 - mse: 4.8749e-05\n",
      "Epoch 822: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.0541e-05 - mae: 0.0047 - mse: 5.0541e-05 - val_loss: 3.5473e-04 - val_mae: 0.0082 - val_mse: 3.5473e-04\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0758e-05 - mae: 0.0057 - mse: 8.0758e-05\n",
      "Epoch 823: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.3155e-05 - mae: 0.0054 - mse: 7.3155e-05 - val_loss: 3.3000e-04 - val_mae: 0.0077 - val_mse: 3.3000e-04\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9014e-05 - mae: 0.0052 - mse: 6.9014e-05\n",
      "Epoch 824: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.8543e-05 - mae: 0.0047 - mse: 5.8543e-05 - val_loss: 3.1978e-04 - val_mae: 0.0070 - val_mse: 3.1978e-04\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3843e-05 - mae: 0.0037 - mse: 3.3843e-05\n",
      "Epoch 825: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.7326e-05 - mae: 0.0039 - mse: 3.7326e-05 - val_loss: 3.3995e-04 - val_mae: 0.0073 - val_mse: 3.3995e-04\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6693e-05 - mae: 0.0042 - mse: 4.6693e-05\n",
      "Epoch 826: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.8691e-05 - mae: 0.0044 - mse: 4.8691e-05 - val_loss: 3.2502e-04 - val_mae: 0.0075 - val_mse: 3.2502e-04\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2114e-05 - mae: 0.0045 - mse: 5.2114e-05\n",
      "Epoch 827: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.6652e-05 - mae: 0.0047 - mse: 5.6652e-05 - val_loss: 3.5127e-04 - val_mae: 0.0090 - val_mse: 3.5127e-04\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0239e-05 - mae: 0.0060 - mse: 8.0239e-05\n",
      "Epoch 828: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.1093e-05 - mae: 0.0055 - mse: 7.1093e-05 - val_loss: 3.3629e-04 - val_mae: 0.0080 - val_mse: 3.3629e-04\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4680e-05 - mae: 0.0049 - mse: 4.4680e-05\n",
      "Epoch 829: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.6868e-05 - mae: 0.0049 - mse: 4.6868e-05 - val_loss: 3.3180e-04 - val_mae: 0.0082 - val_mse: 3.3180e-04\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2499e-05 - mae: 0.0048 - mse: 4.2499e-05\n",
      "Epoch 830: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.5595e-05 - mae: 0.0049 - mse: 4.5595e-05 - val_loss: 3.2125e-04 - val_mae: 0.0076 - val_mse: 3.2125e-04\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1037e-05 - mae: 0.0046 - mse: 4.1037e-05\n",
      "Epoch 831: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.0348e-05 - mae: 0.0046 - mse: 4.0348e-05 - val_loss: 3.0915e-04 - val_mae: 0.0072 - val_mse: 3.0915e-04\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0330e-05 - mae: 0.0035 - mse: 2.0330e-05\n",
      "Epoch 832: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.1336e-05 - mae: 0.0041 - mse: 3.1336e-05 - val_loss: 3.1777e-04 - val_mae: 0.0072 - val_mse: 3.1777e-04\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8493e-05 - mae: 0.0039 - mse: 2.8493e-05\n",
      "Epoch 833: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.4546e-05 - mae: 0.0042 - mse: 3.4546e-05 - val_loss: 2.9140e-04 - val_mae: 0.0066 - val_mse: 2.9140e-04\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8954e-05 - mae: 0.0032 - mse: 1.8954e-05\n",
      "Epoch 834: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7443e-05 - mae: 0.0038 - mse: 2.7443e-05 - val_loss: 3.2447e-04 - val_mae: 0.0070 - val_mse: 3.2447e-04\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9471e-05 - mae: 0.0040 - mse: 2.9471e-05\n",
      "Epoch 835: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.9653e-05 - mae: 0.0040 - mse: 2.9653e-05 - val_loss: 3.8187e-04 - val_mae: 0.0091 - val_mse: 3.8187e-04\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.6410e-05 - mae: 0.0050 - mse: 4.6410e-05\n",
      "Epoch 836: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.9415e-05 - mae: 0.0045 - mse: 3.9415e-05 - val_loss: 3.4455e-04 - val_mae: 0.0093 - val_mse: 3.4455e-04\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6132e-05 - mae: 0.0050 - mse: 4.6132e-05\n",
      "Epoch 837: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.2460e-05 - mae: 0.0047 - mse: 4.2460e-05 - val_loss: 3.1441e-04 - val_mae: 0.0076 - val_mse: 3.1441e-04\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8879e-05 - mae: 0.0041 - mse: 2.8879e-05\n",
      "Epoch 838: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0689e-05 - mae: 0.0042 - mse: 3.0689e-05 - val_loss: 3.2440e-04 - val_mae: 0.0070 - val_mse: 3.2440e-04\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2400e-05 - mae: 0.0036 - mse: 2.2400e-05\n",
      "Epoch 839: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4782e-05 - mae: 0.0038 - mse: 2.4782e-05 - val_loss: 3.1281e-04 - val_mae: 0.0068 - val_mse: 3.1281e-04\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9003e-05 - mae: 0.0033 - mse: 1.9003e-05\n",
      "Epoch 840: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1630e-05 - mae: 0.0034 - mse: 2.1630e-05 - val_loss: 2.8854e-04 - val_mae: 0.0069 - val_mse: 2.8854e-04\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.0874e-05 - mae: 0.0034 - mse: 2.0874e-05\n",
      "Epoch 841: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1642e-05 - mae: 0.0035 - mse: 2.1642e-05 - val_loss: 3.1188e-04 - val_mae: 0.0071 - val_mse: 3.1188e-04\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6811e-05 - mae: 0.0038 - mse: 2.6811e-05\n",
      "Epoch 842: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6725e-05 - mae: 0.0038 - mse: 2.6725e-05 - val_loss: 3.1890e-04 - val_mae: 0.0074 - val_mse: 3.1890e-04\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.4162e-05 - mae: 0.0037 - mse: 2.4162e-05\n",
      "Epoch 843: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0142e-05 - mae: 0.0039 - mse: 3.0142e-05 - val_loss: 2.8878e-04 - val_mae: 0.0068 - val_mse: 2.8878e-04\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4253e-05 - mae: 0.0036 - mse: 2.4253e-05\n",
      "Epoch 844: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.1364e-05 - mae: 0.0038 - mse: 3.1364e-05 - val_loss: 3.0398e-04 - val_mae: 0.0068 - val_mse: 3.0398e-04\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7928e-05 - mae: 0.0030 - mse: 1.7928e-05\n",
      "Epoch 845: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.2713e-05 - mae: 0.0033 - mse: 2.2713e-05 - val_loss: 3.1121e-04 - val_mae: 0.0072 - val_mse: 3.1121e-04\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.4318e-05 - mae: 0.0038 - mse: 3.4318e-05\n",
      "Epoch 846: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.0970e-05 - mae: 0.0036 - mse: 3.0970e-05 - val_loss: 3.1326e-04 - val_mae: 0.0072 - val_mse: 3.1326e-04\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9298e-05 - mae: 0.0044 - mse: 4.9298e-05\n",
      "Epoch 847: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.4930e-05 - mae: 0.0042 - mse: 4.4930e-05 - val_loss: 3.3137e-04 - val_mae: 0.0080 - val_mse: 3.3137e-04\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4904e-05 - mae: 0.0048 - mse: 5.4904e-05\n",
      "Epoch 848: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.9152e-05 - mae: 0.0046 - mse: 4.9152e-05 - val_loss: 3.1608e-04 - val_mae: 0.0074 - val_mse: 3.1608e-04\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7289e-05 - mae: 0.0039 - mse: 2.7289e-05\n",
      "Epoch 849: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.9664e-05 - mae: 0.0040 - mse: 2.9664e-05 - val_loss: 3.0651e-04 - val_mae: 0.0072 - val_mse: 3.0651e-04\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7895e-05 - mae: 0.0038 - mse: 2.7895e-05\n",
      "Epoch 850: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0480e-05 - mae: 0.0041 - mse: 3.0480e-05 - val_loss: 3.1304e-04 - val_mae: 0.0068 - val_mse: 3.1304e-04\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7099e-05 - mae: 0.0029 - mse: 1.7099e-05\n",
      "Epoch 851: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3639e-05 - mae: 0.0034 - mse: 2.3639e-05 - val_loss: 3.0058e-04 - val_mae: 0.0067 - val_mse: 3.0058e-04\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1812e-05 - mae: 0.0033 - mse: 2.1812e-05\n",
      "Epoch 852: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.3860e-05 - mae: 0.0034 - mse: 2.3860e-05 - val_loss: 2.9832e-04 - val_mae: 0.0070 - val_mse: 2.9832e-04\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4345e-05 - mae: 0.0034 - mse: 2.4345e-05\n",
      "Epoch 853: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6296e-05 - mae: 0.0036 - mse: 2.6296e-05 - val_loss: 3.3477e-04 - val_mae: 0.0080 - val_mse: 3.3477e-04\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2211e-05 - mae: 0.0041 - mse: 3.2211e-05\n",
      "Epoch 854: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.0361e-05 - mae: 0.0040 - mse: 3.0361e-05 - val_loss: 3.1114e-04 - val_mae: 0.0073 - val_mse: 3.1114e-04\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5023e-05 - mae: 0.0037 - mse: 2.5023e-05\n",
      "Epoch 855: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6224e-05 - mae: 0.0037 - mse: 2.6224e-05 - val_loss: 2.9324e-04 - val_mae: 0.0069 - val_mse: 2.9324e-04\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.7893e-05 - mae: 0.0038 - mse: 2.7893e-05\n",
      "Epoch 856: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.7281e-05 - mae: 0.0038 - mse: 2.7281e-05 - val_loss: 3.0440e-04 - val_mae: 0.0072 - val_mse: 3.0440e-04\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6109e-05 - mae: 0.0039 - mse: 2.6109e-05\n",
      "Epoch 857: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.4596e-05 - mae: 0.0038 - mse: 2.4596e-05 - val_loss: 3.3614e-04 - val_mae: 0.0079 - val_mse: 3.3614e-04\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9999e-05 - mae: 0.0041 - mse: 2.9999e-05\n",
      "Epoch 858: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7154e-05 - mae: 0.0039 - mse: 2.7154e-05 - val_loss: 3.2117e-04 - val_mae: 0.0077 - val_mse: 3.2117e-04\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2278e-05 - mae: 0.0043 - mse: 3.2278e-05\n",
      "Epoch 859: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.9035e-05 - mae: 0.0040 - mse: 2.9035e-05 - val_loss: 2.9738e-04 - val_mae: 0.0068 - val_mse: 2.9738e-04\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9907e-05 - mae: 0.0039 - mse: 2.9907e-05\n",
      "Epoch 860: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7476e-05 - mae: 0.0038 - mse: 2.7476e-05 - val_loss: 3.1994e-04 - val_mae: 0.0073 - val_mse: 3.1994e-04\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9067e-05 - mae: 0.0038 - mse: 2.9067e-05\n",
      "Epoch 861: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.7060e-05 - mae: 0.0038 - mse: 2.7060e-05 - val_loss: 3.1208e-04 - val_mae: 0.0070 - val_mse: 3.1208e-04\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.7503e-05 - mae: 0.0037 - mse: 2.7503e-05\n",
      "Epoch 862: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 2.4265e-05 - mae: 0.0035 - mse: 2.4265e-05 - val_loss: 2.9537e-04 - val_mae: 0.0070 - val_mse: 2.9537e-04\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3815e-05 - mae: 0.0034 - mse: 2.3815e-05\n",
      "Epoch 863: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1879e-05 - mae: 0.0033 - mse: 2.1879e-05 - val_loss: 2.9656e-04 - val_mae: 0.0067 - val_mse: 2.9656e-04\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0370e-05 - mae: 0.0032 - mse: 2.0370e-05\n",
      "Epoch 864: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0680e-05 - mae: 0.0032 - mse: 2.0680e-05 - val_loss: 3.2476e-04 - val_mae: 0.0074 - val_mse: 3.2476e-04\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3032e-05 - mae: 0.0043 - mse: 4.3032e-05\n",
      "Epoch 865: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.5685e-05 - mae: 0.0039 - mse: 3.5685e-05 - val_loss: 3.0868e-04 - val_mae: 0.0069 - val_mse: 3.0868e-04\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3625e-05 - mae: 0.0038 - mse: 3.3625e-05\n",
      "Epoch 866: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.9749e-05 - mae: 0.0035 - mse: 2.9749e-05 - val_loss: 3.1336e-04 - val_mae: 0.0070 - val_mse: 3.1336e-04\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9226e-05 - mae: 0.0036 - mse: 2.9226e-05\n",
      "Epoch 867: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9955e-05 - mae: 0.0037 - mse: 2.9955e-05 - val_loss: 3.2691e-04 - val_mae: 0.0075 - val_mse: 3.2691e-04\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3208e-05 - mae: 0.0051 - mse: 6.3208e-05\n",
      "Epoch 868: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9843e-05 - mae: 0.0044 - mse: 4.9843e-05 - val_loss: 3.2732e-04 - val_mae: 0.0074 - val_mse: 3.2732e-04\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9606e-05 - mae: 0.0043 - mse: 3.9606e-05\n",
      "Epoch 869: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2876e-05 - mae: 0.0039 - mse: 3.2876e-05 - val_loss: 3.0227e-04 - val_mae: 0.0068 - val_mse: 3.0227e-04\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4226e-05 - mae: 0.0036 - mse: 2.4226e-05\n",
      "Epoch 870: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1520e-05 - mae: 0.0034 - mse: 2.1520e-05 - val_loss: 2.9426e-04 - val_mae: 0.0066 - val_mse: 2.9426e-04\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7718e-05 - mae: 0.0030 - mse: 1.7718e-05\n",
      "Epoch 871: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9648e-05 - mae: 0.0031 - mse: 1.9648e-05 - val_loss: 3.0899e-04 - val_mae: 0.0068 - val_mse: 3.0899e-04\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9498e-05 - mae: 0.0037 - mse: 2.9498e-05\n",
      "Epoch 872: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5409e-05 - mae: 0.0034 - mse: 2.5409e-05 - val_loss: 3.0142e-04 - val_mae: 0.0064 - val_mse: 3.0142e-04\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1230e-05 - mae: 0.0030 - mse: 2.1230e-05\n",
      "Epoch 873: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0017e-05 - mae: 0.0030 - mse: 2.0017e-05 - val_loss: 3.0406e-04 - val_mae: 0.0066 - val_mse: 3.0406e-04\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.4767e-05 - mae: 0.0032 - mse: 2.4767e-05\n",
      "Epoch 874: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.2435e-05 - mae: 0.0031 - mse: 2.2435e-05 - val_loss: 3.0597e-04 - val_mae: 0.0065 - val_mse: 3.0597e-04\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5806e-05 - mae: 0.0033 - mse: 2.5806e-05\n",
      "Epoch 875: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1883e-05 - mae: 0.0031 - mse: 2.1883e-05 - val_loss: 3.1570e-04 - val_mae: 0.0064 - val_mse: 3.1570e-04\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6144e-05 - mae: 0.0028 - mse: 1.6144e-05\n",
      "Epoch 876: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6088e-05 - mae: 0.0028 - mse: 1.6088e-05 - val_loss: 3.1697e-04 - val_mae: 0.0066 - val_mse: 3.1697e-04\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9446e-05 - mae: 0.0032 - mse: 1.9446e-05\n",
      "Epoch 877: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8982e-05 - mae: 0.0031 - mse: 1.8982e-05 - val_loss: 3.0193e-04 - val_mae: 0.0067 - val_mse: 3.0193e-04\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7372e-05 - mae: 0.0032 - mse: 1.7372e-05\n",
      "Epoch 878: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6890e-05 - mae: 0.0031 - mse: 1.6890e-05 - val_loss: 3.0707e-04 - val_mae: 0.0071 - val_mse: 3.0707e-04\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1825e-05 - mae: 0.0035 - mse: 2.1825e-05\n",
      "Epoch 879: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9850e-05 - mae: 0.0034 - mse: 1.9850e-05 - val_loss: 3.0563e-04 - val_mae: 0.0066 - val_mse: 3.0563e-04\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3188e-05 - mae: 0.0034 - mse: 2.3188e-05\n",
      "Epoch 880: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.0478e-05 - mae: 0.0032 - mse: 2.0478e-05 - val_loss: 3.0323e-04 - val_mae: 0.0067 - val_mse: 3.0323e-04\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0922e-05 - mae: 0.0032 - mse: 2.0922e-05\n",
      "Epoch 881: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9307e-05 - mae: 0.0031 - mse: 1.9307e-05 - val_loss: 3.1119e-04 - val_mae: 0.0067 - val_mse: 3.1119e-04\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6094e-05 - mae: 0.0034 - mse: 2.6094e-05\n",
      "Epoch 882: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.2967e-05 - mae: 0.0032 - mse: 2.2967e-05 - val_loss: 3.0442e-04 - val_mae: 0.0066 - val_mse: 3.0442e-04\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8497e-05 - mae: 0.0031 - mse: 1.8497e-05\n",
      "Epoch 883: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7993e-05 - mae: 0.0030 - mse: 1.7993e-05 - val_loss: 3.0242e-04 - val_mae: 0.0064 - val_mse: 3.0242e-04\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2762e-05 - mae: 0.0033 - mse: 2.2762e-05\n",
      "Epoch 884: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0279e-05 - mae: 0.0031 - mse: 2.0279e-05 - val_loss: 3.1100e-04 - val_mae: 0.0065 - val_mse: 3.1100e-04\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1970e-05 - mae: 0.0031 - mse: 2.1970e-05\n",
      "Epoch 885: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0104e-05 - mae: 0.0031 - mse: 2.0104e-05 - val_loss: 3.0444e-04 - val_mae: 0.0066 - val_mse: 3.0444e-04\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2307e-05 - mae: 0.0033 - mse: 2.2307e-05\n",
      "Epoch 886: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0180e-05 - mae: 0.0031 - mse: 2.0180e-05 - val_loss: 3.2070e-04 - val_mae: 0.0068 - val_mse: 3.2070e-04\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.8782e-05 - mae: 0.0031 - mse: 1.8782e-05\n",
      "Epoch 887: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.8438e-05 - mae: 0.0032 - mse: 1.8438e-05 - val_loss: 2.9540e-04 - val_mae: 0.0063 - val_mse: 2.9540e-04\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0986e-05 - mae: 0.0025 - mse: 1.0986e-05\n",
      "Epoch 888: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.2747e-05 - mae: 0.0027 - mse: 1.2747e-05 - val_loss: 3.0257e-04 - val_mae: 0.0063 - val_mse: 3.0257e-04\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0613e-05 - mae: 0.0024 - mse: 1.0613e-05\n",
      "Epoch 889: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1749e-05 - mae: 0.0026 - mse: 1.1749e-05 - val_loss: 3.1648e-04 - val_mae: 0.0066 - val_mse: 3.1648e-04\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2940e-05 - mae: 0.0028 - mse: 1.2940e-05\n",
      "Epoch 890: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2385e-05 - mae: 0.0027 - mse: 1.2385e-05 - val_loss: 3.0258e-04 - val_mae: 0.0065 - val_mse: 3.0258e-04\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1359e-05 - mae: 0.0025 - mse: 1.1359e-05\n",
      "Epoch 891: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0806e-05 - mae: 0.0024 - mse: 1.0806e-05 - val_loss: 3.0721e-04 - val_mae: 0.0064 - val_mse: 3.0721e-04\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5553e-05 - mae: 0.0029 - mse: 1.5553e-05\n",
      "Epoch 892: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3517e-05 - mae: 0.0026 - mse: 1.3517e-05 - val_loss: 3.0223e-04 - val_mae: 0.0065 - val_mse: 3.0223e-04\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4876e-05 - mae: 0.0029 - mse: 1.4876e-05\n",
      "Epoch 893: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4130e-05 - mae: 0.0028 - mse: 1.4130e-05 - val_loss: 2.9989e-04 - val_mae: 0.0061 - val_mse: 2.9989e-04\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0761e-05 - mae: 0.0024 - mse: 1.0761e-05\n",
      "Epoch 894: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0477e-05 - mae: 0.0024 - mse: 1.0477e-05 - val_loss: 2.9590e-04 - val_mae: 0.0062 - val_mse: 2.9590e-04\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0461e-05 - mae: 0.0023 - mse: 1.0461e-05\n",
      "Epoch 895: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0420e-05 - mae: 0.0023 - mse: 1.0420e-05 - val_loss: 3.0147e-04 - val_mae: 0.0061 - val_mse: 3.0147e-04\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2467e-05 - mae: 0.0024 - mse: 1.2467e-05\n",
      "Epoch 896: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1626e-05 - mae: 0.0023 - mse: 1.1626e-05 - val_loss: 3.0051e-04 - val_mae: 0.0062 - val_mse: 3.0051e-04\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2121e-05 - mae: 0.0024 - mse: 1.2121e-05\n",
      "Epoch 897: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1748e-05 - mae: 0.0024 - mse: 1.1748e-05 - val_loss: 2.9339e-04 - val_mae: 0.0060 - val_mse: 2.9339e-04\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.2834e-05 - mae: 0.0025 - mse: 1.2834e-05\n",
      "Epoch 898: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1746e-05 - mae: 0.0024 - mse: 1.1746e-05 - val_loss: 2.9868e-04 - val_mae: 0.0060 - val_mse: 2.9868e-04\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0119e-05 - mae: 0.0022 - mse: 1.0119e-05\n",
      "Epoch 899: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0188e-05 - mae: 0.0022 - mse: 1.0188e-05 - val_loss: 3.0120e-04 - val_mae: 0.0059 - val_mse: 3.0120e-04\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0364e-06 - mae: 0.0022 - mse: 9.0364e-06\n",
      "Epoch 900: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.9061e-06 - mae: 0.0022 - mse: 9.9061e-06 - val_loss: 3.0316e-04 - val_mae: 0.0063 - val_mse: 3.0316e-04\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1311e-05 - mae: 0.0024 - mse: 1.1311e-05\n",
      "Epoch 901: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.0927e-05 - mae: 0.0024 - mse: 1.0927e-05 - val_loss: 2.9085e-04 - val_mae: 0.0061 - val_mse: 2.9085e-04\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2402e-05 - mae: 0.0025 - mse: 1.2402e-05\n",
      "Epoch 902: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0815e-05 - mae: 0.0023 - mse: 1.0815e-05 - val_loss: 2.8844e-04 - val_mae: 0.0061 - val_mse: 2.8844e-04\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3546e-05 - mae: 0.0026 - mse: 1.3546e-05\n",
      "Epoch 903: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1385e-05 - mae: 0.0024 - mse: 1.1385e-05 - val_loss: 2.9429e-04 - val_mae: 0.0060 - val_mse: 2.9429e-04\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3272e-05 - mae: 0.0025 - mse: 1.3272e-05\n",
      "Epoch 904: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1519e-05 - mae: 0.0023 - mse: 1.1519e-05 - val_loss: 2.9833e-04 - val_mae: 0.0061 - val_mse: 2.9833e-04\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3019e-05 - mae: 0.0024 - mse: 1.3019e-05\n",
      "Epoch 905: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1575e-05 - mae: 0.0023 - mse: 1.1575e-05 - val_loss: 2.9565e-04 - val_mae: 0.0059 - val_mse: 2.9565e-04\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2431e-05 - mae: 0.0023 - mse: 1.2431e-05\n",
      "Epoch 906: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1478e-05 - mae: 0.0022 - mse: 1.1478e-05 - val_loss: 2.9570e-04 - val_mae: 0.0060 - val_mse: 2.9570e-04\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2553e-05 - mae: 0.0022 - mse: 1.2553e-05\n",
      "Epoch 907: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1545e-05 - mae: 0.0022 - mse: 1.1545e-05 - val_loss: 2.9123e-04 - val_mae: 0.0059 - val_mse: 2.9123e-04\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3548e-05 - mae: 0.0024 - mse: 1.3548e-05\n",
      "Epoch 908: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1875e-05 - mae: 0.0022 - mse: 1.1875e-05 - val_loss: 3.0489e-04 - val_mae: 0.0061 - val_mse: 3.0489e-04\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1706e-05 - mae: 0.0023 - mse: 1.1706e-05\n",
      "Epoch 909: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0317e-05 - mae: 0.0022 - mse: 1.0317e-05 - val_loss: 2.9445e-04 - val_mae: 0.0057 - val_mse: 2.9445e-04\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7754e-06 - mae: 0.0018 - mse: 6.7754e-06\n",
      "Epoch 910: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1084e-06 - mae: 0.0020 - mse: 8.1084e-06 - val_loss: 2.9480e-04 - val_mae: 0.0059 - val_mse: 2.9480e-04\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0284e-05 - mae: 0.0022 - mse: 1.0284e-05\n",
      "Epoch 911: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1669e-05 - mae: 0.0023 - mse: 1.1669e-05 - val_loss: 2.9618e-04 - val_mae: 0.0061 - val_mse: 2.9618e-04\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4368e-05 - mae: 0.0026 - mse: 1.4368e-05\n",
      "Epoch 912: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.3811e-05 - mae: 0.0025 - mse: 1.3811e-05 - val_loss: 2.9959e-04 - val_mae: 0.0059 - val_mse: 2.9959e-04\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1471e-05 - mae: 0.0023 - mse: 1.1471e-05\n",
      "Epoch 913: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1152e-05 - mae: 0.0023 - mse: 1.1152e-05 - val_loss: 2.9079e-04 - val_mae: 0.0059 - val_mse: 2.9079e-04\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1150e-05 - mae: 0.0023 - mse: 1.1150e-05\n",
      "Epoch 914: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1110e-05 - mae: 0.0023 - mse: 1.1110e-05 - val_loss: 2.8916e-04 - val_mae: 0.0062 - val_mse: 2.8916e-04\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0981e-05 - mae: 0.0024 - mse: 1.0981e-05\n",
      "Epoch 915: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1522e-05 - mae: 0.0024 - mse: 1.1522e-05 - val_loss: 3.0494e-04 - val_mae: 0.0064 - val_mse: 3.0494e-04\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0723e-05 - mae: 0.0024 - mse: 1.0723e-05\n",
      "Epoch 916: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2029e-05 - mae: 0.0025 - mse: 1.2029e-05 - val_loss: 2.9569e-04 - val_mae: 0.0062 - val_mse: 2.9569e-04\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4146e-06 - mae: 0.0023 - mse: 9.4146e-06\n",
      "Epoch 917: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.0362e-05 - mae: 0.0024 - mse: 1.0362e-05 - val_loss: 2.9373e-04 - val_mae: 0.0062 - val_mse: 2.9373e-04\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3241e-05 - mae: 0.0026 - mse: 1.3241e-05\n",
      "Epoch 918: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3331e-05 - mae: 0.0026 - mse: 1.3331e-05 - val_loss: 2.9677e-04 - val_mae: 0.0064 - val_mse: 2.9677e-04\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4638e-05 - mae: 0.0028 - mse: 1.4638e-05\n",
      "Epoch 919: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3138e-05 - mae: 0.0026 - mse: 1.3138e-05 - val_loss: 3.0308e-04 - val_mae: 0.0063 - val_mse: 3.0308e-04\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3960e-05 - mae: 0.0027 - mse: 1.3960e-05\n",
      "Epoch 920: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2526e-05 - mae: 0.0025 - mse: 1.2526e-05 - val_loss: 2.9518e-04 - val_mae: 0.0061 - val_mse: 2.9518e-04\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1423e-05 - mae: 0.0025 - mse: 1.1423e-05\n",
      "Epoch 921: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 1.0946e-05 - mae: 0.0024 - mse: 1.0946e-05 - val_loss: 2.9043e-04 - val_mae: 0.0060 - val_mse: 2.9043e-04\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5314e-06 - mae: 0.0022 - mse: 9.5314e-06\n",
      "Epoch 922: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.9770e-06 - mae: 0.0023 - mse: 9.9770e-06 - val_loss: 2.9668e-04 - val_mae: 0.0061 - val_mse: 2.9668e-04\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.1392e-05 - mae: 0.0025 - mse: 1.1392e-05\n",
      "Epoch 923: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.6787e-06 - mae: 0.0023 - mse: 9.6787e-06 - val_loss: 2.8794e-04 - val_mae: 0.0062 - val_mse: 2.8794e-04\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8089e-05 - mae: 0.0028 - mse: 1.8089e-05\n",
      "Epoch 924: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5676e-05 - mae: 0.0026 - mse: 1.5676e-05 - val_loss: 2.9370e-04 - val_mae: 0.0063 - val_mse: 2.9370e-04\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7055e-05 - mae: 0.0028 - mse: 1.7055e-05\n",
      "Epoch 925: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6724e-05 - mae: 0.0027 - mse: 1.6724e-05 - val_loss: 2.9172e-04 - val_mae: 0.0061 - val_mse: 2.9172e-04\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6640e-05 - mae: 0.0027 - mse: 1.6640e-05\n",
      "Epoch 926: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6983e-05 - mae: 0.0027 - mse: 1.6983e-05 - val_loss: 2.8859e-04 - val_mae: 0.0063 - val_mse: 2.8859e-04\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4278e-05 - mae: 0.0027 - mse: 1.4278e-05\n",
      "Epoch 927: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5289e-05 - mae: 0.0027 - mse: 1.5289e-05 - val_loss: 2.9479e-04 - val_mae: 0.0062 - val_mse: 2.9479e-04\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1396e-05 - mae: 0.0025 - mse: 1.1396e-05\n",
      "Epoch 928: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2222e-05 - mae: 0.0025 - mse: 1.2222e-05 - val_loss: 3.0065e-04 - val_mae: 0.0063 - val_mse: 3.0065e-04\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6014e-05 - mae: 0.0028 - mse: 1.6014e-05\n",
      "Epoch 929: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5438e-05 - mae: 0.0028 - mse: 1.5438e-05 - val_loss: 2.9182e-04 - val_mae: 0.0063 - val_mse: 2.9182e-04\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8875e-05 - mae: 0.0030 - mse: 1.8875e-05\n",
      "Epoch 930: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7537e-05 - mae: 0.0029 - mse: 1.7537e-05 - val_loss: 3.0192e-04 - val_mae: 0.0064 - val_mse: 3.0192e-04\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2131e-05 - mae: 0.0030 - mse: 2.2131e-05\n",
      "Epoch 931: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0098e-05 - mae: 0.0029 - mse: 2.0098e-05 - val_loss: 3.0034e-04 - val_mae: 0.0062 - val_mse: 3.0034e-04\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2234e-05 - mae: 0.0024 - mse: 1.2234e-05\n",
      "Epoch 932: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2176e-05 - mae: 0.0024 - mse: 1.2176e-05 - val_loss: 2.8715e-04 - val_mae: 0.0060 - val_mse: 2.8715e-04\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0386e-05 - mae: 0.0023 - mse: 1.0386e-05\n",
      "Epoch 933: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0396e-05 - mae: 0.0023 - mse: 1.0396e-05 - val_loss: 2.8519e-04 - val_mae: 0.0060 - val_mse: 2.8519e-04\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2993e-05 - mae: 0.0024 - mse: 1.2993e-05\n",
      "Epoch 934: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1048e-05 - mae: 0.0023 - mse: 1.1048e-05 - val_loss: 2.9032e-04 - val_mae: 0.0063 - val_mse: 2.9032e-04\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1244e-05 - mae: 0.0028 - mse: 2.1244e-05\n",
      "Epoch 935: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8798e-05 - mae: 0.0027 - mse: 1.8798e-05 - val_loss: 2.8804e-04 - val_mae: 0.0059 - val_mse: 2.8804e-04\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7452e-05 - mae: 0.0027 - mse: 1.7452e-05\n",
      "Epoch 936: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5352e-05 - mae: 0.0026 - mse: 1.5352e-05 - val_loss: 2.8876e-04 - val_mae: 0.0061 - val_mse: 2.8876e-04\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5378e-05 - mae: 0.0028 - mse: 1.5378e-05\n",
      "Epoch 937: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3913e-05 - mae: 0.0026 - mse: 1.3913e-05 - val_loss: 2.8895e-04 - val_mae: 0.0064 - val_mse: 2.8895e-04\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.2760e-05 - mae: 0.0031 - mse: 2.2760e-05\n",
      "Epoch 938: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0670e-05 - mae: 0.0031 - mse: 2.0670e-05 - val_loss: 2.9773e-04 - val_mae: 0.0065 - val_mse: 2.9773e-04\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8433e-05 - mae: 0.0030 - mse: 1.8433e-05\n",
      "Epoch 939: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8669e-05 - mae: 0.0031 - mse: 1.8669e-05 - val_loss: 2.9545e-04 - val_mae: 0.0064 - val_mse: 2.9545e-04\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3467e-05 - mae: 0.0032 - mse: 2.3467e-05\n",
      "Epoch 940: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.3827e-05 - mae: 0.0034 - mse: 2.3827e-05 - val_loss: 2.9894e-04 - val_mae: 0.0066 - val_mse: 2.9894e-04\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6130e-05 - mae: 0.0029 - mse: 1.6130e-05\n",
      "Epoch 941: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7245e-05 - mae: 0.0031 - mse: 1.7245e-05 - val_loss: 2.8758e-04 - val_mae: 0.0063 - val_mse: 2.8758e-04\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6370e-05 - mae: 0.0029 - mse: 1.6370e-05\n",
      "Epoch 942: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6323e-05 - mae: 0.0030 - mse: 1.6323e-05 - val_loss: 2.9623e-04 - val_mae: 0.0065 - val_mse: 2.9623e-04\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6872e-05 - mae: 0.0029 - mse: 1.6872e-05\n",
      "Epoch 943: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7159e-05 - mae: 0.0030 - mse: 1.7159e-05 - val_loss: 2.9376e-04 - val_mae: 0.0065 - val_mse: 2.9376e-04\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5165e-05 - mae: 0.0028 - mse: 1.5165e-05\n",
      "Epoch 944: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.6604e-05 - mae: 0.0030 - mse: 1.6604e-05 - val_loss: 2.9032e-04 - val_mae: 0.0063 - val_mse: 2.9032e-04\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3029e-05 - mae: 0.0027 - mse: 1.3029e-05\n",
      "Epoch 945: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3994e-05 - mae: 0.0028 - mse: 1.3994e-05 - val_loss: 2.9041e-04 - val_mae: 0.0066 - val_mse: 2.9041e-04\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6300e-05 - mae: 0.0029 - mse: 1.6300e-05\n",
      "Epoch 946: val_loss improved from 0.00028 to 0.00028, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.6163e-05 - mae: 0.0030 - mse: 1.6163e-05 - val_loss: 2.8384e-04 - val_mae: 0.0066 - val_mse: 2.8384e-04\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.6310e-05 - mae: 0.0035 - mse: 2.6310e-05\n",
      "Epoch 947: val_loss did not improve from 0.00028\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.3589e-05 - mae: 0.0034 - mse: 2.3589e-05 - val_loss: 2.9819e-04 - val_mae: 0.0066 - val_mse: 2.9819e-04\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7688e-05 - mae: 0.0030 - mse: 1.7688e-05\n",
      "Epoch 948: val_loss improved from 0.00028 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9159e-05 - mae: 0.0032 - mse: 1.9159e-05 - val_loss: 2.7281e-04 - val_mae: 0.0065 - val_mse: 2.7281e-04\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4190e-05 - mae: 0.0029 - mse: 1.4190e-05\n",
      "Epoch 949: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.6344e-05 - mae: 0.0029 - mse: 1.6344e-05 - val_loss: 2.8539e-04 - val_mae: 0.0065 - val_mse: 2.8539e-04\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1602e-05 - mae: 0.0025 - mse: 1.1602e-05\n",
      "Epoch 950: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2293e-05 - mae: 0.0026 - mse: 1.2293e-05 - val_loss: 2.8413e-04 - val_mae: 0.0065 - val_mse: 2.8413e-04\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4122e-05 - mae: 0.0027 - mse: 1.4122e-05\n",
      "Epoch 951: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.5440e-05 - mae: 0.0028 - mse: 1.5440e-05 - val_loss: 2.7881e-04 - val_mae: 0.0060 - val_mse: 2.7881e-04\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4723e-05 - mae: 0.0029 - mse: 1.4723e-05\n",
      "Epoch 952: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3852e-05 - mae: 0.0028 - mse: 1.3852e-05 - val_loss: 2.9632e-04 - val_mae: 0.0065 - val_mse: 2.9632e-04\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3543e-05 - mae: 0.0027 - mse: 1.3543e-05\n",
      "Epoch 953: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3597e-05 - mae: 0.0027 - mse: 1.3597e-05 - val_loss: 2.7954e-04 - val_mae: 0.0062 - val_mse: 2.7954e-04\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2708e-05 - mae: 0.0025 - mse: 1.2708e-05\n",
      "Epoch 954: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6426e-05 - mae: 0.0028 - mse: 1.6426e-05 - val_loss: 2.8675e-04 - val_mae: 0.0068 - val_mse: 2.8675e-04\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1035e-05 - mae: 0.0044 - mse: 5.1035e-05\n",
      "Epoch 955: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0503e-05 - mae: 0.0039 - mse: 4.0503e-05 - val_loss: 2.9957e-04 - val_mae: 0.0067 - val_mse: 2.9957e-04\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.6709e-05 - mae: 0.0035 - mse: 2.6709e-05\n",
      "Epoch 956: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.2531e-05 - mae: 0.0032 - mse: 2.2531e-05 - val_loss: 2.8013e-04 - val_mae: 0.0064 - val_mse: 2.8013e-04\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4537e-05 - mae: 0.0034 - mse: 2.4537e-05\n",
      "Epoch 957: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1570e-05 - mae: 0.0032 - mse: 2.1570e-05 - val_loss: 2.9053e-04 - val_mae: 0.0066 - val_mse: 2.9053e-04\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1795e-05 - mae: 0.0033 - mse: 2.1795e-05\n",
      "Epoch 958: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8745e-05 - mae: 0.0030 - mse: 1.8745e-05 - val_loss: 2.9354e-04 - val_mae: 0.0065 - val_mse: 2.9354e-04\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5113e-05 - mae: 0.0033 - mse: 2.5113e-05\n",
      "Epoch 959: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.1851e-05 - mae: 0.0031 - mse: 2.1851e-05 - val_loss: 2.9387e-04 - val_mae: 0.0065 - val_mse: 2.9387e-04\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3496e-05 - mae: 0.0032 - mse: 2.3496e-05\n",
      "Epoch 960: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.1219e-05 - mae: 0.0031 - mse: 2.1219e-05 - val_loss: 2.9143e-04 - val_mae: 0.0063 - val_mse: 2.9143e-04\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9200e-05 - mae: 0.0031 - mse: 1.9200e-05\n",
      "Epoch 961: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7578e-05 - mae: 0.0030 - mse: 1.7578e-05 - val_loss: 2.9064e-04 - val_mae: 0.0066 - val_mse: 2.9064e-04\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.9077e-05 - mae: 0.0031 - mse: 1.9077e-05\n",
      "Epoch 962: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.7063e-05 - mae: 0.0029 - mse: 1.7063e-05 - val_loss: 2.9915e-04 - val_mae: 0.0071 - val_mse: 2.9915e-04\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.5077e-05 - mae: 0.0035 - mse: 2.5077e-05\n",
      "Epoch 963: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.2440e-05 - mae: 0.0033 - mse: 2.2440e-05 - val_loss: 2.9149e-04 - val_mae: 0.0067 - val_mse: 2.9149e-04\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6533e-05 - mae: 0.0035 - mse: 2.6533e-05\n",
      "Epoch 964: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.4433e-05 - mae: 0.0034 - mse: 2.4433e-05 - val_loss: 2.9215e-04 - val_mae: 0.0068 - val_mse: 2.9215e-04\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8959e-05 - mae: 0.0032 - mse: 1.8959e-05\n",
      "Epoch 965: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.8424e-05 - mae: 0.0031 - mse: 1.8424e-05 - val_loss: 2.9329e-04 - val_mae: 0.0066 - val_mse: 2.9329e-04\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4496e-05 - mae: 0.0035 - mse: 2.4496e-05\n",
      "Epoch 966: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.2630e-05 - mae: 0.0033 - mse: 2.2630e-05 - val_loss: 2.9806e-04 - val_mae: 0.0068 - val_mse: 2.9806e-04\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2428e-05 - mae: 0.0040 - mse: 4.2428e-05\n",
      "Epoch 967: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7151e-05 - mae: 0.0037 - mse: 3.7151e-05 - val_loss: 3.2794e-04 - val_mae: 0.0078 - val_mse: 3.2794e-04\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9286e-05 - mae: 0.0049 - mse: 5.9286e-05\n",
      "Epoch 968: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2196e-05 - mae: 0.0046 - mse: 5.2196e-05 - val_loss: 2.9833e-04 - val_mae: 0.0070 - val_mse: 2.9833e-04\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.4233e-05 - mae: 0.0042 - mse: 4.4233e-05\n",
      "Epoch 969: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2195e-05 - mae: 0.0042 - mse: 4.2195e-05 - val_loss: 2.9588e-04 - val_mae: 0.0071 - val_mse: 2.9588e-04\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.1764e-05 - mae: 0.0038 - mse: 3.1764e-05\n",
      "Epoch 970: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.0991e-05 - mae: 0.0038 - mse: 3.0991e-05 - val_loss: 3.0400e-04 - val_mae: 0.0071 - val_mse: 3.0400e-04\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9503e-05 - mae: 0.0041 - mse: 3.9503e-05\n",
      "Epoch 971: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.6364e-05 - mae: 0.0039 - mse: 3.6364e-05 - val_loss: 2.9666e-04 - val_mae: 0.0069 - val_mse: 2.9666e-04\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.5338e-05 - mae: 0.0034 - mse: 2.5338e-05\n",
      "Epoch 972: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7777e-05 - mae: 0.0035 - mse: 2.7777e-05 - val_loss: 2.9205e-04 - val_mae: 0.0064 - val_mse: 2.9205e-04\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3373e-05 - mae: 0.0027 - mse: 1.3373e-05\n",
      "Epoch 973: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3763e-05 - mae: 0.0027 - mse: 1.3763e-05 - val_loss: 2.7437e-04 - val_mae: 0.0064 - val_mse: 2.7437e-04\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3900e-05 - mae: 0.0027 - mse: 1.3900e-05\n",
      "Epoch 974: val_loss improved from 0.00027 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5318e-05 - mae: 0.0028 - mse: 1.5317e-05 - val_loss: 2.7221e-04 - val_mae: 0.0063 - val_mse: 2.7221e-04\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4212e-05 - mae: 0.0028 - mse: 1.4212e-05\n",
      "Epoch 975: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5130e-05 - mae: 0.0028 - mse: 1.5130e-05 - val_loss: 2.9403e-04 - val_mae: 0.0069 - val_mse: 2.9403e-04\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7588e-05 - mae: 0.0030 - mse: 1.7588e-05\n",
      "Epoch 976: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 1.9329e-05 - mae: 0.0030 - mse: 1.9329e-05 - val_loss: 3.1953e-04 - val_mae: 0.0071 - val_mse: 3.1953e-04\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2038e-05 - mae: 0.0035 - mse: 2.2038e-05\n",
      "Epoch 977: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3611e-05 - mae: 0.0035 - mse: 2.3611e-05 - val_loss: 3.0617e-04 - val_mae: 0.0070 - val_mse: 3.0617e-04\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1937e-05 - mae: 0.0039 - mse: 3.1937e-05\n",
      "Epoch 978: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9314e-05 - mae: 0.0038 - mse: 2.9314e-05 - val_loss: 2.9973e-04 - val_mae: 0.0069 - val_mse: 2.9973e-04\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6518e-05 - mae: 0.0035 - mse: 2.6518e-05\n",
      "Epoch 979: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5396e-05 - mae: 0.0035 - mse: 2.5396e-05 - val_loss: 2.7693e-04 - val_mae: 0.0064 - val_mse: 2.7693e-04\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.2405e-05 - mae: 0.0030 - mse: 2.2405e-05\n",
      "Epoch 980: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1837e-05 - mae: 0.0031 - mse: 2.1837e-05 - val_loss: 3.1425e-04 - val_mae: 0.0071 - val_mse: 3.1425e-04\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9808e-05 - mae: 0.0037 - mse: 2.9808e-05\n",
      "Epoch 981: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.6175e-05 - mae: 0.0035 - mse: 2.6175e-05 - val_loss: 2.8341e-04 - val_mae: 0.0065 - val_mse: 2.8341e-04\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3158e-05 - mae: 0.0034 - mse: 2.3158e-05\n",
      "Epoch 982: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 2.1321e-05 - mae: 0.0033 - mse: 2.1321e-05 - val_loss: 2.7531e-04 - val_mae: 0.0067 - val_mse: 2.7531e-04\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2345e-05 - mae: 0.0034 - mse: 2.2345e-05\n",
      "Epoch 983: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9939e-05 - mae: 0.0032 - mse: 1.9939e-05 - val_loss: 2.9867e-04 - val_mae: 0.0071 - val_mse: 2.9867e-04\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7453e-05 - mae: 0.0036 - mse: 2.7453e-05\n",
      "Epoch 984: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.3995e-05 - mae: 0.0034 - mse: 2.3995e-05 - val_loss: 2.9201e-04 - val_mae: 0.0069 - val_mse: 2.9201e-04\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0912e-05 - mae: 0.0039 - mse: 3.0912e-05\n",
      "Epoch 985: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.5356e-05 - mae: 0.0035 - mse: 2.5356e-05 - val_loss: 3.0524e-04 - val_mae: 0.0070 - val_mse: 3.0524e-04\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0299e-05 - mae: 0.0043 - mse: 4.0299e-05\n",
      "Epoch 986: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.4102e-05 - mae: 0.0040 - mse: 3.4102e-05 - val_loss: 3.0486e-04 - val_mae: 0.0075 - val_mse: 3.0486e-04\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2489e-05 - mae: 0.0040 - mse: 3.2489e-05\n",
      "Epoch 987: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9370e-05 - mae: 0.0038 - mse: 2.9370e-05 - val_loss: 3.0889e-04 - val_mae: 0.0068 - val_mse: 3.0889e-04\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7821e-05 - mae: 0.0038 - mse: 2.7821e-05\n",
      "Epoch 988: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4876e-05 - mae: 0.0035 - mse: 2.4876e-05 - val_loss: 2.9333e-04 - val_mae: 0.0072 - val_mse: 2.9333e-04\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7927e-05 - mae: 0.0037 - mse: 2.7927e-05\n",
      "Epoch 989: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.5986e-05 - mae: 0.0036 - mse: 2.5986e-05 - val_loss: 2.9463e-04 - val_mae: 0.0070 - val_mse: 2.9463e-04\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1950e-05 - mae: 0.0037 - mse: 3.1950e-05\n",
      "Epoch 990: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.8129e-05 - mae: 0.0035 - mse: 2.8129e-05 - val_loss: 2.9905e-04 - val_mae: 0.0064 - val_mse: 2.9905e-04\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8265e-05 - mae: 0.0030 - mse: 1.8265e-05\n",
      "Epoch 991: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8030e-05 - mae: 0.0029 - mse: 1.8030e-05 - val_loss: 2.7595e-04 - val_mae: 0.0062 - val_mse: 2.7595e-04\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9825e-05 - mae: 0.0029 - mse: 1.9825e-05\n",
      "Epoch 992: val_loss improved from 0.00027 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/model/LI-LAPIRA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.2030e-05 - mae: 0.0031 - mse: 2.2030e-05 - val_loss: 2.7048e-04 - val_mae: 0.0065 - val_mse: 2.7048e-04\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9671e-05 - mae: 0.0032 - mse: 1.9671e-05\n",
      "Epoch 993: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 2.0232e-05 - mae: 0.0033 - mse: 2.0232e-05 - val_loss: 2.9735e-04 - val_mae: 0.0073 - val_mse: 2.9735e-04\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6151e-05 - mae: 0.0038 - mse: 2.6151e-05\n",
      "Epoch 994: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5068e-05 - mae: 0.0037 - mse: 2.5068e-05 - val_loss: 3.0422e-04 - val_mae: 0.0076 - val_mse: 3.0422e-04\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0807e-05 - mae: 0.0035 - mse: 2.0807e-05\n",
      "Epoch 995: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.1929e-05 - mae: 0.0035 - mse: 2.1929e-05 - val_loss: 2.9325e-04 - val_mae: 0.0068 - val_mse: 2.9325e-04\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6725e-05 - mae: 0.0031 - mse: 1.6725e-05\n",
      "Epoch 996: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8788e-05 - mae: 0.0033 - mse: 1.8788e-05 - val_loss: 2.7765e-04 - val_mae: 0.0062 - val_mse: 2.7765e-04\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2452e-05 - mae: 0.0027 - mse: 1.2452e-05\n",
      "Epoch 997: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.8722e-05 - mae: 0.0031 - mse: 1.8722e-05 - val_loss: 2.9656e-04 - val_mae: 0.0068 - val_mse: 2.9656e-04\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8065e-05 - mae: 0.0036 - mse: 2.8065e-05\n",
      "Epoch 998: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.1823e-05 - mae: 0.0037 - mse: 3.1823e-05 - val_loss: 2.8737e-04 - val_mae: 0.0070 - val_mse: 2.8737e-04\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.5445e-05 - mae: 0.0041 - mse: 3.5445e-05\n",
      "Epoch 999: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 4.6690e-05 - mae: 0.0043 - mse: 4.6690e-05 - val_loss: 3.3055e-04 - val_mae: 0.0085 - val_mse: 3.3055e-04\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4085e-05 - mae: 0.0057 - mse: 8.4085e-05\n",
      "Epoch 1000: val_loss did not improve from 0.00027\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.5796e-05 - mae: 0.0055 - mse: 7.5796e-05 - val_loss: 2.8816e-04 - val_mae: 0.0075 - val_mse: 2.8816e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "--- federated after local fine-tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/vnvjtlb516n5mswtv7rf58b80000gn/T/ipykernel_1850/2011710758.py:96: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k--\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo 55 plot in: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/federated_fd/TEST\n",
      "Plot salvati correttamente.\n",
      "Test MAE: 0.0221\n",
      "Test RMSE: 0.0498\n",
      "Test MAPE: 0.17%\n",
      "Test R2: 0.9999\n",
      "Valore medio del test set: 13.7463\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_LI-LAPIRA_14-19-07/federated_fd_evaluation_log.json\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip(model, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_np = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    #plot_diagnosis_gradient(y_pred, y_test_np, max_samples_heatmap=10, scatter_sample_ratio=0.7)\n",
    "    evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/{name.replace(' ', '_').lower()}_evaluation_log.json\")\n",
    "    save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/{name.replace(\" \", \"_\").lower()}/TEST', prefix=\"pred_plot\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    if name == 'federated':\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=128, callbacks=[model_checkpoint_callback], validation_split=0.2)\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred)\n",
    "        print(f\"--- {name} after local fine-tuning ---\")\n",
    "        plot_diagnosis_gradient(y_pred, y_test_np, save_path=f\"{name}_pred_quality\", max_samples_heatmap=10, scatter_sample_ratio=0.7)\n",
    "        save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/{name.replace(\" \", \"_\").lower()}_fd/TEST', prefix=\"pred_plot\")\n",
    "        evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/{name.replace(' ', '_').lower()}_fd_evaluation_log.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
