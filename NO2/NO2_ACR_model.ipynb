{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b80b337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import os, pickle, random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "674923c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_after_QA = lambda s: s.split(\"QA_\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20627845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 16)\n"
     ]
    }
   ],
   "source": [
    "dati = pd.read_excel('/Users/lapotinacci/thesis/metric_datasets/NO2_dataset.xlsx')\n",
    "dati = dati[dati[\"serviceUri\"] == \"http://www.disit.org/km4city/resource/iot/orionUNIFI/DISIT/ARPAT_QA_AR-ACROPOLI\"].copy()\n",
    "sensor_name = get_after_QA(dati[\"serviceUri\"].iloc[0])\n",
    "dati.drop(columns=[\"serviceUri\"], inplace=True)\n",
    "print(dati.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d394f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ora inizio esperimento: 14-19-01\n",
      "Giorno inizio esperimento: 2025-11-30\n",
      "Cartella esperimento creata: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01\n"
     ]
    }
   ],
   "source": [
    "# === Creazione cartella esperimento con timestamp ISO ===\n",
    "timestamp = datetime.now().strftime(\"%H-%M-%S\")\n",
    "print(f\"Ora inizio esperimento: {timestamp}\")\n",
    "day= datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Giorno inizio esperimento: {day}\")\n",
    "exp_dir = f\"../RISULTATI/{day}/esperimento_{sensor_name}_{timestamp}\"\n",
    "\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Cartella esperimento creata: {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7794e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "mask = ~dati['TTT'].str.contains(\"nan\", na=True)\n",
    "dtset_completo = dati[mask]\n",
    "\n",
    "dtset_completo['TTT'] = dtset_completo['TTT'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46880af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtra le righe dove la colonna TTT ha lunghezza 24, ed elimina tutte le colonne le cui osservazioni sono indipendenti dal giorno\n",
    "dtset_filtrato = dtset_completo[dtset_completo[\"TTT\"].apply(lambda x: len(x) == 24)].sample(frac=1).reset_index(drop=True)\n",
    "dtset_filtrato = dtset_filtrato[dtset_filtrato[\"type_of_TTT\"] == \"daily\"]\n",
    "len(dtset_filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "022b3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def is_useful_series(series, zero_ratio_thr=0.85, min_nonzero_value=0.1):\n",
    "    arr = np.array(series, dtype=float)\n",
    "    \n",
    "    # Serie troppo corta\n",
    "    if len(arr) <= 1:\n",
    "        return False\n",
    "    \n",
    "    # Troppi zeri\n",
    "    zero_ratio = (arr == 0).mean()\n",
    "    if zero_ratio >= zero_ratio_thr:\n",
    "        return False\n",
    "    \n",
    "    # Valore medio trascurabile (quasi zero)\n",
    "    mean_val = np.mean(arr)\n",
    "    if abs(mean_val) < min_nonzero_value:\n",
    "        return False\n",
    "    \n",
    "    # Se arriva qui, la serie ha valori significativi\n",
    "    return True\n",
    "\n",
    "# Applica filtro\n",
    "mask_useful = dtset_filtrato[\"TTT\"].apply(is_useful_series)\n",
    "df_useful = dtset_filtrato[mask_useful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b897db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spezza_serie_in_colonne(df, colonna_stringa, prefix='col_'):\n",
    "    # --- Controllo colonna ---\n",
    "    if colonna_stringa not in df.columns:\n",
    "        raise ValueError(f\"La colonna '{colonna_stringa}' non esiste nel DataFrame\")\n",
    "\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Estraggo la colonna contenente gli embedding\n",
    "    col = result_df.pop(colonna_stringa)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for item in col:\n",
    "        if pd.isna(item) or item == \"\":\n",
    "            embeddings.append([])\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parsing sicuro della stringa in lista Python\n",
    "            vett = ast.literal_eval(item)\n",
    "\n",
    "            # Se l’embedding è una numpy array o altro iterabile, lo converto in list\n",
    "            if not isinstance(vett, list):\n",
    "                vett = list(vett)\n",
    "\n",
    "            # Converto tutto in float\n",
    "            vett = [float(x) for x in vett]\n",
    "\n",
    "            embeddings.append(vett)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel parsing dell'elemento '{item}': {e}\")\n",
    "            embeddings.append([])\n",
    "\n",
    "    # --- Uniformo dimensione dei vettori ---\n",
    "    lengths = [len(v) for v in embeddings]\n",
    "    if not lengths:\n",
    "        raise ValueError(\"Nessun embedding valido nella colonna\")\n",
    "\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    embeddings_padded = [\n",
    "        v + [np.nan] * (max_len - len(v)) if len(v) < max_len else v\n",
    "        for v in embeddings\n",
    "    ]\n",
    "\n",
    "    # --- Creo DataFrame delle nuove colonne ---\n",
    "    colonne_embedding = pd.DataFrame(\n",
    "        embeddings_padded,\n",
    "        index=result_df.index,\n",
    "        columns=[f\"{prefix}{i}\" for i in range(max_len)]\n",
    "    )\n",
    "\n",
    "    # --- Merge col DataFrame originale ---\n",
    "    return pd.concat([result_df, colonne_embedding], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e1a7a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ttt in df_useful.TTT:\n",
    "    plt.plot(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d7bcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_df(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'n_missing': df.isna().sum(),\n",
    "        '%_missing': (df.isna().mean() * 100).round(2),\n",
    "        'n_unique': df.nunique(),\n",
    "        'top_value': df.mode().iloc[0],  # moda\n",
    "        'top_freq': [df[col].value_counts(dropna=True).iloc[0] if not df[col].value_counts(dropna=True).empty else None for col in df.columns],\n",
    "        'min': [df[col].min() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'max': [df[col].max() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'mean': [df[col].mean() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'std': [df[col].std() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "    })\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0d224ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nella precedente sono state eliminate le colonne con Nan, tuttavia alcuni dataset dei sensori METRO hanno dei Nan in city e surface dunque vengono rimossi nel prcedente box\n",
    "\n",
    "categorical = [\n",
    "    'is_weekend'\n",
    "    ]\n",
    "\n",
    "#consiglio, per serie cicliche usare funzioni periodiche tipo seno coseno \n",
    "df_encoded = pd.get_dummies(df_useful\n",
    "                            , columns=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1247ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Salvato: {path}\")\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80bcd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/dataframe_AR-ACROPOLI/filtered_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "#codifica ciclica delle features e individuazione del'ora del giorno e della settimana \n",
    "\n",
    "def encode_time_features(df, start_col=\"interval_start\", end_col=\"interval_end\"):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Step 1: Ensure datetime columns are in the correct format first\n",
    "    df[start_col] = pd.to_datetime(df[start_col], utc=True, format=\"mixed\")\n",
    "    df[end_col] = pd.to_datetime(df[end_col], utc=True, format=\"mixed\")\n",
    "\n",
    "    # Step 2: Extract 'month' and 'day' after conversion\n",
    "    df['month'] = df[start_col].dt.month\n",
    "    df['day'] = df[start_col].dt.dayofweek # Note: dayofweek is typically used for cyclical weekly patterns\n",
    "    \n",
    "    # Step 3: Now you can create the cyclical features\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month']/len(df['month'].unique()))\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month']/len(df['month'].unique()))\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day']/len(df['day'].unique()))\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day']/len(df['day'].unique()))\n",
    "\n",
    "\n",
    "    # Ora del giorno (0-23) → ciclo giornaliero\n",
    "    df[\"hour\"] = df[start_col].dt.hour\n",
    "    angle_day_start = 2 * np.pi * df[\"hour\"] / 24\n",
    "    df[\"start_time_sin\"] = np.sin(angle_day_start)\n",
    "    df[\"start_time_cos\"] = np.cos(angle_day_start)\n",
    "\n",
    "    df[\"hour_end\"] = df[end_col].dt.hour\n",
    "    angle_day_end = 2 * np.pi * df[\"hour_end\"] / 24\n",
    "    df[\"end_time_sin\"] = np.sin(angle_day_end)\n",
    "    df[\"end_time_cos\"] = np.cos(angle_day_end)\n",
    "\n",
    "    # Durata in minuti\n",
    "    df[\"duration_minutes\"] = (df[end_col] - df[start_col]).dt.total_seconds() / 60\n",
    "\n",
    "    # Giorno della settimana (0=Mon..6=Sun) → ciclo settimanale\n",
    "    dayofweek = df[start_col].dt.dayofweek\n",
    "    angle_week = 2 * np.pi * dayofweek / 7\n",
    "    df[\"dow_sin\"] = np.sin(angle_week)\n",
    "    df[\"dow_cos\"] = np.cos(angle_week)\n",
    "\n",
    "    # Giorno dell’anno (1-365) → ciclo annuale\n",
    "    dayofyear = df[start_col].dt.dayofyear\n",
    "    angle_year = 2 * np.pi * dayofyear / 365\n",
    "    df[\"doy_sin\"] = np.sin(angle_year)\n",
    "    df[\"doy_cos\"] = np.cos(angle_year)\n",
    "\n",
    "    # Rimuovo colonne temporali e variabili ausiliarie\n",
    "    df = df.drop(columns=[start_col, end_col, \"hour\", \"hour_end\", \"day\", \"month\"])\n",
    "    return df\n",
    "\n",
    "embedding_cols = ['highway_embedding', 'AreaTypeEmbeddings']\n",
    "\n",
    "df_final = encode_time_features(df_encoded)\n",
    "df_final.drop(columns=['type_of_TTT'], inplace=True)\n",
    "for emb_col in embedding_cols:\n",
    "    df_final = spezza_serie_in_colonne(df_final, emb_col, prefix=f'{emb_col}_')\n",
    "df_final.shape\n",
    "\n",
    "# Salvataggio DataFrame finale\n",
    "df_path = os.path.join(exp_dir, f\"dataframe_{sensor_name}\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "save_pkl(df_final, os.path.join(df_path, f\"filtered_dataframe.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86f0e301",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ttt in df_final.TTT[10:20]:\n",
    "    plt.plot(ttt)\n",
    "    plt.title(\"Esempi di TTT ARPAT\")\n",
    "    plt.xlabel(\"Ora del Giorno\")\n",
    "    plt.ylabel(\"Valore TTT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dc56e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (217, 33), (217, 24)\n",
      "Test size: (55, 33), (55, 24)\n",
      "Final shapes:\n",
      "X_train: (217, 33)\n",
      "y_train: (217, 24)\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/X_train_unscaled_AR-ACROPOLI.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/y_train_unscaled_AR-ACROPOLI.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/X_test_unscaled_AR-ACROPOLI.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/y_test_unscaled_AR-ACROPOLI.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/X_train.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/y_train.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/X_test.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/y_test.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/scaler_X.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/scaler_y.pkl\n",
      "Scaler salvati.\n",
      "\n",
      "Tutti i file sono stati salvati correttamente.\n",
      "Percorso cartella: /Users/lapotinacci/thesis/Federated_Sys/RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def series_to_2d_array(series, output_dim=24):\n",
    "    arr = np.stack(series.apply(lambda x: np.array(x, dtype=np.float32)))\n",
    "    if arr.shape[1] != output_dim:\n",
    "        raise ValueError(f\"Ogni elemento deve avere {output_dim} valori, trovato {arr.shape[1]}\")\n",
    "    return arr\n",
    "\n",
    " # Separazione delle feature e del target\n",
    "X = df_final.drop(columns=['TTT'])\n",
    "y = df_final['TTT']\n",
    "\n",
    "X_np = X.to_numpy().astype(np.float32)\n",
    "y_np = series_to_2d_array(y, output_dim=24)\n",
    "\n",
    "# Calcolo deviazione standard per ogni serie\n",
    "std_scores = np.std(y_np, axis=1)\n",
    "\n",
    "std_scores_log = np.log1p(std_scores)  # log(1+x) per evitare problemi con valori vicini a 0\n",
    "\n",
    "std_scores_normalized = (std_scores_log - np.min(std_scores_log)) / (np.max(std_scores_log) - np.min(std_scores_log))\n",
    "\n",
    "# Creo bin basati sui quantili\n",
    "bins = np.array([0.0, 0.4, 0.8, 1.0])\n",
    "std_bins = np.digitize(std_scores_normalized, bins)\n",
    "\n",
    "# Primo split: train (80%) vs temp (20%)\n",
    "# Passo anche std_bins per poter stratificare\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_np, y_np,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=std_bins, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test size: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Debug prints\n",
    "print(f\"Final shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "# Scaler per input\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test  = scaler_X.transform(X_test)\n",
    "\n",
    "# Scaler per output (se serve normalizzare anche y)\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test  = scaler_y.transform(y_test)\n",
    "\n",
    "#cartella salvataggio train e test\n",
    "path = os.path.join(exp_dir, \"train_test_data\")\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "#  === Salvataggio dataset e scaler in formato .pkl ===\n",
    "save_pkl(scaler_X.inverse_transform(X_train), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"X_train_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_y.inverse_transform(y_train), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"y_train_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_X.inverse_transform(X_test), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"X_test_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_y.inverse_transform(y_test), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"y_test_unscaled_{sensor_name}.pkl\"))\n",
    "\n",
    "save_pkl(X_train, os.path.join(exp_dir, \"X_train.pkl\"))\n",
    "save_pkl(y_train, os.path.join(exp_dir, \"y_train.pkl\"))\n",
    "save_pkl(X_test, os.path.join(exp_dir, \"X_test.pkl\"))\n",
    "save_pkl(y_test, os.path.join(exp_dir, \"y_test.pkl\"))\n",
    "\n",
    "save_pkl(scaler_X, os.path.join(exp_dir, \"scaler_X.pkl\"))\n",
    "save_pkl(scaler_y, os.path.join(exp_dir, \"scaler_y.pkl\"))\n",
    "\n",
    "print(\"Scaler salvati.\")\n",
    "\n",
    "print(\"\\nTutti i file sono stati salvati correttamente.\")\n",
    "print(f\"Percorso cartella: {os.path.abspath(exp_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2d0d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ricostruite:\n",
      "X_train: (217, 33)\n",
      "y_train: (217, 24)\n",
      "X_test: (55, 33)\n",
      "y_test: (55, 24)\n",
      "\n",
      "Scaler caricati:\n",
      "scaler_X: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "scaler_y: <class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "# === Costruisci i path ===\n",
    "path_X_train = os.path.join(exp_dir, \"X_train.pkl\")\n",
    "path_y_train = os.path.join(exp_dir, \"y_train.pkl\")\n",
    "path_X_test  = os.path.join(exp_dir, \"X_test.pkl\")\n",
    "path_y_test  = os.path.join(exp_dir, \"y_test.pkl\")\n",
    "\n",
    "path_scaler_X = os.path.join(exp_dir, \"scaler_X.pkl\")\n",
    "path_scaler_y = os.path.join(exp_dir, \"scaler_y.pkl\")\n",
    "\n",
    "# === Ricaricamento ===\n",
    "X_train = load_pkl(path_X_train)\n",
    "y_train = load_pkl(path_y_train)\n",
    "X_test  = load_pkl(path_X_test)\n",
    "y_test  = load_pkl(path_y_test)\n",
    "\n",
    "\n",
    "scaler_X = load_pkl(path_scaler_X)\n",
    "scaler_y = load_pkl(path_scaler_y)\n",
    "\n",
    "print(\"Shapes ricostruite:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "print(\"\\nScaler caricati:\")\n",
    "print(\"scaler_X:\", type(scaler_X))\n",
    "print(\"scaler_y:\", type(scaler_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece47aa",
   "metadata": {},
   "source": [
    "# modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08dc75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers # type: ignore\n",
    "from tensorflow.keras.layers import Dropout # type: ignore\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b8b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_plots(y_true, y_pred, output_dir, prefix=\"pred_plot\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    n = len(y_true)\n",
    "    print(f\"Salvo {n} plot in: {output_dir}\")\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        plt.plot(y_true[i], label=\"True\")\n",
    "        plt.plot(y_pred[i], label=\"Pred\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"{prefix}_{i+1}.png\"\n",
    "        path = os.path.join(output_dir, filename)\n",
    "\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Plot salvati correttamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0608b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lapotinacci/thesis/Federated_Sys/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - loss: 1.3128 - mae: 0.9042 - val_loss: 0.9736 - val_mae: 0.7270\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9488 - mae: 0.7620 - val_loss: 0.8203 - val_mae: 0.6688\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.7618 - mae: 0.6783 - val_loss: 0.7321 - val_mae: 0.6380\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6420 - mae: 0.6201 - val_loss: 0.6693 - val_mae: 0.6139\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5598 - mae: 0.5776 - val_loss: 0.6168 - val_mae: 0.5968\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5040 - mae: 0.5493 - val_loss: 0.5687 - val_mae: 0.5807\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.4643 - mae: 0.5296 - val_loss: 0.5259 - val_mae: 0.5630\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4326 - mae: 0.5131 - val_loss: 0.4908 - val_mae: 0.5477\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4033 - mae: 0.4998 - val_loss: 0.4616 - val_mae: 0.5348\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3746 - mae: 0.4835 - val_loss: 0.4359 - val_mae: 0.5214\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3478 - mae: 0.4656 - val_loss: 0.4127 - val_mae: 0.5063\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3253 - mae: 0.4500 - val_loss: 0.3863 - val_mae: 0.4884\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3048 - mae: 0.4350 - val_loss: 0.3568 - val_mae: 0.4689\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2842 - mae: 0.4194 - val_loss: 0.3274 - val_mae: 0.4490\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2632 - mae: 0.4018 - val_loss: 0.3011 - val_mae: 0.4286\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2425 - mae: 0.3822 - val_loss: 0.2798 - val_mae: 0.4113\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2238 - mae: 0.3638 - val_loss: 0.2616 - val_mae: 0.3983\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2076 - mae: 0.3490 - val_loss: 0.2448 - val_mae: 0.3861\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1933 - mae: 0.3358 - val_loss: 0.2297 - val_mae: 0.3727\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1812 - mae: 0.3233 - val_loss: 0.2153 - val_mae: 0.3573\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1702 - mae: 0.3104 - val_loss: 0.2019 - val_mae: 0.3443\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1593 - mae: 0.2984 - val_loss: 0.1906 - val_mae: 0.3327\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1488 - mae: 0.2864 - val_loss: 0.1822 - val_mae: 0.3237\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1400 - mae: 0.2776 - val_loss: 0.1742 - val_mae: 0.3154\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1322 - mae: 0.2697 - val_loss: 0.1661 - val_mae: 0.3076\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1248 - mae: 0.2626 - val_loss: 0.1567 - val_mae: 0.2999\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1177 - mae: 0.2562 - val_loss: 0.1464 - val_mae: 0.2902\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1105 - mae: 0.2490 - val_loss: 0.1358 - val_mae: 0.2783\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1037 - mae: 0.2408 - val_loss: 0.1269 - val_mae: 0.2675\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0969 - mae: 0.2313 - val_loss: 0.1203 - val_mae: 0.2586\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0903 - mae: 0.2218 - val_loss: 0.1153 - val_mae: 0.2509\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0841 - mae: 0.2129 - val_loss: 0.1116 - val_mae: 0.2445\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0787 - mae: 0.2048 - val_loss: 0.1078 - val_mae: 0.2381\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0737 - mae: 0.1974 - val_loss: 0.1029 - val_mae: 0.2316\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0687 - mae: 0.1904 - val_loss: 0.0977 - val_mae: 0.2253\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0639 - mae: 0.1840 - val_loss: 0.0927 - val_mae: 0.2193\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0596 - mae: 0.1783 - val_loss: 0.0881 - val_mae: 0.2138\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0558 - mae: 0.1729 - val_loss: 0.0836 - val_mae: 0.2078\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0522 - mae: 0.1673 - val_loss: 0.0790 - val_mae: 0.2013\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0487 - mae: 0.1613 - val_loss: 0.0745 - val_mae: 0.1945\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0454 - mae: 0.1558 - val_loss: 0.0702 - val_mae: 0.1879\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0423 - mae: 0.1503 - val_loss: 0.0660 - val_mae: 0.1819\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0394 - mae: 0.1450 - val_loss: 0.0624 - val_mae: 0.1765\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0366 - mae: 0.1396 - val_loss: 0.0595 - val_mae: 0.1713\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0340 - mae: 0.1346 - val_loss: 0.0571 - val_mae: 0.1671\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0317 - mae: 0.1302 - val_loss: 0.0550 - val_mae: 0.1634\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0295 - mae: 0.1254 - val_loss: 0.0528 - val_mae: 0.1591\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0275 - mae: 0.1208 - val_loss: 0.0503 - val_mae: 0.1546\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0257 - mae: 0.1166 - val_loss: 0.0478 - val_mae: 0.1504\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0240 - mae: 0.1121 - val_loss: 0.0458 - val_mae: 0.1468\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0225 - mae: 0.1078 - val_loss: 0.0439 - val_mae: 0.1434\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0210 - mae: 0.1042 - val_loss: 0.0421 - val_mae: 0.1401\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0197 - mae: 0.1012 - val_loss: 0.0404 - val_mae: 0.1369\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0184 - mae: 0.0982 - val_loss: 0.0390 - val_mae: 0.1336\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0173 - mae: 0.0951 - val_loss: 0.0375 - val_mae: 0.1300\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0163 - mae: 0.0921 - val_loss: 0.0361 - val_mae: 0.1264\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0153 - mae: 0.0890 - val_loss: 0.0347 - val_mae: 0.1230\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0144 - mae: 0.0860 - val_loss: 0.0333 - val_mae: 0.1199\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0136 - mae: 0.0834 - val_loss: 0.0318 - val_mae: 0.1168\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0129 - mae: 0.0809 - val_loss: 0.0305 - val_mae: 0.1136\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0122 - mae: 0.0782 - val_loss: 0.0292 - val_mae: 0.1107\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0115 - mae: 0.0756 - val_loss: 0.0282 - val_mae: 0.1085\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0736 - val_loss: 0.0274 - val_mae: 0.1068\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0103 - mae: 0.0716 - val_loss: 0.0266 - val_mae: 0.1046\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0692 - val_loss: 0.0255 - val_mae: 0.1016\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0669 - val_loss: 0.0246 - val_mae: 0.0991\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0650 - val_loss: 0.0238 - val_mae: 0.0970\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0083 - mae: 0.0632 - val_loss: 0.0231 - val_mae: 0.0953\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0079 - mae: 0.0614 - val_loss: 0.0222 - val_mae: 0.0931\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0598 - val_loss: 0.0213 - val_mae: 0.0908\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0072 - mae: 0.0582 - val_loss: 0.0206 - val_mae: 0.0888\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0566 - val_loss: 0.0200 - val_mae: 0.0870\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0551 - val_loss: 0.0194 - val_mae: 0.0854\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0063 - mae: 0.0536 - val_loss: 0.0188 - val_mae: 0.0836\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0522 - val_loss: 0.0181 - val_mae: 0.0819\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 0.0176 - val_mae: 0.0803\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0494 - val_loss: 0.0172 - val_mae: 0.0791\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0053 - mae: 0.0482 - val_loss: 0.0167 - val_mae: 0.0781\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0050 - mae: 0.0471 - val_loss: 0.0161 - val_mae: 0.0766\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0048 - mae: 0.0461 - val_loss: 0.0155 - val_mae: 0.0748\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0046 - mae: 0.0452 - val_loss: 0.0149 - val_mae: 0.0731\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0045 - mae: 0.0441 - val_loss: 0.0146 - val_mae: 0.0719\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0043 - mae: 0.0429 - val_loss: 0.0142 - val_mae: 0.0708\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - mae: 0.0419 - val_loss: 0.0139 - val_mae: 0.0696\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - mae: 0.0409 - val_loss: 0.0134 - val_mae: 0.0680\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0038 - mae: 0.0400 - val_loss: 0.0129 - val_mae: 0.0664\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - mae: 0.0392 - val_loss: 0.0125 - val_mae: 0.0651\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - mae: 0.0384 - val_loss: 0.0121 - val_mae: 0.0640\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0375 - val_loss: 0.0118 - val_mae: 0.0632\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0033 - mae: 0.0367 - val_loss: 0.0115 - val_mae: 0.0623\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0359 - val_loss: 0.0113 - val_mae: 0.0616\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0350 - val_loss: 0.0110 - val_mae: 0.0605\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0030 - mae: 0.0342 - val_loss: 0.0107 - val_mae: 0.0596\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0029 - mae: 0.0337 - val_loss: 0.0105 - val_mae: 0.0588\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0028 - mae: 0.0331 - val_loss: 0.0102 - val_mae: 0.0579\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0027 - mae: 0.0324 - val_loss: 0.0100 - val_mae: 0.0569\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0026 - mae: 0.0317 - val_loss: 0.0097 - val_mae: 0.0561\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0025 - mae: 0.0311 - val_loss: 0.0095 - val_mae: 0.0553\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0024 - mae: 0.0306 - val_loss: 0.0093 - val_mae: 0.0545\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0023 - mae: 0.0301 - val_loss: 0.0092 - val_mae: 0.0539\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0023 - mae: 0.0294 - val_loss: 0.0090 - val_mae: 0.0534\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0022 - mae: 0.0289 - val_loss: 0.0088 - val_mae: 0.0526\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0021 - mae: 0.0285 - val_loss: 0.0086 - val_mae: 0.0521\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0282 - val_loss: 0.0084 - val_mae: 0.0514\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0020 - mae: 0.0275 - val_loss: 0.0083 - val_mae: 0.0510\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0270 - val_loss: 0.0082 - val_mae: 0.0503\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0019 - mae: 0.0267 - val_loss: 0.0080 - val_mae: 0.0498\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0265 - val_loss: 0.0078 - val_mae: 0.0492\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0018 - mae: 0.0261 - val_loss: 0.0077 - val_mae: 0.0492\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0018 - mae: 0.0258 - val_loss: 0.0076 - val_mae: 0.0485\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0017 - mae: 0.0257 - val_loss: 0.0075 - val_mae: 0.0486\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0017 - mae: 0.0261 - val_loss: 0.0074 - val_mae: 0.0486\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0018 - mae: 0.0266 - val_loss: 0.0074 - val_mae: 0.0500\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0018 - mae: 0.0279 - val_loss: 0.0075 - val_mae: 0.0502\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 0.0074 - val_mae: 0.0517\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0074 - val_mae: 0.0512\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0070 - val_mae: 0.0494\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0066 - val_mae: 0.0454\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0015 - mae: 0.0246 - val_loss: 0.0063 - val_mae: 0.0433\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0218 - val_loss: 0.0062 - val_mae: 0.0436\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0014 - mae: 0.0233 - val_loss: 0.0065 - val_mae: 0.0461\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 0.0063 - val_mae: 0.0460\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 0.0062 - val_mae: 0.0444\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 0.0057 - val_mae: 0.0414\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0214 - val_loss: 0.0056 - val_mae: 0.0404\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0011 - mae: 0.0201 - val_loss: 0.0057 - val_mae: 0.0412\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0215 - val_loss: 0.0056 - val_mae: 0.0418\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 0.0057 - val_mae: 0.0421\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 0.0053 - val_mae: 0.0404\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 0.0053 - val_mae: 0.0391\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0201 - val_loss: 0.0051 - val_mae: 0.0380\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.5043e-04 - mae: 0.0185 - val_loss: 0.0051 - val_mae: 0.0380\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.5066e-04 - mae: 0.0189 - val_loss: 0.0051 - val_mae: 0.0387\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.9646e-04 - mae: 0.0202 - val_loss: 0.0050 - val_mae: 0.0384\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 0.0050 - val_mae: 0.0386\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 0.0048 - val_mae: 0.0374\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.4372e-04 - mae: 0.0197 - val_loss: 0.0048 - val_mae: 0.0363\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.5767e-04 - mae: 0.0181 - val_loss: 0.0046 - val_mae: 0.0353\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.0382e-04 - mae: 0.0171 - val_loss: 0.0045 - val_mae: 0.0351\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.9370e-04 - mae: 0.0171 - val_loss: 0.0046 - val_mae: 0.0354\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.1342e-04 - mae: 0.0179 - val_loss: 0.0045 - val_mae: 0.0357\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.4195e-04 - mae: 0.0187 - val_loss: 0.0046 - val_mae: 0.0361\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.5749e-04 - mae: 0.0192 - val_loss: 0.0044 - val_mae: 0.0355\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.5416e-04 - mae: 0.0193 - val_loss: 0.0045 - val_mae: 0.0356\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.2988e-04 - mae: 0.0189 - val_loss: 0.0043 - val_mae: 0.0348\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.8844e-04 - mae: 0.0183 - val_loss: 0.0043 - val_mae: 0.0341\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3436e-04 - mae: 0.0172 - val_loss: 0.0042 - val_mae: 0.0330\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.8473e-04 - mae: 0.0163 - val_loss: 0.0042 - val_mae: 0.0326\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.4879e-04 - mae: 0.0155 - val_loss: 0.0041 - val_mae: 0.0323\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.2793e-04 - mae: 0.0151 - val_loss: 0.0041 - val_mae: 0.0321\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1948e-04 - mae: 0.0151 - val_loss: 0.0041 - val_mae: 0.0320\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.2009e-04 - mae: 0.0152 - val_loss: 0.0040 - val_mae: 0.0320\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.2867e-04 - mae: 0.0157 - val_loss: 0.0041 - val_mae: 0.0324\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4513e-04 - mae: 0.0162 - val_loss: 0.0040 - val_mae: 0.0328\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 6.7674e-04 - mae: 0.0172 - val_loss: 0.0042 - val_mae: 0.0337\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.1794e-04 - mae: 0.0181 - val_loss: 0.0041 - val_mae: 0.0345\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.8461e-04 - mae: 0.0196 - val_loss: 0.0043 - val_mae: 0.0357\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.6092e-04 - mae: 0.0209 - val_loss: 0.0042 - val_mae: 0.0365\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.3785e-04 - mae: 0.0223 - val_loss: 0.0044 - val_mae: 0.0370\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.8086e-04 - mae: 0.0229 - val_loss: 0.0042 - val_mae: 0.0369\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.6388e-04 - mae: 0.0228 - val_loss: 0.0042 - val_mae: 0.0353\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.4804e-04 - mae: 0.0210 - val_loss: 0.0039 - val_mae: 0.0326\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.7769e-04 - mae: 0.0181 - val_loss: 0.0038 - val_mae: 0.0305\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.3464e-04 - mae: 0.0148 - val_loss: 0.0037 - val_mae: 0.0293\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7547e-04 - mae: 0.0132 - val_loss: 0.0037 - val_mae: 0.0297\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.0674e-04 - mae: 0.0144 - val_loss: 0.0039 - val_mae: 0.0315\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8846e-04 - mae: 0.0165 - val_loss: 0.0038 - val_mae: 0.0324\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6976e-04 - mae: 0.0182 - val_loss: 0.0040 - val_mae: 0.0331\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0928e-04 - mae: 0.0190 - val_loss: 0.0038 - val_mae: 0.0330\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0965e-04 - mae: 0.0190 - val_loss: 0.0039 - val_mae: 0.0319\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.4640e-04 - mae: 0.0180 - val_loss: 0.0036 - val_mae: 0.0304\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.5071e-04 - mae: 0.0160 - val_loss: 0.0037 - val_mae: 0.0289\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.6230e-04 - mae: 0.0138 - val_loss: 0.0036 - val_mae: 0.0278\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.0979e-04 - mae: 0.0123 - val_loss: 0.0036 - val_mae: 0.0277\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.0259e-04 - mae: 0.0122 - val_loss: 0.0036 - val_mae: 0.0284\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.2992e-04 - mae: 0.0132 - val_loss: 0.0036 - val_mae: 0.0290\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.7589e-04 - mae: 0.0146 - val_loss: 0.0037 - val_mae: 0.0300\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1976e-04 - mae: 0.0157 - val_loss: 0.0036 - val_mae: 0.0306\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.6326e-04 - mae: 0.0168 - val_loss: 0.0038 - val_mae: 0.0310\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.8651e-04 - mae: 0.0173 - val_loss: 0.0036 - val_mae: 0.0310\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.8597e-04 - mae: 0.0174 - val_loss: 0.0037 - val_mae: 0.0303\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5010e-04 - mae: 0.0167 - val_loss: 0.0035 - val_mae: 0.0295\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9570e-04 - mae: 0.0156 - val_loss: 0.0036 - val_mae: 0.0283\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.3196e-04 - mae: 0.0139 - val_loss: 0.0034 - val_mae: 0.0270\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3.7737e-04 - mae: 0.0125 - val_loss: 0.0035 - val_mae: 0.0264\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.4236e-04 - mae: 0.0113 - val_loss: 0.0034 - val_mae: 0.0260\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2761e-04 - mae: 0.0109 - val_loss: 0.0034 - val_mae: 0.0260\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.2958e-04 - mae: 0.0111 - val_loss: 0.0034 - val_mae: 0.0265\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.4405e-04 - mae: 0.0116 - val_loss: 0.0034 - val_mae: 0.0268\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.6738e-04 - mae: 0.0125 - val_loss: 0.0035 - val_mae: 0.0274\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.9889e-04 - mae: 0.0135 - val_loss: 0.0034 - val_mae: 0.0282\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.4108e-04 - mae: 0.0147 - val_loss: 0.0036 - val_mae: 0.0292\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.9129e-04 - mae: 0.0159 - val_loss: 0.0035 - val_mae: 0.0303\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.5908e-04 - mae: 0.0174 - val_loss: 0.0038 - val_mae: 0.0313\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 6.3712e-04 - mae: 0.0189 - val_loss: 0.0036 - val_mae: 0.0329\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.2962e-04 - mae: 0.0206 - val_loss: 0.0039 - val_mae: 0.0335\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.9777e-04 - mae: 0.0217 - val_loss: 0.0037 - val_mae: 0.0341\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.3157e-04 - mae: 0.0224 - val_loss: 0.0039 - val_mae: 0.0333\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.8243e-04 - mae: 0.0216 - val_loss: 0.0035 - val_mae: 0.0313\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.5168e-04 - mae: 0.0194 - val_loss: 0.0036 - val_mae: 0.0287\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.7814e-04 - mae: 0.0159 - val_loss: 0.0033 - val_mae: 0.0256\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.3040e-04 - mae: 0.0122 - val_loss: 0.0033 - val_mae: 0.0243\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.6390e-04 - mae: 0.0098 - val_loss: 0.0033 - val_mae: 0.0249\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.8511e-04 - mae: 0.0107 - val_loss: 0.0033 - val_mae: 0.0264\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3.6251e-04 - mae: 0.0133 - val_loss: 0.0036 - val_mae: 0.0283\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.5875e-04 - mae: 0.0157 - val_loss: 0.0034 - val_mae: 0.0296\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.3990e-04 - mae: 0.0174 - val_loss: 0.0037 - val_mae: 0.0302\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.8294e-04 - mae: 0.0183 - val_loss: 0.0034 - val_mae: 0.0302\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.6753e-04 - mae: 0.0181 - val_loss: 0.0036 - val_mae: 0.0288\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.9173e-04 - mae: 0.0165 - val_loss: 0.0033 - val_mae: 0.0267\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.8256e-04 - mae: 0.0141 - val_loss: 0.0033 - val_mae: 0.0247\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.8473e-04 - mae: 0.0112 - val_loss: 0.0032 - val_mae: 0.0233\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.3250e-04 - mae: 0.0092 - val_loss: 0.0032 - val_mae: 0.0233\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.3465e-04 - mae: 0.0094 - val_loss: 0.0033 - val_mae: 0.0246\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.7546e-04 - mae: 0.0110 - val_loss: 0.0032 - val_mae: 0.0256\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.3125e-04 - mae: 0.0129 - val_loss: 0.0034 - val_mae: 0.0266\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.7789e-04 - mae: 0.0141 - val_loss: 0.0033 - val_mae: 0.0270\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.0402e-04 - mae: 0.0148 - val_loss: 0.0034 - val_mae: 0.0271\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.0170e-04 - mae: 0.0148 - val_loss: 0.0033 - val_mae: 0.0263\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.7405e-04 - mae: 0.0141 - val_loss: 0.0034 - val_mae: 0.0255\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.2673e-04 - mae: 0.0129 - val_loss: 0.0032 - val_mae: 0.0243\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.7676e-04 - mae: 0.0115 - val_loss: 0.0032 - val_mae: 0.0232\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.3196e-04 - mae: 0.0099 - val_loss: 0.0031 - val_mae: 0.0223\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0339e-04 - mae: 0.0087 - val_loss: 0.0031 - val_mae: 0.0221\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.9477e-04 - mae: 0.0083 - val_loss: 0.0032 - val_mae: 0.0225\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.0245e-04 - mae: 0.0088 - val_loss: 0.0031 - val_mae: 0.0228\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.2096e-04 - mae: 0.0097 - val_loss: 0.0033 - val_mae: 0.0236\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.4589e-04 - mae: 0.0106 - val_loss: 0.0032 - val_mae: 0.0242\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.7676e-04 - mae: 0.0117 - val_loss: 0.0033 - val_mae: 0.0251\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.1239e-04 - mae: 0.0128 - val_loss: 0.0032 - val_mae: 0.0260\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.5866e-04 - mae: 0.0141 - val_loss: 0.0035 - val_mae: 0.0269\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0589e-04 - mae: 0.0153 - val_loss: 0.0033 - val_mae: 0.0281\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.6193e-04 - mae: 0.0166 - val_loss: 0.0036 - val_mae: 0.0287\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0844e-04 - mae: 0.0175 - val_loss: 0.0034 - val_mae: 0.0294\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.5103e-04 - mae: 0.0184 - val_loss: 0.0036 - val_mae: 0.0295\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.6302e-04 - mae: 0.0186 - val_loss: 0.0033 - val_mae: 0.0291\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.3984e-04 - mae: 0.0182 - val_loss: 0.0035 - val_mae: 0.0283\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.8228e-04 - mae: 0.0170 - val_loss: 0.0032 - val_mae: 0.0263\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.9285e-04 - mae: 0.0151 - val_loss: 0.0033 - val_mae: 0.0246\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9763e-04 - mae: 0.0127 - val_loss: 0.0031 - val_mae: 0.0225\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.1925e-04 - mae: 0.0102 - val_loss: 0.0032 - val_mae: 0.0213\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.7151e-04 - mae: 0.0081 - val_loss: 0.0031 - val_mae: 0.0208\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5722e-04 - mae: 0.0074 - val_loss: 0.0031 - val_mae: 0.0212\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7062e-04 - mae: 0.0083 - val_loss: 0.0032 - val_mae: 0.0222\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.0157e-04 - mae: 0.0097 - val_loss: 0.0031 - val_mae: 0.0230\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.4190e-04 - mae: 0.0111 - val_loss: 0.0033 - val_mae: 0.0244\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.8678e-04 - mae: 0.0126 - val_loss: 0.0032 - val_mae: 0.0253\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.4090e-04 - mae: 0.0140 - val_loss: 0.0035 - val_mae: 0.0266\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.9616e-04 - mae: 0.0154 - val_loss: 0.0033 - val_mae: 0.0276\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.5922e-04 - mae: 0.0167 - val_loss: 0.0036 - val_mae: 0.0284\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 5.0561e-04 - mae: 0.0178 - val_loss: 0.0034 - val_mae: 0.0289\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.4833e-04 - mae: 0.0186 - val_loss: 0.0036 - val_mae: 0.0292\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.4979e-04 - mae: 0.0187 - val_loss: 0.0033 - val_mae: 0.0282\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0597e-04 - mae: 0.0179 - val_loss: 0.0035 - val_mae: 0.0271\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.2319e-04 - mae: 0.0161 - val_loss: 0.0032 - val_mae: 0.0245\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.1669e-04 - mae: 0.0136 - val_loss: 0.0033 - val_mae: 0.0226\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.1850e-04 - mae: 0.0107 - val_loss: 0.0031 - val_mae: 0.0205\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5360e-04 - mae: 0.0081 - val_loss: 0.0031 - val_mae: 0.0197\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3170e-04 - mae: 0.0067 - val_loss: 0.0032 - val_mae: 0.0204\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4695e-04 - mae: 0.0078 - val_loss: 0.0031 - val_mae: 0.0214\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8738e-04 - mae: 0.0096 - val_loss: 0.0033 - val_mae: 0.0231\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.3869e-04 - mae: 0.0115 - val_loss: 0.0032 - val_mae: 0.0239\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.9145e-04 - mae: 0.0130 - val_loss: 0.0034 - val_mae: 0.0254\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.3949e-04 - mae: 0.0143 - val_loss: 0.0033 - val_mae: 0.0259\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3.8847e-04 - mae: 0.0154 - val_loss: 0.0035 - val_mae: 0.0268\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.1716e-04 - mae: 0.0162 - val_loss: 0.0033 - val_mae: 0.0266\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.2605e-04 - mae: 0.0163 - val_loss: 0.0035 - val_mae: 0.0265\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.0469e-04 - mae: 0.0160 - val_loss: 0.0032 - val_mae: 0.0254\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.6145e-04 - mae: 0.0149 - val_loss: 0.0034 - val_mae: 0.0243\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.0364e-04 - mae: 0.0135 - val_loss: 0.0031 - val_mae: 0.0226\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.3907e-04 - mae: 0.0117 - val_loss: 0.0032 - val_mae: 0.0214\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8079e-04 - mae: 0.0097 - val_loss: 0.0031 - val_mae: 0.0197\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3793e-04 - mae: 0.0078 - val_loss: 0.0031 - val_mae: 0.0190\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1494e-04 - mae: 0.0065 - val_loss: 0.0031 - val_mae: 0.0188\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1040e-04 - mae: 0.0062 - val_loss: 0.0031 - val_mae: 0.0191\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2004e-04 - mae: 0.0069 - val_loss: 0.0032 - val_mae: 0.0200\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.3972e-04 - mae: 0.0081 - val_loss: 0.0031 - val_mae: 0.0207\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6833e-04 - mae: 0.0093 - val_loss: 0.0033 - val_mae: 0.0220\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.0603e-04 - mae: 0.0108 - val_loss: 0.0032 - val_mae: 0.0231\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.6246e-04 - mae: 0.0124 - val_loss: 0.0034 - val_mae: 0.0250\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.3471e-04 - mae: 0.0144 - val_loss: 0.0033 - val_mae: 0.0267\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.4514e-04 - mae: 0.0168 - val_loss: 0.0037 - val_mae: 0.0293\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.8115e-04 - mae: 0.0195 - val_loss: 0.0036 - val_mae: 0.0316\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.7540e-04 - mae: 0.0226 - val_loss: 0.0041 - val_mae: 0.0347\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.9663e-04 - mae: 0.0258 - val_loss: 0.0039 - val_mae: 0.0364\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0012 - mae: 0.0285 - val_loss: 0.0044 - val_mae: 0.0381\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0296 - val_loss: 0.0038 - val_mae: 0.0359\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mae: 0.0282 - val_loss: 0.0039 - val_mae: 0.0328\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.4451e-04 - mae: 0.0239 - val_loss: 0.0032 - val_mae: 0.0260\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.3210e-04 - mae: 0.0166 - val_loss: 0.0032 - val_mae: 0.0202\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4983e-04 - mae: 0.0088 - val_loss: 0.0031 - val_mae: 0.0191\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1838e-04 - mae: 0.0073 - val_loss: 0.0031 - val_mae: 0.0233\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.8741e-04 - mae: 0.0133 - val_loss: 0.0036 - val_mae: 0.0279\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0331e-04 - mae: 0.0182 - val_loss: 0.0034 - val_mae: 0.0289\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.2025e-04 - mae: 0.0202 - val_loss: 0.0037 - val_mae: 0.0289\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.6554e-04 - mae: 0.0194 - val_loss: 0.0032 - val_mae: 0.0250\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.7960e-04 - mae: 0.0156 - val_loss: 0.0032 - val_mae: 0.0211\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8203e-04 - mae: 0.0102 - val_loss: 0.0031 - val_mae: 0.0178\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.1740e-05 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0194\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3468e-04 - mae: 0.0083 - val_loss: 0.0033 - val_mae: 0.0226\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.4658e-04 - mae: 0.0124 - val_loss: 0.0032 - val_mae: 0.0242\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3538e-04 - mae: 0.0146 - val_loss: 0.0035 - val_mae: 0.0248\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 3.4687e-04 - mae: 0.0150 - val_loss: 0.0032 - val_mae: 0.0232\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.8307e-04 - mae: 0.0132 - val_loss: 0.0032 - val_mae: 0.0209\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8161e-04 - mae: 0.0103 - val_loss: 0.0031 - val_mae: 0.0183\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0365e-04 - mae: 0.0069 - val_loss: 0.0031 - val_mae: 0.0174\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.2945e-05 - mae: 0.0055 - val_loss: 0.0032 - val_mae: 0.0189\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1514e-04 - mae: 0.0076 - val_loss: 0.0031 - val_mae: 0.0204\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6755e-04 - mae: 0.0098 - val_loss: 0.0033 - val_mae: 0.0216\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.0488e-04 - mae: 0.0111 - val_loss: 0.0031 - val_mae: 0.0215\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.1276e-04 - mae: 0.0113 - val_loss: 0.0033 - val_mae: 0.0210\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8575e-04 - mae: 0.0105 - val_loss: 0.0031 - val_mae: 0.0195\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4095e-04 - mae: 0.0088 - val_loss: 0.0031 - val_mae: 0.0182\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.8981e-05 - mae: 0.0069 - val_loss: 0.0031 - val_mae: 0.0170\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.6559e-05 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0171\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.8303e-05 - mae: 0.0055 - val_loss: 0.0031 - val_mae: 0.0181\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.6706e-05 - mae: 0.0068 - val_loss: 0.0031 - val_mae: 0.0187\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1994e-04 - mae: 0.0080 - val_loss: 0.0032 - val_mae: 0.0195\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 1.3712e-04 - mae: 0.0088 - val_loss: 0.0031 - val_mae: 0.0195\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4516e-04 - mae: 0.0091 - val_loss: 0.0032 - val_mae: 0.0197\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4059e-04 - mae: 0.0090 - val_loss: 0.0031 - val_mae: 0.0190\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2995e-04 - mae: 0.0084 - val_loss: 0.0032 - val_mae: 0.0187\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1322e-04 - mae: 0.0078 - val_loss: 0.0031 - val_mae: 0.0178\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.6705e-05 - mae: 0.0069 - val_loss: 0.0031 - val_mae: 0.0173\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.1702e-05 - mae: 0.0061 - val_loss: 0.0031 - val_mae: 0.0167\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.1219e-05 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0165\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.6353e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0165\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.6486e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0166\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.0216e-05 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0170\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6252e-05 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0173\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.4100e-05 - mae: 0.0063 - val_loss: 0.0032 - val_mae: 0.0178\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 9.3756e-05 - mae: 0.0069 - val_loss: 0.0031 - val_mae: 0.0181\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0651e-04 - mae: 0.0075 - val_loss: 0.0032 - val_mae: 0.0189\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2236e-04 - mae: 0.0083 - val_loss: 0.0031 - val_mae: 0.0194\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4385e-04 - mae: 0.0092 - val_loss: 0.0033 - val_mae: 0.0204\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7089e-04 - mae: 0.0103 - val_loss: 0.0031 - val_mae: 0.0211\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.1126e-04 - mae: 0.0114 - val_loss: 0.0034 - val_mae: 0.0227\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.6181e-04 - mae: 0.0130 - val_loss: 0.0032 - val_mae: 0.0237\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.3212e-04 - mae: 0.0147 - val_loss: 0.0035 - val_mae: 0.0258\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.1521e-04 - mae: 0.0166 - val_loss: 0.0033 - val_mae: 0.0271\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.2233e-04 - mae: 0.0187 - val_loss: 0.0038 - val_mae: 0.0294\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.3782e-04 - mae: 0.0208 - val_loss: 0.0035 - val_mae: 0.0303\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.5854e-04 - mae: 0.0226 - val_loss: 0.0040 - val_mae: 0.0323\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 8.4786e-04 - mae: 0.0241 - val_loss: 0.0036 - val_mae: 0.0322\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.9189e-04 - mae: 0.0246 - val_loss: 0.0039 - val_mae: 0.0318\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.3912e-04 - mae: 0.0239 - val_loss: 0.0034 - val_mae: 0.0292\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.9891e-04 - mae: 0.0217 - val_loss: 0.0036 - val_mae: 0.0268\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.8357e-04 - mae: 0.0181 - val_loss: 0.0031 - val_mae: 0.0221\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.6184e-04 - mae: 0.0130 - val_loss: 0.0032 - val_mae: 0.0181\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0696e-04 - mae: 0.0078 - val_loss: 0.0031 - val_mae: 0.0160\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.7921e-05 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0178\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.0369e-04 - mae: 0.0076 - val_loss: 0.0033 - val_mae: 0.0210\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.0109e-04 - mae: 0.0114 - val_loss: 0.0032 - val_mae: 0.0229\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 2.9943e-04 - mae: 0.0139 - val_loss: 0.0035 - val_mae: 0.0245\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.6088e-04 - mae: 0.0155 - val_loss: 0.0033 - val_mae: 0.0244\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.7046e-04 - mae: 0.0156 - val_loss: 0.0035 - val_mae: 0.0238\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2657e-04 - mae: 0.0147 - val_loss: 0.0032 - val_mae: 0.0217\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.4395e-04 - mae: 0.0125 - val_loss: 0.0033 - val_mae: 0.0196\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.5278e-04 - mae: 0.0098 - val_loss: 0.0031 - val_mae: 0.0171\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.3788e-05 - mae: 0.0067 - val_loss: 0.0031 - val_mae: 0.0157\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.2796e-05 - mae: 0.0044 - val_loss: 0.0031 - val_mae: 0.0160\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.9665e-05 - mae: 0.0051 - val_loss: 0.0031 - val_mae: 0.0174\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 9.2197e-05 - mae: 0.0072 - val_loss: 0.0032 - val_mae: 0.0189\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3331e-04 - mae: 0.0090 - val_loss: 0.0031 - val_mae: 0.0197\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.7015e-04 - mae: 0.0103 - val_loss: 0.0033 - val_mae: 0.0207\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9202e-04 - mae: 0.0112 - val_loss: 0.0031 - val_mae: 0.0204\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.9725e-04 - mae: 0.0112 - val_loss: 0.0033 - val_mae: 0.0205\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.8362e-04 - mae: 0.0108 - val_loss: 0.0031 - val_mae: 0.0193\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.5856e-04 - mae: 0.0099 - val_loss: 0.0032 - val_mae: 0.0188\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2557e-04 - mae: 0.0088 - val_loss: 0.0031 - val_mae: 0.0173\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.3113e-05 - mae: 0.0073 - val_loss: 0.0032 - val_mae: 0.0165\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.7285e-05 - mae: 0.0059 - val_loss: 0.0031 - val_mae: 0.0155\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.1194e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0151\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4991e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0153\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.7316e-05 - mae: 0.0043 - val_loss: 0.0031 - val_mae: 0.0157\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 5.5810e-05 - mae: 0.0051 - val_loss: 0.0032 - val_mae: 0.0164\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.7726e-05 - mae: 0.0060 - val_loss: 0.0031 - val_mae: 0.0168\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.1830e-05 - mae: 0.0068 - val_loss: 0.0032 - val_mae: 0.0177\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.7062e-05 - mae: 0.0076 - val_loss: 0.0031 - val_mae: 0.0180\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1456e-04 - mae: 0.0083 - val_loss: 0.0033 - val_mae: 0.0190\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3395e-04 - mae: 0.0091 - val_loss: 0.0031 - val_mae: 0.0194\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.5887e-04 - mae: 0.0100 - val_loss: 0.0033 - val_mae: 0.0204\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8692e-04 - mae: 0.0110 - val_loss: 0.0032 - val_mae: 0.0210\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.2563e-04 - mae: 0.0121 - val_loss: 0.0034 - val_mae: 0.0224\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.6731e-04 - mae: 0.0134 - val_loss: 0.0032 - val_mae: 0.0229\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.1752e-04 - mae: 0.0145 - val_loss: 0.0035 - val_mae: 0.0244\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.7292e-04 - mae: 0.0159 - val_loss: 0.0033 - val_mae: 0.0250\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.3379e-04 - mae: 0.0171 - val_loss: 0.0036 - val_mae: 0.0266\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.8752e-04 - mae: 0.0182 - val_loss: 0.0033 - val_mae: 0.0266\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.3223e-04 - mae: 0.0190 - val_loss: 0.0037 - val_mae: 0.0276\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.5719e-04 - mae: 0.0195 - val_loss: 0.0033 - val_mae: 0.0269\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.5056e-04 - mae: 0.0193 - val_loss: 0.0037 - val_mae: 0.0268\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.0498e-04 - mae: 0.0186 - val_loss: 0.0033 - val_mae: 0.0249\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.3058e-04 - mae: 0.0171 - val_loss: 0.0035 - val_mae: 0.0236\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 3.2861e-04 - mae: 0.0149 - val_loss: 0.0031 - val_mae: 0.0207\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.2211e-04 - mae: 0.0120 - val_loss: 0.0033 - val_mae: 0.0185\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.2952e-04 - mae: 0.0091 - val_loss: 0.0031 - val_mae: 0.0161\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.6654e-05 - mae: 0.0061 - val_loss: 0.0031 - val_mae: 0.0147\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.9384e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0150\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.3743e-05 - mae: 0.0044 - val_loss: 0.0031 - val_mae: 0.0163\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.0542e-05 - mae: 0.0063 - val_loss: 0.0032 - val_mae: 0.0179\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.0950e-04 - mae: 0.0083 - val_loss: 0.0031 - val_mae: 0.0190\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.5356e-04 - mae: 0.0099 - val_loss: 0.0033 - val_mae: 0.0205\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.9639e-04 - mae: 0.0114 - val_loss: 0.0032 - val_mae: 0.0211\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3455e-04 - mae: 0.0124 - val_loss: 0.0034 - val_mae: 0.0221\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.6355e-04 - mae: 0.0133 - val_loss: 0.0032 - val_mae: 0.0222\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.9053e-04 - mae: 0.0139 - val_loss: 0.0034 - val_mae: 0.0229\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.0025e-04 - mae: 0.0142 - val_loss: 0.0032 - val_mae: 0.0226\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 2.9859e-04 - mae: 0.0141 - val_loss: 0.0034 - val_mae: 0.0224\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.8029e-04 - mae: 0.0138 - val_loss: 0.0032 - val_mae: 0.0212\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.4883e-04 - mae: 0.0129 - val_loss: 0.0033 - val_mae: 0.0207\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.0713e-04 - mae: 0.0118 - val_loss: 0.0031 - val_mae: 0.0191\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.6111e-04 - mae: 0.0102 - val_loss: 0.0032 - val_mae: 0.0181\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.1765e-04 - mae: 0.0087 - val_loss: 0.0031 - val_mae: 0.0165\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.0981e-05 - mae: 0.0070 - val_loss: 0.0031 - val_mae: 0.0156\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.4540e-05 - mae: 0.0054 - val_loss: 0.0031 - val_mae: 0.0145\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.8745e-05 - mae: 0.0042 - val_loss: 0.0031 - val_mae: 0.0141\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.2332e-05 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0142\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.3250e-05 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0147\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.9655e-05 - mae: 0.0043 - val_loss: 0.0032 - val_mae: 0.0153\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.0120e-05 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0159\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.4433e-05 - mae: 0.0061 - val_loss: 0.0032 - val_mae: 0.0167\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.2318e-05 - mae: 0.0071 - val_loss: 0.0031 - val_mae: 0.0175\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0604e-04 - mae: 0.0081 - val_loss: 0.0033 - val_mae: 0.0187\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.3574e-04 - mae: 0.0094 - val_loss: 0.0031 - val_mae: 0.0194\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7464e-04 - mae: 0.0107 - val_loss: 0.0034 - val_mae: 0.0211\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 2.2428e-04 - mae: 0.0123 - val_loss: 0.0032 - val_mae: 0.0223\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.9452e-04 - mae: 0.0141 - val_loss: 0.0036 - val_mae: 0.0246\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.8919e-04 - mae: 0.0164 - val_loss: 0.0034 - val_mae: 0.0266\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.3544e-04 - mae: 0.0191 - val_loss: 0.0039 - val_mae: 0.0299\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.2580e-04 - mae: 0.0223 - val_loss: 0.0037 - val_mae: 0.0326\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.8291e-04 - mae: 0.0259 - val_loss: 0.0044 - val_mae: 0.0363\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0013 - mae: 0.0295 - val_loss: 0.0040 - val_mae: 0.0376\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0015 - mae: 0.0321 - val_loss: 0.0047 - val_mae: 0.0394\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0015 - mae: 0.0331 - val_loss: 0.0038 - val_mae: 0.0362\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0014 - mae: 0.0310 - val_loss: 0.0041 - val_mae: 0.0330\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.4601e-04 - mae: 0.0258 - val_loss: 0.0032 - val_mae: 0.0245\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 4.4643e-04 - mae: 0.0174 - val_loss: 0.0032 - val_mae: 0.0175\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.0454e-04 - mae: 0.0080 - val_loss: 0.0031 - val_mae: 0.0154\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.1020e-05 - mae: 0.0052 - val_loss: 0.0031 - val_mae: 0.0205\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.3657e-04 - mae: 0.0125 - val_loss: 0.0036 - val_mae: 0.0262\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.8686e-04 - mae: 0.0183 - val_loss: 0.0034 - val_mae: 0.0278\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.2767e-04 - mae: 0.0208 - val_loss: 0.0037 - val_mae: 0.0278\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.7932e-04 - mae: 0.0201 - val_loss: 0.0032 - val_mae: 0.0240\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.8165e-04 - mae: 0.0162 - val_loss: 0.0033 - val_mae: 0.0191\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.5645e-04 - mae: 0.0101 - val_loss: 0.0031 - val_mae: 0.0145\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.7150e-05 - mae: 0.0041 - val_loss: 0.0031 - val_mae: 0.0161\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 6.7526e-05 - mae: 0.0064 - val_loss: 0.0033 - val_mae: 0.0199\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.8629e-04 - mae: 0.0112 - val_loss: 0.0032 - val_mae: 0.0221\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.9047e-04 - mae: 0.0140 - val_loss: 0.0034 - val_mae: 0.0226\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.0871e-04 - mae: 0.0145 - val_loss: 0.0031 - val_mae: 0.0209\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.3589e-04 - mae: 0.0125 - val_loss: 0.0032 - val_mae: 0.0180\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2218e-04 - mae: 0.0089 - val_loss: 0.0031 - val_mae: 0.0149\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 4.1472e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0143\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.2931e-05 - mae: 0.0039 - val_loss: 0.0032 - val_mae: 0.0165\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.1625e-05 - mae: 0.0072 - val_loss: 0.0031 - val_mae: 0.0185\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.4029e-04 - mae: 0.0096 - val_loss: 0.0033 - val_mae: 0.0195\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.6584e-04 - mae: 0.0106 - val_loss: 0.0031 - val_mae: 0.0185\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4634e-04 - mae: 0.0098 - val_loss: 0.0032 - val_mae: 0.0172\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.6822e-05 - mae: 0.0079 - val_loss: 0.0031 - val_mae: 0.0151\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.8490e-05 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0137\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.5593e-05 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0143\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.3440e-05 - mae: 0.0041 - val_loss: 0.0031 - val_mae: 0.0155\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.9188e-05 - mae: 0.0059 - val_loss: 0.0032 - val_mae: 0.0167\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.3700e-05 - mae: 0.0073 - val_loss: 0.0031 - val_mae: 0.0168\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.2622e-05 - mae: 0.0077 - val_loss: 0.0032 - val_mae: 0.0166\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 8.3225e-05 - mae: 0.0074 - val_loss: 0.0031 - val_mae: 0.0156\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.1817e-05 - mae: 0.0062 - val_loss: 0.0031 - val_mae: 0.0145\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 3.9136e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0136\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.5037e-05 - mae: 0.0033 - val_loss: 0.0031 - val_mae: 0.0134\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 2.3147e-05 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0140\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.0852e-05 - mae: 0.0040 - val_loss: 0.0031 - val_mae: 0.0146\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.2381e-05 - mae: 0.0049 - val_loss: 0.0032 - val_mae: 0.0152\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.1729e-05 - mae: 0.0056 - val_loss: 0.0031 - val_mae: 0.0153\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.6816e-05 - mae: 0.0059 - val_loss: 0.0032 - val_mae: 0.0154\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.5193e-05 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0150\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.8463e-05 - mae: 0.0054 - val_loss: 0.0032 - val_mae: 0.0145\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.8798e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0139\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.9482e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0134\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.2975e-05 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0132\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.0255e-05 - mae: 0.0027 - val_loss: 0.0031 - val_mae: 0.0132\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 2.1019e-05 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.4095e-05 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0138\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.8200e-05 - mae: 0.0038 - val_loss: 0.0032 - val_mae: 0.0141\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 3.2121e-05 - mae: 0.0042 - val_loss: 0.0031 - val_mae: 0.0142\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.5200e-05 - mae: 0.0044 - val_loss: 0.0032 - val_mae: 0.0144\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 3.7213e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0144\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.8306e-05 - mae: 0.0047 - val_loss: 0.0032 - val_mae: 0.0144\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.8220e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0144\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 3.7751e-05 - mae: 0.0047 - val_loss: 0.0032 - val_mae: 0.0143\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.6468e-05 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0142\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.4780e-05 - mae: 0.0044 - val_loss: 0.0032 - val_mae: 0.0141\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.2770e-05 - mae: 0.0043 - val_loss: 0.0031 - val_mae: 0.0140\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.0727e-05 - mae: 0.0041 - val_loss: 0.0032 - val_mae: 0.0138\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.8656e-05 - mae: 0.0040 - val_loss: 0.0031 - val_mae: 0.0137\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.6824e-05 - mae: 0.0038 - val_loss: 0.0032 - val_mae: 0.0136\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.5276e-05 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.4050e-05 - mae: 0.0035 - val_loss: 0.0032 - val_mae: 0.0134\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 2.3152e-05 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0134\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.2568e-05 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0134\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 2.2261e-05 - mae: 0.0033 - val_loss: 0.0031 - val_mae: 0.0134\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.2533e-05 - mae: 0.0033 - val_loss: 0.0032 - val_mae: 0.0135\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3323e-05 - mae: 0.0035 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.5008e-05 - mae: 0.0036 - val_loss: 0.0032 - val_mae: 0.0138\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.7606e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0141\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.2252e-05 - mae: 0.0043 - val_loss: 0.0032 - val_mae: 0.0145\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 3.9490e-05 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0151\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.2855e-05 - mae: 0.0057 - val_loss: 0.0032 - val_mae: 0.0162\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.3766e-05 - mae: 0.0069 - val_loss: 0.0031 - val_mae: 0.0174\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.0887e-04 - mae: 0.0085 - val_loss: 0.0034 - val_mae: 0.0193\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.6494e-04 - mae: 0.0106 - val_loss: 0.0032 - val_mae: 0.0215\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.6371e-04 - mae: 0.0134 - val_loss: 0.0037 - val_mae: 0.0251\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.2319e-04 - mae: 0.0172 - val_loss: 0.0035 - val_mae: 0.0289\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 6.8698e-04 - mae: 0.0218 - val_loss: 0.0043 - val_mae: 0.0346\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0011 - mae: 0.0277 - val_loss: 0.0043 - val_mae: 0.0405\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0017 - mae: 0.0348 - val_loss: 0.0057 - val_mae: 0.0477\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0026 - mae: 0.0426 - val_loss: 0.0057 - val_mae: 0.0539\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0036 - mae: 0.0501 - val_loss: 0.0071 - val_mae: 0.0581\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0041 - mae: 0.0541 - val_loss: 0.0056 - val_mae: 0.0536\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0036 - mae: 0.0506 - val_loss: 0.0051 - val_mae: 0.0433\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0020 - mae: 0.0378 - val_loss: 0.0032 - val_mae: 0.0232\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.2343e-04 - mae: 0.0168 - val_loss: 0.0033 - val_mae: 0.0196\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 2.3157e-04 - mae: 0.0106 - val_loss: 0.0043 - val_mae: 0.0349\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0011 - mae: 0.0275 - val_loss: 0.0040 - val_mae: 0.0393\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0018 - mae: 0.0353 - val_loss: 0.0045 - val_mae: 0.0359\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0014 - mae: 0.0308 - val_loss: 0.0032 - val_mae: 0.0246\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3659e-04 - mae: 0.0186 - val_loss: 0.0033 - val_mae: 0.0188\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.7010e-04 - mae: 0.0085 - val_loss: 0.0037 - val_mae: 0.0265\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.5658e-04 - mae: 0.0192 - val_loss: 0.0035 - val_mae: 0.0317\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.7720e-04 - mae: 0.0260 - val_loss: 0.0040 - val_mae: 0.0290\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.7853e-04 - mae: 0.0226 - val_loss: 0.0031 - val_mae: 0.0206\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4327e-04 - mae: 0.0127 - val_loss: 0.0032 - val_mae: 0.0177\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1833e-04 - mae: 0.0077 - val_loss: 0.0037 - val_mae: 0.0260\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.6105e-04 - mae: 0.0181 - val_loss: 0.0033 - val_mae: 0.0273\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.2037e-04 - mae: 0.0206 - val_loss: 0.0035 - val_mae: 0.0219\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.2855e-04 - mae: 0.0144 - val_loss: 0.0031 - val_mae: 0.0158\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.2407e-05 - mae: 0.0060 - val_loss: 0.0031 - val_mae: 0.0200\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.7920e-04 - mae: 0.0109 - val_loss: 0.0035 - val_mae: 0.0240\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 3.8146e-04 - mae: 0.0163 - val_loss: 0.0031 - val_mae: 0.0221\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.0631e-04 - mae: 0.0143 - val_loss: 0.0031 - val_mae: 0.0169\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 9.8784e-05 - mae: 0.0079 - val_loss: 0.0031 - val_mae: 0.0160\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.1321e-05 - mae: 0.0063 - val_loss: 0.0031 - val_mae: 0.0203\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9530e-04 - mae: 0.0115 - val_loss: 0.0034 - val_mae: 0.0213\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.3157e-04 - mae: 0.0125 - val_loss: 0.0031 - val_mae: 0.0177\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3030e-04 - mae: 0.0090 - val_loss: 0.0031 - val_mae: 0.0151\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9815e-05 - mae: 0.0050 - val_loss: 0.0032 - val_mae: 0.0169\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.2043e-05 - mae: 0.0072 - val_loss: 0.0031 - val_mae: 0.0185\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.4304e-04 - mae: 0.0096 - val_loss: 0.0032 - val_mae: 0.0181\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.3074e-04 - mae: 0.0088 - val_loss: 0.0031 - val_mae: 0.0154\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.5309e-05 - mae: 0.0059 - val_loss: 0.0030 - val_mae: 0.0143\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.4729e-05 - mae: 0.0044 - val_loss: 0.0031 - val_mae: 0.0161\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 6.7298e-05 - mae: 0.0064 - val_loss: 0.0031 - val_mae: 0.0167\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.0046e-04 - mae: 0.0075 - val_loss: 0.0031 - val_mae: 0.0160\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.8348e-05 - mae: 0.0065 - val_loss: 0.0031 - val_mae: 0.0140\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.0995e-05 - mae: 0.0040 - val_loss: 0.0030 - val_mae: 0.0136\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.4880e-05 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0154\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.8464e-05 - mae: 0.0056 - val_loss: 0.0031 - val_mae: 0.0156\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 7.1227e-05 - mae: 0.0061 - val_loss: 0.0031 - val_mae: 0.0146\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.2565e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0128\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.6074e-05 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.6064e-05 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0148\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.7762e-05 - mae: 0.0050 - val_loss: 0.0031 - val_mae: 0.0145\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.4717e-05 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.3827e-05 - mae: 0.0036 - val_loss: 0.0030 - val_mae: 0.0127\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.5337e-05 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0133\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.5117e-05 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0140\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.3623e-05 - mae: 0.0043 - val_loss: 0.0030 - val_mae: 0.0137\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.9075e-05 - mae: 0.0040 - val_loss: 0.0031 - val_mae: 0.0131\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.9056e-05 - mae: 0.0032 - val_loss: 0.0031 - val_mae: 0.0127\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.5492e-05 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0129\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.9460e-05 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0134\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.3761e-05 - mae: 0.0037 - val_loss: 0.0030 - val_mae: 0.0133\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2650e-05 - mae: 0.0036 - val_loss: 0.0031 - val_mae: 0.0129\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7185e-05 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0125\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 1.3430e-05 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0126\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.4943e-05 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0130\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.8696e-05 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0130\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.9061e-05 - mae: 0.0033 - val_loss: 0.0031 - val_mae: 0.0127\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.5254e-05 - mae: 0.0028 - val_loss: 0.0031 - val_mae: 0.0123\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 1.1924e-05 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0123\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2550e-05 - mae: 0.0023 - val_loss: 0.0031 - val_mae: 0.0127\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.5303e-05 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0127\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6158e-05 - mae: 0.0029 - val_loss: 0.0031 - val_mae: 0.0126\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4085e-05 - mae: 0.0027 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.1688e-05 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.1319e-05 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0124\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2535e-05 - mae: 0.0024 - val_loss: 0.0031 - val_mae: 0.0124\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3421e-05 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0124\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3046e-05 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1982e-05 - mae: 0.0023 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.1114e-05 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0882e-05 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1133e-05 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.1490e-05 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.1528e-05 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.1087e-05 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0120\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0463e-05 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0120\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0066e-05 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0120\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0170e-05 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0120\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0525e-05 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0630e-05 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0120\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.0348e-05 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 9.8906e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.6208e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.6210e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.7309e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 9.7707e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.6975e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.5604e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 9.3890e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 9.2274e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9.1066e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 9.0692e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.1000e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 9.1207e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 9.0694e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 8.9492e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.8160e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.7102e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 8.6370e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 8.5822e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.5307e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 8.4820e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 8.4508e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 8.4282e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.3931e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 8.3320e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 8.2545e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 8.1764e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 8.1063e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.0480e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 7.9919e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.9364e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 7.8822e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 7.8309e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 7.7902e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.7549e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 7.7206e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.6842e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.6525e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.6212e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7.5929e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 7.5651e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 7.5387e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 7.5108e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.4911e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7.4750e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 7.4684e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 7.4662e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.4810e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.5072e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.5587e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.6274e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.7296e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.8626e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.0855e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 8.3449e-06 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0118\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 8.6828e-06 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 9.1146e-06 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 9.7318e-06 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0120\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0524e-05 - mae: 0.0024 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.1677e-05 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0123\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.3226e-05 - mae: 0.0028 - val_loss: 0.0031 - val_mae: 0.0125\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 1.5529e-05 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0128\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.8895e-05 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0131\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.3985e-05 - mae: 0.0039 - val_loss: 0.0032 - val_mae: 0.0137\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 3.1399e-05 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0143\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 4.2711e-05 - mae: 0.0054 - val_loss: 0.0032 - val_mae: 0.0153\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 5.9947e-05 - mae: 0.0065 - val_loss: 0.0031 - val_mae: 0.0164\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.8740e-05 - mae: 0.0079 - val_loss: 0.0033 - val_mae: 0.0181\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.3527e-04 - mae: 0.0098 - val_loss: 0.0031 - val_mae: 0.0201\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.1172e-04 - mae: 0.0123 - val_loss: 0.0036 - val_mae: 0.0233\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.3777e-04 - mae: 0.0156 - val_loss: 0.0033 - val_mae: 0.0267\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 5.4751e-04 - mae: 0.0197 - val_loss: 0.0042 - val_mae: 0.0324\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.0401e-04 - mae: 0.0254 - val_loss: 0.0039 - val_mae: 0.0376\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0014 - mae: 0.0318 - val_loss: 0.0053 - val_mae: 0.0445\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0021 - mae: 0.0386 - val_loss: 0.0048 - val_mae: 0.0483\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0028 - mae: 0.0444 - val_loss: 0.0062 - val_mae: 0.0522\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0032 - mae: 0.0476 - val_loss: 0.0046 - val_mae: 0.0475\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0028 - mae: 0.0452 - val_loss: 0.0049 - val_mae: 0.0406\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0019 - mae: 0.0364 - val_loss: 0.0035 - val_mae: 0.0306\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 9.3055e-04 - mae: 0.0254 - val_loss: 0.0038 - val_mae: 0.0266\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.9875e-04 - mae: 0.0164 - val_loss: 0.0038 - val_mae: 0.0259\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.5570e-04 - mae: 0.0162 - val_loss: 0.0034 - val_mae: 0.0297\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.5133e-04 - mae: 0.0228 - val_loss: 0.0041 - val_mae: 0.0297\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.8785e-04 - mae: 0.0241 - val_loss: 0.0034 - val_mae: 0.0306\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.8704e-04 - mae: 0.0247 - val_loss: 0.0039 - val_mae: 0.0298\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.7327e-04 - mae: 0.0215 - val_loss: 0.0035 - val_mae: 0.0232\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 4.1654e-04 - mae: 0.0132 - val_loss: 0.0033 - val_mae: 0.0216\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.7773e-04 - mae: 0.0122 - val_loss: 0.0037 - val_mae: 0.0263\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.8187e-04 - mae: 0.0177 - val_loss: 0.0032 - val_mae: 0.0254\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.4171e-04 - mae: 0.0178 - val_loss: 0.0034 - val_mae: 0.0214\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.5069e-04 - mae: 0.0134 - val_loss: 0.0032 - val_mae: 0.0193\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.0328e-04 - mae: 0.0100 - val_loss: 0.0033 - val_mae: 0.0219\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.5768e-04 - mae: 0.0124 - val_loss: 0.0036 - val_mae: 0.0241\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.1100e-04 - mae: 0.0142 - val_loss: 0.0031 - val_mae: 0.0202\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.2246e-04 - mae: 0.0113 - val_loss: 0.0031 - val_mae: 0.0146\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.7488e-05 - mae: 0.0055 - val_loss: 0.0031 - val_mae: 0.0168\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0360e-04 - mae: 0.0073 - val_loss: 0.0032 - val_mae: 0.0199\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.4499e-04 - mae: 0.0107 - val_loss: 0.0033 - val_mae: 0.0201\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.5161e-04 - mae: 0.0103 - val_loss: 0.0031 - val_mae: 0.0167\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.3771e-04 - mae: 0.0071 - val_loss: 0.0030 - val_mae: 0.0149\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 5.6136e-05 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0156\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.5271e-05 - mae: 0.0060 - val_loss: 0.0030 - val_mae: 0.0166\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.1006e-04 - mae: 0.0073 - val_loss: 0.0032 - val_mae: 0.0169\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.3076e-04 - mae: 0.0070 - val_loss: 0.0031 - val_mae: 0.0159\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0882e-04 - mae: 0.0062 - val_loss: 0.0030 - val_mae: 0.0154\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.2896e-05 - mae: 0.0058 - val_loss: 0.0031 - val_mae: 0.0143\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.8822e-05 - mae: 0.0051 - val_loss: 0.0030 - val_mae: 0.0149\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.7942e-05 - mae: 0.0059 - val_loss: 0.0031 - val_mae: 0.0156\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.8301e-05 - mae: 0.0059 - val_loss: 0.0030 - val_mae: 0.0145\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.9162e-05 - mae: 0.0051 - val_loss: 0.0030 - val_mae: 0.0135\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.7531e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.0290e-05 - mae: 0.0045 - val_loss: 0.0030 - val_mae: 0.0147\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.5353e-05 - mae: 0.0059 - val_loss: 0.0031 - val_mae: 0.0149\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.6364e-05 - mae: 0.0057 - val_loss: 0.0030 - val_mae: 0.0131\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.9091e-05 - mae: 0.0040 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0490e-05 - mae: 0.0023 - val_loss: 0.0031 - val_mae: 0.0128\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9977e-05 - mae: 0.0034 - val_loss: 0.0030 - val_mae: 0.0138\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.6466e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0138\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.6138e-05 - mae: 0.0047 - val_loss: 0.0030 - val_mae: 0.0129\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.3037e-05 - mae: 0.0038 - val_loss: 0.0031 - val_mae: 0.0125\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.3782e-05 - mae: 0.0029 - val_loss: 0.0030 - val_mae: 0.0124\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.4259e-05 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0125\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.8458e-05 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0128\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 2.0012e-05 - mae: 0.0035 - val_loss: 0.0030 - val_mae: 0.0126\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.7822e-05 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0125\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.3991e-05 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.1671e-05 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0120\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2562e-05 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0124\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.4719e-05 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0123\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.4108e-05 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0119\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.0054e-05 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.9108e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0117\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.1826e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0120\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.1686e-05 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.2618e-05 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0118\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.8604e-06 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.9539e-06 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 6.6981e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0117\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.9668e-06 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0117\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 8.3997e-06 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0116\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.6320e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.8394e-06 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.6542e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.7599e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.9081e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0115\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 7.1062e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 7.1107e-06 - mae: 0.0019 - val_loss: 0.0031 - val_mae: 0.0114\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.5127e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.6179e-06 - mae: 0.0016 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.1963e-06 - mae: 0.0014 - val_loss: 0.0030 - val_mae: 0.0113\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 5.5116e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0113\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.9845e-06 - mae: 0.0016 - val_loss: 0.0031 - val_mae: 0.0113\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.9809e-06 - mae: 0.0016 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.5431e-06 - mae: 0.0016 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.1571e-06 - mae: 0.0014 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.1300e-06 - mae: 0.0014 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5.3133e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.4718e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.4934e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.4424e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.3272e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 5.1750e-06 - mae: 0.0015 - val_loss: 0.0031 - val_mae: 0.0112\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.0620e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.0537e-06 - mae: 0.0015 - val_loss: 0.0031 - val_mae: 0.0112\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.1290e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.2033e-06 - mae: 0.0015 - val_loss: 0.0031 - val_mae: 0.0112\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.1744e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.0707e-06 - mae: 0.0015 - val_loss: 0.0031 - val_mae: 0.0112\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.9689e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.9792e-06 - mae: 0.0015 - val_loss: 0.0031 - val_mae: 0.0112\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.1242e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3946e-06 - mae: 0.0016 - val_loss: 0.0031 - val_mae: 0.0113\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.7210e-06 - mae: 0.0016 - val_loss: 0.0030 - val_mae: 0.0113\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.1511e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0114\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.7102e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.5274e-06 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 8.7136e-06 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0119\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.0590e-05 - mae: 0.0025 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3392e-05 - mae: 0.0029 - val_loss: 0.0030 - val_mae: 0.0125\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 1.8044e-05 - mae: 0.0034 - val_loss: 0.0031 - val_mae: 0.0131\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.4624e-05 - mae: 0.0040 - val_loss: 0.0030 - val_mae: 0.0137\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.4208e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0145\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 4.6909e-05 - mae: 0.0057 - val_loss: 0.0030 - val_mae: 0.0154\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.5571e-05 - mae: 0.0067 - val_loss: 0.0032 - val_mae: 0.0166\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.0957e-05 - mae: 0.0080 - val_loss: 0.0031 - val_mae: 0.0178\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2588e-04 - mae: 0.0094 - val_loss: 0.0033 - val_mae: 0.0194\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.7231e-04 - mae: 0.0111 - val_loss: 0.0031 - val_mae: 0.0209\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.3678e-04 - mae: 0.0131 - val_loss: 0.0035 - val_mae: 0.0233\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.2933e-04 - mae: 0.0154 - val_loss: 0.0033 - val_mae: 0.0255\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.5700e-04 - mae: 0.0181 - val_loss: 0.0038 - val_mae: 0.0284\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.1985e-04 - mae: 0.0211 - val_loss: 0.0035 - val_mae: 0.0310\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.3060e-04 - mae: 0.0245 - val_loss: 0.0042 - val_mae: 0.0345\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0011 - mae: 0.0279 - val_loss: 0.0038 - val_mae: 0.0367\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0013 - mae: 0.0309 - val_loss: 0.0046 - val_mae: 0.0393\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0015 - mae: 0.0332 - val_loss: 0.0040 - val_mae: 0.0389\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0016 - mae: 0.0339 - val_loss: 0.0045 - val_mae: 0.0382\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0015 - mae: 0.0328 - val_loss: 0.0036 - val_mae: 0.0340\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0011 - mae: 0.0289 - val_loss: 0.0037 - val_mae: 0.0288\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.5699e-04 - mae: 0.0222 - val_loss: 0.0029 - val_mae: 0.0203\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.3624e-04 - mae: 0.0132 - val_loss: 0.0031 - val_mae: 0.0140\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.5467e-05 - mae: 0.0047 - val_loss: 0.0031 - val_mae: 0.0159\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.6665e-05 - mae: 0.0070 - val_loss: 0.0031 - val_mae: 0.0221\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.9341e-04 - mae: 0.0143 - val_loss: 0.0036 - val_mae: 0.0264\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.9741e-04 - mae: 0.0191 - val_loss: 0.0033 - val_mae: 0.0274\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.8171e-04 - mae: 0.0208 - val_loss: 0.0036 - val_mae: 0.0260\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.9723e-04 - mae: 0.0193 - val_loss: 0.0030 - val_mae: 0.0217\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 3.0290e-04 - mae: 0.0148 - val_loss: 0.0032 - val_mae: 0.0167\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1327e-04 - mae: 0.0088 - val_loss: 0.0030 - val_mae: 0.0130\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.3968e-05 - mae: 0.0038 - val_loss: 0.0030 - val_mae: 0.0149\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.5993e-05 - mae: 0.0058 - val_loss: 0.0032 - val_mae: 0.0182\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5690e-04 - mae: 0.0105 - val_loss: 0.0030 - val_mae: 0.0210\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4449e-04 - mae: 0.0134 - val_loss: 0.0034 - val_mae: 0.0212\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.6053e-04 - mae: 0.0140 - val_loss: 0.0030 - val_mae: 0.0198\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2.0122e-04 - mae: 0.0122 - val_loss: 0.0032 - val_mae: 0.0167\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0621e-04 - mae: 0.0087 - val_loss: 0.0029 - val_mae: 0.0134\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.2497e-05 - mae: 0.0047 - val_loss: 0.0030 - val_mae: 0.0122\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4562e-05 - mae: 0.0027 - val_loss: 0.0031 - val_mae: 0.0146\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.6803e-05 - mae: 0.0057 - val_loss: 0.0030 - val_mae: 0.0165\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.4835e-05 - mae: 0.0084 - val_loss: 0.0032 - val_mae: 0.0176\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 1.2388e-04 - mae: 0.0096 - val_loss: 0.0030 - val_mae: 0.0169\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1668e-04 - mae: 0.0091 - val_loss: 0.0032 - val_mae: 0.0157\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.0156e-05 - mae: 0.0075 - val_loss: 0.0030 - val_mae: 0.0136\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 3.7720e-05 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2197e-05 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.2075e-05 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0134\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 3.0037e-05 - mae: 0.0046 - val_loss: 0.0031 - val_mae: 0.0147\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.0756e-05 - mae: 0.0061 - val_loss: 0.0030 - val_mae: 0.0150\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 6.1040e-05 - mae: 0.0066 - val_loss: 0.0032 - val_mae: 0.0149\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.6078e-05 - mae: 0.0063 - val_loss: 0.0030 - val_mae: 0.0138\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.0066e-05 - mae: 0.0053 - val_loss: 0.0031 - val_mae: 0.0128\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.1728e-05 - mae: 0.0038 - val_loss: 0.0030 - val_mae: 0.0118\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.5650e-06 - mae: 0.0024 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.1390e-06 - mae: 0.0020 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2833e-05 - mae: 0.0029 - val_loss: 0.0030 - val_mae: 0.0128\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.1542e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0133\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.7804e-05 - mae: 0.0044 - val_loss: 0.0030 - val_mae: 0.0133\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.9090e-05 - mae: 0.0045 - val_loss: 0.0031 - val_mae: 0.0131\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.5145e-05 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0125\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.8200e-05 - mae: 0.0035 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1154e-05 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.5784e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.3650e-06 - mae: 0.0017 - val_loss: 0.0031 - val_mae: 0.0115\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 6.9380e-06 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0118\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.9597e-06 - mae: 0.0026 - val_loss: 0.0031 - val_mae: 0.0121\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.2981e-05 - mae: 0.0030 - val_loss: 0.0030 - val_mae: 0.0122\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.4843e-05 - mae: 0.0031 - val_loss: 0.0031 - val_mae: 0.0122\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4897e-05 - mae: 0.0032 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.3315e-05 - mae: 0.0030 - val_loss: 0.0031 - val_mae: 0.0119\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.0622e-05 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.7044e-06 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.3311e-06 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0109\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 4.0486e-06 - mae: 0.0013 - val_loss: 0.0030 - val_mae: 0.0109\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.9022e-06 - mae: 0.0013 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.6046e-06 - mae: 0.0015 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.7388e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0114\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.9105e-06 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 7.8523e-06 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.3181e-06 - mae: 0.0023 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 8.3538e-06 - mae: 0.0023 - val_loss: 0.0031 - val_mae: 0.0116\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.9276e-06 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.2767e-06 - mae: 0.0021 - val_loss: 0.0031 - val_mae: 0.0114\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.4059e-06 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.5123e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0111\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.7080e-06 - mae: 0.0016 - val_loss: 0.0030 - val_mae: 0.0109\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.0782e-06 - mae: 0.0014 - val_loss: 0.0030 - val_mae: 0.0109\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 3.6240e-06 - mae: 0.0013 - val_loss: 0.0030 - val_mae: 0.0108\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.3568e-06 - mae: 0.0012 - val_loss: 0.0030 - val_mae: 0.0108\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.2491e-06 - mae: 0.0011 - val_loss: 0.0030 - val_mae: 0.0108\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.2739e-06 - mae: 0.0011 - val_loss: 0.0030 - val_mae: 0.0108\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.4167e-06 - mae: 0.0012 - val_loss: 0.0030 - val_mae: 0.0109\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 3.6787e-06 - mae: 0.0013 - val_loss: 0.0030 - val_mae: 0.0110\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 4.0961e-06 - mae: 0.0014 - val_loss: 0.0031 - val_mae: 0.0111\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.6560e-06 - mae: 0.0016 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.4646e-06 - mae: 0.0018 - val_loss: 0.0031 - val_mae: 0.0113\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.4945e-06 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.8979e-06 - mae: 0.0022 - val_loss: 0.0031 - val_mae: 0.0117\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.7082e-06 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0120\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.2285e-05 - mae: 0.0028 - val_loss: 0.0031 - val_mae: 0.0123\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.5566e-05 - mae: 0.0033 - val_loss: 0.0030 - val_mae: 0.0127\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.0062e-05 - mae: 0.0037 - val_loss: 0.0031 - val_mae: 0.0131\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.5482e-05 - mae: 0.0042 - val_loss: 0.0030 - val_mae: 0.0136\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.3265e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0143\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.3540e-05 - mae: 0.0056 - val_loss: 0.0030 - val_mae: 0.0149\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.7036e-05 - mae: 0.0064 - val_loss: 0.0032 - val_mae: 0.0158\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 7.5002e-05 - mae: 0.0074 - val_loss: 0.0030 - val_mae: 0.0167\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 9.8511e-05 - mae: 0.0085 - val_loss: 0.0033 - val_mae: 0.0180\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.3063e-04 - mae: 0.0099 - val_loss: 0.0030 - val_mae: 0.0193\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.7768e-04 - mae: 0.0115 - val_loss: 0.0034 - val_mae: 0.0212\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.4161e-04 - mae: 0.0135 - val_loss: 0.0031 - val_mae: 0.0230\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 3.3139e-04 - mae: 0.0158 - val_loss: 0.0036 - val_mae: 0.0256\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 4.4990e-04 - mae: 0.0184 - val_loss: 0.0033 - val_mae: 0.0279\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.2143e-04 - mae: 0.0215 - val_loss: 0.0040 - val_mae: 0.0314\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.3909e-04 - mae: 0.0250 - val_loss: 0.0036 - val_mae: 0.0343\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0011 - mae: 0.0287 - val_loss: 0.0045 - val_mae: 0.0379\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0014 - mae: 0.0322 - val_loss: 0.0040 - val_mae: 0.0400\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0017 - mae: 0.0351 - val_loss: 0.0050 - val_mae: 0.0423\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0019 - mae: 0.0370 - val_loss: 0.0041 - val_mae: 0.0415\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0019 - mae: 0.0369 - val_loss: 0.0047 - val_mae: 0.0394\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0016 - mae: 0.0339 - val_loss: 0.0035 - val_mae: 0.0326\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0010 - mae: 0.0272 - val_loss: 0.0035 - val_mae: 0.0244\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.4153e-04 - mae: 0.0178 - val_loss: 0.0029 - val_mae: 0.0162\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.1106e-04 - mae: 0.0085 - val_loss: 0.0032 - val_mae: 0.0165\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.1311e-04 - mae: 0.0070 - val_loss: 0.0034 - val_mae: 0.0219\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 3.4206e-04 - mae: 0.0137 - val_loss: 0.0034 - val_mae: 0.0267\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.9474e-04 - mae: 0.0192 - val_loss: 0.0039 - val_mae: 0.0288\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 7.0556e-04 - mae: 0.0217 - val_loss: 0.0033 - val_mae: 0.0277\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.0135e-04 - mae: 0.0207 - val_loss: 0.0035 - val_mae: 0.0236\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 3.5751e-04 - mae: 0.0164 - val_loss: 0.0029 - val_mae: 0.0181\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4640e-04 - mae: 0.0102 - val_loss: 0.0032 - val_mae: 0.0165\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.3359e-05 - mae: 0.0072 - val_loss: 0.0031 - val_mae: 0.0168\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.5382e-04 - mae: 0.0078 - val_loss: 0.0032 - val_mae: 0.0201\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.4964e-04 - mae: 0.0112 - val_loss: 0.0033 - val_mae: 0.0209\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2.8187e-04 - mae: 0.0131 - val_loss: 0.0031 - val_mae: 0.0208\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.3217e-04 - mae: 0.0128 - val_loss: 0.0032 - val_mae: 0.0179\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.5257e-04 - mae: 0.0105 - val_loss: 0.0029 - val_mae: 0.0166\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.0490e-04 - mae: 0.0087 - val_loss: 0.0032 - val_mae: 0.0171\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0512e-04 - mae: 0.0082 - val_loss: 0.0030 - val_mae: 0.0169\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.2394e-04 - mae: 0.0078 - val_loss: 0.0032 - val_mae: 0.0165\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.2421e-04 - mae: 0.0076 - val_loss: 0.0031 - val_mae: 0.0162\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 9.8934e-05 - mae: 0.0073 - val_loss: 0.0030 - val_mae: 0.0152\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.7859e-05 - mae: 0.0069 - val_loss: 0.0031 - val_mae: 0.0150\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.6444e-05 - mae: 0.0063 - val_loss: 0.0029 - val_mae: 0.0153\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.7253e-05 - mae: 0.0067 - val_loss: 0.0032 - val_mae: 0.0161\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 8.1803e-05 - mae: 0.0069 - val_loss: 0.0030 - val_mae: 0.0155\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.1177e-05 - mae: 0.0064 - val_loss: 0.0031 - val_mae: 0.0147\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.0820e-05 - mae: 0.0055 - val_loss: 0.0030 - val_mae: 0.0135\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.6155e-05 - mae: 0.0043 - val_loss: 0.0030 - val_mae: 0.0130\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.4348e-05 - mae: 0.0039 - val_loss: 0.0031 - val_mae: 0.0137\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.0708e-05 - mae: 0.0045 - val_loss: 0.0030 - val_mae: 0.0143\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.5416e-05 - mae: 0.0051 - val_loss: 0.0031 - val_mae: 0.0147\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.2143e-05 - mae: 0.0053 - val_loss: 0.0030 - val_mae: 0.0140\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.4282e-05 - mae: 0.0048 - val_loss: 0.0031 - val_mae: 0.0131\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2.7131e-05 - mae: 0.0037 - val_loss: 0.0030 - val_mae: 0.0120\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.3730e-05 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.2160e-05 - mae: 0.0027 - val_loss: 0.0030 - val_mae: 0.0129\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2.0350e-05 - mae: 0.0034 - val_loss: 0.0030 - val_mae: 0.0133\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 2.9523e-05 - mae: 0.0040 - val_loss: 0.0031 - val_mae: 0.0135\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 3.1685e-05 - mae: 0.0040 - val_loss: 0.0030 - val_mae: 0.0129\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 2.5084e-05 - mae: 0.0036 - val_loss: 0.0030 - val_mae: 0.0122\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4336e-05 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 6.6138e-06 - mae: 0.0020 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.6329e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0117\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.0075e-05 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.5333e-05 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0123\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.7294e-05 - mae: 0.0028 - val_loss: 0.0030 - val_mae: 0.0121\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.5124e-05 - mae: 0.0026 - val_loss: 0.0030 - val_mae: 0.0118\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.0629e-05 - mae: 0.0023 - val_loss: 0.0030 - val_mae: 0.0113\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.9118e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.7386e-06 - mae: 0.0018 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.8973e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.6084e-06 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.3009e-06 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0114\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.4021e-06 - mae: 0.0021 - val_loss: 0.0030 - val_mae: 0.0112\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 6.6448e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.3255e-06 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0111\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.3680e-06 - mae: 0.0017 - val_loss: 0.0030 - val_mae: 0.0113\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.8436e-06 - mae: 0.0019 - val_loss: 0.0030 - val_mae: 0.0115\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 9.2535e-06 - mae: 0.0022 - val_loss: 0.0030 - val_mae: 0.0118\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 1.1890e-05 - mae: 0.0025 - val_loss: 0.0030 - val_mae: 0.0120\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4431e-05 - mae: 0.0028 - val_loss: 0.0031 - val_mae: 0.0123\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.7161e-05 - mae: 0.0031 - val_loss: 0.0030 - val_mae: 0.0125\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.1148e-05 - mae: 0.0035 - val_loss: 0.0031 - val_mae: 0.0130\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2.8098e-05 - mae: 0.0041 - val_loss: 0.0030 - val_mae: 0.0135\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 3.9897e-05 - mae: 0.0049 - val_loss: 0.0031 - val_mae: 0.0145\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.9639e-05 - mae: 0.0060 - val_loss: 0.0030 - val_mae: 0.0155\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.9048e-05 - mae: 0.0073 - val_loss: 0.0032 - val_mae: 0.0169\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3170e-04 - mae: 0.0089 - val_loss: 0.0031 - val_mae: 0.0185\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.9188e-04 - mae: 0.0108 - val_loss: 0.0033 - val_mae: 0.0206\n",
      "Epoch 970: early stopping\n",
      "Restoring model weights from the end of the best epoch: 870.\n"
     ]
    }
   ],
   "source": [
    "# Definizione modello DNN\n",
    "def build_model(input_shape: tuple, output_shape: tuple):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation = \"relu\", input_shape=input_shape),\n",
    "        Dropout(0.0),\n",
    "        layers.Dense(output_shape, 'linear')\n",
    "    ])\n",
    "    model.compile(\n",
    "    optimizer=optimizers.AdamW(learning_rate=0.0101, weight_decay=0.0107),\n",
    "    loss= 'mse',\n",
    "    metrics=['mae'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',      # metrica da monitorare, es. val_loss o val_mae\n",
    "    patience=100,             # numero di epoche senza miglioramento prima di fermare\n",
    "    restore_best_weights=True,  # ripristina i pesi migliori trovati\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Training del modello\n",
    "model = build_model((X_test.shape[1],), y_test.shape[1])\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=256,\n",
    "    callbacks = [early_stop],\n",
    "    validation_split = 0.2,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "'''print(\"y_train min/max:\", y_train_np.min(), y_train_np.max())\n",
    "print(\"y_pred min/max (scaled):\", y_pred.min(), y_pred.max())\n",
    "y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
    "print(\"y_pred_rescaled min/max:\", y_pred_rescaled.min(), y_pred_rescaled.max())'''\n",
    "\n",
    "if not os.path.exists(os.path.join(exp_dir, \"model\")):\n",
    "    os.makedirs(os.path.join(exp_dir, \"model\"))\n",
    "    model.save(os.path.join(exp_dir, \"model\", \"NO2_MAREMMA_model.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b6149cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{exp_dir}/model/NO2_{sensor_name}_model.keras') if os.path.exists(f'{exp_dir}/model/NO2_{sensor_name}_model.keras') else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "105abd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai losses da tutti i folds\n",
    "train_losses = history.history['loss']\n",
    "val_losses   = history.history['val_loss']\n",
    "\n",
    "train_losses = train_losses\n",
    "val_losses = val_losses\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "\n",
    "# Training loss\n",
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "# Validation loss\n",
    "plt.plot(val_losses, color='red', label='Validation Loss')\n",
    "\n",
    "\n",
    "# Dettagli grafico\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.savefig(f'{exp_dir}/loss_plot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd1f8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_n_series(y_pred, y_test, n_series=10, title=\"Confronto Serie Predette vs Reali\"):\n",
    "    \"\"\"\n",
    "    Plotta le prime n_series serie reali e predette per un confronto diretto.\n",
    "\n",
    "    Args:\n",
    "        y_pred (np.ndarray): Predizioni del modello (shape: num_samples x seq_len).\n",
    "        y_test (np.ndarray): Serie reali (shape: num_samples x seq_len).\n",
    "        n_series (int): Numero di serie da plottare.\n",
    "        title (str): Titolo del grafico.\n",
    "    \"\"\"\n",
    "\n",
    "    # Limitiamo a n_series per evitare problemi\n",
    "    n = min(n_series, y_pred.shape[0], y_test.shape[0])\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.plot(\n",
    "            y_test[i], \n",
    "            linewidth=1.8, \n",
    "            alpha=0.5, \n",
    "            label=f\"Reale {i+1}\" if i == 0 else \"\",\n",
    "            color = 'blue'\n",
    "        )\n",
    "        plt.plot(\n",
    "            y_pred[i], \n",
    "            linewidth=1.2, \n",
    "            linestyle=\"--\", \n",
    "            alpha=0.9, \n",
    "            label=f\"Predetto {i+1}\" if i == 0 else \"\",\n",
    "            color = 'orange'\n",
    "        )\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Time Step\", fontsize=12)\n",
    "    plt.ylabel(\"Valore\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ddfb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_diagnosis_gradient(y_pred, y_test, save_path: str,  tolerance:float =0.05, max_samples_heatmap=50, scatter_sample_ratio=0.5, tol_auto = True):\n",
    "    \"\"\"\n",
    "    Dashboard diagnostica con tolleranza AUTO-ADATTIVA alla scala dei dati.\n",
    "    \n",
    "    Args:\n",
    "        tolerance (float): \n",
    "            - Se None: La tolleranza viene calcolata automaticamente come il 5% del range dei dati (Max-Min).\n",
    "            - Se float: Valore assoluto (es. 0.5).\n",
    "        tol_auto (bool): Se True, usa la tolleranza automatica basata sul range dei dati, altrimenti usa il valore manuale fornito \n",
    "        col parametro tolerance.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test_flat = y_test.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # AUTOMAZIONE TOLLERANZA\n",
    "    # ---------------------------------------------------------\n",
    "    if tol_auto:\n",
    "        data_range = y_test_flat.max() - y_test_flat.min()\n",
    "        # Impostiamo la tolleranza al 5% del range totale (regolabile)\n",
    "        tolerance = data_range * tolerance \n",
    "        tol_label = f\"Auto (5% Range: ±{tolerance:.2f})\"\n",
    "    else:\n",
    "        tol_label = f\"Manuale (±{tolerance})\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(22, 8))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. HEATMAP (SX)\n",
    "    # -----------------------------\n",
    "    errors = np.abs(y_test - y_pred)\n",
    "    errors_subset = errors[:max_samples_heatmap]\n",
    "    \n",
    "    # Adattiamo anche la scala colori della heatmap alla tolleranza\n",
    "    # Tutto ciò che è oltre 3 volte la tolleranza è \"errore massimo\" visivo\n",
    "    sns.heatmap(errors_subset, cmap=\"plasma\", ax=axes[0], \n",
    "                vmax=tolerance * 3,\n",
    "                cbar_kws={'label': 'Errore Assoluto'})\n",
    "    \n",
    "    axes[0].set_title(f\"Heatmap Errori (Primi {max_samples_heatmap} campioni)\", fontsize=16)\n",
    "    axes[0].set_xlabel(\"Time Step\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Indice Campione\", fontsize=12)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. SCATTER CON SFONDO GRADIENTE (DX)\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Campionamento dati\n",
    "    if scatter_sample_ratio < 1.0:\n",
    "        mask = np.random.rand(len(y_test_flat)) < scatter_sample_ratio\n",
    "        sample_test = y_test_flat[mask]\n",
    "        sample_pred = y_pred_flat[mask]\n",
    "    else:\n",
    "        sample_test = y_test_flat\n",
    "        sample_pred = y_pred_flat\n",
    "\n",
    "    # Calcolo limiti grafico\n",
    "    min_val = min(y_test_flat.min(), y_pred_flat.min())\n",
    "    max_val = max(y_test_flat.max(), y_pred_flat.max())\n",
    "    padding = (max_val - min_val) * 0.05\n",
    "    plot_min = min_val - padding\n",
    "    plot_max = max_val + padding\n",
    "\n",
    "    # --- SFONDO GRADIENTE ---\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.linspace(plot_min, plot_max, 200),\n",
    "        np.linspace(plot_min, plot_max, 200)\n",
    "    )\n",
    "    grid_z = np.abs(grid_y - grid_x)\n",
    "\n",
    "    im = axes[1].imshow(\n",
    "        grid_z, \n",
    "        extent=(plot_min, plot_max, plot_min, plot_max), \n",
    "        origin='lower', \n",
    "        cmap='RdYlGn_r', \n",
    "        alpha=0.4, \n",
    "        vmax=tolerance * 4, # Il rosso satura a 4x della tolleranza\n",
    "        aspect='auto'\n",
    "    )\n",
    "\n",
    "    # --- PUNTI BLU ---\n",
    "    axes[1].scatter(\n",
    "        sample_test, \n",
    "        sample_pred, \n",
    "        alpha=0.6, \n",
    "        s=15, \n",
    "        color='royalblue', \n",
    "        edgecolors='white', \n",
    "        linewidth=0.3,\n",
    "        label='Campioni'\n",
    "    )\n",
    "\n",
    "    axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n",
    "\n",
    "    # Metriche\n",
    "    within_tol = np.mean(np.abs(y_test_flat - y_pred_flat) <= tolerance) * 100\n",
    "\n",
    "    axes[1].set_title(\n",
    "        f\"Bontà delle previsioni con {tol_label}\\nValori nel range di Tolleranza: {within_tol:.1f}%\", \n",
    "        fontsize=16\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Valore Reale\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Valore Predetto\", fontsize=12)\n",
    "    axes[1].set_xlim(plot_min, plot_max)\n",
    "    axes[1].set_ylim(plot_min, plot_max)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=axes[1], pad=0.02)\n",
    "    cbar.set_label('Gravità Errore (Distanza da diagonale)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{exp_dir}/{save_path}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00d6ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x125eff9c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/stepWARNING:tensorflow:6 out of the last 8 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x125eff9c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/vnvjtlb516n5mswtv7rf58b80000gn/T/ipykernel_2013/2011710758.py:96: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k--\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)\n",
    "y_test_np = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "plot_diagnosis_gradient(y_pred, y_test_np, save_path='pred_quality', max_samples_heatmap=10, scatter_sample_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "44ca8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo 55 plot in: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/TEST\n",
      "Plot salvati correttamente.\n"
     ]
    }
   ],
   "source": [
    "save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/TEST', prefix=\"pred_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5d0ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.0113\n",
      "Test RMSE: 0.0691\n",
      "Test MAPE: 0.19%\n",
      "Test R2: 0.9971\n",
      "Valore medio del test set: 5.9393\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/evaluation_log.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_and_log(y_true, y_pred, log_path=\"log.json\"):\n",
    "    # --- Metriche ---\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput=\"uniform_average\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"uniform_average\"))\n",
    "\n",
    "    mask = y_true != 0\n",
    "    mape = float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0)\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred, multioutput=\"uniform_average\")\n",
    "\n",
    "    # Valore medio del test set\n",
    "    v_mean = float(np.mean(y_true))\n",
    "\n",
    "    # --- Stampa ---\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAPE: {mape:.2f}%\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Valore medio del test set: {v_mean:.4f}\")\n",
    "\n",
    "    # --- Salvataggio log ---\n",
    "    log_data = {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2,\n",
    "        \"test_mean_value\": v_mean\n",
    "    }\n",
    "\n",
    "    with open(log_path, \"w\") as f:\n",
    "        json.dump(log_data, f, indent=4)\n",
    "\n",
    "    print(f\"\\nLog salvato in: {log_path}\")\n",
    "evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/evaluation_log.json\")\n",
    "# Impostazioni pandas per visualizzare tutti i dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031eff0",
   "metadata": {},
   "source": [
    "# globale e federato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd226e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed = tf.keras.models.load_model('/Users/lapotinacci/thesis/Federated_Sys/app/custom/models/fed_model_Arpat.keras')\n",
    "\n",
    "model  = [fed]\n",
    "model_name = [\"federated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31b7374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = f'{exp_dir}/model/{sensor_name}_fed_model.keras'\n",
    "\n",
    "# 2. Crea l'istanza della callback\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "27698951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "--- federated ---\n",
      "Test MAE: 0.7015\n",
      "Test RMSE: 0.9790\n",
      "Test MAPE: 13.20%\n",
      "Test R2: 0.2679\n",
      "Valore medio del test set: 5.9393\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/federated_evaluation_log.json\n",
      "Salvo 55 plot in: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/federated/TEST\n",
      "Plot salvati correttamente.\n",
      "\n",
      "\n",
      "Epoch 1/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.6644 - mae: 0.6280 - mse: 0.6644 - val_loss: 0.4725 - val_mae: 0.5202 - val_mse: 0.4725\n",
      "Epoch 2/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3583 - mae: 0.4558 - mse: 0.3583 - val_loss: 0.3180 - val_mae: 0.4269 - val_mse: 0.3180\n",
      "Epoch 3/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2488 - mae: 0.3787 - mse: 0.2488 - val_loss: 0.2432 - val_mae: 0.3741 - val_mse: 0.2432\n",
      "Epoch 4/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1794 - mae: 0.3207 - mse: 0.1794 - val_loss: 0.1546 - val_mae: 0.2972 - val_mse: 0.1546\n",
      "Epoch 5/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1304 - mae: 0.2767 - mse: 0.1304 - val_loss: 0.1284 - val_mae: 0.2743 - val_mse: 0.1284\n",
      "Epoch 6/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0994 - mae: 0.2428 - mse: 0.0994 - val_loss: 0.1009 - val_mae: 0.2460 - val_mse: 0.1009\n",
      "Epoch 7/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0740 - mae: 0.2071 - mse: 0.0740 - val_loss: 0.0812 - val_mae: 0.2159 - val_mse: 0.0812\n",
      "Epoch 8/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0554 - mae: 0.1770 - mse: 0.0554 - val_loss: 0.0687 - val_mae: 0.1971 - val_mse: 0.0687\n",
      "Epoch 9/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0440 - mae: 0.1589 - mse: 0.0440 - val_loss: 0.0562 - val_mae: 0.1751 - val_mse: 0.0562\n",
      "Epoch 10/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0332 - mae: 0.1377 - mse: 0.0332 - val_loss: 0.0471 - val_mae: 0.1597 - val_mse: 0.0471\n",
      "Epoch 11/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0267 - mae: 0.1249 - mse: 0.0267 - val_loss: 0.0415 - val_mae: 0.1511 - val_mse: 0.0415\n",
      "Epoch 12/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0211 - mae: 0.1112 - mse: 0.0211 - val_loss: 0.0333 - val_mae: 0.1330 - val_mse: 0.0333\n",
      "Epoch 13/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0173 - mae: 0.0998 - mse: 0.0173 - val_loss: 0.0261 - val_mae: 0.1146 - val_mse: 0.0261\n",
      "Epoch 14/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0139 - mae: 0.0891 - mse: 0.0139 - val_loss: 0.0234 - val_mae: 0.1075 - val_mse: 0.0234\n",
      "Epoch 15/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0119 - mae: 0.0801 - mse: 0.0119 - val_loss: 0.0208 - val_mae: 0.0978 - val_mse: 0.0208\n",
      "Epoch 16/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0099 - mae: 0.0731 - mse: 0.0099 - val_loss: 0.0196 - val_mae: 0.0945 - val_mse: 0.0196\n",
      "Epoch 17/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0088 - mae: 0.0671 - mse: 0.0088 - val_loss: 0.0159 - val_mae: 0.0877 - val_mse: 0.0159\n",
      "Epoch 18/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0076 - mae: 0.0629 - mse: 0.0076 - val_loss: 0.0148 - val_mae: 0.0803 - val_mse: 0.0148\n",
      "Epoch 19/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0069 - mae: 0.0573 - mse: 0.0069 - val_loss: 0.0136 - val_mae: 0.0752 - val_mse: 0.0136\n",
      "Epoch 20/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - mae: 0.0545 - mse: 0.0061 - val_loss: 0.0108 - val_mae: 0.0676 - val_mse: 0.0108\n",
      "Epoch 21/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - mae: 0.0503 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0640 - val_mse: 0.0101\n",
      "Epoch 22/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - mae: 0.0475 - mse: 0.0049 - val_loss: 0.0093 - val_mae: 0.0609 - val_mse: 0.0093\n",
      "Epoch 23/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0042 - mae: 0.0424 - mse: 0.0042 - val_loss: 0.0080 - val_mae: 0.0549 - val_mse: 0.0080\n",
      "Epoch 24/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0037 - mae: 0.0404 - mse: 0.0037 - val_loss: 0.0069 - val_mae: 0.0506 - val_mse: 0.0069\n",
      "Epoch 25/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 - mae: 0.0368 - mse: 0.0032 - val_loss: 0.0071 - val_mae: 0.0512 - val_mse: 0.0071\n",
      "Epoch 26/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0027 - mae: 0.0337 - mse: 0.0027 - val_loss: 0.0067 - val_mae: 0.0501 - val_mse: 0.0067\n",
      "Epoch 27/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0025 - mae: 0.0325 - mse: 0.0025 - val_loss: 0.0063 - val_mae: 0.0483 - val_mse: 0.0063\n",
      "Epoch 28/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0024 - mae: 0.0315 - mse: 0.0024 - val_loss: 0.0061 - val_mae: 0.0468 - val_mse: 0.0061\n",
      "Epoch 29/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0021 - mae: 0.0294 - mse: 0.0021 - val_loss: 0.0056 - val_mae: 0.0445 - val_mse: 0.0056\n",
      "Epoch 30/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0020 - mae: 0.0287 - mse: 0.0020 - val_loss: 0.0055 - val_mae: 0.0436 - val_mse: 0.0055\n",
      "Epoch 31/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0019 - mae: 0.0272 - mse: 0.0019 - val_loss: 0.0052 - val_mae: 0.0422 - val_mse: 0.0052\n",
      "Epoch 32/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - mae: 0.0262 - mse: 0.0018 - val_loss: 0.0053 - val_mae: 0.0434 - val_mse: 0.0053\n",
      "Epoch 33/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0253 - mse: 0.0017 - val_loss: 0.0049 - val_mae: 0.0403 - val_mse: 0.0049\n",
      "Epoch 34/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0016 - mae: 0.0238 - mse: 0.0016 - val_loss: 0.0045 - val_mae: 0.0384 - val_mse: 0.0045\n",
      "Epoch 35/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0014 - mae: 0.0232 - mse: 0.0014 - val_loss: 0.0041 - val_mae: 0.0369 - val_mse: 0.0041\n",
      "Epoch 36/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0013 - mae: 0.0221 - mse: 0.0013 - val_loss: 0.0040 - val_mae: 0.0366 - val_mse: 0.0040\n",
      "Epoch 37/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0013 - mae: 0.0218 - mse: 0.0013 - val_loss: 0.0040 - val_mae: 0.0356 - val_mse: 0.0040\n",
      "Epoch 38/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0012 - mae: 0.0210 - mse: 0.0012 - val_loss: 0.0039 - val_mae: 0.0355 - val_mse: 0.0039\n",
      "Epoch 39/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0204 - mse: 0.0011 - val_loss: 0.0036 - val_mae: 0.0348 - val_mse: 0.0036\n",
      "Epoch 40/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0011 - mae: 0.0205 - mse: 0.0011 - val_loss: 0.0034 - val_mae: 0.0335 - val_mse: 0.0034\n",
      "Epoch 41/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010 - mae: 0.0197 - mse: 0.0010 - val_loss: 0.0034 - val_mae: 0.0332 - val_mse: 0.0034\n",
      "Epoch 42/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.9478e-04 - mae: 0.0190 - mse: 9.9478e-04 - val_loss: 0.0033 - val_mae: 0.0326 - val_mse: 0.0033\n",
      "Epoch 43/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.7777e-04 - mae: 0.0191 - mse: 9.7777e-04 - val_loss: 0.0032 - val_mae: 0.0318 - val_mse: 0.0032\n",
      "Epoch 44/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5815e-04 - mae: 0.0186 - mse: 9.5815e-04 - val_loss: 0.0032 - val_mae: 0.0319 - val_mse: 0.0032\n",
      "Epoch 45/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.0400e-04 - mae: 0.0182 - mse: 9.0400e-04 - val_loss: 0.0030 - val_mae: 0.0310 - val_mse: 0.0030\n",
      "Epoch 46/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.7358e-04 - mae: 0.0178 - mse: 8.7358e-04 - val_loss: 0.0031 - val_mae: 0.0314 - val_mse: 0.0031\n",
      "Epoch 47/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.2398e-04 - mae: 0.0172 - mse: 8.2398e-04 - val_loss: 0.0029 - val_mae: 0.0304 - val_mse: 0.0029\n",
      "Epoch 48/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.3438e-04 - mae: 0.0175 - mse: 8.3438e-04 - val_loss: 0.0029 - val_mae: 0.0301 - val_mse: 0.0029\n",
      "Epoch 49/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.8371e-04 - mae: 0.0169 - mse: 7.8371e-04 - val_loss: 0.0028 - val_mae: 0.0300 - val_mse: 0.0028\n",
      "Epoch 50/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.5082e-04 - mae: 0.0163 - mse: 7.5082e-04 - val_loss: 0.0028 - val_mae: 0.0296 - val_mse: 0.0028\n",
      "Epoch 51/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.4323e-04 - mae: 0.0164 - mse: 7.4323e-04 - val_loss: 0.0027 - val_mae: 0.0287 - val_mse: 0.0027\n",
      "Epoch 52/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 7.3061e-04 - mae: 0.0163 - mse: 7.3061e-04 - val_loss: 0.0026 - val_mae: 0.0287 - val_mse: 0.0026\n",
      "Epoch 53/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.2895e-04 - mae: 0.0163 - mse: 7.2895e-04 - val_loss: 0.0025 - val_mae: 0.0282 - val_mse: 0.0025\n",
      "Epoch 54/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.9636e-04 - mae: 0.0161 - mse: 6.9636e-04 - val_loss: 0.0026 - val_mae: 0.0283 - val_mse: 0.0026\n",
      "Epoch 55/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.7753e-04 - mae: 0.0157 - mse: 6.7753e-04 - val_loss: 0.0025 - val_mae: 0.0281 - val_mse: 0.0025\n",
      "Epoch 56/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.5617e-04 - mae: 0.0160 - mse: 6.5617e-04 - val_loss: 0.0024 - val_mae: 0.0268 - val_mse: 0.0024\n",
      "Epoch 57/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.3380e-04 - mae: 0.0154 - mse: 6.3380e-04 - val_loss: 0.0023 - val_mae: 0.0269 - val_mse: 0.0023\n",
      "Epoch 58/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.1416e-04 - mae: 0.0151 - mse: 6.1416e-04 - val_loss: 0.0022 - val_mae: 0.0263 - val_mse: 0.0022\n",
      "Epoch 59/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.8046e-04 - mae: 0.0146 - mse: 5.8046e-04 - val_loss: 0.0022 - val_mae: 0.0258 - val_mse: 0.0022\n",
      "Epoch 60/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.6294e-04 - mae: 0.0143 - mse: 5.6294e-04 - val_loss: 0.0022 - val_mae: 0.0258 - val_mse: 0.0022\n",
      "Epoch 61/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5226e-04 - mae: 0.0141 - mse: 5.5225e-04 - val_loss: 0.0022 - val_mae: 0.0259 - val_mse: 0.0022\n",
      "Epoch 62/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.4979e-04 - mae: 0.0139 - mse: 5.4979e-04 - val_loss: 0.0022 - val_mae: 0.0256 - val_mse: 0.0022\n",
      "Epoch 63/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.2015e-04 - mae: 0.0137 - mse: 5.2015e-04 - val_loss: 0.0021 - val_mae: 0.0251 - val_mse: 0.0021\n",
      "Epoch 64/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.0823e-04 - mae: 0.0134 - mse: 5.0823e-04 - val_loss: 0.0021 - val_mae: 0.0246 - val_mse: 0.0021\n",
      "Epoch 65/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8774e-04 - mae: 0.0131 - mse: 4.8774e-04 - val_loss: 0.0021 - val_mae: 0.0246 - val_mse: 0.0021\n",
      "Epoch 66/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7854e-04 - mae: 0.0131 - mse: 4.7854e-04 - val_loss: 0.0020 - val_mae: 0.0243 - val_mse: 0.0020\n",
      "Epoch 67/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6701e-04 - mae: 0.0128 - mse: 4.6701e-04 - val_loss: 0.0020 - val_mae: 0.0241 - val_mse: 0.0020\n",
      "Epoch 68/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5487e-04 - mae: 0.0124 - mse: 4.5487e-04 - val_loss: 0.0020 - val_mae: 0.0237 - val_mse: 0.0020\n",
      "Epoch 69/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.4439e-04 - mae: 0.0123 - mse: 4.4439e-04 - val_loss: 0.0019 - val_mae: 0.0234 - val_mse: 0.0019\n",
      "Epoch 70/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.4160e-04 - mae: 0.0124 - mse: 4.4160e-04 - val_loss: 0.0019 - val_mae: 0.0233 - val_mse: 0.0019\n",
      "Epoch 71/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2853e-04 - mae: 0.0122 - mse: 4.2853e-04 - val_loss: 0.0019 - val_mae: 0.0230 - val_mse: 0.0019\n",
      "Epoch 72/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.2260e-04 - mae: 0.0120 - mse: 4.2260e-04 - val_loss: 0.0019 - val_mae: 0.0228 - val_mse: 0.0019\n",
      "Epoch 73/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1094e-04 - mae: 0.0118 - mse: 4.1094e-04 - val_loss: 0.0019 - val_mae: 0.0228 - val_mse: 0.0019\n",
      "Epoch 74/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0174e-04 - mae: 0.0117 - mse: 4.0174e-04 - val_loss: 0.0018 - val_mae: 0.0227 - val_mse: 0.0018\n",
      "Epoch 75/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9946e-04 - mae: 0.0117 - mse: 3.9946e-04 - val_loss: 0.0018 - val_mae: 0.0224 - val_mse: 0.0018\n",
      "Epoch 76/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8683e-04 - mae: 0.0116 - mse: 3.8683e-04 - val_loss: 0.0018 - val_mae: 0.0225 - val_mse: 0.0018\n",
      "Epoch 77/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8337e-04 - mae: 0.0115 - mse: 3.8337e-04 - val_loss: 0.0018 - val_mae: 0.0222 - val_mse: 0.0018\n",
      "Epoch 78/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.7020e-04 - mae: 0.0112 - mse: 3.7020e-04 - val_loss: 0.0018 - val_mae: 0.0221 - val_mse: 0.0018\n",
      "Epoch 79/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6519e-04 - mae: 0.0111 - mse: 3.6519e-04 - val_loss: 0.0018 - val_mae: 0.0220 - val_mse: 0.0018\n",
      "Epoch 80/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5883e-04 - mae: 0.0109 - mse: 3.5883e-04 - val_loss: 0.0018 - val_mae: 0.0220 - val_mse: 0.0018\n",
      "Epoch 81/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5612e-04 - mae: 0.0110 - mse: 3.5612e-04 - val_loss: 0.0017 - val_mae: 0.0217 - val_mse: 0.0017\n",
      "Epoch 82/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5127e-04 - mae: 0.0109 - mse: 3.5127e-04 - val_loss: 0.0017 - val_mae: 0.0211 - val_mse: 0.0017\n",
      "Epoch 83/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.4982e-04 - mae: 0.0108 - mse: 3.4982e-04 - val_loss: 0.0017 - val_mae: 0.0211 - val_mse: 0.0017\n",
      "Epoch 84/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3872e-04 - mae: 0.0107 - mse: 3.3872e-04 - val_loss: 0.0017 - val_mae: 0.0211 - val_mse: 0.0017\n",
      "Epoch 85/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2812e-04 - mae: 0.0105 - mse: 3.2812e-04 - val_loss: 0.0016 - val_mae: 0.0207 - val_mse: 0.0016\n",
      "Epoch 86/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.2335e-04 - mae: 0.0105 - mse: 3.2335e-04 - val_loss: 0.0016 - val_mae: 0.0207 - val_mse: 0.0016\n",
      "Epoch 87/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2260e-04 - mae: 0.0105 - mse: 3.2260e-04 - val_loss: 0.0016 - val_mae: 0.0204 - val_mse: 0.0016\n",
      "Epoch 88/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1963e-04 - mae: 0.0105 - mse: 3.1963e-04 - val_loss: 0.0016 - val_mae: 0.0203 - val_mse: 0.0016\n",
      "Epoch 89/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.1158e-04 - mae: 0.0103 - mse: 3.1158e-04 - val_loss: 0.0016 - val_mae: 0.0202 - val_mse: 0.0016\n",
      "Epoch 90/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0593e-04 - mae: 0.0103 - mse: 3.0593e-04 - val_loss: 0.0015 - val_mae: 0.0199 - val_mse: 0.0015\n",
      "Epoch 91/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0225e-04 - mae: 0.0101 - mse: 3.0225e-04 - val_loss: 0.0015 - val_mae: 0.0201 - val_mse: 0.0015\n",
      "Epoch 92/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9816e-04 - mae: 0.0102 - mse: 2.9816e-04 - val_loss: 0.0015 - val_mae: 0.0199 - val_mse: 0.0015\n",
      "Epoch 93/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9528e-04 - mae: 0.0101 - mse: 2.9528e-04 - val_loss: 0.0015 - val_mae: 0.0196 - val_mse: 0.0015\n",
      "Epoch 94/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9353e-04 - mae: 0.0100 - mse: 2.9353e-04 - val_loss: 0.0015 - val_mae: 0.0199 - val_mse: 0.0015\n",
      "Epoch 95/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9287e-04 - mae: 0.0098 - mse: 2.9287e-04 - val_loss: 0.0015 - val_mae: 0.0195 - val_mse: 0.0015\n",
      "Epoch 96/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9055e-04 - mae: 0.0098 - mse: 2.9055e-04 - val_loss: 0.0015 - val_mae: 0.0194 - val_mse: 0.0015\n",
      "Epoch 97/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7782e-04 - mae: 0.0097 - mse: 2.7782e-04 - val_loss: 0.0015 - val_mae: 0.0196 - val_mse: 0.0015\n",
      "Epoch 98/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.7002e-04 - mae: 0.0097 - mse: 2.7002e-04 - val_loss: 0.0015 - val_mae: 0.0193 - val_mse: 0.0015\n",
      "Epoch 99/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6907e-04 - mae: 0.0097 - mse: 2.6907e-04 - val_loss: 0.0015 - val_mae: 0.0192 - val_mse: 0.0015\n",
      "Epoch 100/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6287e-04 - mae: 0.0094 - mse: 2.6287e-04 - val_loss: 0.0014 - val_mae: 0.0189 - val_mse: 0.0014\n",
      "Epoch 101/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5994e-04 - mae: 0.0094 - mse: 2.5994e-04 - val_loss: 0.0014 - val_mae: 0.0186 - val_mse: 0.0014\n",
      "Epoch 102/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5406e-04 - mae: 0.0091 - mse: 2.5406e-04 - val_loss: 0.0014 - val_mae: 0.0189 - val_mse: 0.0014\n",
      "Epoch 103/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6003e-04 - mae: 0.0092 - mse: 2.6003e-04 - val_loss: 0.0014 - val_mae: 0.0185 - val_mse: 0.0014\n",
      "Epoch 104/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5057e-04 - mae: 0.0091 - mse: 2.5057e-04 - val_loss: 0.0014 - val_mae: 0.0186 - val_mse: 0.0014\n",
      "Epoch 105/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5159e-04 - mae: 0.0091 - mse: 2.5159e-04 - val_loss: 0.0014 - val_mae: 0.0187 - val_mse: 0.0014\n",
      "Epoch 106/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.5054e-04 - mae: 0.0091 - mse: 2.5054e-04 - val_loss: 0.0014 - val_mae: 0.0184 - val_mse: 0.0014\n",
      "Epoch 107/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5235e-04 - mae: 0.0091 - mse: 2.5235e-04 - val_loss: 0.0014 - val_mae: 0.0184 - val_mse: 0.0014\n",
      "Epoch 108/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4281e-04 - mae: 0.0090 - mse: 2.4281e-04 - val_loss: 0.0014 - val_mae: 0.0182 - val_mse: 0.0014\n",
      "Epoch 109/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3803e-04 - mae: 0.0089 - mse: 2.3803e-04 - val_loss: 0.0014 - val_mae: 0.0181 - val_mse: 0.0014\n",
      "Epoch 110/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3457e-04 - mae: 0.0088 - mse: 2.3457e-04 - val_loss: 0.0014 - val_mae: 0.0183 - val_mse: 0.0014\n",
      "Epoch 111/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3503e-04 - mae: 0.0088 - mse: 2.3503e-04 - val_loss: 0.0013 - val_mae: 0.0179 - val_mse: 0.0013\n",
      "Epoch 112/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3802e-04 - mae: 0.0088 - mse: 2.3802e-04 - val_loss: 0.0013 - val_mae: 0.0178 - val_mse: 0.0013\n",
      "Epoch 113/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3074e-04 - mae: 0.0087 - mse: 2.3074e-04 - val_loss: 0.0013 - val_mae: 0.0177 - val_mse: 0.0013\n",
      "Epoch 114/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2808e-04 - mae: 0.0087 - mse: 2.2808e-04 - val_loss: 0.0013 - val_mae: 0.0177 - val_mse: 0.0013\n",
      "Epoch 115/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.2261e-04 - mae: 0.0086 - mse: 2.2261e-04 - val_loss: 0.0013 - val_mae: 0.0178 - val_mse: 0.0013\n",
      "Epoch 116/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1922e-04 - mae: 0.0086 - mse: 2.1922e-04 - val_loss: 0.0013 - val_mae: 0.0174 - val_mse: 0.0013\n",
      "Epoch 117/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1837e-04 - mae: 0.0085 - mse: 2.1837e-04 - val_loss: 0.0014 - val_mae: 0.0178 - val_mse: 0.0014\n",
      "Epoch 118/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1680e-04 - mae: 0.0083 - mse: 2.1680e-04 - val_loss: 0.0013 - val_mae: 0.0175 - val_mse: 0.0013\n",
      "Epoch 119/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2211e-04 - mae: 0.0085 - mse: 2.2211e-04 - val_loss: 0.0013 - val_mae: 0.0174 - val_mse: 0.0013\n",
      "Epoch 120/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.2015e-04 - mae: 0.0085 - mse: 2.2015e-04 - val_loss: 0.0013 - val_mae: 0.0174 - val_mse: 0.0013\n",
      "Epoch 121/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1064e-04 - mae: 0.0085 - mse: 2.1064e-04 - val_loss: 0.0013 - val_mae: 0.0173 - val_mse: 0.0013\n",
      "Epoch 122/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1079e-04 - mae: 0.0083 - mse: 2.1079e-04 - val_loss: 0.0013 - val_mae: 0.0174 - val_mse: 0.0013\n",
      "Epoch 123/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1041e-04 - mae: 0.0085 - mse: 2.1041e-04 - val_loss: 0.0013 - val_mae: 0.0171 - val_mse: 0.0013\n",
      "Epoch 124/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0651e-04 - mae: 0.0083 - mse: 2.0651e-04 - val_loss: 0.0013 - val_mae: 0.0170 - val_mse: 0.0013\n",
      "Epoch 125/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0114e-04 - mae: 0.0081 - mse: 2.0114e-04 - val_loss: 0.0013 - val_mae: 0.0169 - val_mse: 0.0013\n",
      "Epoch 126/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9391e-04 - mae: 0.0079 - mse: 1.9391e-04 - val_loss: 0.0013 - val_mae: 0.0168 - val_mse: 0.0013\n",
      "Epoch 127/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9307e-04 - mae: 0.0078 - mse: 1.9307e-04 - val_loss: 0.0013 - val_mae: 0.0168 - val_mse: 0.0013\n",
      "Epoch 128/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9020e-04 - mae: 0.0078 - mse: 1.9020e-04 - val_loss: 0.0013 - val_mae: 0.0168 - val_mse: 0.0013\n",
      "Epoch 129/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8722e-04 - mae: 0.0077 - mse: 1.8722e-04 - val_loss: 0.0013 - val_mae: 0.0165 - val_mse: 0.0013\n",
      "Epoch 130/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8371e-04 - mae: 0.0076 - mse: 1.8371e-04 - val_loss: 0.0013 - val_mae: 0.0167 - val_mse: 0.0013\n",
      "Epoch 131/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8514e-04 - mae: 0.0076 - mse: 1.8514e-04 - val_loss: 0.0013 - val_mae: 0.0165 - val_mse: 0.0013\n",
      "Epoch 132/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8284e-04 - mae: 0.0075 - mse: 1.8284e-04 - val_loss: 0.0013 - val_mae: 0.0164 - val_mse: 0.0013\n",
      "Epoch 133/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.8442e-04 - mae: 0.0076 - mse: 1.8442e-04 - val_loss: 0.0013 - val_mae: 0.0162 - val_mse: 0.0013\n",
      "Epoch 134/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7675e-04 - mae: 0.0074 - mse: 1.7675e-04 - val_loss: 0.0013 - val_mae: 0.0163 - val_mse: 0.0013\n",
      "Epoch 135/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7755e-04 - mae: 0.0074 - mse: 1.7755e-04 - val_loss: 0.0013 - val_mae: 0.0164 - val_mse: 0.0013\n",
      "Epoch 136/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7342e-04 - mae: 0.0073 - mse: 1.7342e-04 - val_loss: 0.0012 - val_mae: 0.0161 - val_mse: 0.0012\n",
      "Epoch 137/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7337e-04 - mae: 0.0073 - mse: 1.7337e-04 - val_loss: 0.0013 - val_mae: 0.0162 - val_mse: 0.0013\n",
      "Epoch 138/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7411e-04 - mae: 0.0072 - mse: 1.7411e-04 - val_loss: 0.0013 - val_mae: 0.0161 - val_mse: 0.0013\n",
      "Epoch 139/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6827e-04 - mae: 0.0072 - mse: 1.6827e-04 - val_loss: 0.0012 - val_mae: 0.0160 - val_mse: 0.0012\n",
      "Epoch 140/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6776e-04 - mae: 0.0071 - mse: 1.6776e-04 - val_loss: 0.0013 - val_mae: 0.0160 - val_mse: 0.0013\n",
      "Epoch 141/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6750e-04 - mae: 0.0072 - mse: 1.6750e-04 - val_loss: 0.0012 - val_mae: 0.0158 - val_mse: 0.0012\n",
      "Epoch 142/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6288e-04 - mae: 0.0071 - mse: 1.6288e-04 - val_loss: 0.0012 - val_mae: 0.0159 - val_mse: 0.0012\n",
      "Epoch 143/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6293e-04 - mae: 0.0071 - mse: 1.6293e-04 - val_loss: 0.0012 - val_mae: 0.0158 - val_mse: 0.0012\n",
      "Epoch 144/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.6484e-04 - mae: 0.0072 - mse: 1.6484e-04 - val_loss: 0.0012 - val_mae: 0.0156 - val_mse: 0.0012\n",
      "Epoch 145/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6186e-04 - mae: 0.0071 - mse: 1.6186e-04 - val_loss: 0.0012 - val_mae: 0.0158 - val_mse: 0.0012\n",
      "Epoch 146/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6081e-04 - mae: 0.0071 - mse: 1.6081e-04 - val_loss: 0.0012 - val_mae: 0.0157 - val_mse: 0.0012\n",
      "Epoch 147/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5993e-04 - mae: 0.0071 - mse: 1.5993e-04 - val_loss: 0.0012 - val_mae: 0.0155 - val_mse: 0.0012\n",
      "Epoch 148/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5751e-04 - mae: 0.0070 - mse: 1.5751e-04 - val_loss: 0.0012 - val_mae: 0.0154 - val_mse: 0.0012\n",
      "Epoch 149/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5394e-04 - mae: 0.0069 - mse: 1.5394e-04 - val_loss: 0.0012 - val_mae: 0.0154 - val_mse: 0.0012\n",
      "Epoch 150/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5594e-04 - mae: 0.0068 - mse: 1.5594e-04 - val_loss: 0.0012 - val_mae: 0.0153 - val_mse: 0.0012\n",
      "Epoch 151/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5222e-04 - mae: 0.0068 - mse: 1.5222e-04 - val_loss: 0.0012 - val_mae: 0.0154 - val_mse: 0.0012\n",
      "Epoch 152/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5333e-04 - mae: 0.0068 - mse: 1.5333e-04 - val_loss: 0.0012 - val_mae: 0.0154 - val_mse: 0.0012\n",
      "Epoch 153/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.5061e-04 - mae: 0.0069 - mse: 1.5061e-04 - val_loss: 0.0012 - val_mae: 0.0154 - val_mse: 0.0012\n",
      "Epoch 154/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4953e-04 - mae: 0.0068 - mse: 1.4953e-04 - val_loss: 0.0012 - val_mae: 0.0153 - val_mse: 0.0012\n",
      "Epoch 155/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4925e-04 - mae: 0.0067 - mse: 1.4925e-04 - val_loss: 0.0012 - val_mae: 0.0152 - val_mse: 0.0012\n",
      "Epoch 156/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4449e-04 - mae: 0.0066 - mse: 1.4449e-04 - val_loss: 0.0012 - val_mae: 0.0152 - val_mse: 0.0012\n",
      "Epoch 157/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4557e-04 - mae: 0.0067 - mse: 1.4557e-04 - val_loss: 0.0012 - val_mae: 0.0152 - val_mse: 0.0012\n",
      "Epoch 158/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4269e-04 - mae: 0.0065 - mse: 1.4269e-04 - val_loss: 0.0012 - val_mae: 0.0151 - val_mse: 0.0012\n",
      "Epoch 159/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3957e-04 - mae: 0.0064 - mse: 1.3957e-04 - val_loss: 0.0012 - val_mae: 0.0150 - val_mse: 0.0012\n",
      "Epoch 160/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3868e-04 - mae: 0.0064 - mse: 1.3868e-04 - val_loss: 0.0012 - val_mae: 0.0149 - val_mse: 0.0012\n",
      "Epoch 161/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3588e-04 - mae: 0.0063 - mse: 1.3588e-04 - val_loss: 0.0012 - val_mae: 0.0149 - val_mse: 0.0012\n",
      "Epoch 162/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3573e-04 - mae: 0.0063 - mse: 1.3573e-04 - val_loss: 0.0012 - val_mae: 0.0149 - val_mse: 0.0012\n",
      "Epoch 163/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3594e-04 - mae: 0.0063 - mse: 1.3594e-04 - val_loss: 0.0012 - val_mae: 0.0148 - val_mse: 0.0012\n",
      "Epoch 164/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3389e-04 - mae: 0.0063 - mse: 1.3389e-04 - val_loss: 0.0012 - val_mae: 0.0148 - val_mse: 0.0012\n",
      "Epoch 165/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3429e-04 - mae: 0.0064 - mse: 1.3429e-04 - val_loss: 0.0012 - val_mae: 0.0147 - val_mse: 0.0012\n",
      "Epoch 166/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3282e-04 - mae: 0.0063 - mse: 1.3282e-04 - val_loss: 0.0012 - val_mae: 0.0148 - val_mse: 0.0012\n",
      "Epoch 167/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3665e-04 - mae: 0.0064 - mse: 1.3665e-04 - val_loss: 0.0012 - val_mae: 0.0148 - val_mse: 0.0012\n",
      "Epoch 168/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3155e-04 - mae: 0.0064 - mse: 1.3155e-04 - val_loss: 0.0012 - val_mae: 0.0146 - val_mse: 0.0012\n",
      "Epoch 169/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2821e-04 - mae: 0.0063 - mse: 1.2821e-04 - val_loss: 0.0012 - val_mae: 0.0144 - val_mse: 0.0012\n",
      "Epoch 170/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3071e-04 - mae: 0.0063 - mse: 1.3071e-04 - val_loss: 0.0012 - val_mae: 0.0145 - val_mse: 0.0012\n",
      "Epoch 171/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2474e-04 - mae: 0.0062 - mse: 1.2474e-04 - val_loss: 0.0012 - val_mae: 0.0144 - val_mse: 0.0012\n",
      "Epoch 172/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2706e-04 - mae: 0.0062 - mse: 1.2706e-04 - val_loss: 0.0011 - val_mae: 0.0143 - val_mse: 0.0011\n",
      "Epoch 173/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2464e-04 - mae: 0.0061 - mse: 1.2464e-04 - val_loss: 0.0012 - val_mae: 0.0144 - val_mse: 0.0012\n",
      "Epoch 174/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2189e-04 - mae: 0.0061 - mse: 1.2189e-04 - val_loss: 0.0011 - val_mae: 0.0143 - val_mse: 0.0011\n",
      "Epoch 175/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2280e-04 - mae: 0.0061 - mse: 1.2280e-04 - val_loss: 0.0011 - val_mae: 0.0144 - val_mse: 0.0011\n",
      "Epoch 176/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2379e-04 - mae: 0.0061 - mse: 1.2379e-04 - val_loss: 0.0011 - val_mae: 0.0142 - val_mse: 0.0011\n",
      "Epoch 177/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1931e-04 - mae: 0.0061 - mse: 1.1931e-04 - val_loss: 0.0012 - val_mae: 0.0144 - val_mse: 0.0012\n",
      "Epoch 178/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1804e-04 - mae: 0.0060 - mse: 1.1804e-04 - val_loss: 0.0011 - val_mae: 0.0141 - val_mse: 0.0011\n",
      "Epoch 179/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1686e-04 - mae: 0.0059 - mse: 1.1686e-04 - val_loss: 0.0011 - val_mae: 0.0141 - val_mse: 0.0011\n",
      "Epoch 180/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1563e-04 - mae: 0.0059 - mse: 1.1563e-04 - val_loss: 0.0012 - val_mae: 0.0142 - val_mse: 0.0012\n",
      "Epoch 181/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1577e-04 - mae: 0.0059 - mse: 1.1577e-04 - val_loss: 0.0012 - val_mae: 0.0141 - val_mse: 0.0012\n",
      "Epoch 182/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1191e-04 - mae: 0.0058 - mse: 1.1191e-04 - val_loss: 0.0011 - val_mae: 0.0140 - val_mse: 0.0011\n",
      "Epoch 183/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1240e-04 - mae: 0.0058 - mse: 1.1240e-04 - val_loss: 0.0011 - val_mae: 0.0139 - val_mse: 0.0011\n",
      "Epoch 184/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1053e-04 - mae: 0.0057 - mse: 1.1053e-04 - val_loss: 0.0011 - val_mae: 0.0138 - val_mse: 0.0011\n",
      "Epoch 185/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1046e-04 - mae: 0.0057 - mse: 1.1046e-04 - val_loss: 0.0011 - val_mae: 0.0139 - val_mse: 0.0011\n",
      "Epoch 186/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0838e-04 - mae: 0.0057 - mse: 1.0838e-04 - val_loss: 0.0011 - val_mae: 0.0139 - val_mse: 0.0011\n",
      "Epoch 187/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0743e-04 - mae: 0.0057 - mse: 1.0743e-04 - val_loss: 0.0011 - val_mae: 0.0138 - val_mse: 0.0011\n",
      "Epoch 188/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0852e-04 - mae: 0.0056 - mse: 1.0852e-04 - val_loss: 0.0011 - val_mae: 0.0139 - val_mse: 0.0011\n",
      "Epoch 189/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0664e-04 - mae: 0.0056 - mse: 1.0664e-04 - val_loss: 0.0011 - val_mae: 0.0137 - val_mse: 0.0011\n",
      "Epoch 190/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0756e-04 - mae: 0.0056 - mse: 1.0756e-04 - val_loss: 0.0011 - val_mae: 0.0136 - val_mse: 0.0011\n",
      "Epoch 191/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0348e-04 - mae: 0.0055 - mse: 1.0348e-04 - val_loss: 0.0011 - val_mae: 0.0136 - val_mse: 0.0011\n",
      "Epoch 192/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0567e-04 - mae: 0.0056 - mse: 1.0567e-04 - val_loss: 0.0011 - val_mae: 0.0137 - val_mse: 0.0011\n",
      "Epoch 193/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0283e-04 - mae: 0.0056 - mse: 1.0283e-04 - val_loss: 0.0011 - val_mae: 0.0136 - val_mse: 0.0011\n",
      "Epoch 194/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0199e-04 - mae: 0.0056 - mse: 1.0199e-04 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 195/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0213e-04 - mae: 0.0055 - mse: 1.0213e-04 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 196/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0071e-04 - mae: 0.0056 - mse: 1.0071e-04 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 197/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9486e-05 - mae: 0.0055 - mse: 9.9486e-05 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 198/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9016e-05 - mae: 0.0055 - mse: 9.9016e-05 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 199/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8817e-05 - mae: 0.0054 - mse: 9.8817e-05 - val_loss: 0.0011 - val_mae: 0.0134 - val_mse: 0.0011\n",
      "Epoch 200/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6775e-05 - mae: 0.0053 - mse: 9.6775e-05 - val_loss: 0.0011 - val_mae: 0.0134 - val_mse: 0.0011\n",
      "Epoch 201/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5794e-05 - mae: 0.0053 - mse: 9.5794e-05 - val_loss: 0.0011 - val_mae: 0.0133 - val_mse: 0.0011\n",
      "Epoch 202/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4978e-05 - mae: 0.0053 - mse: 9.4978e-05 - val_loss: 0.0011 - val_mae: 0.0133 - val_mse: 0.0011\n",
      "Epoch 203/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.2777e-05 - mae: 0.0052 - mse: 9.2777e-05 - val_loss: 0.0011 - val_mae: 0.0132 - val_mse: 0.0011\n",
      "Epoch 204/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3332e-05 - mae: 0.0052 - mse: 9.3332e-05 - val_loss: 0.0011 - val_mae: 0.0131 - val_mse: 0.0011\n",
      "Epoch 205/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3924e-05 - mae: 0.0052 - mse: 9.3924e-05 - val_loss: 0.0011 - val_mae: 0.0132 - val_mse: 0.0011\n",
      "Epoch 206/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3478e-05 - mae: 0.0053 - mse: 9.3478e-05 - val_loss: 0.0011 - val_mae: 0.0132 - val_mse: 0.0011\n",
      "Epoch 207/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2595e-05 - mae: 0.0053 - mse: 9.2595e-05 - val_loss: 0.0011 - val_mae: 0.0132 - val_mse: 0.0011\n",
      "Epoch 208/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2882e-05 - mae: 0.0054 - mse: 9.2882e-05 - val_loss: 0.0011 - val_mae: 0.0133 - val_mse: 0.0011\n",
      "Epoch 209/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.4140e-05 - mae: 0.0054 - mse: 9.4140e-05 - val_loss: 0.0011 - val_mae: 0.0133 - val_mse: 0.0011\n",
      "Epoch 210/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6163e-05 - mae: 0.0055 - mse: 9.6163e-05 - val_loss: 0.0011 - val_mae: 0.0134 - val_mse: 0.0011\n",
      "Epoch 211/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3503e-05 - mae: 0.0055 - mse: 9.3503e-05 - val_loss: 0.0011 - val_mae: 0.0134 - val_mse: 0.0011\n",
      "Epoch 212/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.2707e-05 - mae: 0.0054 - mse: 9.2707e-05 - val_loss: 0.0011 - val_mae: 0.0130 - val_mse: 0.0011\n",
      "Epoch 213/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9983e-05 - mae: 0.0053 - mse: 8.9983e-05 - val_loss: 0.0011 - val_mae: 0.0129 - val_mse: 0.0011\n",
      "Epoch 214/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8313e-05 - mae: 0.0051 - mse: 8.8313e-05 - val_loss: 0.0011 - val_mae: 0.0130 - val_mse: 0.0011\n",
      "Epoch 215/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.0427e-05 - mae: 0.0054 - mse: 9.0427e-05 - val_loss: 0.0011 - val_mae: 0.0130 - val_mse: 0.0011\n",
      "Epoch 216/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9524e-05 - mae: 0.0053 - mse: 8.9524e-05 - val_loss: 0.0011 - val_mae: 0.0130 - val_mse: 0.0011\n",
      "Epoch 217/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8561e-05 - mae: 0.0051 - mse: 8.8561e-05 - val_loss: 0.0011 - val_mae: 0.0131 - val_mse: 0.0011\n",
      "Epoch 218/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0676e-05 - mae: 0.0053 - mse: 9.0676e-05 - val_loss: 0.0011 - val_mae: 0.0129 - val_mse: 0.0011\n",
      "Epoch 219/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8145e-05 - mae: 0.0052 - mse: 8.8145e-05 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 220/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.5881e-05 - mae: 0.0052 - mse: 8.5881e-05 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 221/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3352e-05 - mae: 0.0052 - mse: 8.3352e-05 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 222/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3795e-05 - mae: 0.0051 - mse: 8.3795e-05 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 223/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.2493e-05 - mae: 0.0050 - mse: 8.2493e-05 - val_loss: 0.0011 - val_mae: 0.0126 - val_mse: 0.0011\n",
      "Epoch 224/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9950e-05 - mae: 0.0049 - mse: 7.9950e-05 - val_loss: 0.0011 - val_mae: 0.0126 - val_mse: 0.0011\n",
      "Epoch 225/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0570e-05 - mae: 0.0050 - mse: 8.0570e-05 - val_loss: 0.0011 - val_mae: 0.0126 - val_mse: 0.0011\n",
      "Epoch 226/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8337e-05 - mae: 0.0048 - mse: 7.8337e-05 - val_loss: 0.0011 - val_mae: 0.0127 - val_mse: 0.0011\n",
      "Epoch 227/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7729e-05 - mae: 0.0048 - mse: 7.7729e-05 - val_loss: 0.0011 - val_mae: 0.0127 - val_mse: 0.0011\n",
      "Epoch 228/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1148e-05 - mae: 0.0050 - mse: 8.1148e-05 - val_loss: 0.0011 - val_mae: 0.0125 - val_mse: 0.0011\n",
      "Epoch 229/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.8712e-05 - mae: 0.0050 - mse: 7.8712e-05 - val_loss: 0.0011 - val_mae: 0.0127 - val_mse: 0.0011\n",
      "Epoch 230/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1160e-05 - mae: 0.0050 - mse: 8.1160e-05 - val_loss: 0.0011 - val_mae: 0.0125 - val_mse: 0.0011\n",
      "Epoch 231/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6449e-05 - mae: 0.0049 - mse: 7.6449e-05 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 232/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9449e-05 - mae: 0.0050 - mse: 7.9449e-05 - val_loss: 0.0011 - val_mae: 0.0125 - val_mse: 0.0011\n",
      "Epoch 233/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7734e-05 - mae: 0.0050 - mse: 7.7734e-05 - val_loss: 0.0011 - val_mae: 0.0126 - val_mse: 0.0011\n",
      "Epoch 234/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7541e-05 - mae: 0.0050 - mse: 7.7541e-05 - val_loss: 0.0011 - val_mae: 0.0124 - val_mse: 0.0011\n",
      "Epoch 235/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4557e-05 - mae: 0.0048 - mse: 7.4557e-05 - val_loss: 0.0011 - val_mae: 0.0124 - val_mse: 0.0011\n",
      "Epoch 236/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4816e-05 - mae: 0.0048 - mse: 7.4816e-05 - val_loss: 0.0011 - val_mae: 0.0125 - val_mse: 0.0011\n",
      "Epoch 237/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4838e-05 - mae: 0.0049 - mse: 7.4838e-05 - val_loss: 0.0011 - val_mae: 0.0124 - val_mse: 0.0011\n",
      "Epoch 238/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.1860e-05 - mae: 0.0048 - mse: 7.1860e-05 - val_loss: 0.0011 - val_mae: 0.0123 - val_mse: 0.0011\n",
      "Epoch 239/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3794e-05 - mae: 0.0049 - mse: 7.3794e-05 - val_loss: 0.0011 - val_mae: 0.0123 - val_mse: 0.0011\n",
      "Epoch 240/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.2543e-05 - mae: 0.0049 - mse: 7.2543e-05 - val_loss: 0.0011 - val_mae: 0.0123 - val_mse: 0.0011\n",
      "Epoch 241/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1093e-05 - mae: 0.0047 - mse: 7.1093e-05 - val_loss: 0.0011 - val_mae: 0.0125 - val_mse: 0.0011\n",
      "Epoch 242/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1199e-05 - mae: 0.0047 - mse: 7.1199e-05 - val_loss: 0.0011 - val_mae: 0.0124 - val_mse: 0.0011\n",
      "Epoch 243/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0247e-05 - mae: 0.0047 - mse: 7.0247e-05 - val_loss: 0.0011 - val_mae: 0.0123 - val_mse: 0.0011\n",
      "Epoch 244/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0190e-05 - mae: 0.0047 - mse: 7.0190e-05 - val_loss: 0.0011 - val_mae: 0.0122 - val_mse: 0.0011\n",
      "Epoch 245/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8172e-05 - mae: 0.0046 - mse: 6.8172e-05 - val_loss: 0.0011 - val_mae: 0.0121 - val_mse: 0.0011\n",
      "Epoch 246/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.8995e-05 - mae: 0.0047 - mse: 6.8995e-05 - val_loss: 0.0011 - val_mae: 0.0122 - val_mse: 0.0011\n",
      "Epoch 247/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7668e-05 - mae: 0.0046 - mse: 6.7668e-05 - val_loss: 0.0011 - val_mae: 0.0122 - val_mse: 0.0011\n",
      "Epoch 248/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7260e-05 - mae: 0.0046 - mse: 6.7260e-05 - val_loss: 0.0011 - val_mae: 0.0121 - val_mse: 0.0011\n",
      "Epoch 249/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5883e-05 - mae: 0.0046 - mse: 6.5883e-05 - val_loss: 0.0011 - val_mae: 0.0120 - val_mse: 0.0011\n",
      "Epoch 250/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6240e-05 - mae: 0.0045 - mse: 6.6240e-05 - val_loss: 0.0011 - val_mae: 0.0121 - val_mse: 0.0011\n",
      "Epoch 251/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4129e-05 - mae: 0.0044 - mse: 6.4129e-05 - val_loss: 0.0011 - val_mae: 0.0119 - val_mse: 0.0011\n",
      "Epoch 252/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3172e-05 - mae: 0.0043 - mse: 6.3172e-05 - val_loss: 0.0011 - val_mae: 0.0119 - val_mse: 0.0011\n",
      "Epoch 253/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.3294e-05 - mae: 0.0044 - mse: 6.3294e-05 - val_loss: 0.0011 - val_mae: 0.0119 - val_mse: 0.0011\n",
      "Epoch 254/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.1377e-05 - mae: 0.0043 - mse: 6.1377e-05 - val_loss: 0.0011 - val_mae: 0.0119 - val_mse: 0.0011\n",
      "Epoch 255/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3242e-05 - mae: 0.0044 - mse: 6.3242e-05 - val_loss: 0.0011 - val_mae: 0.0119 - val_mse: 0.0011\n",
      "Epoch 256/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.2491e-05 - mae: 0.0043 - mse: 6.2491e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 257/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.1459e-05 - mae: 0.0043 - mse: 6.1459e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 258/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.2427e-05 - mae: 0.0043 - mse: 6.2427e-05 - val_loss: 0.0010 - val_mae: 0.0117 - val_mse: 0.0010\n",
      "Epoch 259/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1358e-05 - mae: 0.0044 - mse: 6.1358e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 260/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0320e-05 - mae: 0.0043 - mse: 6.0320e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 261/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8210e-05 - mae: 0.0042 - mse: 5.8210e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 262/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8083e-05 - mae: 0.0041 - mse: 5.8083e-05 - val_loss: 0.0011 - val_mae: 0.0118 - val_mse: 0.0011\n",
      "Epoch 263/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.7521e-05 - mae: 0.0041 - mse: 5.7521e-05 - val_loss: 0.0010 - val_mae: 0.0117 - val_mse: 0.0010\n",
      "Epoch 264/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8059e-05 - mae: 0.0042 - mse: 5.8059e-05 - val_loss: 0.0011 - val_mae: 0.0115 - val_mse: 0.0011\n",
      "Epoch 265/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7023e-05 - mae: 0.0041 - mse: 5.7023e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 266/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7137e-05 - mae: 0.0041 - mse: 5.7137e-05 - val_loss: 0.0010 - val_mae: 0.0116 - val_mse: 0.0010\n",
      "Epoch 267/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8129e-05 - mae: 0.0042 - mse: 5.8129e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 268/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7480e-05 - mae: 0.0044 - mse: 5.7480e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 269/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9328e-05 - mae: 0.0045 - mse: 5.9328e-05 - val_loss: 0.0011 - val_mae: 0.0119 - val_mse: 0.0011\n",
      "Epoch 270/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.8914e-05 - mae: 0.0044 - mse: 5.8914e-05 - val_loss: 0.0011 - val_mae: 0.0118 - val_mse: 0.0011\n",
      "Epoch 271/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.7482e-05 - mae: 0.0044 - mse: 5.7482e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 272/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6030e-05 - mae: 0.0043 - mse: 5.6030e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 273/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4431e-05 - mae: 0.0041 - mse: 5.4431e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 274/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4682e-05 - mae: 0.0041 - mse: 5.4682e-05 - val_loss: 0.0010 - val_mae: 0.0114 - val_mse: 0.0010\n",
      "Epoch 275/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1526e-05 - mae: 0.0040 - mse: 5.1526e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 276/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4632e-05 - mae: 0.0042 - mse: 5.4632e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 277/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6146e-05 - mae: 0.0044 - mse: 5.6146e-05 - val_loss: 0.0011 - val_mae: 0.0115 - val_mse: 0.0011\n",
      "Epoch 278/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7065e-05 - mae: 0.0045 - mse: 5.7065e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 279/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6339e-05 - mae: 0.0043 - mse: 5.6339e-05 - val_loss: 0.0011 - val_mae: 0.0115 - val_mse: 0.0011\n",
      "Epoch 280/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5827e-05 - mae: 0.0043 - mse: 5.5827e-05 - val_loss: 0.0010 - val_mae: 0.0116 - val_mse: 0.0010\n",
      "Epoch 281/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5188e-05 - mae: 0.0044 - mse: 5.5188e-05 - val_loss: 0.0011 - val_mae: 0.0118 - val_mse: 0.0011\n",
      "Epoch 282/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6716e-05 - mae: 0.0045 - mse: 5.6716e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 283/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4732e-05 - mae: 0.0043 - mse: 5.4732e-05 - val_loss: 0.0011 - val_mae: 0.0117 - val_mse: 0.0011\n",
      "Epoch 284/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3325e-05 - mae: 0.0043 - mse: 5.3325e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 285/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2307e-05 - mae: 0.0042 - mse: 5.2307e-05 - val_loss: 0.0011 - val_mae: 0.0115 - val_mse: 0.0011\n",
      "Epoch 286/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2694e-05 - mae: 0.0042 - mse: 5.2694e-05 - val_loss: 0.0010 - val_mae: 0.0114 - val_mse: 0.0010\n",
      "Epoch 287/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2281e-05 - mae: 0.0043 - mse: 5.2281e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 288/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1673e-05 - mae: 0.0043 - mse: 5.1673e-05 - val_loss: 0.0010 - val_mae: 0.0114 - val_mse: 0.0010\n",
      "Epoch 289/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1096e-05 - mae: 0.0042 - mse: 5.1096e-05 - val_loss: 0.0011 - val_mae: 0.0114 - val_mse: 0.0011\n",
      "Epoch 290/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0065e-05 - mae: 0.0042 - mse: 5.0065e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 291/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.0678e-05 - mae: 0.0042 - mse: 5.0678e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 292/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.1732e-05 - mae: 0.0043 - mse: 5.1732e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 293/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0469e-05 - mae: 0.0041 - mse: 5.0469e-05 - val_loss: 0.0011 - val_mae: 0.0114 - val_mse: 0.0011\n",
      "Epoch 294/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9002e-05 - mae: 0.0041 - mse: 4.9002e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 295/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8370e-05 - mae: 0.0040 - mse: 4.8370e-05 - val_loss: 0.0010 - val_mae: 0.0114 - val_mse: 0.0010\n",
      "Epoch 296/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0033e-05 - mae: 0.0041 - mse: 5.0033e-05 - val_loss: 0.0010 - val_mae: 0.0112 - val_mse: 0.0010\n",
      "Epoch 297/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.3141e-05 - mae: 0.0043 - mse: 5.3141e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 298/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4429e-05 - mae: 0.0044 - mse: 5.4429e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 299/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3943e-05 - mae: 0.0045 - mse: 5.3943e-05 - val_loss: 0.0010 - val_mae: 0.0114 - val_mse: 0.0010\n",
      "Epoch 300/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.2128e-05 - mae: 0.0044 - mse: 5.2128e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 301/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8040e-05 - mae: 0.0042 - mse: 4.8040e-05 - val_loss: 0.0011 - val_mae: 0.0116 - val_mse: 0.0011\n",
      "Epoch 302/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.8808e-05 - mae: 0.0043 - mse: 4.8808e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 303/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8393e-05 - mae: 0.0042 - mse: 4.8393e-05 - val_loss: 0.0011 - val_mae: 0.0114 - val_mse: 0.0011\n",
      "Epoch 304/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9230e-05 - mae: 0.0043 - mse: 4.9230e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 305/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8378e-05 - mae: 0.0042 - mse: 4.8378e-05 - val_loss: 0.0010 - val_mae: 0.0111 - val_mse: 0.0010\n",
      "Epoch 306/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7042e-05 - mae: 0.0040 - mse: 4.7042e-05 - val_loss: 0.0010 - val_mae: 0.0111 - val_mse: 0.0010\n",
      "Epoch 307/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8734e-05 - mae: 0.0040 - mse: 4.8734e-05 - val_loss: 0.0011 - val_mae: 0.0111 - val_mse: 0.0011\n",
      "Epoch 308/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5465e-05 - mae: 0.0039 - mse: 4.5465e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 309/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.4115e-05 - mae: 0.0039 - mse: 4.4115e-05 - val_loss: 0.0010 - val_mae: 0.0108 - val_mse: 0.0010\n",
      "Epoch 310/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3667e-05 - mae: 0.0038 - mse: 4.3667e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 311/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2649e-05 - mae: 0.0038 - mse: 4.2649e-05 - val_loss: 0.0010 - val_mae: 0.0110 - val_mse: 0.0010\n",
      "Epoch 312/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2737e-05 - mae: 0.0037 - mse: 4.2737e-05 - val_loss: 0.0010 - val_mae: 0.0110 - val_mse: 0.0010\n",
      "Epoch 313/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.1980e-05 - mae: 0.0037 - mse: 4.1980e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 314/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2348e-05 - mae: 0.0037 - mse: 4.2348e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 315/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9767e-05 - mae: 0.0036 - mse: 3.9767e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 316/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9189e-05 - mae: 0.0035 - mse: 3.9189e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 317/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9581e-05 - mae: 0.0035 - mse: 3.9581e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 318/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7413e-05 - mae: 0.0034 - mse: 3.7413e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 319/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.7280e-05 - mae: 0.0034 - mse: 3.7280e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 320/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.6907e-05 - mae: 0.0034 - mse: 3.6907e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 321/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.7299e-05 - mae: 0.0035 - mse: 3.7299e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 322/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7030e-05 - mae: 0.0035 - mse: 3.7030e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 323/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7094e-05 - mae: 0.0035 - mse: 3.7094e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 324/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7654e-05 - mae: 0.0035 - mse: 3.7654e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 325/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6838e-05 - mae: 0.0035 - mse: 3.6838e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 326/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5356e-05 - mae: 0.0034 - mse: 3.5356e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 327/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5349e-05 - mae: 0.0033 - mse: 3.5349e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 328/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6045e-05 - mae: 0.0034 - mse: 3.6045e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 329/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6587e-05 - mae: 0.0035 - mse: 3.6587e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 330/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5232e-05 - mae: 0.0035 - mse: 3.5232e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 331/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.5813e-05 - mae: 0.0035 - mse: 3.5813e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 332/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.4786e-05 - mae: 0.0034 - mse: 3.4786e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 333/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4353e-05 - mae: 0.0034 - mse: 3.4353e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 334/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.5585e-05 - mae: 0.0035 - mse: 3.5585e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 335/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.4063e-05 - mae: 0.0034 - mse: 3.4063e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 336/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.3895e-05 - mae: 0.0034 - mse: 3.3895e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 337/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.2906e-05 - mae: 0.0033 - mse: 3.2906e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 338/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3104e-05 - mae: 0.0033 - mse: 3.3104e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 339/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1979e-05 - mae: 0.0032 - mse: 3.1979e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 340/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.1579e-05 - mae: 0.0032 - mse: 3.1579e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 341/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0775e-05 - mae: 0.0031 - mse: 3.0775e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 342/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1274e-05 - mae: 0.0032 - mse: 3.1274e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 343/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0207e-05 - mae: 0.0031 - mse: 3.0207e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 344/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0578e-05 - mae: 0.0031 - mse: 3.0578e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 345/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0641e-05 - mae: 0.0032 - mse: 3.0641e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 346/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0098e-05 - mae: 0.0032 - mse: 3.0098e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 347/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0480e-05 - mae: 0.0032 - mse: 3.0480e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 348/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.1044e-05 - mae: 0.0032 - mse: 3.1044e-05 - val_loss: 0.0010 - val_mae: 0.0100 - val_mse: 0.0010\n",
      "Epoch 349/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1644e-05 - mae: 0.0033 - mse: 3.1644e-05 - val_loss: 0.0010 - val_mae: 0.0100 - val_mse: 0.0010\n",
      "Epoch 350/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0519e-05 - mae: 0.0032 - mse: 3.0519e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 351/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0342e-05 - mae: 0.0032 - mse: 3.0342e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 352/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2045e-05 - mae: 0.0033 - mse: 3.2045e-05 - val_loss: 0.0010 - val_mae: 0.0100 - val_mse: 0.0010\n",
      "Epoch 353/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0682e-05 - mae: 0.0033 - mse: 3.0682e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 354/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0646e-05 - mae: 0.0033 - mse: 3.0646e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 355/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1066e-05 - mae: 0.0033 - mse: 3.1066e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 356/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2452e-05 - mae: 0.0034 - mse: 3.2452e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 357/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2002e-05 - mae: 0.0034 - mse: 3.2002e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 358/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0257e-05 - mae: 0.0032 - mse: 3.0257e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 359/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1231e-05 - mae: 0.0033 - mse: 3.1231e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 360/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.0512e-05 - mae: 0.0033 - mse: 3.0512e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 361/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9646e-05 - mae: 0.0033 - mse: 2.9646e-05 - val_loss: 0.0010 - val_mae: 0.0100 - val_mse: 0.0010\n",
      "Epoch 362/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.9672e-05 - mae: 0.0033 - mse: 2.9672e-05 - val_loss: 0.0010 - val_mae: 0.0100 - val_mse: 0.0010\n",
      "Epoch 363/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7785e-05 - mae: 0.0031 - mse: 2.7785e-05 - val_loss: 0.0010 - val_mae: 0.0099 - val_mse: 0.0010\n",
      "Epoch 364/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7877e-05 - mae: 0.0031 - mse: 2.7877e-05 - val_loss: 0.0010 - val_mae: 0.0099 - val_mse: 0.0010\n",
      "Epoch 365/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8372e-05 - mae: 0.0031 - mse: 2.8372e-05 - val_loss: 0.0010 - val_mae: 0.0097 - val_mse: 0.0010\n",
      "Epoch 366/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7289e-05 - mae: 0.0031 - mse: 2.7289e-05 - val_loss: 0.0010 - val_mae: 0.0099 - val_mse: 0.0010\n",
      "Epoch 367/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6600e-05 - mae: 0.0030 - mse: 2.6600e-05 - val_loss: 9.9820e-04 - val_mae: 0.0098 - val_mse: 9.9820e-04\n",
      "Epoch 368/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6634e-05 - mae: 0.0031 - mse: 2.6634e-05 - val_loss: 0.0010 - val_mae: 0.0097 - val_mse: 0.0010\n",
      "Epoch 369/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7572e-05 - mae: 0.0031 - mse: 2.7572e-05 - val_loss: 0.0010 - val_mae: 0.0099 - val_mse: 0.0010\n",
      "Epoch 370/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7567e-05 - mae: 0.0031 - mse: 2.7567e-05 - val_loss: 0.0010 - val_mae: 0.0098 - val_mse: 0.0010\n",
      "Epoch 371/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7978e-05 - mae: 0.0032 - mse: 2.7978e-05 - val_loss: 0.0010 - val_mae: 0.0098 - val_mse: 0.0010\n",
      "Epoch 372/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8747e-05 - mae: 0.0033 - mse: 2.8747e-05 - val_loss: 0.0010 - val_mae: 0.0098 - val_mse: 0.0010\n",
      "Epoch 373/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9150e-05 - mae: 0.0033 - mse: 2.9150e-05 - val_loss: 9.9978e-04 - val_mae: 0.0096 - val_mse: 9.9978e-04\n",
      "Epoch 374/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6238e-05 - mae: 0.0030 - mse: 2.6238e-05 - val_loss: 0.0010 - val_mae: 0.0095 - val_mse: 0.0010\n",
      "Epoch 375/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5100e-05 - mae: 0.0029 - mse: 2.5100e-05 - val_loss: 9.9389e-04 - val_mae: 0.0096 - val_mse: 9.9389e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4515e-05 - mae: 0.0029 - mse: 2.4515e-05 - val_loss: 9.9755e-04 - val_mae: 0.0097 - val_mse: 9.9755e-04\n",
      "Epoch 377/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5010e-05 - mae: 0.0029 - mse: 2.5010e-05 - val_loss: 9.9502e-04 - val_mae: 0.0096 - val_mse: 9.9502e-04\n",
      "Epoch 378/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5090e-05 - mae: 0.0030 - mse: 2.5090e-05 - val_loss: 9.9235e-04 - val_mae: 0.0096 - val_mse: 9.9235e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7005e-05 - mae: 0.0032 - mse: 2.7005e-05 - val_loss: 9.9775e-04 - val_mae: 0.0096 - val_mse: 9.9775e-04\n",
      "Epoch 380/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6689e-05 - mae: 0.0031 - mse: 2.6689e-05 - val_loss: 9.8851e-04 - val_mae: 0.0096 - val_mse: 9.8851e-04\n",
      "Epoch 381/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6202e-05 - mae: 0.0031 - mse: 2.6202e-05 - val_loss: 0.0010 - val_mae: 0.0099 - val_mse: 0.0010\n",
      "Epoch 382/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.9614e-05 - mae: 0.0033 - mse: 2.9614e-05 - val_loss: 9.9075e-04 - val_mae: 0.0097 - val_mse: 9.9075e-04\n",
      "Epoch 383/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7871e-05 - mae: 0.0032 - mse: 2.7871e-05 - val_loss: 9.9640e-04 - val_mae: 0.0098 - val_mse: 9.9640e-04\n",
      "Epoch 384/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7906e-05 - mae: 0.0033 - mse: 2.7906e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 385/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7999e-05 - mae: 0.0033 - mse: 2.7999e-05 - val_loss: 9.9493e-04 - val_mae: 0.0101 - val_mse: 9.9493e-04\n",
      "Epoch 386/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9128e-05 - mae: 0.0034 - mse: 2.9128e-05 - val_loss: 0.0010 - val_mae: 0.0101 - val_mse: 0.0010\n",
      "Epoch 387/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0257e-05 - mae: 0.0035 - mse: 3.0257e-05 - val_loss: 0.0010 - val_mae: 0.0097 - val_mse: 0.0010\n",
      "Epoch 388/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8891e-05 - mae: 0.0034 - mse: 2.8891e-05 - val_loss: 9.9492e-04 - val_mae: 0.0102 - val_mse: 9.9492e-04\n",
      "Epoch 389/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9712e-05 - mae: 0.0035 - mse: 2.9712e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 390/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2118e-05 - mae: 0.0038 - mse: 3.2118e-05 - val_loss: 0.0010 - val_mae: 0.0100 - val_mse: 0.0010\n",
      "Epoch 391/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4403e-05 - mae: 0.0040 - mse: 3.4403e-05 - val_loss: 9.9706e-04 - val_mae: 0.0101 - val_mse: 9.9706e-04\n",
      "Epoch 392/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8470e-05 - mae: 0.0041 - mse: 3.8470e-05 - val_loss: 0.0010 - val_mae: 0.0116 - val_mse: 0.0010\n",
      "Epoch 393/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6315e-05 - mae: 0.0046 - mse: 4.6315e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 394/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8365e-05 - mae: 0.0049 - mse: 4.8365e-05 - val_loss: 9.9786e-04 - val_mae: 0.0104 - val_mse: 9.9786e-04\n",
      "Epoch 395/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3035e-05 - mae: 0.0045 - mse: 4.3035e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 396/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8336e-05 - mae: 0.0041 - mse: 3.8336e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 397/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6265e-05 - mae: 0.0040 - mse: 3.6265e-05 - val_loss: 9.9309e-04 - val_mae: 0.0104 - val_mse: 9.9309e-04\n",
      "Epoch 398/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.2136e-05 - mae: 0.0043 - mse: 4.2136e-05 - val_loss: 0.0010 - val_mae: 0.0104 - val_mse: 0.0010\n",
      "Epoch 399/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0849e-05 - mae: 0.0041 - mse: 4.0849e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 400/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0082e-05 - mae: 0.0041 - mse: 4.0082e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 401/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7218e-05 - mae: 0.0040 - mse: 3.7218e-05 - val_loss: 9.8964e-04 - val_mae: 0.0100 - val_mse: 9.8964e-04\n",
      "Epoch 402/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5894e-05 - mae: 0.0040 - mse: 3.5894e-05 - val_loss: 9.7995e-04 - val_mae: 0.0099 - val_mse: 9.7995e-04\n",
      "Epoch 403/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.5994e-05 - mae: 0.0039 - mse: 3.5994e-05 - val_loss: 9.9987e-04 - val_mae: 0.0108 - val_mse: 9.9987e-04\n",
      "Epoch 404/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.2147e-05 - mae: 0.0046 - mse: 5.2147e-05 - val_loss: 0.0011 - val_mae: 0.0122 - val_mse: 0.0011\n",
      "Epoch 405/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.0787e-05 - mae: 0.0056 - mse: 7.0787e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 406/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.7285e-05 - mae: 0.0066 - mse: 9.7285e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 407/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0926e-04 - mae: 0.0073 - mse: 1.0926e-04 - val_loss: 0.0010 - val_mae: 0.0129 - val_mse: 0.0010\n",
      "Epoch 408/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.7695e-05 - mae: 0.0070 - mse: 9.7695e-05 - val_loss: 0.0011 - val_mae: 0.0144 - val_mse: 0.0011\n",
      "Epoch 409/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.9979e-05 - mae: 0.0066 - mse: 8.9979e-05 - val_loss: 9.6591e-04 - val_mae: 0.0112 - val_mse: 9.6591e-04\n",
      "Epoch 410/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.1560e-05 - mae: 0.0060 - mse: 7.1560e-05 - val_loss: 0.0010 - val_mae: 0.0117 - val_mse: 0.0010\n",
      "Epoch 411/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2136e-05 - mae: 0.0064 - mse: 8.2136e-05 - val_loss: 0.0011 - val_mae: 0.0137 - val_mse: 0.0011\n",
      "Epoch 412/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3244e-04 - mae: 0.0077 - mse: 1.3244e-04 - val_loss: 0.0011 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 413/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0061e-04 - mae: 0.0099 - mse: 2.0061e-04 - val_loss: 0.0012 - val_mae: 0.0167 - val_mse: 0.0012\n",
      "Epoch 414/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1012e-04 - mae: 0.0099 - mse: 2.1012e-04 - val_loss: 0.0011 - val_mae: 0.0133 - val_mse: 0.0011\n",
      "Epoch 415/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1224e-04 - mae: 0.0098 - mse: 2.1225e-04 - val_loss: 0.0011 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 416/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8787e-04 - mae: 0.0114 - mse: 2.8787e-04 - val_loss: 0.0014 - val_mae: 0.0196 - val_mse: 0.0014\n",
      "Epoch 417/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6337e-04 - mae: 0.0110 - mse: 2.6337e-04 - val_loss: 0.0011 - val_mae: 0.0144 - val_mse: 0.0011\n",
      "Epoch 418/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0630e-04 - mae: 0.0098 - mse: 2.0630e-04 - val_loss: 0.0010 - val_mae: 0.0137 - val_mse: 0.0010\n",
      "Epoch 419/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9592e-04 - mae: 0.0100 - mse: 1.9592e-04 - val_loss: 0.0012 - val_mae: 0.0179 - val_mse: 0.0012\n",
      "Epoch 420/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8339e-04 - mae: 0.0096 - mse: 1.8339e-04 - val_loss: 0.0012 - val_mae: 0.0164 - val_mse: 0.0012\n",
      "Epoch 421/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6622e-04 - mae: 0.0093 - mse: 1.6622e-04 - val_loss: 0.0012 - val_mae: 0.0161 - val_mse: 0.0012\n",
      "Epoch 422/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4814e-04 - mae: 0.0087 - mse: 1.4814e-04 - val_loss: 0.0010 - val_mae: 0.0129 - val_mse: 0.0010\n",
      "Epoch 423/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2642e-04 - mae: 0.0085 - mse: 1.2642e-04 - val_loss: 0.0010 - val_mae: 0.0128 - val_mse: 0.0010\n",
      "Epoch 424/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.5578e-05 - mae: 0.0072 - mse: 9.5578e-05 - val_loss: 0.0010 - val_mae: 0.0127 - val_mse: 0.0010\n",
      "Epoch 425/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1409e-05 - mae: 0.0068 - mse: 8.1409e-05 - val_loss: 0.0010 - val_mae: 0.0125 - val_mse: 0.0010\n",
      "Epoch 426/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6354e-05 - mae: 0.0060 - mse: 6.6354e-05 - val_loss: 9.7248e-04 - val_mae: 0.0119 - val_mse: 9.7248e-04\n",
      "Epoch 427/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5053e-05 - mae: 0.0056 - mse: 5.5053e-05 - val_loss: 0.0010 - val_mae: 0.0111 - val_mse: 0.0010\n",
      "Epoch 428/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0868e-05 - mae: 0.0052 - mse: 5.0868e-05 - val_loss: 0.0010 - val_mae: 0.0111 - val_mse: 0.0010\n",
      "Epoch 429/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4617e-05 - mae: 0.0048 - mse: 4.4617e-05 - val_loss: 9.8699e-04 - val_mae: 0.0107 - val_mse: 9.8699e-04\n",
      "Epoch 430/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2046e-05 - mae: 0.0046 - mse: 4.2046e-05 - val_loss: 9.5079e-04 - val_mae: 0.0101 - val_mse: 9.5079e-04\n",
      "Epoch 431/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6628e-05 - mae: 0.0043 - mse: 3.6628e-05 - val_loss: 9.8045e-04 - val_mae: 0.0103 - val_mse: 9.8045e-04\n",
      "Epoch 432/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5183e-05 - mae: 0.0042 - mse: 3.5183e-05 - val_loss: 9.9600e-04 - val_mae: 0.0101 - val_mse: 9.9600e-04\n",
      "Epoch 433/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2462e-05 - mae: 0.0040 - mse: 3.2462e-05 - val_loss: 9.6947e-04 - val_mae: 0.0101 - val_mse: 9.6947e-04\n",
      "Epoch 434/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1189e-05 - mae: 0.0038 - mse: 3.1189e-05 - val_loss: 9.8526e-04 - val_mae: 0.0106 - val_mse: 9.8526e-04\n",
      "Epoch 435/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6113e-05 - mae: 0.0040 - mse: 3.6113e-05 - val_loss: 9.5858e-04 - val_mae: 0.0099 - val_mse: 9.5858e-04\n",
      "Epoch 436/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2630e-05 - mae: 0.0039 - mse: 3.2630e-05 - val_loss: 9.9745e-04 - val_mae: 0.0102 - val_mse: 9.9745e-04\n",
      "Epoch 437/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2924e-05 - mae: 0.0038 - mse: 3.2924e-05 - val_loss: 9.7966e-04 - val_mae: 0.0098 - val_mse: 9.7966e-04\n",
      "Epoch 438/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7968e-05 - mae: 0.0034 - mse: 2.7968e-05 - val_loss: 9.6764e-04 - val_mae: 0.0096 - val_mse: 9.6764e-04\n",
      "Epoch 439/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9348e-05 - mae: 0.0035 - mse: 2.9348e-05 - val_loss: 9.6644e-04 - val_mae: 0.0097 - val_mse: 9.6644e-04\n",
      "Epoch 440/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0805e-05 - mae: 0.0036 - mse: 3.0805e-05 - val_loss: 9.8712e-04 - val_mae: 0.0101 - val_mse: 9.8712e-04\n",
      "Epoch 441/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0722e-05 - mae: 0.0036 - mse: 3.0722e-05 - val_loss: 9.8942e-04 - val_mae: 0.0100 - val_mse: 9.8942e-04\n",
      "Epoch 442/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.2385e-05 - mae: 0.0037 - mse: 3.2385e-05 - val_loss: 9.8023e-04 - val_mae: 0.0096 - val_mse: 9.8023e-04\n",
      "Epoch 443/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5958e-05 - mae: 0.0034 - mse: 2.5958e-05 - val_loss: 9.7120e-04 - val_mae: 0.0097 - val_mse: 9.7120e-04\n",
      "Epoch 444/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6249e-05 - mae: 0.0035 - mse: 2.6249e-05 - val_loss: 9.9040e-04 - val_mae: 0.0102 - val_mse: 9.9040e-04\n",
      "Epoch 445/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2613e-05 - mae: 0.0039 - mse: 3.2613e-05 - val_loss: 9.8884e-04 - val_mae: 0.0102 - val_mse: 9.8884e-04\n",
      "Epoch 446/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7005e-05 - mae: 0.0041 - mse: 3.7005e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 447/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1646e-05 - mae: 0.0043 - mse: 4.1646e-05 - val_loss: 0.0010 - val_mae: 0.0109 - val_mse: 0.0010\n",
      "Epoch 448/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6143e-05 - mae: 0.0048 - mse: 5.6143e-05 - val_loss: 0.0010 - val_mae: 0.0122 - val_mse: 0.0010\n",
      "Epoch 449/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0041e-05 - mae: 0.0051 - mse: 6.0041e-05 - val_loss: 0.0010 - val_mae: 0.0124 - val_mse: 0.0010\n",
      "Epoch 450/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9472e-05 - mae: 0.0056 - mse: 7.9472e-05 - val_loss: 0.0011 - val_mae: 0.0129 - val_mse: 0.0011\n",
      "Epoch 451/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.6308e-05 - mae: 0.0056 - mse: 7.6308e-05 - val_loss: 0.0010 - val_mae: 0.0125 - val_mse: 0.0010\n",
      "Epoch 452/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8045e-05 - mae: 0.0058 - mse: 7.8045e-05 - val_loss: 0.0011 - val_mae: 0.0124 - val_mse: 0.0011\n",
      "Epoch 453/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3157e-05 - mae: 0.0054 - mse: 7.3157e-05 - val_loss: 9.7699e-04 - val_mae: 0.0114 - val_mse: 9.7699e-04\n",
      "Epoch 454/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2412e-05 - mae: 0.0054 - mse: 6.2412e-05 - val_loss: 0.0010 - val_mae: 0.0117 - val_mse: 0.0010\n",
      "Epoch 455/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3834e-05 - mae: 0.0055 - mse: 6.3834e-05 - val_loss: 9.9178e-04 - val_mae: 0.0116 - val_mse: 9.9178e-04\n",
      "Epoch 456/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.6406e-05 - mae: 0.0055 - mse: 6.6406e-05 - val_loss: 9.8835e-04 - val_mae: 0.0113 - val_mse: 9.8835e-04\n",
      "Epoch 457/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 6.2697e-05 - mae: 0.0053 - mse: 6.2697e-05 - val_loss: 0.0010 - val_mae: 0.0112 - val_mse: 0.0010\n",
      "Epoch 458/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9396e-05 - mae: 0.0049 - mse: 4.9396e-05 - val_loss: 9.8811e-04 - val_mae: 0.0104 - val_mse: 9.8811e-04\n",
      "Epoch 459/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1807e-05 - mae: 0.0044 - mse: 4.1807e-05 - val_loss: 9.7968e-04 - val_mae: 0.0101 - val_mse: 9.7968e-04\n",
      "Epoch 460/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.7607e-05 - mae: 0.0042 - mse: 3.7607e-05 - val_loss: 9.4921e-04 - val_mae: 0.0099 - val_mse: 9.4921e-04\n",
      "Epoch 461/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9144e-05 - mae: 0.0043 - mse: 3.9144e-05 - val_loss: 9.7864e-04 - val_mae: 0.0104 - val_mse: 9.7864e-04\n",
      "Epoch 462/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1422e-05 - mae: 0.0043 - mse: 4.1422e-05 - val_loss: 9.7392e-04 - val_mae: 0.0102 - val_mse: 9.7392e-04\n",
      "Epoch 463/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4185e-05 - mae: 0.0044 - mse: 4.4185e-05 - val_loss: 9.9150e-04 - val_mae: 0.0104 - val_mse: 9.9150e-04\n",
      "Epoch 464/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3308e-05 - mae: 0.0044 - mse: 4.3308e-05 - val_loss: 9.7144e-04 - val_mae: 0.0103 - val_mse: 9.7144e-04\n",
      "Epoch 465/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4734e-05 - mae: 0.0041 - mse: 3.4734e-05 - val_loss: 9.8856e-04 - val_mae: 0.0107 - val_mse: 9.8856e-04\n",
      "Epoch 466/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2642e-05 - mae: 0.0048 - mse: 5.2642e-05 - val_loss: 0.0010 - val_mae: 0.0112 - val_mse: 0.0010\n",
      "Epoch 467/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7663e-05 - mae: 0.0047 - mse: 4.7663e-05 - val_loss: 9.7253e-04 - val_mae: 0.0101 - val_mse: 9.7253e-04\n",
      "Epoch 468/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8456e-05 - mae: 0.0049 - mse: 5.8456e-05 - val_loss: 0.0010 - val_mae: 0.0110 - val_mse: 0.0010\n",
      "Epoch 469/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8325e-05 - mae: 0.0055 - mse: 7.8325e-05 - val_loss: 0.0010 - val_mae: 0.0122 - val_mse: 0.0010\n",
      "Epoch 470/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0065e-05 - mae: 0.0050 - mse: 6.0065e-05 - val_loss: 9.8422e-04 - val_mae: 0.0108 - val_mse: 9.8422e-04\n",
      "Epoch 471/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6436e-05 - mae: 0.0051 - mse: 5.6436e-05 - val_loss: 9.7975e-04 - val_mae: 0.0106 - val_mse: 9.7975e-04\n",
      "Epoch 472/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7342e-05 - mae: 0.0048 - mse: 4.7342e-05 - val_loss: 9.9827e-04 - val_mae: 0.0104 - val_mse: 9.9827e-04\n",
      "Epoch 473/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9921e-05 - mae: 0.0050 - mse: 4.9921e-05 - val_loss: 9.7996e-04 - val_mae: 0.0109 - val_mse: 9.7996e-04\n",
      "Epoch 474/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7125e-05 - mae: 0.0052 - mse: 5.7125e-05 - val_loss: 9.8906e-04 - val_mae: 0.0112 - val_mse: 9.8906e-04\n",
      "Epoch 475/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1914e-05 - mae: 0.0052 - mse: 5.1914e-05 - val_loss: 9.7525e-04 - val_mae: 0.0107 - val_mse: 9.7525e-04\n",
      "Epoch 476/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9621e-05 - mae: 0.0051 - mse: 4.9621e-05 - val_loss: 9.7569e-04 - val_mae: 0.0103 - val_mse: 9.7569e-04\n",
      "Epoch 477/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7637e-05 - mae: 0.0050 - mse: 4.7637e-05 - val_loss: 9.8103e-04 - val_mae: 0.0106 - val_mse: 9.8103e-04\n",
      "Epoch 478/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9615e-05 - mae: 0.0053 - mse: 4.9615e-05 - val_loss: 9.6183e-04 - val_mae: 0.0097 - val_mse: 9.6183e-04\n",
      "Epoch 479/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8071e-05 - mae: 0.0046 - mse: 3.8071e-05 - val_loss: 9.6332e-04 - val_mae: 0.0099 - val_mse: 9.6332e-04\n",
      "Epoch 480/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3868e-05 - mae: 0.0048 - mse: 4.3868e-05 - val_loss: 9.6908e-04 - val_mae: 0.0099 - val_mse: 9.6908e-04\n",
      "Epoch 481/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.8477e-05 - mae: 0.0045 - mse: 3.8477e-05 - val_loss: 9.5507e-04 - val_mae: 0.0105 - val_mse: 9.5507e-04\n",
      "Epoch 482/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6938e-05 - mae: 0.0045 - mse: 3.6938e-05 - val_loss: 9.7674e-04 - val_mae: 0.0103 - val_mse: 9.7674e-04\n",
      "Epoch 483/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5116e-05 - mae: 0.0045 - mse: 3.5116e-05 - val_loss: 9.4096e-04 - val_mae: 0.0101 - val_mse: 9.4096e-04\n",
      "Epoch 484/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1147e-05 - mae: 0.0042 - mse: 3.1147e-05 - val_loss: 9.6900e-04 - val_mae: 0.0099 - val_mse: 9.6900e-04\n",
      "Epoch 485/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8643e-05 - mae: 0.0039 - mse: 2.8643e-05 - val_loss: 9.6589e-04 - val_mae: 0.0099 - val_mse: 9.6589e-04\n",
      "Epoch 486/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8923e-05 - mae: 0.0038 - mse: 2.8923e-05 - val_loss: 9.4277e-04 - val_mae: 0.0093 - val_mse: 9.4277e-04\n",
      "Epoch 487/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.3964e-05 - mae: 0.0035 - mse: 2.3964e-05 - val_loss: 9.2933e-04 - val_mae: 0.0092 - val_mse: 9.2933e-04\n",
      "Epoch 488/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1958e-05 - mae: 0.0033 - mse: 2.1958e-05 - val_loss: 9.6056e-04 - val_mae: 0.0093 - val_mse: 9.6056e-04\n",
      "Epoch 489/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8957e-05 - mae: 0.0031 - mse: 1.8957e-05 - val_loss: 9.4968e-04 - val_mae: 0.0091 - val_mse: 9.4968e-04\n",
      "Epoch 490/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7912e-05 - mae: 0.0030 - mse: 1.7912e-05 - val_loss: 9.4677e-04 - val_mae: 0.0090 - val_mse: 9.4677e-04\n",
      "Epoch 491/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7353e-05 - mae: 0.0029 - mse: 1.7353e-05 - val_loss: 9.3431e-04 - val_mae: 0.0089 - val_mse: 9.3431e-04\n",
      "Epoch 492/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6492e-05 - mae: 0.0028 - mse: 1.6492e-05 - val_loss: 9.5461e-04 - val_mae: 0.0090 - val_mse: 9.5461e-04\n",
      "Epoch 493/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6610e-05 - mae: 0.0028 - mse: 1.6610e-05 - val_loss: 9.4166e-04 - val_mae: 0.0089 - val_mse: 9.4166e-04\n",
      "Epoch 494/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6747e-05 - mae: 0.0027 - mse: 1.6747e-05 - val_loss: 9.6394e-04 - val_mae: 0.0090 - val_mse: 9.6394e-04\n",
      "Epoch 495/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6598e-05 - mae: 0.0028 - mse: 1.6598e-05 - val_loss: 9.3218e-04 - val_mae: 0.0087 - val_mse: 9.3218e-04\n",
      "Epoch 496/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6779e-05 - mae: 0.0028 - mse: 1.6779e-05 - val_loss: 9.5694e-04 - val_mae: 0.0090 - val_mse: 9.5694e-04\n",
      "Epoch 497/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8224e-05 - mae: 0.0030 - mse: 1.8224e-05 - val_loss: 9.5381e-04 - val_mae: 0.0092 - val_mse: 9.5381e-04\n",
      "Epoch 498/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1661e-05 - mae: 0.0032 - mse: 2.1661e-05 - val_loss: 9.6656e-04 - val_mae: 0.0101 - val_mse: 9.6656e-04\n",
      "Epoch 499/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9302e-05 - mae: 0.0039 - mse: 2.9302e-05 - val_loss: 9.3789e-04 - val_mae: 0.0103 - val_mse: 9.3789e-04\n",
      "Epoch 500/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1839e-05 - mae: 0.0039 - mse: 3.1839e-05 - val_loss: 9.8432e-04 - val_mae: 0.0105 - val_mse: 9.8432e-04\n",
      "Epoch 501/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1416e-05 - mae: 0.0040 - mse: 3.1416e-05 - val_loss: 9.5527e-04 - val_mae: 0.0103 - val_mse: 9.5527e-04\n",
      "Epoch 502/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9232e-05 - mae: 0.0039 - mse: 2.9232e-05 - val_loss: 9.7750e-04 - val_mae: 0.0107 - val_mse: 9.7750e-04\n",
      "Epoch 503/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2166e-05 - mae: 0.0040 - mse: 3.2166e-05 - val_loss: 9.5556e-04 - val_mae: 0.0103 - val_mse: 9.5556e-04\n",
      "Epoch 504/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0854e-05 - mae: 0.0040 - mse: 3.0854e-05 - val_loss: 9.5747e-04 - val_mae: 0.0097 - val_mse: 9.5747e-04\n",
      "Epoch 505/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7103e-05 - mae: 0.0037 - mse: 2.7103e-05 - val_loss: 9.3499e-04 - val_mae: 0.0098 - val_mse: 9.3499e-04\n",
      "Epoch 506/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4461e-05 - mae: 0.0036 - mse: 2.4461e-05 - val_loss: 9.5182e-04 - val_mae: 0.0097 - val_mse: 9.5182e-04\n",
      "Epoch 507/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4519e-05 - mae: 0.0036 - mse: 2.4519e-05 - val_loss: 9.3933e-04 - val_mae: 0.0094 - val_mse: 9.3933e-04\n",
      "Epoch 508/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3039e-05 - mae: 0.0034 - mse: 2.3039e-05 - val_loss: 9.6479e-04 - val_mae: 0.0097 - val_mse: 9.6479e-04\n",
      "Epoch 509/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4503e-05 - mae: 0.0035 - mse: 2.4503e-05 - val_loss: 9.3892e-04 - val_mae: 0.0094 - val_mse: 9.3892e-04\n",
      "Epoch 510/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2590e-05 - mae: 0.0033 - mse: 2.2590e-05 - val_loss: 9.7440e-04 - val_mae: 0.0097 - val_mse: 9.7440e-04\n",
      "Epoch 511/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5961e-05 - mae: 0.0036 - mse: 2.5961e-05 - val_loss: 9.2781e-04 - val_mae: 0.0093 - val_mse: 9.2781e-04\n",
      "Epoch 512/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3823e-05 - mae: 0.0036 - mse: 2.3823e-05 - val_loss: 9.6529e-04 - val_mae: 0.0100 - val_mse: 9.6529e-04\n",
      "Epoch 513/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4140e-05 - mae: 0.0036 - mse: 2.4140e-05 - val_loss: 9.3934e-04 - val_mae: 0.0093 - val_mse: 9.3934e-04\n",
      "Epoch 514/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0100e-05 - mae: 0.0032 - mse: 2.0100e-05 - val_loss: 9.5085e-04 - val_mae: 0.0087 - val_mse: 9.5085e-04\n",
      "Epoch 515/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9481e-05 - mae: 0.0031 - mse: 1.9481e-05 - val_loss: 9.3914e-04 - val_mae: 0.0095 - val_mse: 9.3914e-04\n",
      "Epoch 516/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2777e-05 - mae: 0.0033 - mse: 2.2777e-05 - val_loss: 9.4706e-04 - val_mae: 0.0093 - val_mse: 9.4706e-04\n",
      "Epoch 517/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0826e-05 - mae: 0.0032 - mse: 2.0826e-05 - val_loss: 9.3025e-04 - val_mae: 0.0093 - val_mse: 9.3025e-04\n",
      "Epoch 518/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.9233e-05 - mae: 0.0031 - mse: 1.9233e-05 - val_loss: 9.4305e-04 - val_mae: 0.0091 - val_mse: 9.4305e-04\n",
      "Epoch 519/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3115e-05 - mae: 0.0033 - mse: 2.3115e-05 - val_loss: 9.3471e-04 - val_mae: 0.0089 - val_mse: 9.3471e-04\n",
      "Epoch 520/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9733e-05 - mae: 0.0031 - mse: 1.9733e-05 - val_loss: 9.4354e-04 - val_mae: 0.0088 - val_mse: 9.4354e-04\n",
      "Epoch 521/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.0845e-05 - mae: 0.0031 - mse: 2.0845e-05 - val_loss: 9.0647e-04 - val_mae: 0.0086 - val_mse: 9.0647e-04\n",
      "Epoch 522/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1667e-05 - mae: 0.0032 - mse: 2.1667e-05 - val_loss: 9.4108e-04 - val_mae: 0.0083 - val_mse: 9.4108e-04\n",
      "Epoch 523/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0292e-05 - mae: 0.0030 - mse: 2.0292e-05 - val_loss: 9.3834e-04 - val_mae: 0.0086 - val_mse: 9.3834e-04\n",
      "Epoch 524/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9768e-05 - mae: 0.0031 - mse: 1.9768e-05 - val_loss: 9.4790e-04 - val_mae: 0.0091 - val_mse: 9.4790e-04\n",
      "Epoch 525/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0422e-05 - mae: 0.0031 - mse: 2.0422e-05 - val_loss: 9.3652e-04 - val_mae: 0.0085 - val_mse: 9.3652e-04\n",
      "Epoch 526/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6878e-05 - mae: 0.0029 - mse: 1.6878e-05 - val_loss: 9.2584e-04 - val_mae: 0.0086 - val_mse: 9.2584e-04\n",
      "Epoch 527/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9795e-05 - mae: 0.0030 - mse: 1.9795e-05 - val_loss: 9.5906e-04 - val_mae: 0.0092 - val_mse: 9.5906e-04\n",
      "Epoch 528/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2329e-05 - mae: 0.0031 - mse: 2.2329e-05 - val_loss: 9.2454e-04 - val_mae: 0.0084 - val_mse: 9.2454e-04\n",
      "Epoch 529/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7368e-05 - mae: 0.0028 - mse: 1.7368e-05 - val_loss: 9.3852e-04 - val_mae: 0.0088 - val_mse: 9.3852e-04\n",
      "Epoch 530/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.9848e-05 - mae: 0.0031 - mse: 1.9848e-05 - val_loss: 9.3484e-04 - val_mae: 0.0091 - val_mse: 9.3484e-04\n",
      "Epoch 531/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1418e-05 - mae: 0.0032 - mse: 2.1418e-05 - val_loss: 9.4557e-04 - val_mae: 0.0085 - val_mse: 9.4557e-04\n",
      "Epoch 532/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0952e-05 - mae: 0.0031 - mse: 2.0952e-05 - val_loss: 9.6399e-04 - val_mae: 0.0104 - val_mse: 9.6399e-04\n",
      "Epoch 533/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.0704e-05 - mae: 0.0045 - mse: 4.0704e-05 - val_loss: 9.6397e-04 - val_mae: 0.0098 - val_mse: 9.6397e-04\n",
      "Epoch 534/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.7445e-05 - mae: 0.0043 - mse: 3.7445e-05 - val_loss: 9.2841e-04 - val_mae: 0.0096 - val_mse: 9.2841e-04\n",
      "Epoch 535/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.6098e-05 - mae: 0.0045 - mse: 3.6098e-05 - val_loss: 9.6546e-04 - val_mae: 0.0098 - val_mse: 9.6546e-04\n",
      "Epoch 536/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4747e-05 - mae: 0.0043 - mse: 3.4747e-05 - val_loss: 9.4074e-04 - val_mae: 0.0091 - val_mse: 9.4074e-04\n",
      "Epoch 537/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4455e-05 - mae: 0.0036 - mse: 2.4455e-05 - val_loss: 9.5675e-04 - val_mae: 0.0093 - val_mse: 9.5675e-04\n",
      "Epoch 538/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3627e-05 - mae: 0.0035 - mse: 2.3627e-05 - val_loss: 9.1294e-04 - val_mae: 0.0092 - val_mse: 9.1294e-04\n",
      "Epoch 539/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.2660e-05 - mae: 0.0036 - mse: 2.2660e-05 - val_loss: 9.2907e-04 - val_mae: 0.0091 - val_mse: 9.2907e-04\n",
      "Epoch 540/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1051e-05 - mae: 0.0034 - mse: 2.1051e-05 - val_loss: 9.2954e-04 - val_mae: 0.0090 - val_mse: 9.2954e-04\n",
      "Epoch 541/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0051e-05 - mae: 0.0033 - mse: 2.0051e-05 - val_loss: 9.4702e-04 - val_mae: 0.0091 - val_mse: 9.4702e-04\n",
      "Epoch 542/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6125e-05 - mae: 0.0029 - mse: 1.6125e-05 - val_loss: 9.4172e-04 - val_mae: 0.0091 - val_mse: 9.4172e-04\n",
      "Epoch 543/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6816e-05 - mae: 0.0028 - mse: 1.6816e-05 - val_loss: 9.3413e-04 - val_mae: 0.0084 - val_mse: 9.3413e-04\n",
      "Epoch 544/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6533e-05 - mae: 0.0028 - mse: 1.6533e-05 - val_loss: 9.2942e-04 - val_mae: 0.0089 - val_mse: 9.2942e-04\n",
      "Epoch 545/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8307e-05 - mae: 0.0031 - mse: 1.8307e-05 - val_loss: 9.4099e-04 - val_mae: 0.0095 - val_mse: 9.4099e-04\n",
      "Epoch 546/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5630e-05 - mae: 0.0037 - mse: 2.5630e-05 - val_loss: 9.1491e-04 - val_mae: 0.0088 - val_mse: 9.1491e-04\n",
      "Epoch 547/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9773e-05 - mae: 0.0033 - mse: 1.9773e-05 - val_loss: 9.3001e-04 - val_mae: 0.0085 - val_mse: 9.3001e-04\n",
      "Epoch 548/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7956e-05 - mae: 0.0031 - mse: 1.7956e-05 - val_loss: 9.2968e-04 - val_mae: 0.0088 - val_mse: 9.2968e-04\n",
      "Epoch 549/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1765e-05 - mae: 0.0033 - mse: 2.1765e-05 - val_loss: 9.3386e-04 - val_mae: 0.0082 - val_mse: 9.3386e-04\n",
      "Epoch 550/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6514e-05 - mae: 0.0029 - mse: 1.6514e-05 - val_loss: 9.3923e-04 - val_mae: 0.0090 - val_mse: 9.3923e-04\n",
      "Epoch 551/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9877e-05 - mae: 0.0030 - mse: 1.9877e-05 - val_loss: 9.3074e-04 - val_mae: 0.0082 - val_mse: 9.3074e-04\n",
      "Epoch 552/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6257e-05 - mae: 0.0027 - mse: 1.6257e-05 - val_loss: 9.3788e-04 - val_mae: 0.0091 - val_mse: 9.3788e-04\n",
      "Epoch 553/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6646e-05 - mae: 0.0027 - mse: 1.6646e-05 - val_loss: 9.3208e-04 - val_mae: 0.0083 - val_mse: 9.3208e-04\n",
      "Epoch 554/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4996e-05 - mae: 0.0026 - mse: 1.4996e-05 - val_loss: 9.2883e-04 - val_mae: 0.0083 - val_mse: 9.2883e-04\n",
      "Epoch 555/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3766e-05 - mae: 0.0026 - mse: 1.3766e-05 - val_loss: 9.2573e-04 - val_mae: 0.0085 - val_mse: 9.2573e-04\n",
      "Epoch 556/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6597e-05 - mae: 0.0028 - mse: 1.6597e-05 - val_loss: 9.2402e-04 - val_mae: 0.0082 - val_mse: 9.2402e-04\n",
      "Epoch 557/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5903e-05 - mae: 0.0028 - mse: 1.5903e-05 - val_loss: 9.3191e-04 - val_mae: 0.0088 - val_mse: 9.3191e-04\n",
      "Epoch 558/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.6368e-05 - mae: 0.0028 - mse: 1.6368e-05 - val_loss: 9.4541e-04 - val_mae: 0.0090 - val_mse: 9.4541e-04\n",
      "Epoch 559/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7825e-05 - mae: 0.0030 - mse: 1.7825e-05 - val_loss: 9.3035e-04 - val_mae: 0.0082 - val_mse: 9.3035e-04\n",
      "Epoch 560/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6470e-05 - mae: 0.0029 - mse: 1.6470e-05 - val_loss: 9.3836e-04 - val_mae: 0.0090 - val_mse: 9.3836e-04\n",
      "Epoch 561/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7139e-05 - mae: 0.0030 - mse: 1.7139e-05 - val_loss: 9.4865e-04 - val_mae: 0.0087 - val_mse: 9.4865e-04\n",
      "Epoch 562/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5113e-05 - mae: 0.0027 - mse: 1.5113e-05 - val_loss: 9.3335e-04 - val_mae: 0.0084 - val_mse: 9.3335e-04\n",
      "Epoch 563/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4741e-05 - mae: 0.0027 - mse: 1.4741e-05 - val_loss: 9.3400e-04 - val_mae: 0.0087 - val_mse: 9.3400e-04\n",
      "Epoch 564/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7736e-05 - mae: 0.0030 - mse: 1.7736e-05 - val_loss: 9.1703e-04 - val_mae: 0.0079 - val_mse: 9.1703e-04\n",
      "Epoch 565/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7429e-05 - mae: 0.0028 - mse: 1.7429e-05 - val_loss: 9.4242e-04 - val_mae: 0.0087 - val_mse: 9.4242e-04\n",
      "Epoch 566/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.0068e-05 - mae: 0.0031 - mse: 2.0068e-05 - val_loss: 9.3000e-04 - val_mae: 0.0083 - val_mse: 9.3000e-04\n",
      "Epoch 567/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6277e-05 - mae: 0.0033 - mse: 2.6277e-05 - val_loss: 9.3233e-04 - val_mae: 0.0087 - val_mse: 9.3233e-04\n",
      "Epoch 568/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4243e-05 - mae: 0.0033 - mse: 2.4243e-05 - val_loss: 9.5261e-04 - val_mae: 0.0090 - val_mse: 9.5261e-04\n",
      "Epoch 569/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1213e-05 - mae: 0.0039 - mse: 3.1213e-05 - val_loss: 9.3465e-04 - val_mae: 0.0090 - val_mse: 9.3465e-04\n",
      "Epoch 570/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.6545e-05 - mae: 0.0038 - mse: 2.6545e-05 - val_loss: 9.3765e-04 - val_mae: 0.0094 - val_mse: 9.3765e-04\n",
      "Epoch 571/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6339e-05 - mae: 0.0040 - mse: 2.6339e-05 - val_loss: 9.4763e-04 - val_mae: 0.0092 - val_mse: 9.4763e-04\n",
      "Epoch 572/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4963e-05 - mae: 0.0037 - mse: 2.4963e-05 - val_loss: 9.4901e-04 - val_mae: 0.0088 - val_mse: 9.4901e-04\n",
      "Epoch 573/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2349e-05 - mae: 0.0035 - mse: 2.2349e-05 - val_loss: 9.4793e-04 - val_mae: 0.0101 - val_mse: 9.4793e-04\n",
      "Epoch 574/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0208e-05 - mae: 0.0041 - mse: 3.0208e-05 - val_loss: 9.5202e-04 - val_mae: 0.0095 - val_mse: 9.5202e-04\n",
      "Epoch 575/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5889e-05 - mae: 0.0037 - mse: 2.5889e-05 - val_loss: 9.4254e-04 - val_mae: 0.0091 - val_mse: 9.4254e-04\n",
      "Epoch 576/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0635e-05 - mae: 0.0038 - mse: 3.0635e-05 - val_loss: 9.6535e-04 - val_mae: 0.0094 - val_mse: 9.6535e-04\n",
      "Epoch 577/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3701e-05 - mae: 0.0042 - mse: 3.3701e-05 - val_loss: 9.3363e-04 - val_mae: 0.0090 - val_mse: 9.3363e-04\n",
      "Epoch 578/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8204e-05 - mae: 0.0039 - mse: 2.8204e-05 - val_loss: 9.4135e-04 - val_mae: 0.0100 - val_mse: 9.4135e-04\n",
      "Epoch 579/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0772e-05 - mae: 0.0041 - mse: 3.0772e-05 - val_loss: 9.1376e-04 - val_mae: 0.0088 - val_mse: 9.1376e-04\n",
      "Epoch 580/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5720e-05 - mae: 0.0037 - mse: 2.5720e-05 - val_loss: 9.5271e-04 - val_mae: 0.0085 - val_mse: 9.5271e-04\n",
      "Epoch 581/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.3446e-05 - mae: 0.0035 - mse: 2.3446e-05 - val_loss: 9.4677e-04 - val_mae: 0.0101 - val_mse: 9.4677e-04\n",
      "Epoch 582/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9829e-05 - mae: 0.0040 - mse: 2.9829e-05 - val_loss: 9.4996e-04 - val_mae: 0.0087 - val_mse: 9.4996e-04\n",
      "Epoch 583/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5438e-05 - mae: 0.0037 - mse: 2.5438e-05 - val_loss: 9.7583e-04 - val_mae: 0.0095 - val_mse: 9.7583e-04\n",
      "Epoch 584/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.9963e-05 - mae: 0.0039 - mse: 2.9963e-05 - val_loss: 9.5202e-04 - val_mae: 0.0094 - val_mse: 9.5202e-04\n",
      "Epoch 585/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4091e-05 - mae: 0.0036 - mse: 2.4091e-05 - val_loss: 9.3576e-04 - val_mae: 0.0085 - val_mse: 9.3576e-04\n",
      "Epoch 586/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7681e-05 - mae: 0.0030 - mse: 1.7681e-05 - val_loss: 9.3138e-04 - val_mae: 0.0085 - val_mse: 9.3138e-04\n",
      "Epoch 587/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5633e-05 - mae: 0.0029 - mse: 1.5633e-05 - val_loss: 9.4199e-04 - val_mae: 0.0085 - val_mse: 9.4199e-04\n",
      "Epoch 588/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5283e-05 - mae: 0.0028 - mse: 1.5283e-05 - val_loss: 9.3210e-04 - val_mae: 0.0082 - val_mse: 9.3210e-04\n",
      "Epoch 589/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2511e-05 - mae: 0.0026 - mse: 1.2511e-05 - val_loss: 9.3740e-04 - val_mae: 0.0087 - val_mse: 9.3740e-04\n",
      "Epoch 590/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0522e-05 - mae: 0.0030 - mse: 2.0522e-05 - val_loss: 9.3745e-04 - val_mae: 0.0088 - val_mse: 9.3745e-04\n",
      "Epoch 591/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4131e-05 - mae: 0.0035 - mse: 2.4131e-05 - val_loss: 9.6917e-04 - val_mae: 0.0090 - val_mse: 9.6917e-04\n",
      "Epoch 592/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5770e-05 - mae: 0.0035 - mse: 2.5770e-05 - val_loss: 9.4536e-04 - val_mae: 0.0091 - val_mse: 9.4536e-04\n",
      "Epoch 593/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4931e-05 - mae: 0.0037 - mse: 2.4931e-05 - val_loss: 9.4116e-04 - val_mae: 0.0102 - val_mse: 9.4116e-04\n",
      "Epoch 594/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0084e-05 - mae: 0.0042 - mse: 3.0084e-05 - val_loss: 9.5880e-04 - val_mae: 0.0093 - val_mse: 9.5880e-04\n",
      "Epoch 595/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5217e-05 - mae: 0.0037 - mse: 2.5217e-05 - val_loss: 9.5181e-04 - val_mae: 0.0092 - val_mse: 9.5181e-04\n",
      "Epoch 596/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.2926e-05 - mae: 0.0036 - mse: 2.2926e-05 - val_loss: 9.5911e-04 - val_mae: 0.0093 - val_mse: 9.5911e-04\n",
      "Epoch 597/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5671e-05 - mae: 0.0037 - mse: 2.5671e-05 - val_loss: 9.3041e-04 - val_mae: 0.0087 - val_mse: 9.3041e-04\n",
      "Epoch 598/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1826e-05 - mae: 0.0034 - mse: 2.1826e-05 - val_loss: 9.4379e-04 - val_mae: 0.0093 - val_mse: 9.4379e-04\n",
      "Epoch 599/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0829e-05 - mae: 0.0041 - mse: 3.0829e-05 - val_loss: 9.4730e-04 - val_mae: 0.0095 - val_mse: 9.4730e-04\n",
      "Epoch 600/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1036e-05 - mae: 0.0041 - mse: 3.1036e-05 - val_loss: 9.6176e-04 - val_mae: 0.0097 - val_mse: 9.6176e-04\n",
      "Epoch 601/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7139e-05 - mae: 0.0045 - mse: 3.7139e-05 - val_loss: 9.7370e-04 - val_mae: 0.0103 - val_mse: 9.7370e-04\n",
      "Epoch 602/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.6298e-05 - mae: 0.0050 - mse: 4.6298e-05 - val_loss: 9.9647e-04 - val_mae: 0.0098 - val_mse: 9.9647e-04\n",
      "Epoch 603/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7143e-05 - mae: 0.0050 - mse: 4.7143e-05 - val_loss: 9.6811e-04 - val_mae: 0.0100 - val_mse: 9.6811e-04\n",
      "Epoch 604/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4706e-05 - mae: 0.0055 - mse: 5.4706e-05 - val_loss: 9.4651e-04 - val_mae: 0.0101 - val_mse: 9.4651e-04\n",
      "Epoch 605/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4774e-05 - mae: 0.0055 - mse: 5.4774e-05 - val_loss: 9.6660e-04 - val_mae: 0.0092 - val_mse: 9.6660e-04\n",
      "Epoch 606/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3518e-05 - mae: 0.0049 - mse: 4.3518e-05 - val_loss: 9.4376e-04 - val_mae: 0.0091 - val_mse: 9.4376e-04\n",
      "Epoch 607/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8317e-05 - mae: 0.0047 - mse: 3.8317e-05 - val_loss: 9.5964e-04 - val_mae: 0.0095 - val_mse: 9.5964e-04\n",
      "Epoch 608/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4943e-05 - mae: 0.0043 - mse: 3.4943e-05 - val_loss: 9.4632e-04 - val_mae: 0.0091 - val_mse: 9.4632e-04\n",
      "Epoch 609/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1949e-05 - mae: 0.0042 - mse: 3.1949e-05 - val_loss: 9.3521e-04 - val_mae: 0.0093 - val_mse: 9.3521e-04\n",
      "Epoch 610/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9583e-05 - mae: 0.0040 - mse: 2.9583e-05 - val_loss: 9.6179e-04 - val_mae: 0.0094 - val_mse: 9.6179e-04\n",
      "Epoch 611/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7925e-05 - mae: 0.0039 - mse: 2.7925e-05 - val_loss: 9.2771e-04 - val_mae: 0.0089 - val_mse: 9.2771e-04\n",
      "Epoch 612/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3286e-05 - mae: 0.0035 - mse: 2.3286e-05 - val_loss: 9.5171e-04 - val_mae: 0.0087 - val_mse: 9.5171e-04\n",
      "Epoch 613/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0068e-05 - mae: 0.0032 - mse: 2.0068e-05 - val_loss: 9.4114e-04 - val_mae: 0.0086 - val_mse: 9.4114e-04\n",
      "Epoch 614/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.9107e-05 - mae: 0.0032 - mse: 1.9107e-05 - val_loss: 9.6904e-04 - val_mae: 0.0089 - val_mse: 9.6904e-04\n",
      "Epoch 615/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9641e-05 - mae: 0.0032 - mse: 1.9641e-05 - val_loss: 9.3605e-04 - val_mae: 0.0089 - val_mse: 9.3605e-04\n",
      "Epoch 616/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4476e-05 - mae: 0.0035 - mse: 2.4476e-05 - val_loss: 9.4914e-04 - val_mae: 0.0088 - val_mse: 9.4914e-04\n",
      "Epoch 617/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1454e-05 - mae: 0.0034 - mse: 2.1454e-05 - val_loss: 9.3769e-04 - val_mae: 0.0085 - val_mse: 9.3769e-04\n",
      "Epoch 618/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3459e-05 - mae: 0.0034 - mse: 2.3459e-05 - val_loss: 9.5617e-04 - val_mae: 0.0089 - val_mse: 9.5617e-04\n",
      "Epoch 619/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6039e-05 - mae: 0.0034 - mse: 2.6039e-05 - val_loss: 9.4914e-04 - val_mae: 0.0085 - val_mse: 9.4914e-04\n",
      "Epoch 620/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1123e-05 - mae: 0.0032 - mse: 2.1123e-05 - val_loss: 9.5265e-04 - val_mae: 0.0083 - val_mse: 9.5265e-04\n",
      "Epoch 621/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7933e-05 - mae: 0.0030 - mse: 1.7933e-05 - val_loss: 9.3771e-04 - val_mae: 0.0083 - val_mse: 9.3771e-04\n",
      "Epoch 622/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5289e-05 - mae: 0.0028 - mse: 1.5289e-05 - val_loss: 9.4764e-04 - val_mae: 0.0087 - val_mse: 9.4764e-04\n",
      "Epoch 623/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.7775e-05 - mae: 0.0029 - mse: 1.7775e-05 - val_loss: 9.3008e-04 - val_mae: 0.0088 - val_mse: 9.3008e-04\n",
      "Epoch 624/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8502e-05 - mae: 0.0042 - mse: 4.8502e-05 - val_loss: 9.8343e-04 - val_mae: 0.0110 - val_mse: 9.8343e-04\n",
      "Epoch 625/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3167e-04 - mae: 0.0068 - mse: 1.3167e-04 - val_loss: 0.0011 - val_mae: 0.0125 - val_mse: 0.0011\n",
      "Epoch 626/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0372e-04 - mae: 0.0066 - mse: 1.0372e-04 - val_loss: 0.0010 - val_mae: 0.0110 - val_mse: 0.0010\n",
      "Epoch 627/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1476e-04 - mae: 0.0073 - mse: 1.1476e-04 - val_loss: 0.0013 - val_mae: 0.0165 - val_mse: 0.0013\n",
      "Epoch 628/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1709e-04 - mae: 0.0071 - mse: 1.1709e-04 - val_loss: 9.5897e-04 - val_mae: 0.0104 - val_mse: 9.5897e-04\n",
      "Epoch 629/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5265e-05 - mae: 0.0070 - mse: 9.5265e-05 - val_loss: 9.8955e-04 - val_mae: 0.0120 - val_mse: 9.8955e-04\n",
      "Epoch 630/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2694e-05 - mae: 0.0071 - mse: 9.2694e-05 - val_loss: 0.0011 - val_mae: 0.0143 - val_mse: 0.0011\n",
      "Epoch 631/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6633e-04 - mae: 0.0089 - mse: 1.6633e-04 - val_loss: 0.0011 - val_mae: 0.0140 - val_mse: 0.0011\n",
      "Epoch 632/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6179e-04 - mae: 0.0086 - mse: 1.6179e-04 - val_loss: 0.0010 - val_mae: 0.0133 - val_mse: 0.0010\n",
      "Epoch 633/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0034e-04 - mae: 0.0099 - mse: 2.0034e-04 - val_loss: 0.0011 - val_mae: 0.0147 - val_mse: 0.0011\n",
      "Epoch 634/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.7391e-04 - mae: 0.0111 - mse: 2.7391e-04 - val_loss: 0.0013 - val_mae: 0.0192 - val_mse: 0.0013\n",
      "Epoch 635/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4944e-04 - mae: 0.0130 - mse: 3.4944e-04 - val_loss: 0.0011 - val_mae: 0.0163 - val_mse: 0.0011\n",
      "Epoch 636/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0123e-04 - mae: 0.0120 - mse: 3.0123e-04 - val_loss: 0.0014 - val_mae: 0.0217 - val_mse: 0.0014\n",
      "Epoch 637/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3294e-04 - mae: 0.0196 - mse: 7.3294e-04 - val_loss: 0.0021 - val_mae: 0.0301 - val_mse: 0.0021\n",
      "Epoch 638/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0236 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0279 - val_mse: 0.0020\n",
      "Epoch 639/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 - mae: 0.0239 - mse: 0.0010 - val_loss: 0.0016 - val_mae: 0.0235 - val_mse: 0.0016\n",
      "Epoch 640/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7461e-04 - mae: 0.0203 - mse: 7.7461e-04 - val_loss: 0.0019 - val_mae: 0.0262 - val_mse: 0.0019\n",
      "Epoch 641/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5808e-04 - mae: 0.0209 - mse: 7.5808e-04 - val_loss: 0.0013 - val_mae: 0.0234 - val_mse: 0.0013\n",
      "Epoch 642/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.3038e-04 - mae: 0.0191 - mse: 6.3038e-04 - val_loss: 0.0015 - val_mae: 0.0238 - val_mse: 0.0015\n",
      "Epoch 643/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.5239e-04 - mae: 0.0198 - mse: 7.5239e-04 - val_loss: 0.0021 - val_mae: 0.0292 - val_mse: 0.0021\n",
      "Epoch 644/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9133e-04 - mae: 0.0184 - mse: 6.9133e-04 - val_loss: 0.0016 - val_mae: 0.0225 - val_mse: 0.0016\n",
      "Epoch 645/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7054e-04 - mae: 0.0190 - mse: 7.7054e-04 - val_loss: 0.0014 - val_mae: 0.0225 - val_mse: 0.0014\n",
      "Epoch 646/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6883e-04 - mae: 0.0180 - mse: 6.6883e-04 - val_loss: 0.0022 - val_mae: 0.0301 - val_mse: 0.0022\n",
      "Epoch 647/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2682e-04 - mae: 0.0192 - mse: 8.2682e-04 - val_loss: 0.0013 - val_mae: 0.0196 - val_mse: 0.0013\n",
      "Epoch 648/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9766e-04 - mae: 0.0172 - mse: 5.9766e-04 - val_loss: 0.0013 - val_mae: 0.0204 - val_mse: 0.0013\n",
      "Epoch 649/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1746e-04 - mae: 0.0188 - mse: 7.1746e-04 - val_loss: 0.0017 - val_mae: 0.0251 - val_mse: 0.0017\n",
      "Epoch 650/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5581e-04 - mae: 0.0207 - mse: 7.5581e-04 - val_loss: 0.0013 - val_mae: 0.0200 - val_mse: 0.0013\n",
      "Epoch 651/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.0709e-04 - mae: 0.0213 - mse: 9.0709e-04 - val_loss: 0.0013 - val_mae: 0.0212 - val_mse: 0.0013\n",
      "Epoch 652/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8351e-04 - mae: 0.0216 - mse: 8.8351e-04 - val_loss: 0.0025 - val_mae: 0.0354 - val_mse: 0.0025\n",
      "Epoch 653/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.6256e-04 - mae: 0.0227 - mse: 9.6256e-04 - val_loss: 0.0029 - val_mae: 0.0361 - val_mse: 0.0029\n",
      "Epoch 654/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - mae: 0.0250 - mse: 0.0013 - val_loss: 0.0020 - val_mae: 0.0266 - val_mse: 0.0020\n",
      "Epoch 655/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.1819e-04 - mae: 0.0217 - mse: 9.1819e-04 - val_loss: 0.0018 - val_mae: 0.0254 - val_mse: 0.0018\n",
      "Epoch 656/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0227 - mse: 0.0011 - val_loss: 0.0020 - val_mae: 0.0283 - val_mse: 0.0020\n",
      "Epoch 657/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0396e-04 - mae: 0.0195 - mse: 8.0396e-04 - val_loss: 0.0021 - val_mae: 0.0274 - val_mse: 0.0021\n",
      "Epoch 658/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8533e-04 - mae: 0.0184 - mse: 7.8533e-04 - val_loss: 0.0018 - val_mae: 0.0245 - val_mse: 0.0018\n",
      "Epoch 659/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0169e-04 - mae: 0.0179 - mse: 7.0169e-04 - val_loss: 0.0012 - val_mae: 0.0186 - val_mse: 0.0012\n",
      "Epoch 660/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7205e-04 - mae: 0.0155 - mse: 4.7205e-04 - val_loss: 0.0014 - val_mae: 0.0205 - val_mse: 0.0014\n",
      "Epoch 661/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4478e-04 - mae: 0.0141 - mse: 4.4478e-04 - val_loss: 0.0018 - val_mae: 0.0235 - val_mse: 0.0018\n",
      "Epoch 662/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3782e-04 - mae: 0.0138 - mse: 4.3782e-04 - val_loss: 0.0019 - val_mae: 0.0243 - val_mse: 0.0019\n",
      "Epoch 663/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6094e-04 - mae: 0.0153 - mse: 5.6094e-04 - val_loss: 0.0014 - val_mae: 0.0194 - val_mse: 0.0014\n",
      "Epoch 664/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7128e-04 - mae: 0.0136 - mse: 3.7128e-04 - val_loss: 0.0012 - val_mae: 0.0185 - val_mse: 0.0012\n",
      "Epoch 665/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0363e-04 - mae: 0.0129 - mse: 3.0363e-04 - val_loss: 0.0013 - val_mae: 0.0195 - val_mse: 0.0013\n",
      "Epoch 666/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.3886e-04 - mae: 0.0131 - mse: 3.3886e-04 - val_loss: 0.0011 - val_mae: 0.0166 - val_mse: 0.0011\n",
      "Epoch 667/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.9001e-04 - mae: 0.0127 - mse: 2.9001e-04 - val_loss: 0.0011 - val_mae: 0.0150 - val_mse: 0.0011\n",
      "Epoch 668/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3029e-04 - mae: 0.0115 - mse: 2.3029e-04 - val_loss: 0.0011 - val_mae: 0.0156 - val_mse: 0.0011\n",
      "Epoch 669/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9058e-04 - mae: 0.0105 - mse: 1.9058e-04 - val_loss: 0.0010 - val_mae: 0.0151 - val_mse: 0.0010\n",
      "Epoch 670/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.9147e-04 - mae: 0.0106 - mse: 1.9147e-04 - val_loss: 0.0012 - val_mae: 0.0171 - val_mse: 0.0012\n",
      "Epoch 671/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9820e-04 - mae: 0.0103 - mse: 1.9820e-04 - val_loss: 0.0012 - val_mae: 0.0169 - val_mse: 0.0012\n",
      "Epoch 672/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.4369e-04 - mae: 0.0110 - mse: 2.4369e-04 - val_loss: 0.0011 - val_mae: 0.0147 - val_mse: 0.0011\n",
      "Epoch 673/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3606e-04 - mae: 0.0115 - mse: 2.3606e-04 - val_loss: 0.0010 - val_mae: 0.0131 - val_mse: 0.0010\n",
      "Epoch 674/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9786e-04 - mae: 0.0102 - mse: 1.9786e-04 - val_loss: 0.0011 - val_mae: 0.0142 - val_mse: 0.0011\n",
      "Epoch 675/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0039e-04 - mae: 0.0098 - mse: 2.0039e-04 - val_loss: 0.0013 - val_mae: 0.0195 - val_mse: 0.0013\n",
      "Epoch 676/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6275e-04 - mae: 0.0114 - mse: 2.6275e-04 - val_loss: 0.0013 - val_mae: 0.0197 - val_mse: 0.0013\n",
      "Epoch 677/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0786e-04 - mae: 0.0120 - mse: 3.0786e-04 - val_loss: 0.0013 - val_mae: 0.0166 - val_mse: 0.0013\n",
      "Epoch 678/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2517e-04 - mae: 0.0103 - mse: 2.2517e-04 - val_loss: 0.0011 - val_mae: 0.0142 - val_mse: 0.0011\n",
      "Epoch 679/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0221e-04 - mae: 0.0102 - mse: 2.0221e-04 - val_loss: 0.0011 - val_mae: 0.0155 - val_mse: 0.0011\n",
      "Epoch 680/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1799e-04 - mae: 0.0109 - mse: 2.1799e-04 - val_loss: 0.0011 - val_mae: 0.0161 - val_mse: 0.0011\n",
      "Epoch 681/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4344e-04 - mae: 0.0117 - mse: 2.4344e-04 - val_loss: 0.0011 - val_mae: 0.0166 - val_mse: 0.0011\n",
      "Epoch 682/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1872e-04 - mae: 0.0111 - mse: 2.1872e-04 - val_loss: 0.0011 - val_mae: 0.0159 - val_mse: 0.0011\n",
      "Epoch 683/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9713e-04 - mae: 0.0102 - mse: 1.9713e-04 - val_loss: 0.0010 - val_mae: 0.0126 - val_mse: 0.0010\n",
      "Epoch 684/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7449e-04 - mae: 0.0096 - mse: 1.7449e-04 - val_loss: 0.0010 - val_mae: 0.0150 - val_mse: 0.0010\n",
      "Epoch 685/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1087e-04 - mae: 0.0107 - mse: 2.1087e-04 - val_loss: 0.0012 - val_mae: 0.0185 - val_mse: 0.0012\n",
      "Epoch 686/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2688e-04 - mae: 0.0109 - mse: 2.2688e-04 - val_loss: 0.0012 - val_mae: 0.0195 - val_mse: 0.0012\n",
      "Epoch 687/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8107e-04 - mae: 0.0126 - mse: 2.8107e-04 - val_loss: 0.0012 - val_mae: 0.0186 - val_mse: 0.0012\n",
      "Epoch 688/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1275e-04 - mae: 0.0111 - mse: 2.1275e-04 - val_loss: 0.0011 - val_mae: 0.0172 - val_mse: 0.0011\n",
      "Epoch 689/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4666e-04 - mae: 0.0117 - mse: 2.4666e-04 - val_loss: 0.0011 - val_mae: 0.0134 - val_mse: 0.0011\n",
      "Epoch 690/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2361e-04 - mae: 0.0112 - mse: 2.2361e-04 - val_loss: 0.0010 - val_mae: 0.0149 - val_mse: 0.0010\n",
      "Epoch 691/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0550e-04 - mae: 0.0108 - mse: 2.0550e-04 - val_loss: 0.0011 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 692/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.6788e-04 - mae: 0.0094 - mse: 1.6788e-04 - val_loss: 0.0013 - val_mae: 0.0181 - val_mse: 0.0013\n",
      "Epoch 693/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4802e-04 - mae: 0.0109 - mse: 2.4802e-04 - val_loss: 0.0015 - val_mae: 0.0204 - val_mse: 0.0015\n",
      "Epoch 694/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3613e-04 - mae: 0.0133 - mse: 4.3613e-04 - val_loss: 0.0012 - val_mae: 0.0168 - val_mse: 0.0012\n",
      "Epoch 695/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.0851e-04 - mae: 0.0133 - mse: 4.0851e-04 - val_loss: 0.0014 - val_mae: 0.0190 - val_mse: 0.0014\n",
      "Epoch 696/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0584e-04 - mae: 0.0123 - mse: 3.0584e-04 - val_loss: 0.0012 - val_mae: 0.0175 - val_mse: 0.0012\n",
      "Epoch 697/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5224e-04 - mae: 0.0125 - mse: 3.5224e-04 - val_loss: 0.0013 - val_mae: 0.0185 - val_mse: 0.0013\n",
      "Epoch 698/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4167e-04 - mae: 0.0126 - mse: 3.4167e-04 - val_loss: 0.0012 - val_mae: 0.0165 - val_mse: 0.0012\n",
      "Epoch 699/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4641e-04 - mae: 0.0112 - mse: 2.4641e-04 - val_loss: 0.0012 - val_mae: 0.0159 - val_mse: 0.0012\n",
      "Epoch 700/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2154e-04 - mae: 0.0107 - mse: 2.2154e-04 - val_loss: 0.0010 - val_mae: 0.0144 - val_mse: 0.0010\n",
      "Epoch 701/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0270e-04 - mae: 0.0103 - mse: 2.0270e-04 - val_loss: 0.0011 - val_mae: 0.0151 - val_mse: 0.0011\n",
      "Epoch 702/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.0182e-04 - mae: 0.0101 - mse: 2.0182e-04 - val_loss: 0.0011 - val_mae: 0.0166 - val_mse: 0.0011\n",
      "Epoch 703/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7341e-04 - mae: 0.0117 - mse: 2.7341e-04 - val_loss: 0.0011 - val_mae: 0.0155 - val_mse: 0.0011\n",
      "Epoch 704/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7947e-04 - mae: 0.0101 - mse: 1.7947e-04 - val_loss: 0.0011 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 705/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2421e-04 - mae: 0.0106 - mse: 2.2421e-04 - val_loss: 0.0011 - val_mae: 0.0153 - val_mse: 0.0011\n",
      "Epoch 706/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9593e-04 - mae: 0.0102 - mse: 1.9593e-04 - val_loss: 0.0011 - val_mae: 0.0154 - val_mse: 0.0011\n",
      "Epoch 707/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1376e-04 - mae: 0.0103 - mse: 2.1376e-04 - val_loss: 0.0011 - val_mae: 0.0149 - val_mse: 0.0011\n",
      "Epoch 708/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1367e-04 - mae: 0.0104 - mse: 2.1367e-04 - val_loss: 0.0010 - val_mae: 0.0143 - val_mse: 0.0010\n",
      "Epoch 709/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8416e-04 - mae: 0.0095 - mse: 1.8416e-04 - val_loss: 0.0011 - val_mae: 0.0146 - val_mse: 0.0011\n",
      "Epoch 710/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7466e-04 - mae: 0.0096 - mse: 1.7466e-04 - val_loss: 0.0010 - val_mae: 0.0148 - val_mse: 0.0010\n",
      "Epoch 711/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.0476e-04 - mae: 0.0104 - mse: 2.0476e-04 - val_loss: 0.0013 - val_mae: 0.0185 - val_mse: 0.0013\n",
      "Epoch 712/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.8254e-04 - mae: 0.0117 - mse: 2.8254e-04 - val_loss: 0.0013 - val_mae: 0.0185 - val_mse: 0.0013\n",
      "Epoch 713/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.9355e-04 - mae: 0.0132 - mse: 3.9355e-04 - val_loss: 0.0012 - val_mae: 0.0174 - val_mse: 0.0012\n",
      "Epoch 714/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.8807e-04 - mae: 0.0131 - mse: 3.8807e-04 - val_loss: 0.0012 - val_mae: 0.0172 - val_mse: 0.0012\n",
      "Epoch 715/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6308e-04 - mae: 0.0142 - mse: 4.6308e-04 - val_loss: 0.0014 - val_mae: 0.0212 - val_mse: 0.0014\n",
      "Epoch 716/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3253e-04 - mae: 0.0153 - mse: 4.3253e-04 - val_loss: 0.0015 - val_mae: 0.0237 - val_mse: 0.0015\n",
      "Epoch 717/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.3993e-04 - mae: 0.0139 - mse: 3.3993e-04 - val_loss: 0.0014 - val_mae: 0.0209 - val_mse: 0.0014\n",
      "Epoch 718/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.2063e-04 - mae: 0.0155 - mse: 4.2063e-04 - val_loss: 0.0012 - val_mae: 0.0178 - val_mse: 0.0012\n",
      "Epoch 719/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1720e-04 - mae: 0.0148 - mse: 4.1720e-04 - val_loss: 0.0011 - val_mae: 0.0145 - val_mse: 0.0011\n",
      "Epoch 720/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4236e-04 - mae: 0.0114 - mse: 2.4236e-04 - val_loss: 0.0011 - val_mae: 0.0165 - val_mse: 0.0011\n",
      "Epoch 721/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6374e-04 - mae: 0.0121 - mse: 2.6374e-04 - val_loss: 0.0012 - val_mae: 0.0175 - val_mse: 0.0012\n",
      "Epoch 722/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3041e-04 - mae: 0.0115 - mse: 2.3041e-04 - val_loss: 0.0010 - val_mae: 0.0163 - val_mse: 0.0010\n",
      "Epoch 723/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8154e-04 - mae: 0.0127 - mse: 2.8154e-04 - val_loss: 0.0012 - val_mae: 0.0168 - val_mse: 0.0012\n",
      "Epoch 724/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7760e-04 - mae: 0.0143 - mse: 3.7760e-04 - val_loss: 0.0013 - val_mae: 0.0188 - val_mse: 0.0013\n",
      "Epoch 725/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5407e-04 - mae: 0.0163 - mse: 4.5407e-04 - val_loss: 0.0011 - val_mae: 0.0172 - val_mse: 0.0011\n",
      "Epoch 726/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.2041e-04 - mae: 0.0156 - mse: 4.2041e-04 - val_loss: 0.0012 - val_mae: 0.0173 - val_mse: 0.0012\n",
      "Epoch 727/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5441e-04 - mae: 0.0159 - mse: 4.5441e-04 - val_loss: 0.0012 - val_mae: 0.0179 - val_mse: 0.0012\n",
      "Epoch 728/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.3679e-04 - mae: 0.0154 - mse: 4.3679e-04 - val_loss: 0.0011 - val_mae: 0.0184 - val_mse: 0.0011\n",
      "Epoch 729/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.2565e-04 - mae: 0.0140 - mse: 3.2565e-04 - val_loss: 0.0012 - val_mae: 0.0180 - val_mse: 0.0012\n",
      "Epoch 730/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.6046e-04 - mae: 0.0123 - mse: 2.6046e-04 - val_loss: 0.0012 - val_mae: 0.0174 - val_mse: 0.0012\n",
      "Epoch 731/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.5485e-04 - mae: 0.0118 - mse: 2.5485e-04 - val_loss: 0.0011 - val_mae: 0.0167 - val_mse: 0.0011\n",
      "Epoch 732/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8366e-04 - mae: 0.0101 - mse: 1.8366e-04 - val_loss: 0.0011 - val_mae: 0.0155 - val_mse: 0.0011\n",
      "Epoch 733/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8308e-04 - mae: 0.0098 - mse: 1.8308e-04 - val_loss: 0.0011 - val_mae: 0.0149 - val_mse: 0.0011\n",
      "Epoch 734/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7350e-04 - mae: 0.0093 - mse: 1.7350e-04 - val_loss: 9.6018e-04 - val_mae: 0.0126 - val_mse: 9.6018e-04\n",
      "Epoch 735/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5745e-04 - mae: 0.0088 - mse: 1.5745e-04 - val_loss: 0.0010 - val_mae: 0.0129 - val_mse: 0.0010\n",
      "Epoch 736/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.7789e-04 - mae: 0.0095 - mse: 1.7789e-04 - val_loss: 9.9126e-04 - val_mae: 0.0130 - val_mse: 9.9126e-04\n",
      "Epoch 737/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5512e-04 - mae: 0.0090 - mse: 1.5512e-04 - val_loss: 9.3582e-04 - val_mae: 0.0125 - val_mse: 9.3582e-04\n",
      "Epoch 738/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2413e-04 - mae: 0.0079 - mse: 1.2413e-04 - val_loss: 0.0010 - val_mae: 0.0120 - val_mse: 0.0010\n",
      "Epoch 739/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1332e-04 - mae: 0.0077 - mse: 1.1332e-04 - val_loss: 0.0010 - val_mae: 0.0119 - val_mse: 0.0010\n",
      "Epoch 740/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.8926e-05 - mae: 0.0072 - mse: 9.8926e-05 - val_loss: 9.5007e-04 - val_mae: 0.0121 - val_mse: 9.5007e-04\n",
      "Epoch 741/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.8482e-05 - mae: 0.0070 - mse: 8.8482e-05 - val_loss: 9.9505e-04 - val_mae: 0.0124 - val_mse: 9.9505e-04\n",
      "Epoch 742/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5352e-05 - mae: 0.0069 - mse: 8.5352e-05 - val_loss: 9.3368e-04 - val_mae: 0.0117 - val_mse: 9.3368e-04\n",
      "Epoch 743/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0702e-05 - mae: 0.0066 - mse: 8.0702e-05 - val_loss: 9.8011e-04 - val_mae: 0.0109 - val_mse: 9.8011e-04\n",
      "Epoch 744/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.1681e-05 - mae: 0.0061 - mse: 7.1681e-05 - val_loss: 9.6800e-04 - val_mae: 0.0124 - val_mse: 9.6800e-04\n",
      "Epoch 745/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.5321e-05 - mae: 0.0061 - mse: 7.5321e-05 - val_loss: 9.9458e-04 - val_mae: 0.0121 - val_mse: 9.9458e-04\n",
      "Epoch 746/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.5247e-05 - mae: 0.0064 - mse: 8.5247e-05 - val_loss: 9.6077e-04 - val_mae: 0.0116 - val_mse: 9.6077e-04\n",
      "Epoch 747/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.0572e-05 - mae: 0.0063 - mse: 8.0572e-05 - val_loss: 0.0010 - val_mae: 0.0113 - val_mse: 0.0010\n",
      "Epoch 748/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.5708e-05 - mae: 0.0061 - mse: 9.5708e-05 - val_loss: 0.0010 - val_mae: 0.0115 - val_mse: 0.0010\n",
      "Epoch 749/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.9974e-05 - mae: 0.0058 - mse: 7.9974e-05 - val_loss: 0.0010 - val_mae: 0.0107 - val_mse: 0.0010\n",
      "Epoch 750/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.7270e-05 - mae: 0.0056 - mse: 7.7270e-05 - val_loss: 9.5867e-04 - val_mae: 0.0111 - val_mse: 9.5867e-04\n",
      "Epoch 751/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.3503e-05 - mae: 0.0055 - mse: 7.3503e-05 - val_loss: 0.0010 - val_mae: 0.0109 - val_mse: 0.0010\n",
      "Epoch 752/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.3809e-05 - mae: 0.0055 - mse: 7.3809e-05 - val_loss: 9.5546e-04 - val_mae: 0.0103 - val_mse: 9.5546e-04\n",
      "Epoch 753/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8437e-05 - mae: 0.0056 - mse: 7.8437e-05 - val_loss: 0.0010 - val_mae: 0.0110 - val_mse: 0.0010\n",
      "Epoch 754/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.6207e-05 - mae: 0.0056 - mse: 7.6207e-05 - val_loss: 9.1905e-04 - val_mae: 0.0090 - val_mse: 9.1905e-04\n",
      "Epoch 755/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9414e-05 - mae: 0.0049 - mse: 5.9414e-05 - val_loss: 9.6866e-04 - val_mae: 0.0097 - val_mse: 9.6866e-04\n",
      "Epoch 756/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5250e-05 - mae: 0.0050 - mse: 6.5250e-05 - val_loss: 9.3488e-04 - val_mae: 0.0094 - val_mse: 9.3488e-04\n",
      "Epoch 757/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1160e-05 - mae: 0.0046 - mse: 5.1160e-05 - val_loss: 9.4348e-04 - val_mae: 0.0093 - val_mse: 9.4348e-04\n",
      "Epoch 758/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0501e-05 - mae: 0.0050 - mse: 6.0501e-05 - val_loss: 9.6252e-04 - val_mae: 0.0097 - val_mse: 9.6252e-04\n",
      "Epoch 759/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0269e-05 - mae: 0.0050 - mse: 6.0269e-05 - val_loss: 9.5943e-04 - val_mae: 0.0095 - val_mse: 9.5943e-04\n",
      "Epoch 760/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.7469e-05 - mae: 0.0049 - mse: 5.7469e-05 - val_loss: 9.0050e-04 - val_mae: 0.0091 - val_mse: 9.0050e-04\n",
      "Epoch 761/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7192e-05 - mae: 0.0048 - mse: 5.7192e-05 - val_loss: 9.7137e-04 - val_mae: 0.0090 - val_mse: 9.7137e-04\n",
      "Epoch 762/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0730e-05 - mae: 0.0045 - mse: 5.0730e-05 - val_loss: 9.4474e-04 - val_mae: 0.0101 - val_mse: 9.4474e-04\n",
      "Epoch 763/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0348e-04 - mae: 0.0057 - mse: 1.0348e-04 - val_loss: 0.0011 - val_mae: 0.0122 - val_mse: 0.0011\n",
      "Epoch 764/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1318e-04 - mae: 0.0061 - mse: 1.1318e-04 - val_loss: 9.7695e-04 - val_mae: 0.0110 - val_mse: 9.7695e-04\n",
      "Epoch 765/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2967e-04 - mae: 0.0068 - mse: 1.2967e-04 - val_loss: 0.0010 - val_mae: 0.0108 - val_mse: 0.0010\n",
      "Epoch 766/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1836e-04 - mae: 0.0069 - mse: 1.1836e-04 - val_loss: 9.3000e-04 - val_mae: 0.0112 - val_mse: 9.3000e-04\n",
      "Epoch 767/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0272e-04 - mae: 0.0067 - mse: 1.0272e-04 - val_loss: 0.0010 - val_mae: 0.0108 - val_mse: 0.0010\n",
      "Epoch 768/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1903e-05 - mae: 0.0061 - mse: 7.1903e-05 - val_loss: 9.1850e-04 - val_mae: 0.0096 - val_mse: 9.1850e-04\n",
      "Epoch 769/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8696e-05 - mae: 0.0057 - mse: 6.8696e-05 - val_loss: 9.7698e-04 - val_mae: 0.0104 - val_mse: 9.7698e-04\n",
      "Epoch 770/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.6930e-05 - mae: 0.0059 - mse: 6.6930e-05 - val_loss: 9.0205e-04 - val_mae: 0.0094 - val_mse: 9.0205e-04\n",
      "Epoch 771/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.1932e-05 - mae: 0.0053 - mse: 5.1932e-05 - val_loss: 0.0010 - val_mae: 0.0111 - val_mse: 0.0010\n",
      "Epoch 772/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5547e-05 - mae: 0.0053 - mse: 5.5547e-05 - val_loss: 9.7394e-04 - val_mae: 0.0106 - val_mse: 9.7394e-04\n",
      "Epoch 773/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4399e-05 - mae: 0.0053 - mse: 5.4399e-05 - val_loss: 9.4754e-04 - val_mae: 0.0099 - val_mse: 9.4754e-04\n",
      "Epoch 774/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7724e-05 - mae: 0.0051 - mse: 4.7724e-05 - val_loss: 9.7340e-04 - val_mae: 0.0104 - val_mse: 9.7340e-04\n",
      "Epoch 775/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8846e-05 - mae: 0.0052 - mse: 4.8846e-05 - val_loss: 9.2930e-04 - val_mae: 0.0096 - val_mse: 9.2930e-04\n",
      "Epoch 776/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0923e-05 - mae: 0.0047 - mse: 4.0923e-05 - val_loss: 9.6122e-04 - val_mae: 0.0103 - val_mse: 9.6122e-04\n",
      "Epoch 777/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3797e-05 - mae: 0.0049 - mse: 4.3797e-05 - val_loss: 9.4762e-04 - val_mae: 0.0098 - val_mse: 9.4762e-04\n",
      "Epoch 778/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8466e-05 - mae: 0.0050 - mse: 4.8466e-05 - val_loss: 9.7718e-04 - val_mae: 0.0095 - val_mse: 9.7718e-04\n",
      "Epoch 779/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.5238e-05 - mae: 0.0043 - mse: 3.5238e-05 - val_loss: 9.3888e-04 - val_mae: 0.0094 - val_mse: 9.3888e-04\n",
      "Epoch 780/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8480e-05 - mae: 0.0045 - mse: 3.8480e-05 - val_loss: 9.5433e-04 - val_mae: 0.0100 - val_mse: 9.5433e-04\n",
      "Epoch 781/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8054e-05 - mae: 0.0044 - mse: 3.8054e-05 - val_loss: 9.1976e-04 - val_mae: 0.0094 - val_mse: 9.1976e-04\n",
      "Epoch 782/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8716e-05 - mae: 0.0051 - mse: 4.8716e-05 - val_loss: 9.3446e-04 - val_mae: 0.0087 - val_mse: 9.3446e-04\n",
      "Epoch 783/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5192e-05 - mae: 0.0050 - mse: 4.5192e-05 - val_loss: 9.2401e-04 - val_mae: 0.0088 - val_mse: 9.2401e-04\n",
      "Epoch 784/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.9054e-05 - mae: 0.0047 - mse: 3.9054e-05 - val_loss: 9.4178e-04 - val_mae: 0.0103 - val_mse: 9.4178e-04\n",
      "Epoch 785/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2579e-05 - mae: 0.0049 - mse: 4.2579e-05 - val_loss: 9.6494e-04 - val_mae: 0.0109 - val_mse: 9.6494e-04\n",
      "Epoch 786/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8330e-05 - mae: 0.0050 - mse: 4.8330e-05 - val_loss: 9.5425e-04 - val_mae: 0.0103 - val_mse: 9.5425e-04\n",
      "Epoch 787/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.1306e-05 - mae: 0.0047 - mse: 4.1306e-05 - val_loss: 9.4620e-04 - val_mae: 0.0093 - val_mse: 9.4620e-04\n",
      "Epoch 788/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4974e-05 - mae: 0.0043 - mse: 3.4974e-05 - val_loss: 9.2764e-04 - val_mae: 0.0088 - val_mse: 9.2764e-04\n",
      "Epoch 789/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9550e-05 - mae: 0.0039 - mse: 2.9550e-05 - val_loss: 9.4792e-04 - val_mae: 0.0094 - val_mse: 9.4792e-04\n",
      "Epoch 790/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7793e-05 - mae: 0.0038 - mse: 2.7793e-05 - val_loss: 9.4596e-04 - val_mae: 0.0094 - val_mse: 9.4596e-04\n",
      "Epoch 791/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8895e-05 - mae: 0.0038 - mse: 2.8895e-05 - val_loss: 9.8240e-04 - val_mae: 0.0093 - val_mse: 9.8240e-04\n",
      "Epoch 792/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9233e-05 - mae: 0.0038 - mse: 2.9233e-05 - val_loss: 9.3908e-04 - val_mae: 0.0091 - val_mse: 9.3908e-04\n",
      "Epoch 793/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6497e-05 - mae: 0.0037 - mse: 2.6497e-05 - val_loss: 9.8140e-04 - val_mae: 0.0088 - val_mse: 9.8140e-04\n",
      "Epoch 794/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4190e-05 - mae: 0.0042 - mse: 3.4190e-05 - val_loss: 9.4732e-04 - val_mae: 0.0086 - val_mse: 9.4732e-04\n",
      "Epoch 795/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2829e-05 - mae: 0.0040 - mse: 3.2829e-05 - val_loss: 9.4828e-04 - val_mae: 0.0093 - val_mse: 9.4828e-04\n",
      "Epoch 796/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6580e-05 - mae: 0.0044 - mse: 3.6580e-05 - val_loss: 9.7229e-04 - val_mae: 0.0109 - val_mse: 9.7229e-04\n",
      "Epoch 797/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6574e-05 - mae: 0.0044 - mse: 3.6574e-05 - val_loss: 9.8682e-04 - val_mae: 0.0108 - val_mse: 9.8682e-04\n",
      "Epoch 798/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.4343e-05 - mae: 0.0042 - mse: 3.4343e-05 - val_loss: 9.4306e-04 - val_mae: 0.0093 - val_mse: 9.4306e-04\n",
      "Epoch 799/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4559e-05 - mae: 0.0043 - mse: 3.4559e-05 - val_loss: 9.8559e-04 - val_mae: 0.0102 - val_mse: 9.8559e-04\n",
      "Epoch 800/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2501e-05 - mae: 0.0041 - mse: 3.2501e-05 - val_loss: 9.6794e-04 - val_mae: 0.0090 - val_mse: 9.6794e-04\n",
      "Epoch 801/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1520e-05 - mae: 0.0040 - mse: 3.1520e-05 - val_loss: 9.2958e-04 - val_mae: 0.0084 - val_mse: 9.2958e-04\n",
      "Epoch 802/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7692e-05 - mae: 0.0038 - mse: 2.7692e-05 - val_loss: 9.5363e-04 - val_mae: 0.0087 - val_mse: 9.5363e-04\n",
      "Epoch 803/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2813e-05 - mae: 0.0036 - mse: 2.2813e-05 - val_loss: 9.3374e-04 - val_mae: 0.0088 - val_mse: 9.3374e-04\n",
      "Epoch 804/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.7141e-05 - mae: 0.0031 - mse: 1.7141e-05 - val_loss: 9.6549e-04 - val_mae: 0.0082 - val_mse: 9.6549e-04\n",
      "Epoch 805/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3937e-05 - mae: 0.0027 - mse: 1.3937e-05 - val_loss: 9.4498e-04 - val_mae: 0.0083 - val_mse: 9.4498e-04\n",
      "Epoch 806/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2454e-05 - mae: 0.0027 - mse: 1.2454e-05 - val_loss: 9.5056e-04 - val_mae: 0.0085 - val_mse: 9.5056e-04\n",
      "Epoch 807/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2846e-05 - mae: 0.0027 - mse: 1.2846e-05 - val_loss: 9.3014e-04 - val_mae: 0.0086 - val_mse: 9.3014e-04\n",
      "Epoch 808/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3035e-05 - mae: 0.0027 - mse: 1.3035e-05 - val_loss: 9.3801e-04 - val_mae: 0.0081 - val_mse: 9.3801e-04\n",
      "Epoch 809/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1912e-05 - mae: 0.0027 - mse: 1.1912e-05 - val_loss: 9.1837e-04 - val_mae: 0.0075 - val_mse: 9.1837e-04\n",
      "Epoch 810/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0140e-05 - mae: 0.0024 - mse: 1.0140e-05 - val_loss: 9.2871e-04 - val_mae: 0.0075 - val_mse: 9.2871e-04\n",
      "Epoch 811/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.2545e-06 - mae: 0.0022 - mse: 8.2545e-06 - val_loss: 9.3911e-04 - val_mae: 0.0077 - val_mse: 9.3911e-04\n",
      "Epoch 812/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9851e-06 - mae: 0.0020 - mse: 6.9851e-06 - val_loss: 9.3160e-04 - val_mae: 0.0078 - val_mse: 9.3160e-04\n",
      "Epoch 813/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8459e-06 - mae: 0.0021 - mse: 7.8459e-06 - val_loss: 9.2332e-04 - val_mae: 0.0072 - val_mse: 9.2332e-04\n",
      "Epoch 814/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9457e-06 - mae: 0.0019 - mse: 6.9457e-06 - val_loss: 9.3188e-04 - val_mae: 0.0072 - val_mse: 9.3188e-04\n",
      "Epoch 815/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9490e-06 - mae: 0.0019 - mse: 6.9490e-06 - val_loss: 9.2675e-04 - val_mae: 0.0072 - val_mse: 9.2675e-04\n",
      "Epoch 816/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1156e-06 - mae: 0.0018 - mse: 6.1156e-06 - val_loss: 9.2337e-04 - val_mae: 0.0071 - val_mse: 9.2337e-04\n",
      "Epoch 817/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.7115e-06 - mae: 0.0017 - mse: 5.7115e-06 - val_loss: 9.2818e-04 - val_mae: 0.0071 - val_mse: 9.2818e-04\n",
      "Epoch 818/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.6836e-06 - mae: 0.0016 - mse: 4.6836e-06 - val_loss: 9.3243e-04 - val_mae: 0.0072 - val_mse: 9.3243e-04\n",
      "Epoch 819/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.8944e-06 - mae: 0.0017 - mse: 5.8944e-06 - val_loss: 9.2494e-04 - val_mae: 0.0071 - val_mse: 9.2494e-04\n",
      "Epoch 820/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.6733e-06 - mae: 0.0017 - mse: 5.6733e-06 - val_loss: 9.2830e-04 - val_mae: 0.0072 - val_mse: 9.2830e-04\n",
      "Epoch 821/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4383e-06 - mae: 0.0017 - mse: 5.4383e-06 - val_loss: 9.2643e-04 - val_mae: 0.0071 - val_mse: 9.2643e-04\n",
      "Epoch 822/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1781e-06 - mae: 0.0016 - mse: 5.1781e-06 - val_loss: 9.2896e-04 - val_mae: 0.0070 - val_mse: 9.2896e-04\n",
      "Epoch 823/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9273e-06 - mae: 0.0016 - mse: 4.9273e-06 - val_loss: 9.3021e-04 - val_mae: 0.0072 - val_mse: 9.3021e-04\n",
      "Epoch 824/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.5997e-06 - mae: 0.0017 - mse: 5.5997e-06 - val_loss: 9.3225e-04 - val_mae: 0.0077 - val_mse: 9.3225e-04\n",
      "Epoch 825/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.7186e-06 - mae: 0.0018 - mse: 7.7186e-06 - val_loss: 9.3462e-04 - val_mae: 0.0073 - val_mse: 9.3462e-04\n",
      "Epoch 826/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.4823e-06 - mae: 0.0018 - mse: 7.4823e-06 - val_loss: 9.2550e-04 - val_mae: 0.0071 - val_mse: 9.2550e-04\n",
      "Epoch 827/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.7059e-06 - mae: 0.0017 - mse: 6.7059e-06 - val_loss: 9.3219e-04 - val_mae: 0.0075 - val_mse: 9.3219e-04\n",
      "Epoch 828/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.7459e-06 - mae: 0.0018 - mse: 6.7459e-06 - val_loss: 9.2096e-04 - val_mae: 0.0072 - val_mse: 9.2096e-04\n",
      "Epoch 829/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.0621e-06 - mae: 0.0018 - mse: 7.0621e-06 - val_loss: 9.4484e-04 - val_mae: 0.0074 - val_mse: 9.4484e-04\n",
      "Epoch 830/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.9867e-06 - mae: 0.0018 - mse: 6.9867e-06 - val_loss: 9.2000e-04 - val_mae: 0.0074 - val_mse: 9.2000e-04\n",
      "Epoch 831/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.6194e-06 - mae: 0.0018 - mse: 6.6194e-06 - val_loss: 9.3412e-04 - val_mae: 0.0076 - val_mse: 9.3412e-04\n",
      "Epoch 832/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.6075e-06 - mae: 0.0019 - mse: 7.6075e-06 - val_loss: 9.2427e-04 - val_mae: 0.0070 - val_mse: 9.2427e-04\n",
      "Epoch 833/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.6832e-06 - mae: 0.0017 - mse: 5.6832e-06 - val_loss: 9.2762e-04 - val_mae: 0.0072 - val_mse: 9.2762e-04\n",
      "Epoch 834/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.8459e-06 - mae: 0.0018 - mse: 6.8459e-06 - val_loss: 9.2976e-04 - val_mae: 0.0075 - val_mse: 9.2976e-04\n",
      "Epoch 835/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8395e-06 - mae: 0.0020 - mse: 7.8395e-06 - val_loss: 9.3262e-04 - val_mae: 0.0075 - val_mse: 9.3262e-04\n",
      "Epoch 836/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0117e-06 - mae: 0.0020 - mse: 8.0117e-06 - val_loss: 9.3038e-04 - val_mae: 0.0074 - val_mse: 9.3038e-04\n",
      "Epoch 837/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.2495e-06 - mae: 0.0019 - mse: 7.2495e-06 - val_loss: 9.2453e-04 - val_mae: 0.0073 - val_mse: 9.2453e-04\n",
      "Epoch 838/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 7.0657e-06 - mae: 0.0019 - mse: 7.0657e-06 - val_loss: 9.2900e-04 - val_mae: 0.0073 - val_mse: 9.2900e-04\n",
      "Epoch 839/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.8069e-06 - mae: 0.0017 - mse: 5.8069e-06 - val_loss: 9.2125e-04 - val_mae: 0.0072 - val_mse: 9.2125e-04\n",
      "Epoch 840/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.5420e-06 - mae: 0.0017 - mse: 5.5420e-06 - val_loss: 9.2759e-04 - val_mae: 0.0071 - val_mse: 9.2759e-04\n",
      "Epoch 841/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2480e-06 - mae: 0.0017 - mse: 5.2480e-06 - val_loss: 9.1833e-04 - val_mae: 0.0070 - val_mse: 9.1833e-04\n",
      "Epoch 842/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3439e-06 - mae: 0.0016 - mse: 5.3439e-06 - val_loss: 9.3422e-04 - val_mae: 0.0074 - val_mse: 9.3422e-04\n",
      "Epoch 843/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0774e-06 - mae: 0.0017 - mse: 6.0774e-06 - val_loss: 9.2676e-04 - val_mae: 0.0071 - val_mse: 9.2676e-04\n",
      "Epoch 844/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5682e-06 - mae: 0.0017 - mse: 5.5682e-06 - val_loss: 9.3826e-04 - val_mae: 0.0076 - val_mse: 9.3826e-04\n",
      "Epoch 845/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.8999e-06 - mae: 0.0018 - mse: 6.8999e-06 - val_loss: 9.3191e-04 - val_mae: 0.0071 - val_mse: 9.3191e-04\n",
      "Epoch 846/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5862e-06 - mae: 0.0017 - mse: 6.5862e-06 - val_loss: 9.2858e-04 - val_mae: 0.0073 - val_mse: 9.2858e-04\n",
      "Epoch 847/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1419e-06 - mae: 0.0018 - mse: 7.1419e-06 - val_loss: 9.4208e-04 - val_mae: 0.0076 - val_mse: 9.4208e-04\n",
      "Epoch 848/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.1386e-06 - mae: 0.0021 - mse: 9.1386e-06 - val_loss: 9.2029e-04 - val_mae: 0.0074 - val_mse: 9.2029e-04\n",
      "Epoch 849/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9680e-06 - mae: 0.0020 - mse: 8.9680e-06 - val_loss: 9.4007e-04 - val_mae: 0.0076 - val_mse: 9.4007e-04\n",
      "Epoch 850/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9878e-06 - mae: 0.0021 - mse: 9.9878e-06 - val_loss: 9.3951e-04 - val_mae: 0.0081 - val_mse: 9.3951e-04\n",
      "Epoch 851/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1990e-05 - mae: 0.0024 - mse: 1.1990e-05 - val_loss: 9.4856e-04 - val_mae: 0.0078 - val_mse: 9.4856e-04\n",
      "Epoch 852/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1957e-05 - mae: 0.0024 - mse: 1.1957e-05 - val_loss: 9.4420e-04 - val_mae: 0.0081 - val_mse: 9.4420e-04\n",
      "Epoch 853/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2318e-05 - mae: 0.0025 - mse: 1.2318e-05 - val_loss: 9.3149e-04 - val_mae: 0.0078 - val_mse: 9.3149e-04\n",
      "Epoch 854/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2092e-05 - mae: 0.0025 - mse: 1.2092e-05 - val_loss: 9.2114e-04 - val_mae: 0.0080 - val_mse: 9.2114e-04\n",
      "Epoch 855/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2710e-05 - mae: 0.0025 - mse: 1.2710e-05 - val_loss: 9.4241e-04 - val_mae: 0.0080 - val_mse: 9.4241e-04\n",
      "Epoch 856/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5837e-05 - mae: 0.0029 - mse: 1.5837e-05 - val_loss: 9.9012e-04 - val_mae: 0.0094 - val_mse: 9.9012e-04\n",
      "Epoch 857/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6563e-05 - mae: 0.0034 - mse: 2.6563e-05 - val_loss: 9.9557e-04 - val_mae: 0.0101 - val_mse: 9.9557e-04\n",
      "Epoch 858/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.3961e-05 - mae: 0.0041 - mse: 4.3961e-05 - val_loss: 9.6342e-04 - val_mae: 0.0104 - val_mse: 9.6342e-04\n",
      "Epoch 859/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5418e-05 - mae: 0.0044 - mse: 4.5418e-05 - val_loss: 9.2846e-04 - val_mae: 0.0089 - val_mse: 9.2846e-04\n",
      "Epoch 860/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.2506e-05 - mae: 0.0040 - mse: 3.2506e-05 - val_loss: 9.5784e-04 - val_mae: 0.0094 - val_mse: 9.5784e-04\n",
      "Epoch 861/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4008e-05 - mae: 0.0041 - mse: 3.4008e-05 - val_loss: 9.6145e-04 - val_mae: 0.0090 - val_mse: 9.6145e-04\n",
      "Epoch 862/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7975e-05 - mae: 0.0039 - mse: 2.7975e-05 - val_loss: 9.6324e-04 - val_mae: 0.0096 - val_mse: 9.6324e-04\n",
      "Epoch 863/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0373e-05 - mae: 0.0040 - mse: 3.0373e-05 - val_loss: 0.0010 - val_mae: 0.0110 - val_mse: 0.0010\n",
      "Epoch 864/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1877e-05 - mae: 0.0040 - mse: 3.1877e-05 - val_loss: 9.7881e-04 - val_mae: 0.0102 - val_mse: 9.7881e-04\n",
      "Epoch 865/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0651e-05 - mae: 0.0040 - mse: 3.0651e-05 - val_loss: 9.6326e-04 - val_mae: 0.0093 - val_mse: 9.6326e-04\n",
      "Epoch 866/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9268e-05 - mae: 0.0040 - mse: 2.9268e-05 - val_loss: 9.7042e-04 - val_mae: 0.0099 - val_mse: 9.7042e-04\n",
      "Epoch 867/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3156e-05 - mae: 0.0043 - mse: 3.3156e-05 - val_loss: 9.7110e-04 - val_mae: 0.0104 - val_mse: 9.7110e-04\n",
      "Epoch 868/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2675e-05 - mae: 0.0047 - mse: 4.2675e-05 - val_loss: 9.8477e-04 - val_mae: 0.0103 - val_mse: 9.8477e-04\n",
      "Epoch 869/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9813e-05 - mae: 0.0049 - mse: 4.9813e-05 - val_loss: 0.0010 - val_mae: 0.0114 - val_mse: 0.0010\n",
      "Epoch 870/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.1720e-05 - mae: 0.0062 - mse: 8.1720e-05 - val_loss: 0.0012 - val_mae: 0.0155 - val_mse: 0.0012\n",
      "Epoch 871/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4765e-04 - mae: 0.0080 - mse: 1.4765e-04 - val_loss: 0.0012 - val_mae: 0.0141 - val_mse: 0.0012\n",
      "Epoch 872/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3510e-04 - mae: 0.0080 - mse: 1.3510e-04 - val_loss: 0.0011 - val_mae: 0.0140 - val_mse: 0.0011\n",
      "Epoch 873/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4139e-04 - mae: 0.0084 - mse: 1.4139e-04 - val_loss: 0.0011 - val_mae: 0.0142 - val_mse: 0.0011\n",
      "Epoch 874/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.2914e-04 - mae: 0.0081 - mse: 1.2914e-04 - val_loss: 0.0010 - val_mae: 0.0133 - val_mse: 0.0010\n",
      "Epoch 875/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1373e-04 - mae: 0.0079 - mse: 1.1373e-04 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 876/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.2680e-05 - mae: 0.0069 - mse: 9.2680e-05 - val_loss: 0.0010 - val_mae: 0.0131 - val_mse: 0.0010\n",
      "Epoch 877/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6102e-05 - mae: 0.0070 - mse: 9.6102e-05 - val_loss: 0.0011 - val_mae: 0.0138 - val_mse: 0.0011\n",
      "Epoch 878/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1676e-04 - mae: 0.0079 - mse: 1.1676e-04 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 879/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1104e-04 - mae: 0.0079 - mse: 1.1104e-04 - val_loss: 0.0011 - val_mae: 0.0133 - val_mse: 0.0011\n",
      "Epoch 880/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0770e-04 - mae: 0.0077 - mse: 1.0770e-04 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 881/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.1959e-04 - mae: 0.0074 - mse: 1.1959e-04 - val_loss: 0.0011 - val_mae: 0.0138 - val_mse: 0.0011\n",
      "Epoch 882/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.4395e-04 - mae: 0.0081 - mse: 1.4395e-04 - val_loss: 0.0011 - val_mae: 0.0138 - val_mse: 0.0011\n",
      "Epoch 883/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2497e-04 - mae: 0.0078 - mse: 1.2497e-04 - val_loss: 0.0012 - val_mae: 0.0139 - val_mse: 0.0012\n",
      "Epoch 884/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6012e-04 - mae: 0.0088 - mse: 1.6012e-04 - val_loss: 0.0011 - val_mae: 0.0155 - val_mse: 0.0011\n",
      "Epoch 885/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4024e-04 - mae: 0.0103 - mse: 2.4024e-04 - val_loss: 0.0014 - val_mae: 0.0184 - val_mse: 0.0014\n",
      "Epoch 886/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4337e-04 - mae: 0.0107 - mse: 2.4337e-04 - val_loss: 0.0011 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 887/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7954e-04 - mae: 0.0096 - mse: 1.7954e-04 - val_loss: 0.0011 - val_mae: 0.0147 - val_mse: 0.0011\n",
      "Epoch 888/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6659e-04 - mae: 0.0097 - mse: 1.6659e-04 - val_loss: 0.0011 - val_mae: 0.0149 - val_mse: 0.0011\n",
      "Epoch 889/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6062e-04 - mae: 0.0095 - mse: 1.6062e-04 - val_loss: 0.0011 - val_mae: 0.0146 - val_mse: 0.0011\n",
      "Epoch 890/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3616e-04 - mae: 0.0088 - mse: 1.3616e-04 - val_loss: 0.0010 - val_mae: 0.0138 - val_mse: 0.0010\n",
      "Epoch 891/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3955e-04 - mae: 0.0086 - mse: 1.3955e-04 - val_loss: 0.0011 - val_mae: 0.0124 - val_mse: 0.0011\n",
      "Epoch 892/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2951e-04 - mae: 0.0081 - mse: 1.2951e-04 - val_loss: 0.0010 - val_mae: 0.0125 - val_mse: 0.0010\n",
      "Epoch 893/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1003e-04 - mae: 0.0075 - mse: 1.1003e-04 - val_loss: 0.0011 - val_mae: 0.0121 - val_mse: 0.0011\n",
      "Epoch 894/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0441e-04 - mae: 0.0072 - mse: 1.0441e-04 - val_loss: 0.0011 - val_mae: 0.0140 - val_mse: 0.0011\n",
      "Epoch 895/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4379e-04 - mae: 0.0087 - mse: 1.4379e-04 - val_loss: 0.0012 - val_mae: 0.0148 - val_mse: 0.0012\n",
      "Epoch 896/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2.1794e-04 - mae: 0.0102 - mse: 2.1794e-04 - val_loss: 0.0012 - val_mae: 0.0184 - val_mse: 0.0012\n",
      "Epoch 897/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.8404e-04 - mae: 0.0127 - mse: 3.8404e-04 - val_loss: 0.0013 - val_mae: 0.0175 - val_mse: 0.0013\n",
      "Epoch 898/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8233e-04 - mae: 0.0114 - mse: 2.8233e-04 - val_loss: 0.0011 - val_mae: 0.0148 - val_mse: 0.0011\n",
      "Epoch 899/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4819e-04 - mae: 0.0111 - mse: 2.4819e-04 - val_loss: 0.0014 - val_mae: 0.0198 - val_mse: 0.0014\n",
      "Epoch 900/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4229e-04 - mae: 0.0136 - mse: 3.4229e-04 - val_loss: 0.0011 - val_mae: 0.0169 - val_mse: 0.0011\n",
      "Epoch 901/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3605e-04 - mae: 0.0132 - mse: 3.3605e-04 - val_loss: 0.0012 - val_mae: 0.0169 - val_mse: 0.0012\n",
      "Epoch 902/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7381e-04 - mae: 0.0119 - mse: 2.7381e-04 - val_loss: 0.0012 - val_mae: 0.0164 - val_mse: 0.0012\n",
      "Epoch 903/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5978e-04 - mae: 0.0136 - mse: 3.5978e-04 - val_loss: 0.0013 - val_mae: 0.0182 - val_mse: 0.0013\n",
      "Epoch 904/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.0362e-04 - mae: 0.0127 - mse: 3.0362e-04 - val_loss: 0.0014 - val_mae: 0.0203 - val_mse: 0.0014\n",
      "Epoch 905/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5339e-04 - mae: 0.0149 - mse: 4.5339e-04 - val_loss: 0.0015 - val_mae: 0.0215 - val_mse: 0.0015\n",
      "Epoch 906/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9953e-04 - mae: 0.0158 - mse: 4.9953e-04 - val_loss: 0.0016 - val_mae: 0.0218 - val_mse: 0.0016\n",
      "Epoch 907/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.8810e-04 - mae: 0.0149 - mse: 4.8810e-04 - val_loss: 0.0012 - val_mae: 0.0179 - val_mse: 0.0012\n",
      "Epoch 908/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.6829e-04 - mae: 0.0152 - mse: 4.6829e-04 - val_loss: 0.0013 - val_mae: 0.0192 - val_mse: 0.0013\n",
      "Epoch 909/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9119e-04 - mae: 0.0164 - mse: 4.9119e-04 - val_loss: 0.0015 - val_mae: 0.0224 - val_mse: 0.0015\n",
      "Epoch 910/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0813e-04 - mae: 0.0175 - mse: 5.0813e-04 - val_loss: 0.0012 - val_mae: 0.0162 - val_mse: 0.0012\n",
      "Epoch 911/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6486e-04 - mae: 0.0139 - mse: 3.6486e-04 - val_loss: 0.0014 - val_mae: 0.0193 - val_mse: 0.0014\n",
      "Epoch 912/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0610e-04 - mae: 0.0154 - mse: 4.0610e-04 - val_loss: 0.0012 - val_mae: 0.0188 - val_mse: 0.0012\n",
      "Epoch 913/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3907e-04 - mae: 0.0144 - mse: 3.3907e-04 - val_loss: 0.0011 - val_mae: 0.0174 - val_mse: 0.0011\n",
      "Epoch 914/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1700e-04 - mae: 0.0135 - mse: 3.1700e-04 - val_loss: 0.0010 - val_mae: 0.0150 - val_mse: 0.0010\n",
      "Epoch 915/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4507e-04 - mae: 0.0120 - mse: 2.4507e-04 - val_loss: 0.0012 - val_mae: 0.0169 - val_mse: 0.0012\n",
      "Epoch 916/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2317e-04 - mae: 0.0115 - mse: 2.2317e-04 - val_loss: 0.0011 - val_mae: 0.0161 - val_mse: 0.0011\n",
      "Epoch 917/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2588e-04 - mae: 0.0111 - mse: 2.2588e-04 - val_loss: 0.0010 - val_mae: 0.0134 - val_mse: 0.0010\n",
      "Epoch 918/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.6868e-04 - mae: 0.0098 - mse: 1.6868e-04 - val_loss: 0.0012 - val_mae: 0.0148 - val_mse: 0.0012\n",
      "Epoch 919/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1624e-04 - mae: 0.0109 - mse: 2.1624e-04 - val_loss: 0.0011 - val_mae: 0.0150 - val_mse: 0.0011\n",
      "Epoch 920/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5822e-04 - mae: 0.0112 - mse: 2.5822e-04 - val_loss: 0.0012 - val_mae: 0.0179 - val_mse: 0.0012\n",
      "Epoch 921/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.4337e-04 - mae: 0.0110 - mse: 2.4337e-04 - val_loss: 0.0013 - val_mae: 0.0179 - val_mse: 0.0013\n",
      "Epoch 922/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.7325e-04 - mae: 0.0124 - mse: 3.7325e-04 - val_loss: 0.0011 - val_mae: 0.0147 - val_mse: 0.0011\n",
      "Epoch 923/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7329e-04 - mae: 0.0132 - mse: 3.7329e-04 - val_loss: 0.0012 - val_mae: 0.0172 - val_mse: 0.0012\n",
      "Epoch 924/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9163e-04 - mae: 0.0187 - mse: 8.9163e-04 - val_loss: 0.0020 - val_mae: 0.0263 - val_mse: 0.0020\n",
      "Epoch 925/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0012 - mae: 0.0201 - mse: 0.0012 - val_loss: 0.0021 - val_mae: 0.0269 - val_mse: 0.0021\n",
      "Epoch 926/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.0301e-04 - mae: 0.0189 - mse: 8.0301e-04 - val_loss: 0.0021 - val_mae: 0.0244 - val_mse: 0.0021\n",
      "Epoch 927/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.5202e-04 - mae: 0.0172 - mse: 6.5202e-04 - val_loss: 0.0019 - val_mae: 0.0259 - val_mse: 0.0019\n",
      "Epoch 928/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.7967e-04 - mae: 0.0176 - mse: 6.7967e-04 - val_loss: 0.0014 - val_mae: 0.0208 - val_mse: 0.0014\n",
      "Epoch 929/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4392e-04 - mae: 0.0178 - mse: 5.4392e-04 - val_loss: 0.0015 - val_mae: 0.0215 - val_mse: 0.0015\n",
      "Epoch 930/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4015e-04 - mae: 0.0180 - mse: 5.4015e-04 - val_loss: 0.0012 - val_mae: 0.0184 - val_mse: 0.0012\n",
      "Epoch 931/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.1445e-04 - mae: 0.0155 - mse: 4.1445e-04 - val_loss: 0.0012 - val_mae: 0.0171 - val_mse: 0.0012\n",
      "Epoch 932/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.2402e-04 - mae: 0.0151 - mse: 4.2402e-04 - val_loss: 0.0013 - val_mae: 0.0192 - val_mse: 0.0013\n",
      "Epoch 933/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.3970e-04 - mae: 0.0139 - mse: 3.3970e-04 - val_loss: 0.0013 - val_mae: 0.0189 - val_mse: 0.0013\n",
      "Epoch 934/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5444e-04 - mae: 0.0139 - mse: 3.5444e-04 - val_loss: 0.0014 - val_mae: 0.0193 - val_mse: 0.0014\n",
      "Epoch 935/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4997e-04 - mae: 0.0141 - mse: 3.4997e-04 - val_loss: 0.0012 - val_mae: 0.0168 - val_mse: 0.0012\n",
      "Epoch 936/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.1426e-04 - mae: 0.0149 - mse: 4.1426e-04 - val_loss: 0.0013 - val_mae: 0.0175 - val_mse: 0.0013\n",
      "Epoch 937/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1386e-04 - mae: 0.0149 - mse: 4.1386e-04 - val_loss: 0.0012 - val_mae: 0.0183 - val_mse: 0.0012\n",
      "Epoch 938/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1227e-04 - mae: 0.0149 - mse: 4.1227e-04 - val_loss: 0.0013 - val_mae: 0.0180 - val_mse: 0.0013\n",
      "Epoch 939/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.2828e-04 - mae: 0.0135 - mse: 3.2828e-04 - val_loss: 0.0013 - val_mae: 0.0182 - val_mse: 0.0013\n",
      "Epoch 940/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.8773e-04 - mae: 0.0133 - mse: 2.8773e-04 - val_loss: 0.0012 - val_mae: 0.0174 - val_mse: 0.0012\n",
      "Epoch 941/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4313e-04 - mae: 0.0121 - mse: 2.4313e-04 - val_loss: 0.0011 - val_mae: 0.0168 - val_mse: 0.0011\n",
      "Epoch 942/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.4262e-04 - mae: 0.0122 - mse: 2.4262e-04 - val_loss: 0.0012 - val_mae: 0.0157 - val_mse: 0.0012\n",
      "Epoch 943/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6313e-04 - mae: 0.0099 - mse: 1.6313e-04 - val_loss: 0.0011 - val_mae: 0.0152 - val_mse: 0.0011\n",
      "Epoch 944/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9525e-04 - mae: 0.0102 - mse: 1.9525e-04 - val_loss: 0.0011 - val_mae: 0.0142 - val_mse: 0.0011\n",
      "Epoch 945/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9348e-04 - mae: 0.0102 - mse: 1.9348e-04 - val_loss: 0.0011 - val_mae: 0.0130 - val_mse: 0.0011\n",
      "Epoch 946/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7766e-04 - mae: 0.0118 - mse: 2.7766e-04 - val_loss: 0.0012 - val_mae: 0.0152 - val_mse: 0.0012\n",
      "Epoch 947/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0462e-04 - mae: 0.0131 - mse: 3.0462e-04 - val_loss: 0.0013 - val_mae: 0.0194 - val_mse: 0.0013\n",
      "Epoch 948/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3358e-04 - mae: 0.0143 - mse: 3.3358e-04 - val_loss: 0.0016 - val_mae: 0.0239 - val_mse: 0.0016\n",
      "Epoch 949/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.4924e-04 - mae: 0.0141 - mse: 3.4924e-04 - val_loss: 0.0015 - val_mae: 0.0216 - val_mse: 0.0015\n",
      "Epoch 950/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0131e-04 - mae: 0.0134 - mse: 3.0131e-04 - val_loss: 0.0012 - val_mae: 0.0157 - val_mse: 0.0012\n",
      "Epoch 951/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7853e-04 - mae: 0.0121 - mse: 2.7853e-04 - val_loss: 0.0014 - val_mae: 0.0174 - val_mse: 0.0014\n",
      "Epoch 952/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2687e-04 - mae: 0.0112 - mse: 2.2687e-04 - val_loss: 0.0012 - val_mae: 0.0157 - val_mse: 0.0012\n",
      "Epoch 953/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1044e-04 - mae: 0.0108 - mse: 2.1044e-04 - val_loss: 0.0013 - val_mae: 0.0175 - val_mse: 0.0013\n",
      "Epoch 954/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8869e-04 - mae: 0.0101 - mse: 1.8869e-04 - val_loss: 0.0011 - val_mae: 0.0144 - val_mse: 0.0011\n",
      "Epoch 955/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5301e-04 - mae: 0.0089 - mse: 1.5301e-04 - val_loss: 0.0012 - val_mae: 0.0151 - val_mse: 0.0012\n",
      "Epoch 956/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.5349e-04 - mae: 0.0090 - mse: 1.5349e-04 - val_loss: 0.0011 - val_mae: 0.0134 - val_mse: 0.0011\n",
      "Epoch 957/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9213e-04 - mae: 0.0094 - mse: 1.9213e-04 - val_loss: 0.0012 - val_mae: 0.0152 - val_mse: 0.0012\n",
      "Epoch 958/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7666e-04 - mae: 0.0121 - mse: 2.7666e-04 - val_loss: 0.0011 - val_mae: 0.0150 - val_mse: 0.0011\n",
      "Epoch 959/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9787e-04 - mae: 0.0129 - mse: 2.9787e-04 - val_loss: 0.0012 - val_mae: 0.0147 - val_mse: 0.0012\n",
      "Epoch 960/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3630e-04 - mae: 0.0115 - mse: 2.3630e-04 - val_loss: 0.0012 - val_mae: 0.0164 - val_mse: 0.0012\n",
      "Epoch 961/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7864e-04 - mae: 0.0124 - mse: 2.7864e-04 - val_loss: 0.0014 - val_mae: 0.0186 - val_mse: 0.0014\n",
      "Epoch 962/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5808e-04 - mae: 0.0122 - mse: 2.5808e-04 - val_loss: 0.0012 - val_mae: 0.0172 - val_mse: 0.0012\n",
      "Epoch 963/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0803e-04 - mae: 0.0111 - mse: 2.0803e-04 - val_loss: 0.0012 - val_mae: 0.0173 - val_mse: 0.0012\n",
      "Epoch 964/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8786e-04 - mae: 0.0103 - mse: 1.8786e-04 - val_loss: 0.0011 - val_mae: 0.0153 - val_mse: 0.0011\n",
      "Epoch 965/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8265e-04 - mae: 0.0101 - mse: 1.8265e-04 - val_loss: 0.0011 - val_mae: 0.0149 - val_mse: 0.0011\n",
      "Epoch 966/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.4246e-04 - mae: 0.0090 - mse: 1.4246e-04 - val_loss: 9.9047e-04 - val_mae: 0.0117 - val_mse: 9.9047e-04\n",
      "Epoch 967/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.9944e-05 - mae: 0.0067 - mse: 7.9944e-05 - val_loss: 0.0010 - val_mae: 0.0116 - val_mse: 0.0010\n",
      "Epoch 968/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.9479e-05 - mae: 0.0063 - mse: 6.9479e-05 - val_loss: 0.0010 - val_mae: 0.0112 - val_mse: 0.0010\n",
      "Epoch 969/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3213e-05 - mae: 0.0059 - mse: 6.3213e-05 - val_loss: 0.0011 - val_mae: 0.0118 - val_mse: 0.0011\n",
      "Epoch 970/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.8310e-05 - mae: 0.0058 - mse: 5.8310e-05 - val_loss: 9.9381e-04 - val_mae: 0.0102 - val_mse: 9.9381e-04\n",
      "Epoch 971/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8758e-05 - mae: 0.0054 - mse: 4.8758e-05 - val_loss: 9.9568e-04 - val_mae: 0.0101 - val_mse: 9.9568e-04\n",
      "Epoch 972/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3167e-05 - mae: 0.0050 - mse: 4.3167e-05 - val_loss: 9.7158e-04 - val_mae: 0.0099 - val_mse: 9.7158e-04\n",
      "Epoch 973/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0349e-05 - mae: 0.0048 - mse: 4.0349e-05 - val_loss: 0.0010 - val_mae: 0.0109 - val_mse: 0.0010\n",
      "Epoch 974/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7968e-05 - mae: 0.0051 - mse: 4.7968e-05 - val_loss: 9.8665e-04 - val_mae: 0.0106 - val_mse: 9.8665e-04\n",
      "Epoch 975/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.5510e-05 - mae: 0.0050 - mse: 4.5510e-05 - val_loss: 0.0010 - val_mae: 0.0118 - val_mse: 0.0010\n",
      "Epoch 976/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3355e-05 - mae: 0.0054 - mse: 5.3355e-05 - val_loss: 0.0010 - val_mae: 0.0108 - val_mse: 0.0010\n",
      "Epoch 977/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0252e-05 - mae: 0.0055 - mse: 6.0252e-05 - val_loss: 0.0011 - val_mae: 0.0113 - val_mse: 0.0011\n",
      "Epoch 978/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.6383e-05 - mae: 0.0058 - mse: 7.6383e-05 - val_loss: 0.0011 - val_mae: 0.0127 - val_mse: 0.0011\n",
      "Epoch 979/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1149e-04 - mae: 0.0069 - mse: 1.1149e-04 - val_loss: 0.0012 - val_mae: 0.0142 - val_mse: 0.0012\n",
      "Epoch 980/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2243e-04 - mae: 0.0073 - mse: 1.2243e-04 - val_loss: 0.0011 - val_mae: 0.0131 - val_mse: 0.0011\n",
      "Epoch 981/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0813e-04 - mae: 0.0072 - mse: 1.0813e-04 - val_loss: 0.0010 - val_mae: 0.0120 - val_mse: 0.0010\n",
      "Epoch 982/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4715e-04 - mae: 0.0083 - mse: 1.4715e-04 - val_loss: 0.0011 - val_mae: 0.0135 - val_mse: 0.0011\n",
      "Epoch 983/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9747e-04 - mae: 0.0096 - mse: 1.9747e-04 - val_loss: 0.0012 - val_mae: 0.0151 - val_mse: 0.0012\n",
      "Epoch 984/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5802e-04 - mae: 0.0090 - mse: 1.5802e-04 - val_loss: 0.0011 - val_mae: 0.0142 - val_mse: 0.0011\n",
      "Epoch 985/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1187e-04 - mae: 0.0077 - mse: 1.1187e-04 - val_loss: 0.0011 - val_mae: 0.0128 - val_mse: 0.0011\n",
      "Epoch 986/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0631e-04 - mae: 0.0076 - mse: 1.0631e-04 - val_loss: 0.0011 - val_mae: 0.0132 - val_mse: 0.0011\n",
      "Epoch 987/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.3849e-05 - mae: 0.0068 - mse: 8.3849e-05 - val_loss: 0.0010 - val_mae: 0.0106 - val_mse: 0.0010\n",
      "Epoch 988/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 7.9866e-05 - mae: 0.0066 - mse: 7.9866e-05 - val_loss: 9.8013e-04 - val_mae: 0.0095 - val_mse: 9.8013e-04\n",
      "Epoch 989/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.1342e-05 - mae: 0.0058 - mse: 6.1342e-05 - val_loss: 0.0010 - val_mae: 0.0111 - val_mse: 0.0010\n",
      "Epoch 990/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.6423e-05 - mae: 0.0056 - mse: 5.6423e-05 - val_loss: 9.8769e-04 - val_mae: 0.0106 - val_mse: 9.8769e-04\n",
      "Epoch 991/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5267e-05 - mae: 0.0054 - mse: 5.5267e-05 - val_loss: 0.0010 - val_mae: 0.0102 - val_mse: 0.0010\n",
      "Epoch 992/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3611e-05 - mae: 0.0048 - mse: 4.3611e-05 - val_loss: 9.9111e-04 - val_mae: 0.0104 - val_mse: 9.9111e-04\n",
      "Epoch 993/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6117e-05 - mae: 0.0050 - mse: 4.6117e-05 - val_loss: 0.0010 - val_mae: 0.0099 - val_mse: 0.0010\n",
      "Epoch 994/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.5839e-05 - mae: 0.0050 - mse: 4.5839e-05 - val_loss: 9.7260e-04 - val_mae: 0.0100 - val_mse: 9.7260e-04\n",
      "Epoch 995/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2776e-05 - mae: 0.0047 - mse: 4.2776e-05 - val_loss: 9.7636e-04 - val_mae: 0.0092 - val_mse: 9.7636e-04\n",
      "Epoch 996/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8704e-05 - mae: 0.0045 - mse: 3.8704e-05 - val_loss: 9.8800e-04 - val_mae: 0.0092 - val_mse: 9.8800e-04\n",
      "Epoch 997/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.6928e-05 - mae: 0.0045 - mse: 4.6928e-05 - val_loss: 0.0010 - val_mae: 0.0092 - val_mse: 0.0010\n",
      "Epoch 998/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.8563e-05 - mae: 0.0043 - mse: 3.8563e-05 - val_loss: 0.0010 - val_mae: 0.0105 - val_mse: 0.0010\n",
      "Epoch 999/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.9200e-05 - mae: 0.0044 - mse: 3.9200e-05 - val_loss: 0.0010 - val_mae: 0.0103 - val_mse: 0.0010\n",
      "Epoch 1000/1000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.9945e-05 - mae: 0.0044 - mse: 3.9945e-05 - val_loss: 9.7959e-04 - val_mae: 0.0095 - val_mse: 9.7959e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "--- federated after local fine-tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/vnvjtlb516n5mswtv7rf58b80000gn/T/ipykernel_2013/2011710758.py:96: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k--\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo 55 plot in: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/federated_fd/TEST\n",
      "Plot salvati correttamente.\n",
      "Test MAE: 0.0097\n",
      "Test RMSE: 0.0334\n",
      "Test MAPE: 0.17%\n",
      "Test R2: 0.9992\n",
      "Valore medio del test set: 5.9393\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_AR-ACROPOLI_14-19-01/federated_fd_evaluation_log.json\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip(model, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_np = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    #plot_diagnosis_gradient(y_pred, y_test_np, max_samples_heatmap=10, scatter_sample_ratio=0.7)\n",
    "    evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/{name.replace(' ', '_').lower()}_evaluation_log.json\")\n",
    "    save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/{name.replace(\" \", \"_\").lower()}/TEST', prefix=\"pred_plot\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    if name == 'federated':\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=64, callbacks=[model_checkpoint_callback], validation_split=0.2)\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred)\n",
    "        print(f\"--- {name} after local fine-tuning ---\")\n",
    "        plot_diagnosis_gradient(y_pred, y_test_np, save_path=f\"{name}_pred_quality\", max_samples_heatmap=10, scatter_sample_ratio=0.7)\n",
    "        save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/{name.replace(\" \", \"_\").lower()}_fd/TEST', prefix=\"pred_plot\")\n",
    "        evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/{name.replace(' ', '_').lower()}_fd_evaluation_log.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
