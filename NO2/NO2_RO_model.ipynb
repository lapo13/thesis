{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80b337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import os, pickle, random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674923c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_after_QA = lambda s: s.split(\"QA_\", 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20627845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 16)\n"
     ]
    }
   ],
   "source": [
    "dati = pd.read_excel('/Users/lapotinacci/thesis/metric_datasets/NO2_dataset.xlsx')\n",
    "dati = dati[dati[\"serviceUri\"] == \"http://www.disit.org/km4city/resource/iot/orionUNIFI/DISIT/ARPAT_QA_PO-ROMA\"].copy()\n",
    "sensor_name = get_after_QA(dati[\"serviceUri\"].iloc[0])\n",
    "dati.drop(columns=[\"serviceUri\"], inplace=True)\n",
    "print(dati.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d394f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ora inizio esperimento: 14-19-09\n",
      "Giorno inizio esperimento: 2025-11-30\n",
      "Cartella esperimento creata: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09\n"
     ]
    }
   ],
   "source": [
    "# === Creazione cartella esperimento con timestamp ISO ===\n",
    "timestamp = datetime.now().strftime(\"%H-%M-%S\")\n",
    "print(f\"Ora inizio esperimento: {timestamp}\")\n",
    "day= datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Giorno inizio esperimento: {day}\")\n",
    "exp_dir = f\"../RISULTATI/{day}/esperimento_{sensor_name}_{timestamp}\"\n",
    "\n",
    "os.makedirs(exp_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Cartella esperimento creata: {exp_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7794e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "mask = ~dati['TTT'].str.contains(\"nan\", na=True)\n",
    "dtset_completo = dati[mask]\n",
    "\n",
    "dtset_completo['TTT'] = dtset_completo['TTT'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46880af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtra le righe dove la colonna TTT ha lunghezza 24, ed elimina tutte le colonne le cui osservazioni sono indipendenti dal giorno\n",
    "dtset_filtrato = dtset_completo[dtset_completo[\"TTT\"].apply(lambda x: len(x) == 24)].sample(frac=1).reset_index(drop=True)\n",
    "dtset_filtrato = dtset_filtrato[dtset_filtrato[\"type_of_TTT\"] == \"daily\"]\n",
    "len(dtset_filtrato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022b3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def is_useful_series(series, zero_ratio_thr=0.85, min_nonzero_value=0.1):\n",
    "    arr = np.array(series, dtype=float)\n",
    "    \n",
    "    # Serie troppo corta\n",
    "    if len(arr) <= 1:\n",
    "        return False\n",
    "    \n",
    "    # Troppi zeri\n",
    "    zero_ratio = (arr == 0).mean()\n",
    "    if zero_ratio >= zero_ratio_thr:\n",
    "        return False\n",
    "    \n",
    "    # Valore medio trascurabile (quasi zero)\n",
    "    mean_val = np.mean(arr)\n",
    "    if abs(mean_val) < min_nonzero_value:\n",
    "        return False\n",
    "    \n",
    "    # Se arriva qui, la serie ha valori significativi\n",
    "    return True\n",
    "\n",
    "# Applica filtro\n",
    "mask_useful = dtset_filtrato[\"TTT\"].apply(is_useful_series)\n",
    "df_useful = dtset_filtrato[mask_useful]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b897db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spezza_serie_in_colonne(df, colonna_stringa, prefix='col_'):\n",
    "    # --- Controllo colonna ---\n",
    "    if colonna_stringa not in df.columns:\n",
    "        raise ValueError(f\"La colonna '{colonna_stringa}' non esiste nel DataFrame\")\n",
    "\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # Estraggo la colonna contenente gli embedding\n",
    "    col = result_df.pop(colonna_stringa)\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for item in col:\n",
    "        if pd.isna(item) or item == \"\":\n",
    "            embeddings.append([])\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Parsing sicuro della stringa in lista Python\n",
    "            vett = ast.literal_eval(item)\n",
    "\n",
    "            # Se l’embedding è una numpy array o altro iterabile, lo converto in list\n",
    "            if not isinstance(vett, list):\n",
    "                vett = list(vett)\n",
    "\n",
    "            # Converto tutto in float\n",
    "            vett = [float(x) for x in vett]\n",
    "\n",
    "            embeddings.append(vett)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Errore nel parsing dell'elemento '{item}': {e}\")\n",
    "            embeddings.append([])\n",
    "\n",
    "    # --- Uniformo dimensione dei vettori ---\n",
    "    lengths = [len(v) for v in embeddings]\n",
    "    if not lengths:\n",
    "        raise ValueError(\"Nessun embedding valido nella colonna\")\n",
    "\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    embeddings_padded = [\n",
    "        v + [np.nan] * (max_len - len(v)) if len(v) < max_len else v\n",
    "        for v in embeddings\n",
    "    ]\n",
    "\n",
    "    # --- Creo DataFrame delle nuove colonne ---\n",
    "    colonne_embedding = pd.DataFrame(\n",
    "        embeddings_padded,\n",
    "        index=result_df.index,\n",
    "        columns=[f\"{prefix}{i}\" for i in range(max_len)]\n",
    "    )\n",
    "\n",
    "    # --- Merge col DataFrame originale ---\n",
    "    return pd.concat([result_df, colonne_embedding], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e1a7a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ttt in df_useful.TTT:\n",
    "    plt.plot(ttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d7bcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_df(df):\n",
    "    summary = pd.DataFrame({\n",
    "        'dtype': df.dtypes,\n",
    "        'n_missing': df.isna().sum(),\n",
    "        '%_missing': (df.isna().mean() * 100).round(2),\n",
    "        'n_unique': df.nunique(),\n",
    "        'top_value': df.mode().iloc[0],  # moda\n",
    "        'top_freq': [df[col].value_counts(dropna=True).iloc[0] if not df[col].value_counts(dropna=True).empty else None for col in df.columns],\n",
    "        'min': [df[col].min() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'max': [df[col].max() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'mean': [df[col].mean() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "        'std': [df[col].std() if pd.api.types.is_numeric_dtype(df[col]) else None for col in df.columns],\n",
    "    })\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0d224ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nella precedente sono state eliminate le colonne con Nan, tuttavia alcuni dataset dei sensori METRO hanno dei Nan in city e surface dunque vengono rimossi nel prcedente box\n",
    "\n",
    "categorical = [\n",
    "    'is_weekend'\n",
    "    ]\n",
    "\n",
    "#consiglio, per serie cicliche usare funzioni periodiche tipo seno coseno \n",
    "df_encoded = pd.get_dummies(df_useful\n",
    "                            , columns=categorical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1247ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "    print(f\"Salvato: {path}\")\n",
    "\n",
    "def load_pkl(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80bcd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/dataframe_PO-ROMA/filtered_dataframe.pkl\n"
     ]
    }
   ],
   "source": [
    "#codifica ciclica delle features e individuazione del'ora del giorno e della settimana \n",
    "\n",
    "def encode_time_features(df, start_col=\"interval_start\", end_col=\"interval_end\"):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Step 1: Ensure datetime columns are in the correct format first\n",
    "    df[start_col] = pd.to_datetime(df[start_col], utc=True, format=\"mixed\")\n",
    "    df[end_col] = pd.to_datetime(df[end_col], utc=True, format=\"mixed\")\n",
    "\n",
    "    # Step 2: Extract 'month' and 'day' after conversion\n",
    "    df['month'] = df[start_col].dt.month\n",
    "    df['day'] = df[start_col].dt.dayofweek # Note: dayofweek is typically used for cyclical weekly patterns\n",
    "    \n",
    "    # Step 3: Now you can create the cyclical features\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month']/len(df['month'].unique()))\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month']/len(df['month'].unique()))\n",
    "    df['day_sin'] = np.sin(2 * np.pi * df['day']/len(df['day'].unique()))\n",
    "    df['day_cos'] = np.cos(2 * np.pi * df['day']/len(df['day'].unique()))\n",
    "\n",
    "\n",
    "    # Ora del giorno (0-23) → ciclo giornaliero\n",
    "    df[\"hour\"] = df[start_col].dt.hour\n",
    "    angle_day_start = 2 * np.pi * df[\"hour\"] / 24\n",
    "    df[\"start_time_sin\"] = np.sin(angle_day_start)\n",
    "    df[\"start_time_cos\"] = np.cos(angle_day_start)\n",
    "\n",
    "    df[\"hour_end\"] = df[end_col].dt.hour\n",
    "    angle_day_end = 2 * np.pi * df[\"hour_end\"] / 24\n",
    "    df[\"end_time_sin\"] = np.sin(angle_day_end)\n",
    "    df[\"end_time_cos\"] = np.cos(angle_day_end)\n",
    "\n",
    "    # Durata in minuti\n",
    "    df[\"duration_minutes\"] = (df[end_col] - df[start_col]).dt.total_seconds() / 60\n",
    "\n",
    "    # Giorno della settimana (0=Mon..6=Sun) → ciclo settimanale\n",
    "    dayofweek = df[start_col].dt.dayofweek\n",
    "    angle_week = 2 * np.pi * dayofweek / 7\n",
    "    df[\"dow_sin\"] = np.sin(angle_week)\n",
    "    df[\"dow_cos\"] = np.cos(angle_week)\n",
    "\n",
    "    # Giorno dell’anno (1-365) → ciclo annuale\n",
    "    dayofyear = df[start_col].dt.dayofyear\n",
    "    angle_year = 2 * np.pi * dayofyear / 365\n",
    "    df[\"doy_sin\"] = np.sin(angle_year)\n",
    "    df[\"doy_cos\"] = np.cos(angle_year)\n",
    "\n",
    "    # Rimuovo colonne temporali e variabili ausiliarie\n",
    "    df = df.drop(columns=[start_col, end_col, \"hour\", \"hour_end\", \"day\", \"month\"])\n",
    "    return df\n",
    "\n",
    "embedding_cols = ['highway_embedding', 'AreaTypeEmbeddings']\n",
    "\n",
    "df_final = encode_time_features(df_encoded)\n",
    "df_final.drop(columns=['type_of_TTT'], inplace=True)\n",
    "for emb_col in embedding_cols:\n",
    "    df_final = spezza_serie_in_colonne(df_final, emb_col, prefix=f'{emb_col}_')\n",
    "df_final.shape\n",
    "\n",
    "# Salvataggio DataFrame finale\n",
    "df_path = os.path.join(exp_dir, f\"dataframe_{sensor_name}\")\n",
    "os.makedirs(df_path, exist_ok=True)\n",
    "save_pkl(df_final, os.path.join(df_path, f\"filtered_dataframe.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f0e301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ttt in df_final.TTT[10:20]:\n",
    "    plt.plot(ttt)\n",
    "    plt.title(\"Esempi di TTT ARPAT\")\n",
    "    plt.xlabel(\"Ora del Giorno\")\n",
    "    plt.ylabel(\"Valore TTT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6dc56e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (236, 33), (236, 24)\n",
      "Test size: (60, 33), (60, 24)\n",
      "Final shapes:\n",
      "X_train: (236, 33)\n",
      "y_train: (236, 24)\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/X_train_unscaled_PO-ROMA.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/y_train_unscaled_PO-ROMA.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/X_test_unscaled_PO-ROMA.pkl\n",
      "Salvato: /Users/lapotinacci/thesis/Federated_Sys/train_test/y_test_unscaled_PO-ROMA.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/X_train.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/y_train.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/X_test.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/y_test.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/scaler_X.pkl\n",
      "Salvato: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/scaler_y.pkl\n",
      "Scaler salvati.\n",
      "\n",
      "Tutti i file sono stati salvati correttamente.\n",
      "Percorso cartella: /Users/lapotinacci/thesis/Federated_Sys/RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def series_to_2d_array(series, output_dim=24):\n",
    "    arr = np.stack(series.apply(lambda x: np.array(x, dtype=np.float32)))\n",
    "    if arr.shape[1] != output_dim:\n",
    "        raise ValueError(f\"Ogni elemento deve avere {output_dim} valori, trovato {arr.shape[1]}\")\n",
    "    return arr\n",
    "\n",
    " # Separazione delle feature e del target\n",
    "X = df_final.drop(columns=['TTT'])\n",
    "y = df_final['TTT']\n",
    "\n",
    "X_np = X.to_numpy().astype(np.float32)\n",
    "y_np = series_to_2d_array(y, output_dim=24)\n",
    "\n",
    "# Calcolo deviazione standard per ogni serie\n",
    "std_scores = np.std(y_np, axis=1)\n",
    "\n",
    "std_scores_log = np.log1p(std_scores)  # log(1+x) per evitare problemi con valori vicini a 0\n",
    "\n",
    "std_scores_normalized = (std_scores_log - np.min(std_scores_log)) / (np.max(std_scores_log) - np.min(std_scores_log))\n",
    "\n",
    "# Creo bin basati sui quantili\n",
    "bins = np.array([0.0, 0.4, 0.8, 1.0])\n",
    "std_bins = np.digitize(std_scores_normalized, bins)\n",
    "\n",
    "# Primo split: train (80%) vs temp (20%)\n",
    "# Passo anche std_bins per poter stratificare\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_np, y_np,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=std_bins, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train size: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Test size: {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Debug prints\n",
    "print(f\"Final shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "# Scaler per input\n",
    "scaler_X = StandardScaler()\n",
    "X_train = scaler_X.fit_transform(X_train)\n",
    "X_test  = scaler_X.transform(X_test)\n",
    "\n",
    "# Scaler per output (se serve normalizzare anche y)\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test  = scaler_y.transform(y_test)\n",
    "\n",
    "#cartella salvataggio train e test\n",
    "path = os.path.join(exp_dir, \"train_test_data\")\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "#  === Salvataggio dataset e scaler in formato .pkl ===\n",
    "save_pkl(scaler_X.inverse_transform(X_train), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"X_train_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_y.inverse_transform(y_train), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"y_train_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_X.inverse_transform(X_test), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"X_test_unscaled_{sensor_name}.pkl\"))\n",
    "save_pkl(scaler_y.inverse_transform(y_test), os.path.join('/Users/lapotinacci/thesis/Federated_Sys/train_test', f\"y_test_unscaled_{sensor_name}.pkl\"))\n",
    "\n",
    "\n",
    "save_pkl(X_train, os.path.join(exp_dir, \"X_train.pkl\"))\n",
    "save_pkl(y_train, os.path.join(exp_dir, \"y_train.pkl\"))\n",
    "save_pkl(X_test, os.path.join(exp_dir, \"X_test.pkl\"))\n",
    "save_pkl(y_test, os.path.join(exp_dir, \"y_test.pkl\"))\n",
    "\n",
    "save_pkl(scaler_X, os.path.join(exp_dir, \"scaler_X.pkl\"))\n",
    "save_pkl(scaler_y, os.path.join(exp_dir, \"scaler_y.pkl\"))\n",
    "\n",
    "print(\"Scaler salvati.\")\n",
    "\n",
    "print(\"\\nTutti i file sono stati salvati correttamente.\")\n",
    "print(f\"Percorso cartella: {os.path.abspath(exp_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2d0d355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes ricostruite:\n",
      "X_train: (236, 33)\n",
      "y_train: (236, 24)\n",
      "X_test: (60, 33)\n",
      "y_test: (60, 24)\n",
      "\n",
      "Scaler caricati:\n",
      "scaler_X: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "scaler_y: <class 'sklearn.preprocessing._data.StandardScaler'>\n"
     ]
    }
   ],
   "source": [
    "# === Costruisci i path ===\n",
    "path_X_train = os.path.join(exp_dir, \"X_train.pkl\")\n",
    "path_y_train = os.path.join(exp_dir, \"y_train.pkl\")\n",
    "path_X_test  = os.path.join(exp_dir, \"X_test.pkl\")\n",
    "path_y_test  = os.path.join(exp_dir, \"y_test.pkl\")\n",
    "\n",
    "path_scaler_X = os.path.join(exp_dir, \"scaler_X.pkl\")\n",
    "path_scaler_y = os.path.join(exp_dir, \"scaler_y.pkl\")\n",
    "\n",
    "# === Ricaricamento ===\n",
    "X_train = load_pkl(path_X_train)\n",
    "y_train = load_pkl(path_y_train)\n",
    "X_test  = load_pkl(path_X_test)\n",
    "y_test  = load_pkl(path_y_test)\n",
    "\n",
    "\n",
    "scaler_X = load_pkl(path_scaler_X)\n",
    "scaler_y = load_pkl(path_scaler_y)\n",
    "\n",
    "print(\"Shapes ricostruite:\")\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "print(\"\\nScaler caricati:\")\n",
    "print(\"scaler_X:\", type(scaler_X))\n",
    "print(\"scaler_y:\", type(scaler_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ece47aa",
   "metadata": {},
   "source": [
    "# modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08dc75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers # type: ignore\n",
    "from tensorflow.keras.layers import Dropout # type: ignore\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b8b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_plots(y_true, y_pred, output_dir, prefix=\"pred_plot\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    n = len(y_true)\n",
    "    print(f\"Salvo {n} plot in: {output_dir}\")\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        plt.plot(y_true[i], label=\"True\")\n",
    "        plt.plot(y_pred[i], label=\"Pred\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        filename = f\"{prefix}_{i+1}.png\"\n",
    "        path = os.path.join(output_dir, filename)\n",
    "\n",
    "        plt.savefig(path)\n",
    "        plt.close()\n",
    "\n",
    "    print(\"Plot salvati correttamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0608b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lapotinacci/thesis/Federated_Sys/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - loss: 1.1584 - mae: 0.8545 - val_loss: 0.9424 - val_mae: 0.7319\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.7740 - mae: 0.6883 - val_loss: 0.7328 - val_mae: 0.6385\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5706 - mae: 0.5761 - val_loss: 0.5827 - val_mae: 0.5644\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4440 - mae: 0.4965 - val_loss: 0.4939 - val_mae: 0.5194\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.3919 - mae: 0.4664 - val_loss: 0.4532 - val_mae: 0.5073\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3804 - mae: 0.4687 - val_loss: 0.4243 - val_mae: 0.4884\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3531 - mae: 0.4484 - val_loss: 0.3918 - val_mae: 0.4588\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3184 - mae: 0.4153 - val_loss: 0.3670 - val_mae: 0.4375\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2915 - mae: 0.3894 - val_loss: 0.3508 - val_mae: 0.4271\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2768 - mae: 0.3794 - val_loss: 0.3351 - val_mae: 0.4201\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2644 - mae: 0.3719 - val_loss: 0.3184 - val_mae: 0.4111\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2507 - mae: 0.3608 - val_loss: 0.2961 - val_mae: 0.3945\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2324 - mae: 0.3428 - val_loss: 0.2747 - val_mae: 0.3768\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2139 - mae: 0.3252 - val_loss: 0.2614 - val_mae: 0.3653\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2027 - mae: 0.3174 - val_loss: 0.2480 - val_mae: 0.3557\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1936 - mae: 0.3100 - val_loss: 0.2292 - val_mae: 0.3422\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1820 - mae: 0.3000 - val_loss: 0.2136 - val_mae: 0.3288\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1720 - mae: 0.2890 - val_loss: 0.2035 - val_mae: 0.3165\n",
      "Epoch 19/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.1617 - mae: 0.2785 - val_loss: 0.1956 - val_mae: 0.3081\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1545 - mae: 0.2719 - val_loss: 0.1862 - val_mae: 0.3007\n",
      "Epoch 21/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1473 - mae: 0.2645 - val_loss: 0.1695 - val_mae: 0.2884\n",
      "Epoch 22/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1382 - mae: 0.2558 - val_loss: 0.1540 - val_mae: 0.2769\n",
      "Epoch 23/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1312 - mae: 0.2481 - val_loss: 0.1430 - val_mae: 0.2672\n",
      "Epoch 24/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1257 - mae: 0.2408 - val_loss: 0.1342 - val_mae: 0.2577\n",
      "Epoch 25/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.1194 - mae: 0.2341 - val_loss: 0.1254 - val_mae: 0.2492\n",
      "Epoch 26/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1126 - mae: 0.2271 - val_loss: 0.1192 - val_mae: 0.2440\n",
      "Epoch 27/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1078 - mae: 0.2219 - val_loss: 0.1126 - val_mae: 0.2384\n",
      "Epoch 28/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1026 - mae: 0.2160 - val_loss: 0.1065 - val_mae: 0.2311\n",
      "Epoch 29/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0985 - mae: 0.2106 - val_loss: 0.1012 - val_mae: 0.2227\n",
      "Epoch 30/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0940 - mae: 0.2051 - val_loss: 0.0941 - val_mae: 0.2154\n",
      "Epoch 31/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0899 - mae: 0.2015 - val_loss: 0.0895 - val_mae: 0.2108\n",
      "Epoch 32/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0846 - mae: 0.1947 - val_loss: 0.0873 - val_mae: 0.2088\n",
      "Epoch 33/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0815 - mae: 0.1905 - val_loss: 0.0819 - val_mae: 0.2014\n",
      "Epoch 34/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0769 - mae: 0.1850 - val_loss: 0.0763 - val_mae: 0.1910\n",
      "Epoch 35/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0754 - mae: 0.1825 - val_loss: 0.0715 - val_mae: 0.1841\n",
      "Epoch 36/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0713 - mae: 0.1764 - val_loss: 0.0698 - val_mae: 0.1825\n",
      "Epoch 37/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0686 - mae: 0.1724 - val_loss: 0.0684 - val_mae: 0.1793\n",
      "Epoch 38/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0664 - mae: 0.1692 - val_loss: 0.0629 - val_mae: 0.1718\n",
      "Epoch 39/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0635 - mae: 0.1665 - val_loss: 0.0607 - val_mae: 0.1689\n",
      "Epoch 40/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0608 - mae: 0.1630 - val_loss: 0.0598 - val_mae: 0.1681\n",
      "Epoch 41/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0577 - mae: 0.1580 - val_loss: 0.0570 - val_mae: 0.1659\n",
      "Epoch 42/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0566 - mae: 0.1570 - val_loss: 0.0527 - val_mae: 0.1581\n",
      "Epoch 43/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0544 - mae: 0.1534 - val_loss: 0.0520 - val_mae: 0.1550\n",
      "Epoch 44/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0514 - mae: 0.1488 - val_loss: 0.0503 - val_mae: 0.1523\n",
      "Epoch 45/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0501 - mae: 0.1465 - val_loss: 0.0489 - val_mae: 0.1502\n",
      "Epoch 46/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0487 - mae: 0.1454 - val_loss: 0.0483 - val_mae: 0.1490\n",
      "Epoch 47/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0465 - mae: 0.1407 - val_loss: 0.0478 - val_mae: 0.1475\n",
      "Epoch 48/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0455 - mae: 0.1389 - val_loss: 0.0444 - val_mae: 0.1421\n",
      "Epoch 49/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0433 - mae: 0.1357 - val_loss: 0.0428 - val_mae: 0.1395\n",
      "Epoch 50/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0420 - mae: 0.1341 - val_loss: 0.0431 - val_mae: 0.1400\n",
      "Epoch 51/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0402 - mae: 0.1314 - val_loss: 0.0415 - val_mae: 0.1389\n",
      "Epoch 52/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0389 - mae: 0.1291 - val_loss: 0.0392 - val_mae: 0.1349\n",
      "Epoch 53/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0372 - mae: 0.1260 - val_loss: 0.0364 - val_mae: 0.1309\n",
      "Epoch 54/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0368 - mae: 0.1267 - val_loss: 0.0364 - val_mae: 0.1299\n",
      "Epoch 55/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0354 - mae: 0.1235 - val_loss: 0.0374 - val_mae: 0.1323\n",
      "Epoch 56/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0339 - mae: 0.1216 - val_loss: 0.0345 - val_mae: 0.1271\n",
      "Epoch 57/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0325 - mae: 0.1184 - val_loss: 0.0323 - val_mae: 0.1227\n",
      "Epoch 58/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0318 - mae: 0.1167 - val_loss: 0.0317 - val_mae: 0.1201\n",
      "Epoch 59/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0306 - mae: 0.1137 - val_loss: 0.0303 - val_mae: 0.1171\n",
      "Epoch 60/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0295 - mae: 0.1123 - val_loss: 0.0292 - val_mae: 0.1147\n",
      "Epoch 61/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0290 - mae: 0.1111 - val_loss: 0.0290 - val_mae: 0.1143\n",
      "Epoch 62/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0279 - mae: 0.1084 - val_loss: 0.0288 - val_mae: 0.1126\n",
      "Epoch 63/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0269 - mae: 0.1060 - val_loss: 0.0270 - val_mae: 0.1093\n",
      "Epoch 64/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0260 - mae: 0.1053 - val_loss: 0.0268 - val_mae: 0.1094\n",
      "Epoch 65/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0254 - mae: 0.1043 - val_loss: 0.0268 - val_mae: 0.1101\n",
      "Epoch 66/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0250 - mae: 0.1033 - val_loss: 0.0255 - val_mae: 0.1069\n",
      "Epoch 67/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0235 - mae: 0.0999 - val_loss: 0.0249 - val_mae: 0.1044\n",
      "Epoch 68/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0239 - mae: 0.1002 - val_loss: 0.0233 - val_mae: 0.1004\n",
      "Epoch 69/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0221 - mae: 0.0964 - val_loss: 0.0234 - val_mae: 0.1030\n",
      "Epoch 70/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0220 - mae: 0.0969 - val_loss: 0.0233 - val_mae: 0.1010\n",
      "Epoch 71/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0209 - mae: 0.0937 - val_loss: 0.0239 - val_mae: 0.1014\n",
      "Epoch 72/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0205 - mae: 0.0926 - val_loss: 0.0215 - val_mae: 0.0965\n",
      "Epoch 73/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0198 - mae: 0.0914 - val_loss: 0.0206 - val_mae: 0.0956\n",
      "Epoch 74/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0188 - mae: 0.0885 - val_loss: 0.0213 - val_mae: 0.0966\n",
      "Epoch 75/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0188 - mae: 0.0886 - val_loss: 0.0195 - val_mae: 0.0914\n",
      "Epoch 76/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0178 - mae: 0.0855 - val_loss: 0.0189 - val_mae: 0.0903\n",
      "Epoch 77/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0172 - mae: 0.0841 - val_loss: 0.0187 - val_mae: 0.0893\n",
      "Epoch 78/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0171 - mae: 0.0837 - val_loss: 0.0175 - val_mae: 0.0869\n",
      "Epoch 79/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0161 - mae: 0.0812 - val_loss: 0.0177 - val_mae: 0.0870\n",
      "Epoch 80/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0157 - mae: 0.0803 - val_loss: 0.0163 - val_mae: 0.0826\n",
      "Epoch 81/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0150 - mae: 0.0783 - val_loss: 0.0160 - val_mae: 0.0821\n",
      "Epoch 82/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0144 - mae: 0.0770 - val_loss: 0.0155 - val_mae: 0.0813\n",
      "Epoch 83/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0139 - mae: 0.0758 - val_loss: 0.0149 - val_mae: 0.0796\n",
      "Epoch 84/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0134 - mae: 0.0739 - val_loss: 0.0150 - val_mae: 0.0803\n",
      "Epoch 85/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0134 - mae: 0.0749 - val_loss: 0.0136 - val_mae: 0.0760\n",
      "Epoch 86/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0126 - mae: 0.0723 - val_loss: 0.0131 - val_mae: 0.0746\n",
      "Epoch 87/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0120 - mae: 0.0704 - val_loss: 0.0129 - val_mae: 0.0744\n",
      "Epoch 88/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0117 - mae: 0.0700 - val_loss: 0.0122 - val_mae: 0.0717\n",
      "Epoch 89/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0113 - mae: 0.0680 - val_loss: 0.0115 - val_mae: 0.0703\n",
      "Epoch 90/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0109 - mae: 0.0666 - val_loss: 0.0112 - val_mae: 0.0691\n",
      "Epoch 91/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0106 - mae: 0.0657 - val_loss: 0.0114 - val_mae: 0.0689\n",
      "Epoch 92/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0102 - mae: 0.0637 - val_loss: 0.0107 - val_mae: 0.0665\n",
      "Epoch 93/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0098 - mae: 0.0624 - val_loss: 0.0105 - val_mae: 0.0659\n",
      "Epoch 94/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0094 - mae: 0.0612 - val_loss: 0.0107 - val_mae: 0.0670\n",
      "Epoch 95/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - mae: 0.0605 - val_loss: 0.0102 - val_mae: 0.0663\n",
      "Epoch 96/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0588 - val_loss: 0.0094 - val_mae: 0.0631\n",
      "Epoch 97/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0085 - mae: 0.0584 - val_loss: 0.0088 - val_mae: 0.0599\n",
      "Epoch 98/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0081 - mae: 0.0566 - val_loss: 0.0090 - val_mae: 0.0618\n",
      "Epoch 99/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - mae: 0.0567 - val_loss: 0.0086 - val_mae: 0.0604\n",
      "Epoch 100/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 0.0078 - val_mae: 0.0578\n",
      "Epoch 101/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0562 - val_loss: 0.0075 - val_mae: 0.0565\n",
      "Epoch 102/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0538 - val_loss: 0.0076 - val_mae: 0.0569\n",
      "Epoch 103/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0070 - mae: 0.0538 - val_loss: 0.0071 - val_mae: 0.0550\n",
      "Epoch 104/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0517 - val_loss: 0.0075 - val_mae: 0.0567\n",
      "Epoch 105/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 0.0074 - val_mae: 0.0559\n",
      "Epoch 106/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0064 - mae: 0.0509 - val_loss: 0.0070 - val_mae: 0.0542\n",
      "Epoch 107/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0061 - mae: 0.0498 - val_loss: 0.0067 - val_mae: 0.0546\n",
      "Epoch 108/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0501 - val_loss: 0.0063 - val_mae: 0.0523\n",
      "Epoch 109/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0480 - val_loss: 0.0062 - val_mae: 0.0521\n",
      "Epoch 110/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0482 - val_loss: 0.0059 - val_mae: 0.0507\n",
      "Epoch 111/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0053 - mae: 0.0469 - val_loss: 0.0056 - val_mae: 0.0495\n",
      "Epoch 112/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0052 - mae: 0.0464 - val_loss: 0.0053 - val_mae: 0.0472\n",
      "Epoch 113/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0049 - mae: 0.0446 - val_loss: 0.0055 - val_mae: 0.0488\n",
      "Epoch 114/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0051 - mae: 0.0467 - val_loss: 0.0054 - val_mae: 0.0495\n",
      "Epoch 115/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0049 - mae: 0.0465 - val_loss: 0.0052 - val_mae: 0.0471\n",
      "Epoch 116/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0047 - mae: 0.0446 - val_loss: 0.0050 - val_mae: 0.0472\n",
      "Epoch 117/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0045 - mae: 0.0442 - val_loss: 0.0048 - val_mae: 0.0462\n",
      "Epoch 118/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0044 - mae: 0.0431 - val_loss: 0.0049 - val_mae: 0.0465\n",
      "Epoch 119/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0042 - mae: 0.0421 - val_loss: 0.0046 - val_mae: 0.0460\n",
      "Epoch 120/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - mae: 0.0425 - val_loss: 0.0042 - val_mae: 0.0429\n",
      "Epoch 121/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0039 - mae: 0.0408 - val_loss: 0.0041 - val_mae: 0.0429\n",
      "Epoch 122/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0038 - mae: 0.0405 - val_loss: 0.0040 - val_mae: 0.0426\n",
      "Epoch 123/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0037 - mae: 0.0399 - val_loss: 0.0039 - val_mae: 0.0411\n",
      "Epoch 124/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0035 - mae: 0.0384 - val_loss: 0.0039 - val_mae: 0.0419\n",
      "Epoch 125/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0036 - mae: 0.0395 - val_loss: 0.0036 - val_mae: 0.0399\n",
      "Epoch 126/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0374 - val_loss: 0.0035 - val_mae: 0.0398\n",
      "Epoch 127/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0034 - mae: 0.0374 - val_loss: 0.0034 - val_mae: 0.0392\n",
      "Epoch 128/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0032 - mae: 0.0371 - val_loss: 0.0035 - val_mae: 0.0390\n",
      "Epoch 129/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0031 - mae: 0.0358 - val_loss: 0.0033 - val_mae: 0.0384\n",
      "Epoch 130/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0031 - mae: 0.0365 - val_loss: 0.0032 - val_mae: 0.0372\n",
      "Epoch 131/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0357 - val_loss: 0.0031 - val_mae: 0.0379\n",
      "Epoch 132/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0029 - mae: 0.0349 - val_loss: 0.0032 - val_mae: 0.0376\n",
      "Epoch 133/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0346 - val_loss: 0.0028 - val_mae: 0.0354\n",
      "Epoch 134/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0027 - mae: 0.0342 - val_loss: 0.0027 - val_mae: 0.0349\n",
      "Epoch 135/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0026 - mae: 0.0333 - val_loss: 0.0027 - val_mae: 0.0347\n",
      "Epoch 136/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0338\n",
      "Epoch 137/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0027 - val_mae: 0.0341\n",
      "Epoch 138/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0026 - val_mae: 0.0344\n",
      "Epoch 139/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0024 - mae: 0.0325 - val_loss: 0.0023 - val_mae: 0.0328\n",
      "Epoch 140/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0022 - mae: 0.0310 - val_loss: 0.0023 - val_mae: 0.0327\n",
      "Epoch 141/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 0.0022 - val_mae: 0.0323\n",
      "Epoch 142/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0021 - mae: 0.0309 - val_loss: 0.0022 - val_mae: 0.0318\n",
      "Epoch 143/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0020 - val_mae: 0.0305\n",
      "Epoch 144/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0308\n",
      "Epoch 145/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0020 - mae: 0.0298 - val_loss: 0.0021 - val_mae: 0.0309\n",
      "Epoch 146/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0019 - mae: 0.0292 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 147/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0020 - val_mae: 0.0304\n",
      "Epoch 148/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0305\n",
      "Epoch 149/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0019 - val_mae: 0.0301\n",
      "Epoch 150/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 0.0019 - val_mae: 0.0302\n",
      "Epoch 151/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 0.0018 - val_mae: 0.0296\n",
      "Epoch 152/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 0.0017 - val_mae: 0.0283\n",
      "Epoch 153/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 0.0016 - val_mae: 0.0279\n",
      "Epoch 154/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 0.0016 - val_mae: 0.0279\n",
      "Epoch 155/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 0.0016 - val_mae: 0.0277\n",
      "Epoch 156/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 0.0016 - val_mae: 0.0276\n",
      "Epoch 157/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0015 - val_mae: 0.0272\n",
      "Epoch 158/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 0.0016 - val_mae: 0.0280\n",
      "Epoch 159/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0015 - val_mae: 0.0266\n",
      "Epoch 160/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 0.0015 - val_mae: 0.0269\n",
      "Epoch 161/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0015 - val_mae: 0.0267\n",
      "Epoch 162/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 0.0015 - val_mae: 0.0270\n",
      "Epoch 163/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0273\n",
      "Epoch 164/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 0.0013 - val_mae: 0.0252\n",
      "Epoch 165/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 0.0014 - val_mae: 0.0262\n",
      "Epoch 166/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 0.0013 - val_mae: 0.0259\n",
      "Epoch 167/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 0.0013 - val_mae: 0.0257\n",
      "Epoch 168/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 0.0013 - val_mae: 0.0258\n",
      "Epoch 169/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 170/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 0.0013 - val_mae: 0.0254\n",
      "Epoch 171/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0238\n",
      "Epoch 172/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 0.0012 - val_mae: 0.0245\n",
      "Epoch 173/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0238\n",
      "Epoch 174/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 175/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0010 - mae: 0.0220 - val_loss: 0.0012 - val_mae: 0.0242\n",
      "Epoch 176/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 177/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.9530e-04 - mae: 0.0216 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 178/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.8685e-04 - mae: 0.0220 - val_loss: 9.9895e-04 - val_mae: 0.0217\n",
      "Epoch 179/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.0852e-04 - mae: 0.0206 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 180/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.2871e-04 - mae: 0.0208 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 181/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.6245e-04 - mae: 0.0212 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 182/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 9.2239e-04 - mae: 0.0209 - val_loss: 9.4570e-04 - val_mae: 0.0215\n",
      "Epoch 183/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.5032e-04 - mae: 0.0200 - val_loss: 9.4354e-04 - val_mae: 0.0212\n",
      "Epoch 184/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.3440e-04 - mae: 0.0198 - val_loss: 9.3323e-04 - val_mae: 0.0208\n",
      "Epoch 185/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.2710e-04 - mae: 0.0196 - val_loss: 9.1072e-04 - val_mae: 0.0210\n",
      "Epoch 186/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.0618e-04 - mae: 0.0194 - val_loss: 8.6887e-04 - val_mae: 0.0209\n",
      "Epoch 187/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.9855e-04 - mae: 0.0198 - val_loss: 8.9365e-04 - val_mae: 0.0207\n",
      "Epoch 188/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.0049e-04 - mae: 0.0196 - val_loss: 8.4538e-04 - val_mae: 0.0202\n",
      "Epoch 189/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3945e-04 - mae: 0.0189 - val_loss: 8.4677e-04 - val_mae: 0.0203\n",
      "Epoch 190/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.5613e-04 - mae: 0.0193 - val_loss: 8.1985e-04 - val_mae: 0.0198\n",
      "Epoch 191/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.2084e-04 - mae: 0.0184 - val_loss: 8.0643e-04 - val_mae: 0.0197\n",
      "Epoch 192/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.9264e-04 - mae: 0.0181 - val_loss: 7.9897e-04 - val_mae: 0.0199\n",
      "Epoch 193/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 6.8306e-04 - mae: 0.0183 - val_loss: 7.7357e-04 - val_mae: 0.0194\n",
      "Epoch 194/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.7708e-04 - mae: 0.0181 - val_loss: 7.9667e-04 - val_mae: 0.0197\n",
      "Epoch 195/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.8315e-04 - mae: 0.0182 - val_loss: 7.8155e-04 - val_mae: 0.0199\n",
      "Epoch 196/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.6195e-04 - mae: 0.0183 - val_loss: 7.7274e-04 - val_mae: 0.0194\n",
      "Epoch 197/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.5742e-04 - mae: 0.0178 - val_loss: 7.0401e-04 - val_mae: 0.0184\n",
      "Epoch 198/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.3065e-04 - mae: 0.0176 - val_loss: 7.1409e-04 - val_mae: 0.0187\n",
      "Epoch 199/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.3089e-04 - mae: 0.0177 - val_loss: 6.7908e-04 - val_mae: 0.0181\n",
      "Epoch 200/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 6.0654e-04 - mae: 0.0170 - val_loss: 6.8509e-04 - val_mae: 0.0182\n",
      "Epoch 201/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.0719e-04 - mae: 0.0170 - val_loss: 6.9467e-04 - val_mae: 0.0182\n",
      "Epoch 202/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.9039e-04 - mae: 0.0168 - val_loss: 6.8795e-04 - val_mae: 0.0183\n",
      "Epoch 203/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.9454e-04 - mae: 0.0169 - val_loss: 7.0813e-04 - val_mae: 0.0182\n",
      "Epoch 204/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 5.7945e-04 - mae: 0.0168 - val_loss: 6.7222e-04 - val_mae: 0.0178\n",
      "Epoch 205/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.5920e-04 - mae: 0.0163 - val_loss: 6.5284e-04 - val_mae: 0.0178\n",
      "Epoch 206/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.6075e-04 - mae: 0.0163 - val_loss: 6.4791e-04 - val_mae: 0.0177\n",
      "Epoch 207/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.5566e-04 - mae: 0.0166 - val_loss: 6.3274e-04 - val_mae: 0.0175\n",
      "Epoch 208/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 5.3949e-04 - mae: 0.0162 - val_loss: 6.3578e-04 - val_mae: 0.0177\n",
      "Epoch 209/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 5.4263e-04 - mae: 0.0163 - val_loss: 6.0694e-04 - val_mae: 0.0174\n",
      "Epoch 210/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.4671e-04 - mae: 0.0166 - val_loss: 6.1443e-04 - val_mae: 0.0174\n",
      "Epoch 211/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.3084e-04 - mae: 0.0163 - val_loss: 6.0874e-04 - val_mae: 0.0176\n",
      "Epoch 212/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.3401e-04 - mae: 0.0163 - val_loss: 6.4049e-04 - val_mae: 0.0177\n",
      "Epoch 213/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.3777e-04 - mae: 0.0163 - val_loss: 6.3945e-04 - val_mae: 0.0177\n",
      "Epoch 214/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.3219e-04 - mae: 0.0163 - val_loss: 5.9911e-04 - val_mae: 0.0169\n",
      "Epoch 215/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0796e-04 - mae: 0.0158 - val_loss: 5.8473e-04 - val_mae: 0.0170\n",
      "Epoch 216/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4.8516e-04 - mae: 0.0155 - val_loss: 6.4068e-04 - val_mae: 0.0176\n",
      "Epoch 217/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.0547e-04 - mae: 0.0159 - val_loss: 5.6008e-04 - val_mae: 0.0164\n",
      "Epoch 218/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.7303e-04 - mae: 0.0152 - val_loss: 5.7975e-04 - val_mae: 0.0166\n",
      "Epoch 219/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.8348e-04 - mae: 0.0154 - val_loss: 5.5367e-04 - val_mae: 0.0162\n",
      "Epoch 220/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.6960e-04 - mae: 0.0153 - val_loss: 5.6668e-04 - val_mae: 0.0166\n",
      "Epoch 221/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 4.5445e-04 - mae: 0.0149 - val_loss: 5.2109e-04 - val_mae: 0.0158\n",
      "Epoch 222/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 4.3890e-04 - mae: 0.0146 - val_loss: 5.5378e-04 - val_mae: 0.0166\n",
      "Epoch 223/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.6647e-04 - mae: 0.0152 - val_loss: 5.1226e-04 - val_mae: 0.0158\n",
      "Epoch 224/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.3630e-04 - mae: 0.0148 - val_loss: 5.3175e-04 - val_mae: 0.0159\n",
      "Epoch 225/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 4.2513e-04 - mae: 0.0144 - val_loss: 5.4554e-04 - val_mae: 0.0162\n",
      "Epoch 226/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.4999e-04 - mae: 0.0149 - val_loss: 5.5258e-04 - val_mae: 0.0161\n",
      "Epoch 227/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.4974e-04 - mae: 0.0148 - val_loss: 4.8482e-04 - val_mae: 0.0153\n",
      "Epoch 228/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.1237e-04 - mae: 0.0143 - val_loss: 5.2792e-04 - val_mae: 0.0163\n",
      "Epoch 229/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 4.4001e-04 - mae: 0.0151 - val_loss: 5.0570e-04 - val_mae: 0.0157\n",
      "Epoch 230/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.3594e-04 - mae: 0.0149 - val_loss: 4.8318e-04 - val_mae: 0.0153\n",
      "Epoch 231/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.1044e-04 - mae: 0.0142 - val_loss: 4.9623e-04 - val_mae: 0.0154\n",
      "Epoch 232/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.0929e-04 - mae: 0.0143 - val_loss: 4.7358e-04 - val_mae: 0.0150\n",
      "Epoch 233/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.9745e-04 - mae: 0.0142 - val_loss: 4.6760e-04 - val_mae: 0.0152\n",
      "Epoch 234/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8730e-04 - mae: 0.0139 - val_loss: 4.7107e-04 - val_mae: 0.0152\n",
      "Epoch 235/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8970e-04 - mae: 0.0139 - val_loss: 4.6990e-04 - val_mae: 0.0155\n",
      "Epoch 236/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.9275e-04 - mae: 0.0143 - val_loss: 4.5761e-04 - val_mae: 0.0150\n",
      "Epoch 237/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.8827e-04 - mae: 0.0141 - val_loss: 4.4120e-04 - val_mae: 0.0150\n",
      "Epoch 238/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.7195e-04 - mae: 0.0137 - val_loss: 4.3086e-04 - val_mae: 0.0147\n",
      "Epoch 239/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.7274e-04 - mae: 0.0135 - val_loss: 4.5103e-04 - val_mae: 0.0150\n",
      "Epoch 240/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 3.8735e-04 - mae: 0.0141 - val_loss: 4.7696e-04 - val_mae: 0.0155\n",
      "Epoch 241/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8190e-04 - mae: 0.0140 - val_loss: 4.4917e-04 - val_mae: 0.0150\n",
      "Epoch 242/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.9243e-04 - mae: 0.0143 - val_loss: 4.4549e-04 - val_mae: 0.0151\n",
      "Epoch 243/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.8048e-04 - mae: 0.0142 - val_loss: 4.6104e-04 - val_mae: 0.0151\n",
      "Epoch 244/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.9893e-04 - mae: 0.0142 - val_loss: 4.6171e-04 - val_mae: 0.0155\n",
      "Epoch 245/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7887e-04 - mae: 0.0140 - val_loss: 5.2175e-04 - val_mae: 0.0161\n",
      "Epoch 246/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.0673e-04 - mae: 0.0146 - val_loss: 4.7716e-04 - val_mae: 0.0154\n",
      "Epoch 247/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.9784e-04 - mae: 0.0143 - val_loss: 4.7259e-04 - val_mae: 0.0152\n",
      "Epoch 248/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.0689e-04 - mae: 0.0144 - val_loss: 4.9694e-04 - val_mae: 0.0158\n",
      "Epoch 249/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.3310e-04 - mae: 0.0148 - val_loss: 4.7783e-04 - val_mae: 0.0157\n",
      "Epoch 250/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.1587e-04 - mae: 0.0147 - val_loss: 5.3472e-04 - val_mae: 0.0165\n",
      "Epoch 251/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.9992e-04 - mae: 0.0144 - val_loss: 4.4684e-04 - val_mae: 0.0151\n",
      "Epoch 252/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.8522e-04 - mae: 0.0143 - val_loss: 4.3853e-04 - val_mae: 0.0151\n",
      "Epoch 253/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.5025e-04 - mae: 0.0136 - val_loss: 4.3061e-04 - val_mae: 0.0149\n",
      "Epoch 254/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.5485e-04 - mae: 0.0136 - val_loss: 3.8107e-04 - val_mae: 0.0138\n",
      "Epoch 255/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.0857e-04 - mae: 0.0125 - val_loss: 3.9270e-04 - val_mae: 0.0138\n",
      "Epoch 256/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.1628e-04 - mae: 0.0127 - val_loss: 4.3305e-04 - val_mae: 0.0147\n",
      "Epoch 257/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.5000e-04 - mae: 0.0133 - val_loss: 4.0177e-04 - val_mae: 0.0142\n",
      "Epoch 258/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.3657e-04 - mae: 0.0132 - val_loss: 4.4377e-04 - val_mae: 0.0153\n",
      "Epoch 259/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.3822e-04 - mae: 0.0134 - val_loss: 3.9356e-04 - val_mae: 0.0141\n",
      "Epoch 260/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.2381e-04 - mae: 0.0131 - val_loss: 4.0387e-04 - val_mae: 0.0144\n",
      "Epoch 261/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.2167e-04 - mae: 0.0130 - val_loss: 3.5568e-04 - val_mae: 0.0136\n",
      "Epoch 262/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.9427e-04 - mae: 0.0124 - val_loss: 3.8869e-04 - val_mae: 0.0140\n",
      "Epoch 263/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.0800e-04 - mae: 0.0127 - val_loss: 3.8160e-04 - val_mae: 0.0138\n",
      "Epoch 264/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.1478e-04 - mae: 0.0131 - val_loss: 3.7702e-04 - val_mae: 0.0141\n",
      "Epoch 265/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.0349e-04 - mae: 0.0126 - val_loss: 3.9134e-04 - val_mae: 0.0142\n",
      "Epoch 266/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 3.1343e-04 - mae: 0.0129 - val_loss: 3.7868e-04 - val_mae: 0.0141\n",
      "Epoch 267/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.9761e-04 - mae: 0.0125 - val_loss: 4.3135e-04 - val_mae: 0.0152\n",
      "Epoch 268/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.3301e-04 - mae: 0.0135 - val_loss: 4.2593e-04 - val_mae: 0.0150\n",
      "Epoch 269/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.3383e-04 - mae: 0.0133 - val_loss: 4.0358e-04 - val_mae: 0.0144\n",
      "Epoch 270/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.1640e-04 - mae: 0.0129 - val_loss: 3.8319e-04 - val_mae: 0.0142\n",
      "Epoch 271/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0223e-04 - mae: 0.0128 - val_loss: 3.9039e-04 - val_mae: 0.0139\n",
      "Epoch 272/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.0185e-04 - mae: 0.0125 - val_loss: 4.4406e-04 - val_mae: 0.0155\n",
      "Epoch 273/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.6232e-04 - mae: 0.0144 - val_loss: 5.0165e-04 - val_mae: 0.0161\n",
      "Epoch 274/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.1322e-04 - mae: 0.0152 - val_loss: 4.5577e-04 - val_mae: 0.0156\n",
      "Epoch 275/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.0114e-04 - mae: 0.0152 - val_loss: 4.3805e-04 - val_mae: 0.0158\n",
      "Epoch 276/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.7736e-04 - mae: 0.0149 - val_loss: 5.6884e-04 - val_mae: 0.0179\n",
      "Epoch 277/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.4228e-04 - mae: 0.0157 - val_loss: 5.9157e-04 - val_mae: 0.0180\n",
      "Epoch 278/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.2341e-04 - mae: 0.0168 - val_loss: 5.3918e-04 - val_mae: 0.0172\n",
      "Epoch 279/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3379e-04 - mae: 0.0155 - val_loss: 4.0984e-04 - val_mae: 0.0150\n",
      "Epoch 280/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.9002e-04 - mae: 0.0147 - val_loss: 3.8774e-04 - val_mae: 0.0143\n",
      "Epoch 281/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.7386e-04 - mae: 0.0143 - val_loss: 4.6746e-04 - val_mae: 0.0161\n",
      "Epoch 282/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.7531e-04 - mae: 0.0144 - val_loss: 4.3145e-04 - val_mae: 0.0154\n",
      "Epoch 283/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.6092e-04 - mae: 0.0139 - val_loss: 4.7474e-04 - val_mae: 0.0160\n",
      "Epoch 284/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.7139e-04 - mae: 0.0142 - val_loss: 4.6553e-04 - val_mae: 0.0157\n",
      "Epoch 285/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.1305e-04 - mae: 0.0150 - val_loss: 4.6569e-04 - val_mae: 0.0162\n",
      "Epoch 286/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.7239e-04 - mae: 0.0142 - val_loss: 3.9116e-04 - val_mae: 0.0147\n",
      "Epoch 287/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.6616e-04 - mae: 0.0139 - val_loss: 4.1230e-04 - val_mae: 0.0146\n",
      "Epoch 288/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.1337e-04 - mae: 0.0146 - val_loss: 3.2181e-04 - val_mae: 0.0131\n",
      "Epoch 289/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.5475e-04 - mae: 0.0140 - val_loss: 4.8040e-04 - val_mae: 0.0155\n",
      "Epoch 290/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.0629e-04 - mae: 0.0143 - val_loss: 5.4730e-04 - val_mae: 0.0164\n",
      "Epoch 291/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.5508e-04 - mae: 0.0152 - val_loss: 5.9695e-04 - val_mae: 0.0170\n",
      "Epoch 292/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.8682e-04 - mae: 0.0154 - val_loss: 6.1607e-04 - val_mae: 0.0174\n",
      "Epoch 293/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.6145e-04 - mae: 0.0153 - val_loss: 5.2945e-04 - val_mae: 0.0163\n",
      "Epoch 294/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6686e-04 - mae: 0.0154 - val_loss: 4.9097e-04 - val_mae: 0.0165\n",
      "Epoch 295/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.8803e-04 - mae: 0.0145 - val_loss: 5.3454e-04 - val_mae: 0.0168\n",
      "Epoch 296/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.4209e-04 - mae: 0.0156 - val_loss: 6.8234e-04 - val_mae: 0.0189\n",
      "Epoch 297/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.1248e-04 - mae: 0.0179 - val_loss: 7.4411e-04 - val_mae: 0.0194\n",
      "Epoch 298/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.3358e-04 - mae: 0.0180 - val_loss: 5.9080e-04 - val_mae: 0.0178\n",
      "Epoch 299/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 5.5793e-04 - mae: 0.0172 - val_loss: 4.7410e-04 - val_mae: 0.0162\n",
      "Epoch 300/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.1541e-04 - mae: 0.0149 - val_loss: 4.0390e-04 - val_mae: 0.0149\n",
      "Epoch 301/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.3718e-04 - mae: 0.0155 - val_loss: 4.6187e-04 - val_mae: 0.0156\n",
      "Epoch 302/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.4795e-04 - mae: 0.0169 - val_loss: 4.3220e-04 - val_mae: 0.0154\n",
      "Epoch 303/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.0402e-04 - mae: 0.0164 - val_loss: 4.3397e-04 - val_mae: 0.0151\n",
      "Epoch 304/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.5378e-04 - mae: 0.0152 - val_loss: 4.7795e-04 - val_mae: 0.0155\n",
      "Epoch 305/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.0249e-04 - mae: 0.0154 - val_loss: 5.8470e-04 - val_mae: 0.0171\n",
      "Epoch 306/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9538e-04 - mae: 0.0163 - val_loss: 4.2701e-04 - val_mae: 0.0149\n",
      "Epoch 307/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 4.3102e-04 - mae: 0.0149 - val_loss: 3.9046e-04 - val_mae: 0.0146\n",
      "Epoch 308/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4996e-04 - mae: 0.0138 - val_loss: 4.1179e-04 - val_mae: 0.0152\n",
      "Epoch 309/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.3818e-04 - mae: 0.0139 - val_loss: 3.2040e-04 - val_mae: 0.0133\n",
      "Epoch 310/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.7619e-04 - mae: 0.0124 - val_loss: 2.9989e-04 - val_mae: 0.0126\n",
      "Epoch 311/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.5008e-04 - mae: 0.0116 - val_loss: 3.0723e-04 - val_mae: 0.0128\n",
      "Epoch 312/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.5059e-04 - mae: 0.0117 - val_loss: 3.3506e-04 - val_mae: 0.0131\n",
      "Epoch 313/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.8737e-04 - mae: 0.0123 - val_loss: 3.2105e-04 - val_mae: 0.0133\n",
      "Epoch 314/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.7571e-04 - mae: 0.0123 - val_loss: 2.8264e-04 - val_mae: 0.0122\n",
      "Epoch 315/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.4608e-04 - mae: 0.0115 - val_loss: 2.9269e-04 - val_mae: 0.0122\n",
      "Epoch 316/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.8447e-04 - mae: 0.0121 - val_loss: 2.5669e-04 - val_mae: 0.0114\n",
      "Epoch 317/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 2.4386e-04 - mae: 0.0110 - val_loss: 2.7458e-04 - val_mae: 0.0120\n",
      "Epoch 318/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.4107e-04 - mae: 0.0114 - val_loss: 2.9127e-04 - val_mae: 0.0124\n",
      "Epoch 319/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.4560e-04 - mae: 0.0113 - val_loss: 3.1334e-04 - val_mae: 0.0129\n",
      "Epoch 320/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.5920e-04 - mae: 0.0117 - val_loss: 2.6341e-04 - val_mae: 0.0118\n",
      "Epoch 321/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4470e-04 - mae: 0.0115 - val_loss: 2.5441e-04 - val_mae: 0.0115\n",
      "Epoch 322/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.2969e-04 - mae: 0.0108 - val_loss: 2.5536e-04 - val_mae: 0.0118\n",
      "Epoch 323/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.1694e-04 - mae: 0.0108 - val_loss: 2.7610e-04 - val_mae: 0.0120\n",
      "Epoch 324/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.4723e-04 - mae: 0.0112 - val_loss: 2.8015e-04 - val_mae: 0.0120\n",
      "Epoch 325/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.7151e-04 - mae: 0.0118 - val_loss: 2.7008e-04 - val_mae: 0.0116\n",
      "Epoch 326/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.4832e-04 - mae: 0.0112 - val_loss: 2.7106e-04 - val_mae: 0.0120\n",
      "Epoch 327/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3706e-04 - mae: 0.0112 - val_loss: 2.7588e-04 - val_mae: 0.0122\n",
      "Epoch 328/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3453e-04 - mae: 0.0112 - val_loss: 2.4272e-04 - val_mae: 0.0112\n",
      "Epoch 329/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.0736e-04 - mae: 0.0104 - val_loss: 2.8385e-04 - val_mae: 0.0121\n",
      "Epoch 330/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3115e-04 - mae: 0.0111 - val_loss: 2.6017e-04 - val_mae: 0.0114\n",
      "Epoch 331/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.4473e-04 - mae: 0.0112 - val_loss: 2.5955e-04 - val_mae: 0.0116\n",
      "Epoch 332/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.1849e-04 - mae: 0.0108 - val_loss: 2.5607e-04 - val_mae: 0.0117\n",
      "Epoch 333/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.1367e-04 - mae: 0.0107 - val_loss: 2.6839e-04 - val_mae: 0.0117\n",
      "Epoch 334/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3356e-04 - mae: 0.0111 - val_loss: 3.0929e-04 - val_mae: 0.0127\n",
      "Epoch 335/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.6283e-04 - mae: 0.0117 - val_loss: 4.9643e-04 - val_mae: 0.0154\n",
      "Epoch 336/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.6862e-04 - mae: 0.0133 - val_loss: 4.8435e-04 - val_mae: 0.0149\n",
      "Epoch 337/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0793e-04 - mae: 0.0138 - val_loss: 4.6417e-04 - val_mae: 0.0152\n",
      "Epoch 338/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.9570e-04 - mae: 0.0141 - val_loss: 3.6926e-04 - val_mae: 0.0135\n",
      "Epoch 339/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.6512e-04 - mae: 0.0135 - val_loss: 3.2895e-04 - val_mae: 0.0130\n",
      "Epoch 340/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 3.4365e-04 - mae: 0.0132 - val_loss: 3.9399e-04 - val_mae: 0.0142\n",
      "Epoch 341/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.5980e-04 - mae: 0.0136 - val_loss: 4.0604e-04 - val_mae: 0.0144\n",
      "Epoch 342/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.7817e-04 - mae: 0.0140 - val_loss: 4.2852e-04 - val_mae: 0.0148\n",
      "Epoch 343/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.5636e-04 - mae: 0.0137 - val_loss: 3.4079e-04 - val_mae: 0.0135\n",
      "Epoch 344/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.4285e-04 - mae: 0.0135 - val_loss: 4.6243e-04 - val_mae: 0.0149\n",
      "Epoch 345/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.5567e-04 - mae: 0.0134 - val_loss: 3.4696e-04 - val_mae: 0.0135\n",
      "Epoch 346/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.6255e-04 - mae: 0.0137 - val_loss: 3.8578e-04 - val_mae: 0.0141\n",
      "Epoch 347/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.6288e-04 - mae: 0.0135 - val_loss: 5.2007e-04 - val_mae: 0.0152\n",
      "Epoch 348/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6033e-04 - mae: 0.0146 - val_loss: 3.7500e-04 - val_mae: 0.0133\n",
      "Epoch 349/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.9871e-04 - mae: 0.0124 - val_loss: 3.0242e-04 - val_mae: 0.0126\n",
      "Epoch 350/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.8238e-04 - mae: 0.0122 - val_loss: 4.1253e-04 - val_mae: 0.0143\n",
      "Epoch 351/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.3179e-04 - mae: 0.0131 - val_loss: 3.9887e-04 - val_mae: 0.0145\n",
      "Epoch 352/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4155e-04 - mae: 0.0137 - val_loss: 3.7004e-04 - val_mae: 0.0142\n",
      "Epoch 353/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.5218e-04 - mae: 0.0140 - val_loss: 3.9582e-04 - val_mae: 0.0151\n",
      "Epoch 354/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.3855e-04 - mae: 0.0138 - val_loss: 4.0414e-04 - val_mae: 0.0145\n",
      "Epoch 355/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.6287e-04 - mae: 0.0140 - val_loss: 5.2393e-04 - val_mae: 0.0165\n",
      "Epoch 356/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.6217e-04 - mae: 0.0157 - val_loss: 4.1433e-04 - val_mae: 0.0149\n",
      "Epoch 357/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.1603e-04 - mae: 0.0149 - val_loss: 3.1069e-04 - val_mae: 0.0129\n",
      "Epoch 358/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.1928e-04 - mae: 0.0131 - val_loss: 3.0440e-04 - val_mae: 0.0126\n",
      "Epoch 359/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4828e-04 - mae: 0.0131 - val_loss: 3.6762e-04 - val_mae: 0.0136\n",
      "Epoch 360/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2688e-04 - mae: 0.0130 - val_loss: 3.1648e-04 - val_mae: 0.0130\n",
      "Epoch 361/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 2.9775e-04 - mae: 0.0125 - val_loss: 2.8598e-04 - val_mae: 0.0125\n",
      "Epoch 362/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.6330e-04 - mae: 0.0120 - val_loss: 3.8307e-04 - val_mae: 0.0137\n",
      "Epoch 363/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.7104e-04 - mae: 0.0121 - val_loss: 3.8932e-04 - val_mae: 0.0139\n",
      "Epoch 364/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.0213e-04 - mae: 0.0126 - val_loss: 4.4044e-04 - val_mae: 0.0146\n",
      "Epoch 365/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.5566e-04 - mae: 0.0131 - val_loss: 6.9046e-04 - val_mae: 0.0173\n",
      "Epoch 366/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.8078e-04 - mae: 0.0150 - val_loss: 8.2990e-04 - val_mae: 0.0188\n",
      "Epoch 367/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 6.2387e-04 - mae: 0.0166 - val_loss: 8.3632e-04 - val_mae: 0.0199\n",
      "Epoch 368/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.7124e-04 - mae: 0.0177 - val_loss: 5.9656e-04 - val_mae: 0.0177\n",
      "Epoch 369/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.4147e-04 - mae: 0.0166 - val_loss: 4.9004e-04 - val_mae: 0.0165\n",
      "Epoch 370/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.0160e-04 - mae: 0.0168 - val_loss: 6.3910e-04 - val_mae: 0.0178\n",
      "Epoch 371/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.2228e-04 - mae: 0.0169 - val_loss: 5.8490e-04 - val_mae: 0.0181\n",
      "Epoch 372/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.9619e-04 - mae: 0.0193 - val_loss: 8.0677e-04 - val_mae: 0.0205\n",
      "Epoch 373/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.1626e-04 - mae: 0.0207 - val_loss: 6.9768e-04 - val_mae: 0.0202\n",
      "Epoch 374/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 0.0012 - val_mae: 0.0252\n",
      "Epoch 375/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 376/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0276 - val_loss: 9.1314e-04 - val_mae: 0.0240\n",
      "Epoch 377/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0010 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 378/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0259 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 379/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0013 - mae: 0.0278 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 380/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0013 - mae: 0.0266 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 381/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0018 - val_mae: 0.0292\n",
      "Epoch 382/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 0.0034 - val_mae: 0.0390\n",
      "Epoch 383/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0028 - mae: 0.0364 - val_loss: 0.0027 - val_mae: 0.0357\n",
      "Epoch 384/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0028 - mae: 0.0378 - val_loss: 0.0049 - val_mae: 0.0452\n",
      "Epoch 385/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0407 - val_loss: 0.0028 - val_mae: 0.0372\n",
      "Epoch 386/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0033 - mae: 0.0418 - val_loss: 0.0022 - val_mae: 0.0328\n",
      "Epoch 387/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0026 - mae: 0.0348 - val_loss: 0.0025 - val_mae: 0.0327\n",
      "Epoch 388/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0028 - val_mae: 0.0364\n",
      "Epoch 389/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0033 - mae: 0.0409 - val_loss: 0.0031 - val_mae: 0.0374\n",
      "Epoch 390/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - mae: 0.0395 - val_loss: 0.0018 - val_mae: 0.0308\n",
      "Epoch 391/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0024 - mae: 0.0362 - val_loss: 0.0028 - val_mae: 0.0369\n",
      "Epoch 392/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0032 - mae: 0.0407 - val_loss: 0.0043 - val_mae: 0.0503\n",
      "Epoch 393/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0035 - mae: 0.0447 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 394/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0033 - mae: 0.0432 - val_loss: 0.0025 - val_mae: 0.0366\n",
      "Epoch 395/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 396/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0341 - val_loss: 0.0021 - val_mae: 0.0337\n",
      "Epoch 397/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0024 - mae: 0.0365 - val_loss: 0.0015 - val_mae: 0.0296\n",
      "Epoch 398/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0329 - val_loss: 0.0016 - val_mae: 0.0310\n",
      "Epoch 399/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0015 - mae: 0.0296 - val_loss: 0.0022 - val_mae: 0.0335\n",
      "Epoch 400/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 401/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0021 - val_mae: 0.0313\n",
      "Epoch 402/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0017 - val_mae: 0.0282\n",
      "Epoch 403/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 0.0031 - val_mae: 0.0365\n",
      "Epoch 404/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0026 - val_mae: 0.0344\n",
      "Epoch 405/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 0.0024 - val_mae: 0.0341\n",
      "Epoch 406/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0020 - val_mae: 0.0324\n",
      "Epoch 407/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0018 - mae: 0.0308 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 408/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0322 - val_loss: 0.0021 - val_mae: 0.0334\n",
      "Epoch 409/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0019 - mae: 0.0321 - val_loss: 0.0016 - val_mae: 0.0308\n",
      "Epoch 410/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0019 - mae: 0.0324 - val_loss: 0.0036 - val_mae: 0.0431\n",
      "Epoch 411/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0028 - mae: 0.0383 - val_loss: 0.0022 - val_mae: 0.0339\n",
      "Epoch 412/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 413/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0020 - mae: 0.0330 - val_loss: 0.0019 - val_mae: 0.0307\n",
      "Epoch 414/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0016 - mae: 0.0296 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 415/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0017 - mae: 0.0311 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 416/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0016 - mae: 0.0301 - val_loss: 0.0013 - val_mae: 0.0288\n",
      "Epoch 417/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0277\n",
      "Epoch 418/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0011 - mae: 0.0266 - val_loss: 9.1143e-04 - val_mae: 0.0238\n",
      "Epoch 419/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.0636e-04 - mae: 0.0238 - val_loss: 7.2395e-04 - val_mae: 0.0206\n",
      "Epoch 420/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 9.0242e-04 - mae: 0.0229 - val_loss: 7.1115e-04 - val_mae: 0.0204\n",
      "Epoch 421/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.7192e-04 - mae: 0.0210 - val_loss: 6.0695e-04 - val_mae: 0.0191\n",
      "Epoch 422/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.5579e-04 - mae: 0.0211 - val_loss: 6.1588e-04 - val_mae: 0.0188\n",
      "Epoch 423/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.2634e-04 - mae: 0.0208 - val_loss: 5.1100e-04 - val_mae: 0.0168\n",
      "Epoch 424/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.4809e-04 - mae: 0.0177 - val_loss: 4.5688e-04 - val_mae: 0.0160\n",
      "Epoch 425/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.3175e-04 - mae: 0.0157 - val_loss: 5.1795e-04 - val_mae: 0.0173\n",
      "Epoch 426/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.3308e-04 - mae: 0.0171 - val_loss: 5.4552e-04 - val_mae: 0.0170\n",
      "Epoch 427/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.5144e-04 - mae: 0.0179 - val_loss: 3.9561e-04 - val_mae: 0.0147\n",
      "Epoch 428/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.4571e-04 - mae: 0.0153 - val_loss: 5.4253e-04 - val_mae: 0.0166\n",
      "Epoch 429/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.3011e-04 - mae: 0.0161 - val_loss: 5.1424e-04 - val_mae: 0.0169\n",
      "Epoch 430/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 4.3943e-04 - mae: 0.0155 - val_loss: 4.4867e-04 - val_mae: 0.0152\n",
      "Epoch 431/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.3084e-04 - mae: 0.0153 - val_loss: 3.5232e-04 - val_mae: 0.0138\n",
      "Epoch 432/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.5527e-04 - mae: 0.0140 - val_loss: 3.1469e-04 - val_mae: 0.0133\n",
      "Epoch 433/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.2504e-04 - mae: 0.0136 - val_loss: 3.9776e-04 - val_mae: 0.0147\n",
      "Epoch 434/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4145e-04 - mae: 0.0136 - val_loss: 3.6876e-04 - val_mae: 0.0141\n",
      "Epoch 435/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.4194e-04 - mae: 0.0135 - val_loss: 2.8417e-04 - val_mae: 0.0123\n",
      "Epoch 436/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.8101e-04 - mae: 0.0123 - val_loss: 2.5651e-04 - val_mae: 0.0119\n",
      "Epoch 437/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.2449e-04 - mae: 0.0109 - val_loss: 2.2958e-04 - val_mae: 0.0113\n",
      "Epoch 438/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.3277e-04 - mae: 0.0110 - val_loss: 1.9310e-04 - val_mae: 0.0100\n",
      "Epoch 439/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.9157e-04 - mae: 0.0099 - val_loss: 2.3995e-04 - val_mae: 0.0115\n",
      "Epoch 440/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.9360e-04 - mae: 0.0102 - val_loss: 2.3868e-04 - val_mae: 0.0111\n",
      "Epoch 441/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9856e-04 - mae: 0.0102 - val_loss: 2.2135e-04 - val_mae: 0.0109\n",
      "Epoch 442/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9750e-04 - mae: 0.0102 - val_loss: 2.0693e-04 - val_mae: 0.0104\n",
      "Epoch 443/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9661e-04 - mae: 0.0100 - val_loss: 2.6892e-04 - val_mae: 0.0117\n",
      "Epoch 444/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.2440e-04 - mae: 0.0106 - val_loss: 2.3598e-04 - val_mae: 0.0110\n",
      "Epoch 445/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.2155e-04 - mae: 0.0106 - val_loss: 2.3689e-04 - val_mae: 0.0113\n",
      "Epoch 446/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.1721e-04 - mae: 0.0108 - val_loss: 1.9146e-04 - val_mae: 0.0100\n",
      "Epoch 447/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.8700e-04 - mae: 0.0099 - val_loss: 2.0370e-04 - val_mae: 0.0103\n",
      "Epoch 448/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 1.8676e-04 - mae: 0.0100 - val_loss: 1.7964e-04 - val_mae: 0.0095\n",
      "Epoch 449/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.7608e-04 - mae: 0.0094 - val_loss: 2.0030e-04 - val_mae: 0.0106\n",
      "Epoch 450/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6679e-04 - mae: 0.0095 - val_loss: 1.9450e-04 - val_mae: 0.0103\n",
      "Epoch 451/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7713e-04 - mae: 0.0098 - val_loss: 1.9380e-04 - val_mae: 0.0100\n",
      "Epoch 452/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7079e-04 - mae: 0.0095 - val_loss: 1.9638e-04 - val_mae: 0.0099\n",
      "Epoch 453/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8003e-04 - mae: 0.0096 - val_loss: 2.1624e-04 - val_mae: 0.0107\n",
      "Epoch 454/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.8554e-04 - mae: 0.0099 - val_loss: 2.0563e-04 - val_mae: 0.0106\n",
      "Epoch 455/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7771e-04 - mae: 0.0098 - val_loss: 2.0164e-04 - val_mae: 0.0104\n",
      "Epoch 456/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7315e-04 - mae: 0.0097 - val_loss: 1.9527e-04 - val_mae: 0.0104\n",
      "Epoch 457/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7460e-04 - mae: 0.0096 - val_loss: 1.8410e-04 - val_mae: 0.0097\n",
      "Epoch 458/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6570e-04 - mae: 0.0094 - val_loss: 1.8366e-04 - val_mae: 0.0099\n",
      "Epoch 459/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5989e-04 - mae: 0.0092 - val_loss: 1.8921e-04 - val_mae: 0.0101\n",
      "Epoch 460/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5848e-04 - mae: 0.0092 - val_loss: 1.8836e-04 - val_mae: 0.0099\n",
      "Epoch 461/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.5493e-04 - mae: 0.0090 - val_loss: 1.7120e-04 - val_mae: 0.0093\n",
      "Epoch 462/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5162e-04 - mae: 0.0087 - val_loss: 1.6967e-04 - val_mae: 0.0093\n",
      "Epoch 463/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5486e-04 - mae: 0.0089 - val_loss: 1.8370e-04 - val_mae: 0.0099\n",
      "Epoch 464/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.4776e-04 - mae: 0.0086 - val_loss: 1.8090e-04 - val_mae: 0.0099\n",
      "Epoch 465/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5099e-04 - mae: 0.0088 - val_loss: 2.0938e-04 - val_mae: 0.0106\n",
      "Epoch 466/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6670e-04 - mae: 0.0094 - val_loss: 2.1390e-04 - val_mae: 0.0107\n",
      "Epoch 467/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7339e-04 - mae: 0.0094 - val_loss: 1.9491e-04 - val_mae: 0.0104\n",
      "Epoch 468/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.6743e-04 - mae: 0.0094 - val_loss: 1.9576e-04 - val_mae: 0.0103\n",
      "Epoch 469/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6988e-04 - mae: 0.0094 - val_loss: 1.8254e-04 - val_mae: 0.0100\n",
      "Epoch 470/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.6032e-04 - mae: 0.0093 - val_loss: 1.8026e-04 - val_mae: 0.0098\n",
      "Epoch 471/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5301e-04 - mae: 0.0090 - val_loss: 2.1644e-04 - val_mae: 0.0107\n",
      "Epoch 472/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8191e-04 - mae: 0.0097 - val_loss: 2.1056e-04 - val_mae: 0.0104\n",
      "Epoch 473/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7494e-04 - mae: 0.0094 - val_loss: 2.2365e-04 - val_mae: 0.0111\n",
      "Epoch 474/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0093e-04 - mae: 0.0103 - val_loss: 2.1961e-04 - val_mae: 0.0110\n",
      "Epoch 475/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.9116e-04 - mae: 0.0100 - val_loss: 3.0052e-04 - val_mae: 0.0127\n",
      "Epoch 476/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.1734e-04 - mae: 0.0106 - val_loss: 2.3399e-04 - val_mae: 0.0113\n",
      "Epoch 477/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.9498e-04 - mae: 0.0102 - val_loss: 2.7381e-04 - val_mae: 0.0123\n",
      "Epoch 478/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3126e-04 - mae: 0.0109 - val_loss: 2.3766e-04 - val_mae: 0.0111\n",
      "Epoch 479/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.1640e-04 - mae: 0.0105 - val_loss: 3.8583e-04 - val_mae: 0.0133\n",
      "Epoch 480/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 2.7671e-04 - mae: 0.0114 - val_loss: 3.2670e-04 - val_mae: 0.0129\n",
      "Epoch 481/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.4452e-04 - mae: 0.0111 - val_loss: 3.5448e-04 - val_mae: 0.0137\n",
      "Epoch 482/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.8215e-04 - mae: 0.0116 - val_loss: 4.8279e-04 - val_mae: 0.0151\n",
      "Epoch 483/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.4401e-04 - mae: 0.0127 - val_loss: 4.7227e-04 - val_mae: 0.0156\n",
      "Epoch 484/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.4893e-04 - mae: 0.0129 - val_loss: 4.6190e-04 - val_mae: 0.0155\n",
      "Epoch 485/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.5860e-04 - mae: 0.0134 - val_loss: 5.9419e-04 - val_mae: 0.0163\n",
      "Epoch 486/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.9330e-04 - mae: 0.0134 - val_loss: 4.0056e-04 - val_mae: 0.0138\n",
      "Epoch 487/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.7450e-04 - mae: 0.0133 - val_loss: 5.1052e-04 - val_mae: 0.0151\n",
      "Epoch 488/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.5873e-04 - mae: 0.0126 - val_loss: 5.5166e-04 - val_mae: 0.0149\n",
      "Epoch 489/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.7022e-04 - mae: 0.0126 - val_loss: 4.6944e-04 - val_mae: 0.0149\n",
      "Epoch 490/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.0198e-04 - mae: 0.0137 - val_loss: 4.0630e-04 - val_mae: 0.0141\n",
      "Epoch 491/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.8484e-04 - mae: 0.0140 - val_loss: 4.6617e-04 - val_mae: 0.0151\n",
      "Epoch 492/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.9847e-04 - mae: 0.0122 - val_loss: 5.2573e-04 - val_mae: 0.0157\n",
      "Epoch 493/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.8815e-04 - mae: 0.0135 - val_loss: 4.9317e-04 - val_mae: 0.0163\n",
      "Epoch 494/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.1000e-04 - mae: 0.0146 - val_loss: 3.4932e-04 - val_mae: 0.0135\n",
      "Epoch 495/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 3.2518e-04 - mae: 0.0132 - val_loss: 3.0294e-04 - val_mae: 0.0130\n",
      "Epoch 496/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.6889e-04 - mae: 0.0121 - val_loss: 2.2918e-04 - val_mae: 0.0110\n",
      "Epoch 497/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9910e-04 - mae: 0.0103 - val_loss: 2.1126e-04 - val_mae: 0.0105\n",
      "Epoch 498/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 2.0158e-04 - mae: 0.0105 - val_loss: 2.4562e-04 - val_mae: 0.0113\n",
      "Epoch 499/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.1071e-04 - mae: 0.0106 - val_loss: 2.2794e-04 - val_mae: 0.0103\n",
      "Epoch 500/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8198e-04 - mae: 0.0095 - val_loss: 2.0881e-04 - val_mae: 0.0105\n",
      "Epoch 501/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7561e-04 - mae: 0.0095 - val_loss: 1.8545e-04 - val_mae: 0.0096\n",
      "Epoch 502/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.6723e-04 - mae: 0.0091 - val_loss: 1.6807e-04 - val_mae: 0.0089\n",
      "Epoch 503/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3924e-04 - mae: 0.0083 - val_loss: 2.0281e-04 - val_mae: 0.0104\n",
      "Epoch 504/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6989e-04 - mae: 0.0092 - val_loss: 2.2427e-04 - val_mae: 0.0105\n",
      "Epoch 505/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8163e-04 - mae: 0.0095 - val_loss: 2.1791e-04 - val_mae: 0.0105\n",
      "Epoch 506/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6599e-04 - mae: 0.0091 - val_loss: 2.0055e-04 - val_mae: 0.0100\n",
      "Epoch 507/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6443e-04 - mae: 0.0090 - val_loss: 2.0098e-04 - val_mae: 0.0101\n",
      "Epoch 508/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5738e-04 - mae: 0.0088 - val_loss: 2.3357e-04 - val_mae: 0.0107\n",
      "Epoch 509/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7178e-04 - mae: 0.0090 - val_loss: 2.1278e-04 - val_mae: 0.0099\n",
      "Epoch 510/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5948e-04 - mae: 0.0086 - val_loss: 1.9665e-04 - val_mae: 0.0097\n",
      "Epoch 511/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5266e-04 - mae: 0.0084 - val_loss: 1.8293e-04 - val_mae: 0.0094\n",
      "Epoch 512/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6112e-04 - mae: 0.0087 - val_loss: 1.9181e-04 - val_mae: 0.0099\n",
      "Epoch 513/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6303e-04 - mae: 0.0091 - val_loss: 1.9940e-04 - val_mae: 0.0099\n",
      "Epoch 514/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.6490e-04 - mae: 0.0090 - val_loss: 1.7341e-04 - val_mae: 0.0091\n",
      "Epoch 515/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.5320e-04 - mae: 0.0086 - val_loss: 1.8253e-04 - val_mae: 0.0096\n",
      "Epoch 516/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3940e-04 - mae: 0.0082 - val_loss: 1.8730e-04 - val_mae: 0.0097\n",
      "Epoch 517/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4930e-04 - mae: 0.0086 - val_loss: 2.0393e-04 - val_mae: 0.0100\n",
      "Epoch 518/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7095e-04 - mae: 0.0090 - val_loss: 1.8153e-04 - val_mae: 0.0093\n",
      "Epoch 519/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.4856e-04 - mae: 0.0084 - val_loss: 2.1313e-04 - val_mae: 0.0100\n",
      "Epoch 520/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.8960e-04 - mae: 0.0093 - val_loss: 2.1137e-04 - val_mae: 0.0103\n",
      "Epoch 521/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.7912e-04 - mae: 0.0094 - val_loss: 1.9647e-04 - val_mae: 0.0099\n",
      "Epoch 522/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.7703e-04 - mae: 0.0095 - val_loss: 2.0726e-04 - val_mae: 0.0102\n",
      "Epoch 523/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7622e-04 - mae: 0.0094 - val_loss: 1.7019e-04 - val_mae: 0.0094\n",
      "Epoch 524/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5407e-04 - mae: 0.0090 - val_loss: 1.6119e-04 - val_mae: 0.0090\n",
      "Epoch 525/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.4207e-04 - mae: 0.0085 - val_loss: 1.6855e-04 - val_mae: 0.0091\n",
      "Epoch 526/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3639e-04 - mae: 0.0083 - val_loss: 1.5820e-04 - val_mae: 0.0092\n",
      "Epoch 527/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3465e-04 - mae: 0.0083 - val_loss: 1.6135e-04 - val_mae: 0.0091\n",
      "Epoch 528/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3428e-04 - mae: 0.0083 - val_loss: 1.4595e-04 - val_mae: 0.0085\n",
      "Epoch 529/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3206e-04 - mae: 0.0081 - val_loss: 1.6795e-04 - val_mae: 0.0093\n",
      "Epoch 530/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.5639e-04 - mae: 0.0091 - val_loss: 1.4312e-04 - val_mae: 0.0085\n",
      "Epoch 531/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2436e-04 - mae: 0.0077 - val_loss: 1.4643e-04 - val_mae: 0.0084\n",
      "Epoch 532/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 1.2584e-04 - mae: 0.0078 - val_loss: 1.3228e-04 - val_mae: 0.0079\n",
      "Epoch 533/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.1566e-04 - mae: 0.0074 - val_loss: 1.3763e-04 - val_mae: 0.0083\n",
      "Epoch 534/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1779e-04 - mae: 0.0075 - val_loss: 1.4508e-04 - val_mae: 0.0085\n",
      "Epoch 535/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2019e-04 - mae: 0.0077 - val_loss: 1.2790e-04 - val_mae: 0.0079\n",
      "Epoch 536/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1240e-04 - mae: 0.0073 - val_loss: 1.4377e-04 - val_mae: 0.0086\n",
      "Epoch 537/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.2441e-04 - mae: 0.0079 - val_loss: 1.6628e-04 - val_mae: 0.0092\n",
      "Epoch 538/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4454e-04 - mae: 0.0086 - val_loss: 1.6056e-04 - val_mae: 0.0091\n",
      "Epoch 539/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5213e-04 - mae: 0.0088 - val_loss: 1.3421e-04 - val_mae: 0.0081\n",
      "Epoch 540/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.4195e-04 - mae: 0.0085 - val_loss: 1.3614e-04 - val_mae: 0.0082\n",
      "Epoch 541/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3793e-04 - mae: 0.0084 - val_loss: 1.5444e-04 - val_mae: 0.0088\n",
      "Epoch 542/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3949e-04 - mae: 0.0084 - val_loss: 1.4495e-04 - val_mae: 0.0087\n",
      "Epoch 543/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4086e-04 - mae: 0.0084 - val_loss: 1.4131e-04 - val_mae: 0.0086\n",
      "Epoch 544/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2883e-04 - mae: 0.0080 - val_loss: 1.4140e-04 - val_mae: 0.0085\n",
      "Epoch 545/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4236e-04 - mae: 0.0085 - val_loss: 2.2629e-04 - val_mae: 0.0110\n",
      "Epoch 546/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8850e-04 - mae: 0.0098 - val_loss: 2.0638e-04 - val_mae: 0.0103\n",
      "Epoch 547/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.1390e-04 - mae: 0.0106 - val_loss: 2.5535e-04 - val_mae: 0.0115\n",
      "Epoch 548/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5406e-04 - mae: 0.0115 - val_loss: 3.9066e-04 - val_mae: 0.0137\n",
      "Epoch 549/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.2634e-04 - mae: 0.0127 - val_loss: 2.8621e-04 - val_mae: 0.0124\n",
      "Epoch 550/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.5658e-04 - mae: 0.0117 - val_loss: 2.3861e-04 - val_mae: 0.0112\n",
      "Epoch 551/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.3645e-04 - mae: 0.0112 - val_loss: 3.1329e-04 - val_mae: 0.0125\n",
      "Epoch 552/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.0789e-04 - mae: 0.0126 - val_loss: 4.7175e-04 - val_mae: 0.0158\n",
      "Epoch 553/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.1938e-04 - mae: 0.0146 - val_loss: 5.2069e-04 - val_mae: 0.0169\n",
      "Epoch 554/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.8101e-04 - mae: 0.0175 - val_loss: 4.3296e-04 - val_mae: 0.0153\n",
      "Epoch 555/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.6353e-04 - mae: 0.0158 - val_loss: 4.9655e-04 - val_mae: 0.0155\n",
      "Epoch 556/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.4022e-04 - mae: 0.0154 - val_loss: 0.0010 - val_mae: 0.0211\n",
      "Epoch 557/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.3134e-04 - mae: 0.0199 - val_loss: 0.0017 - val_mae: 0.0254\n",
      "Epoch 558/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0012 - mae: 0.0212 - val_loss: 0.0017 - val_mae: 0.0263\n",
      "Epoch 559/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0218 - val_loss: 0.0026 - val_mae: 0.0314\n",
      "Epoch 560/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0248 - val_loss: 0.0020 - val_mae: 0.0299\n",
      "Epoch 561/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0016 - mae: 0.0258 - val_loss: 0.0019 - val_mae: 0.0296\n",
      "Epoch 562/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 0.0018 - val_mae: 0.0293\n",
      "Epoch 563/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0021 - val_mae: 0.0313\n",
      "Epoch 564/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0019 - mae: 0.0292 - val_loss: 0.0015 - val_mae: 0.0255\n",
      "Epoch 565/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 566/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.8357e-04 - mae: 0.0235 - val_loss: 5.9110e-04 - val_mae: 0.0190\n",
      "Epoch 567/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.6258e-04 - mae: 0.0189 - val_loss: 5.1608e-04 - val_mae: 0.0178\n",
      "Epoch 568/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.1345e-04 - mae: 0.0184 - val_loss: 5.0238e-04 - val_mae: 0.0170\n",
      "Epoch 569/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.9431e-04 - mae: 0.0176 - val_loss: 3.6878e-04 - val_mae: 0.0144\n",
      "Epoch 570/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0808e-04 - mae: 0.0160 - val_loss: 3.5940e-04 - val_mae: 0.0143\n",
      "Epoch 571/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.0890e-04 - mae: 0.0149 - val_loss: 5.0079e-04 - val_mae: 0.0165\n",
      "Epoch 572/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7993e-04 - mae: 0.0162 - val_loss: 6.9975e-04 - val_mae: 0.0187\n",
      "Epoch 573/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.6386e-04 - mae: 0.0169 - val_loss: 9.1479e-04 - val_mae: 0.0212\n",
      "Epoch 574/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.5184e-04 - mae: 0.0183 - val_loss: 7.6695e-04 - val_mae: 0.0192\n",
      "Epoch 575/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 6.5461e-04 - mae: 0.0174 - val_loss: 6.9068e-04 - val_mae: 0.0182\n",
      "Epoch 576/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.3965e-04 - mae: 0.0162 - val_loss: 5.3530e-04 - val_mae: 0.0161\n",
      "Epoch 577/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.3055e-04 - mae: 0.0162 - val_loss: 3.8864e-04 - val_mae: 0.0146\n",
      "Epoch 578/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4.2997e-04 - mae: 0.0148 - val_loss: 4.5595e-04 - val_mae: 0.0160\n",
      "Epoch 579/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 4.9716e-04 - mae: 0.0158 - val_loss: 4.6680e-04 - val_mae: 0.0164\n",
      "Epoch 580/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.6375e-04 - mae: 0.0172 - val_loss: 5.0854e-04 - val_mae: 0.0165\n",
      "Epoch 581/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.8318e-04 - mae: 0.0196 - val_loss: 5.5167e-04 - val_mae: 0.0172\n",
      "Epoch 582/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.3712e-04 - mae: 0.0184 - val_loss: 4.9438e-04 - val_mae: 0.0163\n",
      "Epoch 583/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.4600e-04 - mae: 0.0168 - val_loss: 5.7938e-04 - val_mae: 0.0160\n",
      "Epoch 584/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.0527e-04 - mae: 0.0172 - val_loss: 4.9896e-04 - val_mae: 0.0161\n",
      "Epoch 585/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 5.9232e-04 - mae: 0.0177 - val_loss: 4.6571e-04 - val_mae: 0.0161\n",
      "Epoch 586/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.1571e-04 - mae: 0.0169 - val_loss: 9.9471e-04 - val_mae: 0.0211\n",
      "Epoch 587/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.4376e-04 - mae: 0.0188 - val_loss: 0.0013 - val_mae: 0.0247\n",
      "Epoch 588/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 589/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.8755e-04 - mae: 0.0210 - val_loss: 0.0012 - val_mae: 0.0234\n",
      "Epoch 590/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.5396e-04 - mae: 0.0210 - val_loss: 8.2171e-04 - val_mae: 0.0203\n",
      "Epoch 591/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5086e-04 - mae: 0.0195 - val_loss: 5.1136e-04 - val_mae: 0.0162\n",
      "Epoch 592/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.9826e-04 - mae: 0.0161 - val_loss: 4.2104e-04 - val_mae: 0.0150\n",
      "Epoch 593/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.2309e-04 - mae: 0.0148 - val_loss: 4.5053e-04 - val_mae: 0.0150\n",
      "Epoch 594/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.0188e-04 - mae: 0.0147 - val_loss: 4.1922e-04 - val_mae: 0.0147\n",
      "Epoch 595/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.7837e-04 - mae: 0.0139 - val_loss: 4.0438e-04 - val_mae: 0.0144\n",
      "Epoch 596/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.3928e-04 - mae: 0.0132 - val_loss: 3.4538e-04 - val_mae: 0.0134\n",
      "Epoch 597/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3.4084e-04 - mae: 0.0134 - val_loss: 6.5255e-04 - val_mae: 0.0158\n",
      "Epoch 598/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.8330e-04 - mae: 0.0141 - val_loss: 6.7083e-04 - val_mae: 0.0174\n",
      "Epoch 599/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.7841e-04 - mae: 0.0149 - val_loss: 4.8045e-04 - val_mae: 0.0158\n",
      "Epoch 600/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.2959e-04 - mae: 0.0146 - val_loss: 3.9432e-04 - val_mae: 0.0135\n",
      "Epoch 601/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.4443e-04 - mae: 0.0130 - val_loss: 2.6521e-04 - val_mae: 0.0118\n",
      "Epoch 602/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.7307e-04 - mae: 0.0119 - val_loss: 1.9656e-04 - val_mae: 0.0102\n",
      "Epoch 603/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1398e-04 - mae: 0.0107 - val_loss: 2.9761e-04 - val_mae: 0.0126\n",
      "Epoch 604/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3952e-04 - mae: 0.0112 - val_loss: 2.6819e-04 - val_mae: 0.0117\n",
      "Epoch 605/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.5767e-04 - mae: 0.0114 - val_loss: 2.7636e-04 - val_mae: 0.0125\n",
      "Epoch 606/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3597e-04 - mae: 0.0113 - val_loss: 2.6336e-04 - val_mae: 0.0123\n",
      "Epoch 607/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.0054e-04 - mae: 0.0105 - val_loss: 2.4537e-04 - val_mae: 0.0116\n",
      "Epoch 608/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.2487e-04 - mae: 0.0109 - val_loss: 1.8931e-04 - val_mae: 0.0101\n",
      "Epoch 609/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7405e-04 - mae: 0.0096 - val_loss: 1.9250e-04 - val_mae: 0.0101\n",
      "Epoch 610/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 1.8266e-04 - mae: 0.0097 - val_loss: 1.9846e-04 - val_mae: 0.0103\n",
      "Epoch 611/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8370e-04 - mae: 0.0100 - val_loss: 1.9798e-04 - val_mae: 0.0104\n",
      "Epoch 612/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.7867e-04 - mae: 0.0098 - val_loss: 2.0407e-04 - val_mae: 0.0105\n",
      "Epoch 613/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8483e-04 - mae: 0.0099 - val_loss: 2.4714e-04 - val_mae: 0.0113\n",
      "Epoch 614/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.1564e-04 - mae: 0.0106 - val_loss: 2.4379e-04 - val_mae: 0.0110\n",
      "Epoch 615/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0569e-04 - mae: 0.0103 - val_loss: 2.3534e-04 - val_mae: 0.0110\n",
      "Epoch 616/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.2625e-04 - mae: 0.0109 - val_loss: 2.5017e-04 - val_mae: 0.0111\n",
      "Epoch 617/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.1477e-04 - mae: 0.0106 - val_loss: 2.5528e-04 - val_mae: 0.0110\n",
      "Epoch 618/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3635e-04 - mae: 0.0108 - val_loss: 2.3271e-04 - val_mae: 0.0109\n",
      "Epoch 619/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.1243e-04 - mae: 0.0102 - val_loss: 3.2527e-04 - val_mae: 0.0124\n",
      "Epoch 620/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.4394e-04 - mae: 0.0110 - val_loss: 2.2645e-04 - val_mae: 0.0111\n",
      "Epoch 621/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.0240e-04 - mae: 0.0102 - val_loss: 2.2201e-04 - val_mae: 0.0109\n",
      "Epoch 622/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.9630e-04 - mae: 0.0102 - val_loss: 2.3850e-04 - val_mae: 0.0111\n",
      "Epoch 623/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.1549e-04 - mae: 0.0104 - val_loss: 2.3341e-04 - val_mae: 0.0112\n",
      "Epoch 624/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.8943e-04 - mae: 0.0099 - val_loss: 2.4434e-04 - val_mae: 0.0116\n",
      "Epoch 625/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 2.4043e-04 - mae: 0.0111 - val_loss: 2.4416e-04 - val_mae: 0.0114\n",
      "Epoch 626/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9585e-04 - mae: 0.0124 - val_loss: 2.6827e-04 - val_mae: 0.0118\n",
      "Epoch 627/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.4228e-04 - mae: 0.0132 - val_loss: 2.3317e-04 - val_mae: 0.0112\n",
      "Epoch 628/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.2244e-04 - mae: 0.0131 - val_loss: 2.8328e-04 - val_mae: 0.0133\n",
      "Epoch 629/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.8200e-04 - mae: 0.0130 - val_loss: 2.5478e-04 - val_mae: 0.0120\n",
      "Epoch 630/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.3847e-04 - mae: 0.0115 - val_loss: 2.6930e-04 - val_mae: 0.0121\n",
      "Epoch 631/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.7381e-04 - mae: 0.0120 - val_loss: 4.3649e-04 - val_mae: 0.0141\n",
      "Epoch 632/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.3229e-04 - mae: 0.0136 - val_loss: 5.6699e-04 - val_mae: 0.0167\n",
      "Epoch 633/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9333e-04 - mae: 0.0149 - val_loss: 3.5332e-04 - val_mae: 0.0138\n",
      "Epoch 634/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.7385e-04 - mae: 0.0142 - val_loss: 2.7792e-04 - val_mae: 0.0122\n",
      "Epoch 635/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.8733e-04 - mae: 0.0125 - val_loss: 4.3588e-04 - val_mae: 0.0149\n",
      "Epoch 636/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.7185e-04 - mae: 0.0142 - val_loss: 6.6410e-04 - val_mae: 0.0178\n",
      "Epoch 637/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.3994e-04 - mae: 0.0134 - val_loss: 5.6528e-04 - val_mae: 0.0159\n",
      "Epoch 638/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.5710e-04 - mae: 0.0148 - val_loss: 9.1400e-04 - val_mae: 0.0202\n",
      "Epoch 639/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.3225e-04 - mae: 0.0178 - val_loss: 7.7235e-04 - val_mae: 0.0195\n",
      "Epoch 640/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.0013e-04 - mae: 0.0183 - val_loss: 0.0011 - val_mae: 0.0236\n",
      "Epoch 641/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.2017e-04 - mae: 0.0182 - val_loss: 9.9289e-04 - val_mae: 0.0220\n",
      "Epoch 642/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7045e-04 - mae: 0.0179 - val_loss: 6.3885e-04 - val_mae: 0.0189\n",
      "Epoch 643/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.9636e-04 - mae: 0.0179 - val_loss: 6.7805e-04 - val_mae: 0.0189\n",
      "Epoch 644/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.9537e-04 - mae: 0.0193 - val_loss: 7.1092e-04 - val_mae: 0.0200\n",
      "Epoch 645/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.1754e-04 - mae: 0.0192 - val_loss: 0.0017 - val_mae: 0.0278\n",
      "Epoch 646/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0267\n",
      "Epoch 647/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.8128e-04 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0238\n",
      "Epoch 648/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.2821e-04 - mae: 0.0227 - val_loss: 0.0013 - val_mae: 0.0260\n",
      "Epoch 649/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0256 - val_loss: 0.0022 - val_mae: 0.0291\n",
      "Epoch 650/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 0.0020 - val_mae: 0.0297\n",
      "Epoch 651/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0013 - mae: 0.0233 - val_loss: 9.8321e-04 - val_mae: 0.0211\n",
      "Epoch 652/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 8.6457e-04 - mae: 0.0205 - val_loss: 0.0010 - val_mae: 0.0227\n",
      "Epoch 653/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 8.8891e-04 - mae: 0.0206 - val_loss: 0.0014 - val_mae: 0.0239\n",
      "Epoch 654/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 0.0021 - val_mae: 0.0275\n",
      "Epoch 655/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0013 - mae: 0.0225 - val_loss: 0.0018 - val_mae: 0.0247\n",
      "Epoch 656/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 0.0021 - val_mae: 0.0312\n",
      "Epoch 657/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 0.0019 - val_mae: 0.0289\n",
      "Epoch 658/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 0.0014 - val_mae: 0.0249\n",
      "Epoch 659/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 0.0024 - val_mae: 0.0334\n",
      "Epoch 660/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0017 - val_mae: 0.0303\n",
      "Epoch 661/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0022 - val_mae: 0.0321\n",
      "Epoch 662/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0019 - mae: 0.0305 - val_loss: 0.0025 - val_mae: 0.0371\n",
      "Epoch 663/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 0.0027 - val_mae: 0.0370\n",
      "Epoch 664/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 0.0022 - val_mae: 0.0329\n",
      "Epoch 665/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0015 - val_mae: 0.0286\n",
      "Epoch 666/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0013 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0281\n",
      "Epoch 667/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 0.0018 - val_mae: 0.0294\n",
      "Epoch 668/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 669/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.1828e-04 - mae: 0.0226 - val_loss: 9.7646e-04 - val_mae: 0.0231\n",
      "Epoch 670/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.4312e-04 - mae: 0.0217 - val_loss: 8.4893e-04 - val_mae: 0.0222\n",
      "Epoch 671/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.4978e-04 - mae: 0.0206 - val_loss: 9.5634e-04 - val_mae: 0.0233\n",
      "Epoch 672/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.0972e-04 - mae: 0.0198 - val_loss: 0.0010 - val_mae: 0.0239\n",
      "Epoch 673/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.2253e-04 - mae: 0.0197 - val_loss: 6.4194e-04 - val_mae: 0.0189\n",
      "Epoch 674/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.0629e-04 - mae: 0.0184 - val_loss: 6.4493e-04 - val_mae: 0.0188\n",
      "Epoch 675/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.6812e-04 - mae: 0.0177 - val_loss: 5.7352e-04 - val_mae: 0.0176\n",
      "Epoch 676/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.1533e-04 - mae: 0.0165 - val_loss: 9.2967e-04 - val_mae: 0.0218\n",
      "Epoch 677/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.8222e-04 - mae: 0.0182 - val_loss: 5.2701e-04 - val_mae: 0.0171\n",
      "Epoch 678/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.9916e-04 - mae: 0.0163 - val_loss: 4.0078e-04 - val_mae: 0.0150\n",
      "Epoch 679/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.8636e-04 - mae: 0.0144 - val_loss: 3.8616e-04 - val_mae: 0.0145\n",
      "Epoch 680/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.3133e-04 - mae: 0.0133 - val_loss: 4.2679e-04 - val_mae: 0.0155\n",
      "Epoch 681/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.0328e-04 - mae: 0.0146 - val_loss: 4.8181e-04 - val_mae: 0.0159\n",
      "Epoch 682/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.4239e-04 - mae: 0.0154 - val_loss: 3.4068e-04 - val_mae: 0.0141\n",
      "Epoch 683/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.6166e-04 - mae: 0.0143 - val_loss: 3.8372e-04 - val_mae: 0.0146\n",
      "Epoch 684/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.1502e-04 - mae: 0.0150 - val_loss: 3.4817e-04 - val_mae: 0.0138\n",
      "Epoch 685/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6244e-04 - mae: 0.0142 - val_loss: 2.7432e-04 - val_mae: 0.0123\n",
      "Epoch 686/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.0319e-04 - mae: 0.0131 - val_loss: 3.3621e-04 - val_mae: 0.0137\n",
      "Epoch 687/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.4694e-04 - mae: 0.0140 - val_loss: 4.1265e-04 - val_mae: 0.0151\n",
      "Epoch 688/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.8853e-04 - mae: 0.0148 - val_loss: 3.3042e-04 - val_mae: 0.0136\n",
      "Epoch 689/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.0322e-04 - mae: 0.0135 - val_loss: 3.2610e-04 - val_mae: 0.0131\n",
      "Epoch 690/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.1677e-04 - mae: 0.0135 - val_loss: 2.9340e-04 - val_mae: 0.0127\n",
      "Epoch 691/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.8177e-04 - mae: 0.0123 - val_loss: 2.5009e-04 - val_mae: 0.0120\n",
      "Epoch 692/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4382e-04 - mae: 0.0115 - val_loss: 2.8801e-04 - val_mae: 0.0125\n",
      "Epoch 693/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 2.7783e-04 - mae: 0.0120 - val_loss: 2.3147e-04 - val_mae: 0.0114\n",
      "Epoch 694/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3173e-04 - mae: 0.0114 - val_loss: 2.5366e-04 - val_mae: 0.0121\n",
      "Epoch 695/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5179e-04 - mae: 0.0120 - val_loss: 3.3834e-04 - val_mae: 0.0137\n",
      "Epoch 696/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 2.7728e-04 - mae: 0.0125 - val_loss: 3.0679e-04 - val_mae: 0.0134\n",
      "Epoch 697/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 3.0649e-04 - mae: 0.0130 - val_loss: 2.8218e-04 - val_mae: 0.0126\n",
      "Epoch 698/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.7156e-04 - mae: 0.0125 - val_loss: 2.4934e-04 - val_mae: 0.0118\n",
      "Epoch 699/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.3216e-04 - mae: 0.0114 - val_loss: 2.2472e-04 - val_mae: 0.0109\n",
      "Epoch 700/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.1006e-04 - mae: 0.0108 - val_loss: 2.0001e-04 - val_mae: 0.0105\n",
      "Epoch 701/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.1378e-04 - mae: 0.0109 - val_loss: 2.2064e-04 - val_mae: 0.0109\n",
      "Epoch 702/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.4988e-04 - mae: 0.0116 - val_loss: 2.5230e-04 - val_mae: 0.0120\n",
      "Epoch 703/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.8544e-04 - mae: 0.0124 - val_loss: 2.5121e-04 - val_mae: 0.0121\n",
      "Epoch 704/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.5088e-04 - mae: 0.0119 - val_loss: 2.5173e-04 - val_mae: 0.0117\n",
      "Epoch 705/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.5756e-04 - mae: 0.0119 - val_loss: 2.0632e-04 - val_mae: 0.0107\n",
      "Epoch 706/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.3810e-04 - mae: 0.0116 - val_loss: 2.6791e-04 - val_mae: 0.0120\n",
      "Epoch 707/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 2.8180e-04 - mae: 0.0124 - val_loss: 2.6225e-04 - val_mae: 0.0120\n",
      "Epoch 708/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.6444e-04 - mae: 0.0119 - val_loss: 1.9646e-04 - val_mae: 0.0103\n",
      "Epoch 709/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.9477e-04 - mae: 0.0104 - val_loss: 2.4343e-04 - val_mae: 0.0115\n",
      "Epoch 710/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.0492e-04 - mae: 0.0104 - val_loss: 2.2935e-04 - val_mae: 0.0111\n",
      "Epoch 711/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.0542e-04 - mae: 0.0104 - val_loss: 2.0671e-04 - val_mae: 0.0108\n",
      "Epoch 712/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2.0173e-04 - mae: 0.0104 - val_loss: 1.8612e-04 - val_mae: 0.0102\n",
      "Epoch 713/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1745e-04 - mae: 0.0108 - val_loss: 2.0988e-04 - val_mae: 0.0111\n",
      "Epoch 714/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.2985e-04 - mae: 0.0116 - val_loss: 2.4039e-04 - val_mae: 0.0121\n",
      "Epoch 715/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 2.3982e-04 - mae: 0.0120 - val_loss: 2.1804e-04 - val_mae: 0.0112\n",
      "Epoch 716/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8799e-04 - mae: 0.0104 - val_loss: 1.9389e-04 - val_mae: 0.0100\n",
      "Epoch 717/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8949e-04 - mae: 0.0098 - val_loss: 1.7061e-04 - val_mae: 0.0095\n",
      "Epoch 718/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.6742e-04 - mae: 0.0093 - val_loss: 1.8256e-04 - val_mae: 0.0097\n",
      "Epoch 719/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6561e-04 - mae: 0.0092 - val_loss: 1.4192e-04 - val_mae: 0.0084\n",
      "Epoch 720/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2903e-04 - mae: 0.0082 - val_loss: 1.6235e-04 - val_mae: 0.0093\n",
      "Epoch 721/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4465e-04 - mae: 0.0086 - val_loss: 1.5238e-04 - val_mae: 0.0088\n",
      "Epoch 722/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.4544e-04 - mae: 0.0084 - val_loss: 1.6644e-04 - val_mae: 0.0096\n",
      "Epoch 723/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 1.5463e-04 - mae: 0.0091 - val_loss: 1.5950e-04 - val_mae: 0.0091\n",
      "Epoch 724/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.5861e-04 - mae: 0.0091 - val_loss: 1.2878e-04 - val_mae: 0.0080\n",
      "Epoch 725/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2878e-04 - mae: 0.0081 - val_loss: 1.4816e-04 - val_mae: 0.0087\n",
      "Epoch 726/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3500e-04 - mae: 0.0083 - val_loss: 1.4274e-04 - val_mae: 0.0086\n",
      "Epoch 727/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2665e-04 - mae: 0.0080 - val_loss: 1.4910e-04 - val_mae: 0.0089\n",
      "Epoch 728/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.3555e-04 - mae: 0.0084 - val_loss: 1.3696e-04 - val_mae: 0.0084\n",
      "Epoch 729/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.2741e-04 - mae: 0.0079 - val_loss: 2.2223e-04 - val_mae: 0.0104\n",
      "Epoch 730/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8289e-04 - mae: 0.0094 - val_loss: 2.5710e-04 - val_mae: 0.0113\n",
      "Epoch 731/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1883e-04 - mae: 0.0101 - val_loss: 1.9182e-04 - val_mae: 0.0098\n",
      "Epoch 732/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7869e-04 - mae: 0.0095 - val_loss: 2.0244e-04 - val_mae: 0.0102\n",
      "Epoch 733/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8320e-04 - mae: 0.0095 - val_loss: 1.7055e-04 - val_mae: 0.0094\n",
      "Epoch 734/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6644e-04 - mae: 0.0092 - val_loss: 1.9202e-04 - val_mae: 0.0101\n",
      "Epoch 735/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8706e-04 - mae: 0.0097 - val_loss: 2.9376e-04 - val_mae: 0.0117\n",
      "Epoch 735: early stopping\n",
      "Restoring model weights from the end of the best epoch: 535.\n"
     ]
    }
   ],
   "source": [
    "# Definizione modello DNN\n",
    "def build_model(input_shape: tuple, output_shape: tuple):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation = \"relu\", input_shape=input_shape),\n",
    "        Dropout(0.0),\n",
    "        layers.Dense(output_shape, 'linear')\n",
    "    ])\n",
    "    model.compile(\n",
    "    optimizer=optimizers.AdamW(learning_rate=0.0062, weight_decay=0.0397),\n",
    "    loss= 'mse',\n",
    "    metrics=['mae'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',      # metrica da monitorare, es. val_loss o val_mae\n",
    "    patience=200,             # numero di epoche senza miglioramento prima di fermare\n",
    "    restore_best_weights=True,  # ripristina i pesi migliori trovati\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Training del modello\n",
    "model = build_model((X_test.shape[1],), y_test.shape[1])\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    callbacks = [early_stop],\n",
    "    validation_split = 0.2,\n",
    "    verbose=1\n",
    "    )\n",
    "\n",
    "'''print(\"y_train min/max:\", y_train_np.min(), y_train_np.max())\n",
    "print(\"y_pred min/max (scaled):\", y_pred.min(), y_pred.max())\n",
    "y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
    "print(\"y_pred_rescaled min/max:\", y_pred_rescaled.min(), y_pred_rescaled.max())'''\n",
    "\n",
    "if not os.path.exists(os.path.join(exp_dir, \"model\")):\n",
    "    os.makedirs(os.path.join(exp_dir, \"model\"))\n",
    "    model.save(os.path.join(exp_dir, \"model\", f\"{sensor_name}_model.keras\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b6149cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f'{exp_dir}/model/NO2_{sensor_name}_model.keras') if os.path.exists(f'{exp_dir}/model/NO2_{sensor_name}_model.keras') else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "105abd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai losses da tutti i folds\n",
    "train_losses = history.history['loss']\n",
    "val_losses   = history.history['val_loss']\n",
    "\n",
    "train_losses = train_losses\n",
    "val_losses = val_losses\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "\n",
    "# Training loss\n",
    "plt.plot(train_losses, color='blue', label='Train Loss')\n",
    "# Validation loss\n",
    "plt.plot(val_losses, color='red', label='Validation Loss')\n",
    "\n",
    "\n",
    "# Dettagli grafico\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training & Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.savefig(f'{exp_dir}/loss_plot.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1f8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_n_series(y_pred, y_test, n_series=10, title=\"Confronto Serie Predette vs Reali\"):\n",
    "    \"\"\"\n",
    "    Plotta le prime n_series serie reali e predette per un confronto diretto.\n",
    "\n",
    "    Args:\n",
    "        y_pred (np.ndarray): Predizioni del modello (shape: num_samples x seq_len).\n",
    "        y_test (np.ndarray): Serie reali (shape: num_samples x seq_len).\n",
    "        n_series (int): Numero di serie da plottare.\n",
    "        title (str): Titolo del grafico.\n",
    "    \"\"\"\n",
    "\n",
    "    # Limitiamo a n_series per evitare problemi\n",
    "    n = min(n_series, y_pred.shape[0], y_test.shape[0])\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.plot(\n",
    "            y_test[i], \n",
    "            linewidth=1.8, \n",
    "            alpha=0.5, \n",
    "            label=f\"Reale {i+1}\" if i == 0 else \"\",\n",
    "            color = 'blue'\n",
    "        )\n",
    "        plt.plot(\n",
    "            y_pred[i], \n",
    "            linewidth=1.2, \n",
    "            linestyle=\"--\", \n",
    "            alpha=0.9, \n",
    "            label=f\"Predetto {i+1}\" if i == 0 else \"\",\n",
    "            color = 'orange'\n",
    "        )\n",
    "\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(\"Time Step\", fontsize=12)\n",
    "    plt.ylabel(\"Valore\", fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ddfb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_diagnosis_gradient(y_pred, y_test, save_path: str,  tolerance:float =0.05, max_samples_heatmap=50, scatter_sample_ratio=0.5, tol_auto = True):\n",
    "    \"\"\"\n",
    "    Dashboard diagnostica con tolleranza AUTO-ADATTIVA alla scala dei dati.\n",
    "    \n",
    "    Args:\n",
    "        tolerance (float): \n",
    "            - Se None: La tolleranza viene calcolata automaticamente come il 5% del range dei dati (Max-Min).\n",
    "            - Se float: Valore assoluto (es. 0.5).\n",
    "        tol_auto (bool): Se True, usa la tolleranza automatica basata sul range dei dati, altrimenti usa il valore manuale fornito \n",
    "        col parametro tolerance.\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test_flat = y_test.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # AUTOMAZIONE TOLLERANZA\n",
    "    # ---------------------------------------------------------\n",
    "    if tol_auto:\n",
    "        data_range = y_test_flat.max() - y_test_flat.min()\n",
    "        # Impostiamo la tolleranza al 5% del range totale (regolabile)\n",
    "        tolerance = data_range * tolerance \n",
    "        tol_label = f\"Auto (5% Range: ±{tolerance:.2f})\"\n",
    "    else:\n",
    "        tol_label = f\"Manuale (±{tolerance})\"\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(22, 8))\n",
    "\n",
    "    # -----------------------------\n",
    "    # 1. HEATMAP (SX)\n",
    "    # -----------------------------\n",
    "    errors = np.abs(y_test - y_pred)\n",
    "    errors_subset = errors[:max_samples_heatmap]\n",
    "    \n",
    "    # Adattiamo anche la scala colori della heatmap alla tolleranza\n",
    "    # Tutto ciò che è oltre 3 volte la tolleranza è \"errore massimo\" visivo\n",
    "    sns.heatmap(errors_subset, cmap=\"plasma\", ax=axes[0], \n",
    "                vmax=tolerance * 3,\n",
    "                cbar_kws={'label': 'Errore Assoluto'})\n",
    "    \n",
    "    axes[0].set_title(f\"Heatmap Errori (Primi {max_samples_heatmap} campioni)\", fontsize=16)\n",
    "    axes[0].set_xlabel(\"Time Step\", fontsize=12)\n",
    "    axes[0].set_ylabel(\"Indice Campione\", fontsize=12)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 2. SCATTER CON SFONDO GRADIENTE (DX)\n",
    "    # -----------------------------\n",
    "    \n",
    "    # Campionamento dati\n",
    "    if scatter_sample_ratio < 1.0:\n",
    "        mask = np.random.rand(len(y_test_flat)) < scatter_sample_ratio\n",
    "        sample_test = y_test_flat[mask]\n",
    "        sample_pred = y_pred_flat[mask]\n",
    "    else:\n",
    "        sample_test = y_test_flat\n",
    "        sample_pred = y_pred_flat\n",
    "\n",
    "    # Calcolo limiti grafico\n",
    "    min_val = min(y_test_flat.min(), y_pred_flat.min())\n",
    "    max_val = max(y_test_flat.max(), y_pred_flat.max())\n",
    "    padding = (max_val - min_val) * 0.05\n",
    "    plot_min = min_val - padding\n",
    "    plot_max = max_val + padding\n",
    "\n",
    "    # --- SFONDO GRADIENTE ---\n",
    "    grid_x, grid_y = np.meshgrid(\n",
    "        np.linspace(plot_min, plot_max, 200),\n",
    "        np.linspace(plot_min, plot_max, 200)\n",
    "    )\n",
    "    grid_z = np.abs(grid_y - grid_x)\n",
    "\n",
    "    im = axes[1].imshow(\n",
    "        grid_z, \n",
    "        extent=(plot_min, plot_max, plot_min, plot_max), \n",
    "        origin='lower', \n",
    "        cmap='RdYlGn_r', \n",
    "        alpha=0.4, \n",
    "        vmax=tolerance * 4, # Il rosso satura a 4x della tolleranza\n",
    "        aspect='auto'\n",
    "    )\n",
    "\n",
    "    # --- PUNTI BLU ---\n",
    "    axes[1].scatter(\n",
    "        sample_test, \n",
    "        sample_pred, \n",
    "        alpha=0.6, \n",
    "        s=15, \n",
    "        color='royalblue', \n",
    "        edgecolors='white', \n",
    "        linewidth=0.3,\n",
    "        label='Campioni'\n",
    "    )\n",
    "\n",
    "    axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n",
    "\n",
    "    # Metriche\n",
    "    within_tol = np.mean(np.abs(y_test_flat - y_pred_flat) <= tolerance) * 100\n",
    "\n",
    "    axes[1].set_title(\n",
    "        f\"Bontà delle previsioni con {tol_label}\\nValori nel range di Tolleranza: {within_tol:.1f}%\", \n",
    "        fontsize=16\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Valore Reale\", fontsize=12)\n",
    "    axes[1].set_ylabel(\"Valore Predetto\", fontsize=12)\n",
    "    axes[1].set_xlim(plot_min, plot_max)\n",
    "    axes[1].set_ylim(plot_min, plot_max)\n",
    "    \n",
    "    cbar = plt.colorbar(im, ax=axes[1], pad=0.02)\n",
    "    cbar.set_label('Gravità Errore (Distanza da diagonale)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{exp_dir}/{save_path}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00d6ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/vnvjtlb516n5mswtv7rf58b80000gn/T/ipykernel_1855/2011710758.py:96: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k--\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)\n",
    "y_test_np = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "plot_diagnosis_gradient(y_pred, y_test_np, save_path='pred_quality', max_samples_heatmap=10, scatter_sample_ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ca8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo 60 plot in: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/TEST\n",
      "Plot salvati correttamente.\n"
     ]
    }
   ],
   "source": [
    "save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/TEST', prefix=\"pred_plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aadcb2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"epsilon = 1e-8  # piccolo valore per evitare log(0) in scala log\\n\\nfor i in range(len(y_test_np)):\\n    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\\n\\n    # Sostituisci i valori nulli con epsilon per il log\\n    y_pred_safe = np.where(y_pred[i] <= 0, epsilon, y_pred[i])\\n    y_test_safe = np.where(y_test_np[i] <= 0, epsilon, y_test_np[i])\\n\\n    # Calcola la differenza percentuale con gestione divisione per 0\\n    differenza = np.divide(\\n        (y_pred[i] - y_test_np[i]) * 100,\\n        y_test_np[i],\\n        out=np.full_like(y_pred[i], np.nan, dtype=float),\\n        where=(y_test_np[i] != 0)\\n    )\\n\\n    # Mask per escludere NaN o infiniti\\n    mask = ~np.isnan(differenza) & ~np.isinf(differenza)\\n\\n    # Primo sottografico: Serie reale vs predetta (log scale)\\n    ax1.plot(y_pred_safe, label='Predetto', linewidth=2, color='blue')\\n    ax1.plot(y_test_safe, label='Reale', linewidth=2, color='orange')\\n    ax1.set_ylabel('Valore della Serie', fontsize=12)\\n    ax1.set_title(f'Grafico {i+1} - Serie Reale vs Predetta (scala log)', fontsize=14)\\n    #ax1.set_yscale('log')  # scala logaritmica\\n    ax1.legend(loc='best')\\n    ax1.grid(True, alpha=0.3, which='both')\\n\\n    # Secondo sottografico: Errore percentuale (solo valori validi)\\n    ax2.plot(\\n        np.arange(len(differenza))[mask],\\n        differenza[mask],\\n        linestyle='--', color='red', linewidth=2, label='Errore %'\\n    )\\n    ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.5, linewidth=1)\\n    ax2.set_xlabel('Ora (Time Step)', fontsize=12)\\n    ax2.set_ylabel('Errore %', fontsize=12)\\n\\n    # Imposta ticks da 0 a 23\\n    ax2.set_xticks(np.arange(24))  \\n\\n    # Se vuoi anche le griglie verticali su ogni ora\\n    ax2.grid(True, axis='x', linestyle='--', alpha=0.7)\\n    ax2.set_title('Errore Percentuale (filtrato)', fontsize=14)\\n    ax2.legend(loc='best')\\n    ax2.grid(True, alpha=0.3)\\n\\n    # Colora l'area sotto l’errore (solo valori validi)\\n    ax2.fill_between(\\n        np.arange(len(differenza))[mask],\\n        differenza[mask], 0,\\n        alpha=0.3, color='red'\\n    )\\n\\n    plt.tight_layout()\\n    plt.show()\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''epsilon = 1e-8  # piccolo valore per evitare log(0) in scala log\n",
    "\n",
    "for i in range(len(y_test_np)):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "    # Sostituisci i valori nulli con epsilon per il log\n",
    "    y_pred_safe = np.where(y_pred[i] <= 0, epsilon, y_pred[i])\n",
    "    y_test_safe = np.where(y_test_np[i] <= 0, epsilon, y_test_np[i])\n",
    "\n",
    "    # Calcola la differenza percentuale con gestione divisione per 0\n",
    "    differenza = np.divide(\n",
    "        (y_pred[i] - y_test_np[i]) * 100,\n",
    "        y_test_np[i],\n",
    "        out=np.full_like(y_pred[i], np.nan, dtype=float),\n",
    "        where=(y_test_np[i] != 0)\n",
    "    )\n",
    "\n",
    "    # Mask per escludere NaN o infiniti\n",
    "    mask = ~np.isnan(differenza) & ~np.isinf(differenza)\n",
    "\n",
    "    # Primo sottografico: Serie reale vs predetta (log scale)\n",
    "    ax1.plot(y_pred_safe, label='Predetto', linewidth=2, color='blue')\n",
    "    ax1.plot(y_test_safe, label='Reale', linewidth=2, color='orange')\n",
    "    ax1.set_ylabel('Valore della Serie', fontsize=12)\n",
    "    ax1.set_title(f'Grafico {i+1} - Serie Reale vs Predetta (scala log)', fontsize=14)\n",
    "    #ax1.set_yscale('log')  # scala logaritmica\n",
    "    ax1.legend(loc='best')\n",
    "    ax1.grid(True, alpha=0.3, which='both')\n",
    "\n",
    "    # Secondo sottografico: Errore percentuale (solo valori validi)\n",
    "    ax2.plot(\n",
    "        np.arange(len(differenza))[mask],\n",
    "        differenza[mask],\n",
    "        linestyle='--', color='red', linewidth=2, label='Errore %'\n",
    "    )\n",
    "    ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.5, linewidth=1)\n",
    "    ax2.set_xlabel('Ora (Time Step)', fontsize=12)\n",
    "    ax2.set_ylabel('Errore %', fontsize=12)\n",
    "\n",
    "    # Imposta ticks da 0 a 23\n",
    "    ax2.set_xticks(np.arange(24))  \n",
    "\n",
    "    # Se vuoi anche le griglie verticali su ogni ora\n",
    "    ax2.grid(True, axis='x', linestyle='--', alpha=0.7)\n",
    "    ax2.set_title('Errore Percentuale (filtrato)', fontsize=14)\n",
    "    ax2.legend(loc='best')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # Colora l'area sotto l’errore (solo valori validi)\n",
    "    ax2.fill_between(\n",
    "        np.arange(len(differenza))[mask],\n",
    "        differenza[mask], 0,\n",
    "        alpha=0.3, color='red'\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5d0ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.0243\n",
      "Test RMSE: 0.0371\n",
      "Test MAPE: 0.31%\n",
      "Test R2: 0.9999\n",
      "Valore medio del test set: 9.3573\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/evaluation_log.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_and_log(y_true, y_pred, log_path=\"log.json\"):\n",
    "    # --- Metriche ---\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput=\"uniform_average\")\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred, multioutput=\"uniform_average\"))\n",
    "\n",
    "    mask = y_true != 0\n",
    "    mape = float(np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0)\n",
    "\n",
    "    r2 = r2_score(y_true, y_pred, multioutput=\"uniform_average\")\n",
    "\n",
    "    # Valore medio del test set\n",
    "    v_mean = float(np.mean(y_true))\n",
    "\n",
    "    # --- Stampa ---\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "    print(f\"Test MAPE: {mape:.2f}%\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "    print(f\"Valore medio del test set: {v_mean:.4f}\")\n",
    "\n",
    "    # --- Salvataggio log ---\n",
    "    log_data = {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2,\n",
    "        \"test_mean_value\": v_mean\n",
    "    }\n",
    "\n",
    "    with open(log_path, \"w\") as f:\n",
    "        json.dump(log_data, f, indent=4)\n",
    "\n",
    "    print(f\"\\nLog salvato in: {log_path}\")\n",
    "evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/evaluation_log.json\")\n",
    "# Impostazioni pandas per visualizzare tutti i dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c031eff0",
   "metadata": {},
   "source": [
    "# globale e federato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd226e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed = tf.keras.models.load_model('/Users/lapotinacci/thesis/Federated_Sys/app/custom/models/fed_model_Arpat.keras')\n",
    "\n",
    "model  = [fed]\n",
    "model_name = [\"federated\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bd1ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = f'{exp_dir}/model/{sensor_name}_fed_model.keras'\n",
    "\n",
    "# 2. Crea l'istanza della callback\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27698951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "--- federated ---\n",
      "Test MAE: 1.8817\n",
      "Test RMSE: 2.7242\n",
      "Test MAPE: 22.97%\n",
      "Test R2: 0.3301\n",
      "Valore medio del test set: 9.3573\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/federated_evaluation_log.json\n",
      "Salvo 60 plot in: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/federated/TEST\n",
      "Plot salvati correttamente.\n",
      "\n",
      "\n",
      "Epoch 1/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - loss: 0.6282 - mae: 0.5736 - mse: 0.6282\n",
      "Epoch 1: val_loss improved from None to 0.39486, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.5672 - mae: 0.5393 - mse: 0.5672 - val_loss: 0.3949 - val_mae: 0.4461 - val_mse: 0.3949\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3572 - mae: 0.4246 - mse: 0.3572\n",
      "Epoch 2: val_loss improved from 0.39486 to 0.33464, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3516 - mae: 0.4243 - mse: 0.3516 - val_loss: 0.3346 - val_mae: 0.4123 - val_mse: 0.3346\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2864 - mae: 0.3888 - mse: 0.2864\n",
      "Epoch 3: val_loss improved from 0.33464 to 0.27653, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2961 - mae: 0.3934 - mse: 0.2961 - val_loss: 0.2765 - val_mae: 0.3817 - val_mse: 0.2765\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2487 - mae: 0.3688 - mse: 0.2487\n",
      "Epoch 4: val_loss improved from 0.27653 to 0.21261, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2450 - mae: 0.3668 - mse: 0.2450 - val_loss: 0.2126 - val_mae: 0.3334 - val_mse: 0.2126\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1847 - mae: 0.3182 - mse: 0.1847\n",
      "Epoch 5: val_loss improved from 0.21261 to 0.17783, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1880 - mae: 0.3208 - mse: 0.1880 - val_loss: 0.1778 - val_mae: 0.3134 - val_mse: 0.1778\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1509 - mae: 0.2939 - mse: 0.1509\n",
      "Epoch 6: val_loss improved from 0.17783 to 0.15055, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1482 - mae: 0.2882 - mse: 0.1482 - val_loss: 0.1506 - val_mae: 0.2874 - val_mse: 0.1506\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1372 - mae: 0.2728 - mse: 0.1372\n",
      "Epoch 7: val_loss improved from 0.15055 to 0.12429, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1359 - mae: 0.2723 - mse: 0.1359 - val_loss: 0.1243 - val_mae: 0.2639 - val_mse: 0.1243\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1276 - mae: 0.2655 - mse: 0.1276\n",
      "Epoch 8: val_loss improved from 0.12429 to 0.10502, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1214 - mae: 0.2601 - mse: 0.1214 - val_loss: 0.1050 - val_mae: 0.2388 - val_mse: 0.1050\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1031 - mae: 0.2379 - mse: 0.1031\n",
      "Epoch 9: val_loss improved from 0.10502 to 0.08294, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1000 - mae: 0.2326 - mse: 0.1000 - val_loss: 0.0829 - val_mae: 0.2142 - val_mse: 0.0829\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0873 - mae: 0.2140 - mse: 0.0873\n",
      "Epoch 10: val_loss improved from 0.08294 to 0.07537, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0836 - mae: 0.2123 - mse: 0.0836 - val_loss: 0.0754 - val_mae: 0.2054 - val_mse: 0.0754\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0748 - mae: 0.2005 - mse: 0.0748\n",
      "Epoch 11: val_loss improved from 0.07537 to 0.06412, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0751 - mae: 0.2011 - mse: 0.0751 - val_loss: 0.0641 - val_mae: 0.1872 - val_mse: 0.0641\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0673 - mae: 0.1866 - mse: 0.0673\n",
      "Epoch 12: val_loss improved from 0.06412 to 0.05394, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0644 - mae: 0.1838 - mse: 0.0644 - val_loss: 0.0539 - val_mae: 0.1735 - val_mse: 0.0539\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0611 - mae: 0.1781 - mse: 0.0611\n",
      "Epoch 13: val_loss improved from 0.05394 to 0.04586, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0613 - mae: 0.1797 - mse: 0.0613 - val_loss: 0.0459 - val_mae: 0.1613 - val_mse: 0.0459\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0513 - mae: 0.1639 - mse: 0.0513\n",
      "Epoch 14: val_loss did not improve from 0.04586\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0509 - mae: 0.1627 - mse: 0.0509 - val_loss: 0.0529 - val_mae: 0.1679 - val_mse: 0.0529\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0469 - mae: 0.1522 - mse: 0.0469\n",
      "Epoch 15: val_loss improved from 0.04586 to 0.04258, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0485 - mae: 0.1554 - mse: 0.0485 - val_loss: 0.0426 - val_mae: 0.1525 - val_mse: 0.0426\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0401 - mae: 0.1443 - mse: 0.0401\n",
      "Epoch 16: val_loss improved from 0.04258 to 0.03803, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0451 - mae: 0.1491 - mse: 0.0451 - val_loss: 0.0380 - val_mae: 0.1419 - val_mse: 0.0380\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0406 - mae: 0.1399 - mse: 0.0406\n",
      "Epoch 17: val_loss did not improve from 0.03803\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0385 - mae: 0.1359 - mse: 0.0385 - val_loss: 0.0397 - val_mae: 0.1390 - val_mse: 0.0397\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0359 - mae: 0.1305 - mse: 0.0359\n",
      "Epoch 18: val_loss improved from 0.03803 to 0.03241, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0378 - mae: 0.1333 - mse: 0.0378 - val_loss: 0.0324 - val_mae: 0.1315 - val_mse: 0.0324\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0342 - mae: 0.1280 - mse: 0.0342\n",
      "Epoch 19: val_loss improved from 0.03241 to 0.03077, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0311 - mae: 0.1240 - mse: 0.0311 - val_loss: 0.0308 - val_mae: 0.1270 - val_mse: 0.0308\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0306 - mae: 0.1199 - mse: 0.0306\n",
      "Epoch 20: val_loss improved from 0.03077 to 0.02585, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0303 - mae: 0.1209 - mse: 0.0303 - val_loss: 0.0258 - val_mae: 0.1136 - val_mse: 0.0258\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0265 - mae: 0.1123 - mse: 0.0265\n",
      "Epoch 21: val_loss did not improve from 0.02585\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0254 - mae: 0.1102 - mse: 0.0254 - val_loss: 0.0328 - val_mae: 0.1250 - val_mse: 0.0328\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0248 - mae: 0.1073 - mse: 0.0248\n",
      "Epoch 22: val_loss improved from 0.02585 to 0.02161, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0266 - mae: 0.1105 - mse: 0.0266 - val_loss: 0.0216 - val_mae: 0.1057 - val_mse: 0.0216\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0213 - mae: 0.1000 - mse: 0.0213\n",
      "Epoch 23: val_loss improved from 0.02161 to 0.02146, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0220 - mae: 0.1031 - mse: 0.0220 - val_loss: 0.0215 - val_mae: 0.1024 - val_mse: 0.0215\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0200 - mae: 0.0990 - mse: 0.0200\n",
      "Epoch 24: val_loss improved from 0.02146 to 0.01982, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0208 - mae: 0.0988 - mse: 0.0208 - val_loss: 0.0198 - val_mae: 0.0982 - val_mse: 0.0198\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0187 - mae: 0.0946 - mse: 0.0187\n",
      "Epoch 25: val_loss improved from 0.01982 to 0.01973, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0193 - mae: 0.0950 - mse: 0.0193 - val_loss: 0.0197 - val_mae: 0.0955 - val_mse: 0.0197\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0176 - mae: 0.0900 - mse: 0.0176\n",
      "Epoch 26: val_loss improved from 0.01973 to 0.01755, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0171 - mae: 0.0883 - mse: 0.0171 - val_loss: 0.0175 - val_mae: 0.0927 - val_mse: 0.0175\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0175 - mae: 0.0895 - mse: 0.0175\n",
      "Epoch 27: val_loss improved from 0.01755 to 0.01469, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0175 - mae: 0.0911 - mse: 0.0175 - val_loss: 0.0147 - val_mae: 0.0836 - val_mse: 0.0147\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0150 - mae: 0.0822 - mse: 0.0150\n",
      "Epoch 28: val_loss did not improve from 0.01469\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0139 - mae: 0.0804 - mse: 0.0139 - val_loss: 0.0181 - val_mae: 0.0910 - val_mse: 0.0181\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0149 - mae: 0.0806 - mse: 0.0149\n",
      "Epoch 29: val_loss did not improve from 0.01469\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0157 - mae: 0.0833 - mse: 0.0157 - val_loss: 0.0147 - val_mae: 0.0825 - val_mse: 0.0147\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - mae: 0.0746 - mse: 0.0128\n",
      "Epoch 30: val_loss did not improve from 0.01469\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0128 - mae: 0.0761 - mse: 0.0128 - val_loss: 0.0151 - val_mae: 0.0829 - val_mse: 0.0151\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0137 - mae: 0.0779 - mse: 0.0137\n",
      "Epoch 31: val_loss improved from 0.01469 to 0.01143, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0131 - mae: 0.0776 - mse: 0.0131 - val_loss: 0.0114 - val_mae: 0.0726 - val_mse: 0.0114\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0112 - mae: 0.0716 - mse: 0.0112\n",
      "Epoch 32: val_loss did not improve from 0.01143\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0111 - mae: 0.0719 - mse: 0.0111 - val_loss: 0.0140 - val_mae: 0.0801 - val_mse: 0.0140\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0109 - mae: 0.0702 - mse: 0.0109\n",
      "Epoch 33: val_loss improved from 0.01143 to 0.00991, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0116 - mae: 0.0725 - mse: 0.0116 - val_loss: 0.0099 - val_mae: 0.0675 - val_mse: 0.0099\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0099 - mae: 0.0685 - mse: 0.0099\n",
      "Epoch 34: val_loss did not improve from 0.00991\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0100 - mae: 0.0686 - mse: 0.0100 - val_loss: 0.0124 - val_mae: 0.0749 - val_mse: 0.0124\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0123 - mae: 0.0754 - mse: 0.0123\n",
      "Epoch 35: val_loss improved from 0.00991 to 0.00921, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0704 - mse: 0.0107 - val_loss: 0.0092 - val_mae: 0.0639 - val_mse: 0.0092\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0075 - mae: 0.0584 - mse: 0.0075\n",
      "Epoch 36: val_loss did not improve from 0.00921\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0087 - mae: 0.0623 - mse: 0.0087 - val_loss: 0.0113 - val_mae: 0.0716 - val_mse: 0.0113\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0088 - mae: 0.0650 - mse: 0.0088\n",
      "Epoch 37: val_loss improved from 0.00921 to 0.00815, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0091 - mae: 0.0645 - mse: 0.0091 - val_loss: 0.0082 - val_mae: 0.0599 - val_mse: 0.0082\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0069 - mae: 0.0554 - mse: 0.0069\n",
      "Epoch 38: val_loss did not improve from 0.00815\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0076 - mae: 0.0583 - mse: 0.0076 - val_loss: 0.0090 - val_mae: 0.0646 - val_mse: 0.0090\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0091 - mae: 0.0648 - mse: 0.0091\n",
      "Epoch 39: val_loss improved from 0.00815 to 0.00736, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0080 - mae: 0.0612 - mse: 0.0080 - val_loss: 0.0074 - val_mae: 0.0569 - val_mse: 0.0074\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0070 - mae: 0.0549 - mse: 0.0070\n",
      "Epoch 40: val_loss did not improve from 0.00736\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0069 - mae: 0.0559 - mse: 0.0069 - val_loss: 0.0076 - val_mae: 0.0598 - val_mse: 0.0076\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0065 - mae: 0.0558 - mse: 0.0065\n",
      "Epoch 41: val_loss improved from 0.00736 to 0.00677, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0547 - mse: 0.0064 - val_loss: 0.0068 - val_mae: 0.0535 - val_mse: 0.0068\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 - mae: 0.0500 - mse: 0.0056\n",
      "Epoch 42: val_loss improved from 0.00677 to 0.00633, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mae: 0.0533 - mse: 0.0064 - val_loss: 0.0063 - val_mae: 0.0539 - val_mse: 0.0063\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0059 - mae: 0.0518 - mse: 0.0059\n",
      "Epoch 43: val_loss did not improve from 0.00633\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0056 - mae: 0.0510 - mse: 0.0056 - val_loss: 0.0068 - val_mae: 0.0554 - val_mse: 0.0068\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0479 - mse: 0.0049\n",
      "Epoch 44: val_loss improved from 0.00633 to 0.00584, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mae: 0.0508 - mse: 0.0058 - val_loss: 0.0058 - val_mae: 0.0499 - val_mse: 0.0058\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0047 - mae: 0.0449 - mse: 0.0047\n",
      "Epoch 45: val_loss improved from 0.00584 to 0.00568, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0050 - mae: 0.0467 - mse: 0.0050 - val_loss: 0.0057 - val_mae: 0.0501 - val_mse: 0.0057\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - mae: 0.0459 - mse: 0.0049\n",
      "Epoch 46: val_loss improved from 0.00568 to 0.00493, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0049 - mae: 0.0467 - mse: 0.0049 - val_loss: 0.0049 - val_mae: 0.0463 - val_mse: 0.0049\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0048 - mae: 0.0457 - mse: 0.0048\n",
      "Epoch 47: val_loss did not improve from 0.00493\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0044 - mae: 0.0441 - mse: 0.0044 - val_loss: 0.0050 - val_mae: 0.0480 - val_mse: 0.0050\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0045 - mae: 0.0446 - mse: 0.0045\n",
      "Epoch 48: val_loss improved from 0.00493 to 0.00440, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0044 - mae: 0.0447 - mse: 0.0044 - val_loss: 0.0044 - val_mae: 0.0443 - val_mse: 0.0044\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0043 - mae: 0.0425 - mse: 0.0043\n",
      "Epoch 49: val_loss improved from 0.00440 to 0.00438, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0040 - mae: 0.0424 - mse: 0.0040 - val_loss: 0.0044 - val_mae: 0.0440 - val_mse: 0.0044\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0434 - mse: 0.0041\n",
      "Epoch 50: val_loss improved from 0.00438 to 0.00402, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - mae: 0.0421 - mse: 0.0039 - val_loss: 0.0040 - val_mae: 0.0415 - val_mse: 0.0040\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0041 - mae: 0.0408 - mse: 0.0041\n",
      "Epoch 51: val_loss improved from 0.00402 to 0.00401, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0036 - mae: 0.0392 - mse: 0.0036 - val_loss: 0.0040 - val_mae: 0.0421 - val_mse: 0.0040\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0038 - mae: 0.0399 - mse: 0.0038\n",
      "Epoch 52: val_loss improved from 0.00401 to 0.00365, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0035 - mae: 0.0390 - mse: 0.0035 - val_loss: 0.0037 - val_mae: 0.0391 - val_mse: 0.0037\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mae: 0.0385 - mse: 0.0035\n",
      "Epoch 53: val_loss improved from 0.00365 to 0.00360, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0033 - mae: 0.0369 - mse: 0.0033 - val_loss: 0.0036 - val_mae: 0.0400 - val_mse: 0.0036\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034 - mae: 0.0379 - mse: 0.0034\n",
      "Epoch 54: val_loss improved from 0.00360 to 0.00334, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0031 - mae: 0.0369 - mse: 0.0031 - val_loss: 0.0033 - val_mae: 0.0380 - val_mse: 0.0033\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0030 - mae: 0.0350 - mse: 0.0030\n",
      "Epoch 55: val_loss improved from 0.00334 to 0.00311, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0030 - mae: 0.0356 - mse: 0.0030 - val_loss: 0.0031 - val_mae: 0.0365 - val_mse: 0.0031\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0028 - mae: 0.0350 - mse: 0.0028\n",
      "Epoch 56: val_loss improved from 0.00311 to 0.00295, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0028 - mae: 0.0347 - mse: 0.0028 - val_loss: 0.0029 - val_mae: 0.0351 - val_mse: 0.0029\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0029 - mae: 0.0342 - mse: 0.0029\n",
      "Epoch 57: val_loss improved from 0.00295 to 0.00283, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0028 - mae: 0.0342 - mse: 0.0028 - val_loss: 0.0028 - val_mae: 0.0348 - val_mse: 0.0028\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 - mae: 0.0338 - mse: 0.0027\n",
      "Epoch 58: val_loss improved from 0.00283 to 0.00273, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0026 - mae: 0.0333 - mse: 0.0026 - val_loss: 0.0027 - val_mae: 0.0346 - val_mse: 0.0027\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 - mae: 0.0325 - mse: 0.0024\n",
      "Epoch 59: val_loss improved from 0.00273 to 0.00269, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0025 - mae: 0.0329 - mse: 0.0025 - val_loss: 0.0027 - val_mae: 0.0344 - val_mse: 0.0027\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0026 - mae: 0.0332 - mse: 0.0026\n",
      "Epoch 60: val_loss improved from 0.00269 to 0.00258, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0024 - mae: 0.0322 - mse: 0.0024 - val_loss: 0.0026 - val_mae: 0.0335 - val_mse: 0.0026\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0315 - mse: 0.0022\n",
      "Epoch 61: val_loss improved from 0.00258 to 0.00243, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0023 - mae: 0.0315 - mse: 0.0023 - val_loss: 0.0024 - val_mae: 0.0322 - val_mse: 0.0024\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0024 - mae: 0.0303 - mse: 0.0024\n",
      "Epoch 62: val_loss did not improve from 0.00243\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - mae: 0.0305 - mse: 0.0022 - val_loss: 0.0025 - val_mae: 0.0331 - val_mse: 0.0025\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0306 - mse: 0.0022\n",
      "Epoch 63: val_loss improved from 0.00243 to 0.00231, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0022 - mae: 0.0305 - mse: 0.0022 - val_loss: 0.0023 - val_mae: 0.0312 - val_mse: 0.0023\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0021 - mae: 0.0292 - mse: 0.0021\n",
      "Epoch 64: val_loss improved from 0.00231 to 0.00224, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0021 - mae: 0.0292 - mse: 0.0021 - val_loss: 0.0022 - val_mae: 0.0310 - val_mse: 0.0022\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0022 - mae: 0.0305 - mse: 0.0022\n",
      "Epoch 65: val_loss did not improve from 0.00224\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0020 - mae: 0.0289 - mse: 0.0020 - val_loss: 0.0022 - val_mae: 0.0309 - val_mse: 0.0022\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020 - mae: 0.0287 - mse: 0.0020\n",
      "Epoch 66: val_loss improved from 0.00224 to 0.00217, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0019 - mae: 0.0283 - mse: 0.0019 - val_loss: 0.0022 - val_mae: 0.0302 - val_mse: 0.0022\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018 - mae: 0.0274 - mse: 0.0018\n",
      "Epoch 67: val_loss improved from 0.00217 to 0.00208, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0277 - mse: 0.0018 - val_loss: 0.0021 - val_mae: 0.0296 - val_mse: 0.0021\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0017 - mae: 0.0271 - mse: 0.0017\n",
      "Epoch 68: val_loss improved from 0.00208 to 0.00192, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0018 - mae: 0.0275 - mse: 0.0018 - val_loss: 0.0019 - val_mae: 0.0287 - val_mse: 0.0019\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019 - mae: 0.0285 - mse: 0.0019\n",
      "Epoch 69: val_loss improved from 0.00192 to 0.00190, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0017 - mae: 0.0272 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0286 - val_mse: 0.0019\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0254 - mse: 0.0016\n",
      "Epoch 70: val_loss did not improve from 0.00190\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0017 - mae: 0.0265 - mse: 0.0017 - val_loss: 0.0019 - val_mae: 0.0284 - val_mse: 0.0019\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0256 - mse: 0.0015\n",
      "Epoch 71: val_loss improved from 0.00190 to 0.00179, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0016 - mae: 0.0260 - mse: 0.0016 - val_loss: 0.0018 - val_mae: 0.0277 - val_mse: 0.0018\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0013 - mae: 0.0246 - mse: 0.0013\n",
      "Epoch 72: val_loss improved from 0.00179 to 0.00165, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0016 - mae: 0.0256 - mse: 0.0016 - val_loss: 0.0016 - val_mae: 0.0269 - val_mse: 0.0016\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0016 - mae: 0.0257 - mse: 0.0016\n",
      "Epoch 73: val_loss improved from 0.00165 to 0.00155, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0015 - mae: 0.0254 - mse: 0.0015 - val_loss: 0.0016 - val_mae: 0.0259 - val_mse: 0.0016\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0254 - mse: 0.0015\n",
      "Epoch 74: val_loss improved from 0.00155 to 0.00153, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0015 - mae: 0.0250 - mse: 0.0015 - val_loss: 0.0015 - val_mae: 0.0254 - val_mse: 0.0015\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0237 - mse: 0.0012\n",
      "Epoch 75: val_loss improved from 0.00153 to 0.00149, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0014 - mae: 0.0246 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0252 - val_mse: 0.0015\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 - mae: 0.0239 - mse: 0.0014\n",
      "Epoch 76: val_loss improved from 0.00149 to 0.00149, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0014 - mae: 0.0242 - mse: 0.0014 - val_loss: 0.0015 - val_mae: 0.0255 - val_mse: 0.0015\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013 - mae: 0.0239 - mse: 0.0013\n",
      "Epoch 77: val_loss improved from 0.00149 to 0.00145, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0238 - mse: 0.0013 - val_loss: 0.0015 - val_mae: 0.0252 - val_mse: 0.0015\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0015 - mae: 0.0251 - mse: 0.0015\n",
      "Epoch 78: val_loss improved from 0.00145 to 0.00140, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0013 - mae: 0.0235 - mse: 0.0013 - val_loss: 0.0014 - val_mae: 0.0249 - val_mse: 0.0014\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0225 - mse: 0.0012\n",
      "Epoch 79: val_loss improved from 0.00140 to 0.00133, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0012 - mae: 0.0231 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0241 - val_mse: 0.0013\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0012 - mae: 0.0226 - mse: 0.0012\n",
      "Epoch 80: val_loss improved from 0.00133 to 0.00129, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0012 - mae: 0.0227 - mse: 0.0012 - val_loss: 0.0013 - val_mae: 0.0238 - val_mse: 0.0013\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 - mae: 0.0228 - mse: 0.0012\n",
      "Epoch 81: val_loss improved from 0.00129 to 0.00123, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0012 - mae: 0.0225 - mse: 0.0012 - val_loss: 0.0012 - val_mae: 0.0230 - val_mse: 0.0012\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011 - mae: 0.0217 - mse: 0.0011\n",
      "Epoch 82: val_loss improved from 0.00123 to 0.00119, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0011 - mae: 0.0220 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0227 - val_mse: 0.0012\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0222 - mse: 0.0011\n",
      "Epoch 83: val_loss improved from 0.00119 to 0.00116, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0011 - mae: 0.0216 - mse: 0.0011 - val_loss: 0.0012 - val_mae: 0.0225 - val_mse: 0.0012\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011\n",
      "Epoch 84: val_loss improved from 0.00116 to 0.00114, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0011 - mae: 0.0213 - mse: 0.0011 - val_loss: 0.0011 - val_mae: 0.0222 - val_mse: 0.0011\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9583e-04 - mae: 0.0196 - mse: 8.9583e-04\n",
      "Epoch 85: val_loss improved from 0.00114 to 0.00113, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0010 - mae: 0.0209 - mse: 0.0010 - val_loss: 0.0011 - val_mae: 0.0219 - val_mse: 0.0011\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 - mae: 0.0218 - mse: 0.0011\n",
      "Epoch 86: val_loss improved from 0.00113 to 0.00107, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.9584e-04 - mae: 0.0207 - mse: 9.9584e-04 - val_loss: 0.0011 - val_mae: 0.0216 - val_mse: 0.0011\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.4086e-04 - mae: 0.0195 - mse: 9.4086e-04\n",
      "Epoch 87: val_loss improved from 0.00107 to 0.00104, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 9.6228e-04 - mae: 0.0204 - mse: 9.6228e-04 - val_loss: 0.0010 - val_mae: 0.0214 - val_mse: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9238e-04 - mae: 0.0196 - mse: 8.9238e-04\n",
      "Epoch 88: val_loss improved from 0.00104 to 0.00102, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.3579e-04 - mae: 0.0200 - mse: 9.3579e-04 - val_loss: 0.0010 - val_mae: 0.0210 - val_mse: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5470e-04 - mae: 0.0201 - mse: 9.5470e-04\n",
      "Epoch 89: val_loss improved from 0.00102 to 0.00099, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 9.1983e-04 - mae: 0.0198 - mse: 9.1983e-04 - val_loss: 9.9110e-04 - val_mae: 0.0208 - val_mse: 9.9110e-04\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3566e-04 - mae: 0.0192 - mse: 8.3566e-04\n",
      "Epoch 90: val_loss improved from 0.00099 to 0.00095, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.8208e-04 - mae: 0.0194 - mse: 8.8208e-04 - val_loss: 9.4708e-04 - val_mae: 0.0205 - val_mse: 9.4708e-04\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0806e-04 - mae: 0.0197 - mse: 9.0806e-04\n",
      "Epoch 91: val_loss improved from 0.00095 to 0.00094, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 8.6396e-04 - mae: 0.0193 - mse: 8.6396e-04 - val_loss: 9.3945e-04 - val_mae: 0.0205 - val_mse: 9.3945e-04\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3498e-04 - mae: 0.0183 - mse: 7.3498e-04\n",
      "Epoch 92: val_loss improved from 0.00094 to 0.00091, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.4286e-04 - mae: 0.0192 - mse: 8.4286e-04 - val_loss: 9.0719e-04 - val_mae: 0.0200 - val_mse: 9.0719e-04\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4901e-04 - mae: 0.0189 - mse: 8.4901e-04\n",
      "Epoch 93: val_loss improved from 0.00091 to 0.00088, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.1562e-04 - mae: 0.0189 - mse: 8.1562e-04 - val_loss: 8.8403e-04 - val_mae: 0.0198 - val_mse: 8.8403e-04\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7730e-04 - mae: 0.0183 - mse: 7.7730e-04\n",
      "Epoch 94: val_loss improved from 0.00088 to 0.00086, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.9484e-04 - mae: 0.0186 - mse: 7.9484e-04 - val_loss: 8.5829e-04 - val_mae: 0.0195 - val_mse: 8.5829e-04\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8752e-04 - mae: 0.0187 - mse: 7.8752e-04\n",
      "Epoch 95: val_loss improved from 0.00086 to 0.00084, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.7545e-04 - mae: 0.0183 - mse: 7.7545e-04 - val_loss: 8.3871e-04 - val_mae: 0.0193 - val_mse: 8.3871e-04\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3957e-04 - mae: 0.0177 - mse: 7.3957e-04\n",
      "Epoch 96: val_loss improved from 0.00084 to 0.00082, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.5434e-04 - mae: 0.0182 - mse: 7.5434e-04 - val_loss: 8.2278e-04 - val_mae: 0.0191 - val_mse: 8.2278e-04\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4853e-04 - mae: 0.0183 - mse: 7.4853e-04\n",
      "Epoch 97: val_loss improved from 0.00082 to 0.00080, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.4291e-04 - mae: 0.0182 - mse: 7.4291e-04 - val_loss: 8.0336e-04 - val_mae: 0.0188 - val_mse: 8.0336e-04\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4227e-04 - mae: 0.0179 - mse: 7.4227e-04\n",
      "Epoch 98: val_loss improved from 0.00080 to 0.00079, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.2301e-04 - mae: 0.0178 - mse: 7.2301e-04 - val_loss: 7.8523e-04 - val_mae: 0.0186 - val_mse: 7.8523e-04\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0729e-04 - mae: 0.0176 - mse: 7.0729e-04\n",
      "Epoch 99: val_loss improved from 0.00079 to 0.00077, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.0350e-04 - mae: 0.0176 - mse: 7.0350e-04 - val_loss: 7.6669e-04 - val_mae: 0.0184 - val_mse: 7.6669e-04\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5098e-04 - mae: 0.0167 - mse: 6.5098e-04\n",
      "Epoch 100: val_loss did not improve from 0.00077\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.8770e-04 - mae: 0.0172 - mse: 6.8770e-04 - val_loss: 7.6978e-04 - val_mae: 0.0184 - val_mse: 7.6978e-04\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8836e-04 - mae: 0.0171 - mse: 6.8836e-04\n",
      "Epoch 101: val_loss improved from 0.00077 to 0.00075, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.7750e-04 - mae: 0.0172 - mse: 6.7750e-04 - val_loss: 7.5085e-04 - val_mae: 0.0182 - val_mse: 7.5085e-04\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9839e-04 - mae: 0.0164 - mse: 5.9839e-04\n",
      "Epoch 102: val_loss improved from 0.00075 to 0.00072, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.6478e-04 - mae: 0.0170 - mse: 6.6478e-04 - val_loss: 7.1534e-04 - val_mae: 0.0178 - val_mse: 7.1534e-04\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1994e-04 - mae: 0.0169 - mse: 6.1994e-04\n",
      "Epoch 103: val_loss improved from 0.00072 to 0.00069, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.5820e-04 - mae: 0.0172 - mse: 6.5820e-04 - val_loss: 6.9277e-04 - val_mae: 0.0176 - val_mse: 6.9277e-04\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8287e-04 - mae: 0.0176 - mse: 6.8287e-04\n",
      "Epoch 104: val_loss improved from 0.00069 to 0.00069, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.2991e-04 - mae: 0.0168 - mse: 6.2991e-04 - val_loss: 6.8880e-04 - val_mae: 0.0176 - val_mse: 6.8880e-04\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7115e-04 - mae: 0.0160 - mse: 5.7115e-04\n",
      "Epoch 105: val_loss improved from 0.00069 to 0.00068, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1856e-04 - mae: 0.0166 - mse: 6.1856e-04 - val_loss: 6.8412e-04 - val_mae: 0.0176 - val_mse: 6.8412e-04\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0656e-04 - mae: 0.0167 - mse: 6.0656e-04\n",
      "Epoch 106: val_loss improved from 0.00068 to 0.00066, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.0843e-04 - mae: 0.0164 - mse: 6.0843e-04 - val_loss: 6.5855e-04 - val_mae: 0.0172 - val_mse: 6.5855e-04\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7287e-04 - mae: 0.0158 - mse: 5.7287e-04\n",
      "Epoch 107: val_loss improved from 0.00066 to 0.00065, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.9049e-04 - mae: 0.0161 - mse: 5.9049e-04 - val_loss: 6.4759e-04 - val_mae: 0.0171 - val_mse: 6.4759e-04\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6357e-04 - mae: 0.0160 - mse: 5.6357e-04\n",
      "Epoch 108: val_loss improved from 0.00065 to 0.00063, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.7360e-04 - mae: 0.0160 - mse: 5.7360e-04 - val_loss: 6.3167e-04 - val_mae: 0.0168 - val_mse: 6.3167e-04\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3911e-04 - mae: 0.0157 - mse: 5.3911e-04\n",
      "Epoch 109: val_loss improved from 0.00063 to 0.00062, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.6961e-04 - mae: 0.0160 - mse: 5.6961e-04 - val_loss: 6.1735e-04 - val_mae: 0.0166 - val_mse: 6.1735e-04\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7580e-04 - mae: 0.0159 - mse: 5.7580e-04\n",
      "Epoch 110: val_loss did not improve from 0.00062\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4896e-04 - mae: 0.0156 - mse: 5.4896e-04 - val_loss: 6.1964e-04 - val_mae: 0.0169 - val_mse: 6.1964e-04\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2667e-04 - mae: 0.0155 - mse: 5.2667e-04\n",
      "Epoch 111: val_loss improved from 0.00062 to 0.00060, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.4670e-04 - mae: 0.0156 - mse: 5.4670e-04 - val_loss: 5.9544e-04 - val_mae: 0.0162 - val_mse: 5.9544e-04\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4440e-04 - mae: 0.0152 - mse: 5.4440e-04\n",
      "Epoch 112: val_loss improved from 0.00060 to 0.00059, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.3365e-04 - mae: 0.0153 - mse: 5.3365e-04 - val_loss: 5.8943e-04 - val_mae: 0.0161 - val_mse: 5.8943e-04\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4281e-04 - mae: 0.0152 - mse: 5.4281e-04\n",
      "Epoch 113: val_loss improved from 0.00059 to 0.00057, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.2267e-04 - mae: 0.0152 - mse: 5.2267e-04 - val_loss: 5.6773e-04 - val_mae: 0.0160 - val_mse: 5.6773e-04\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4507e-04 - mae: 0.0153 - mse: 5.4507e-04\n",
      "Epoch 114: val_loss improved from 0.00057 to 0.00056, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.0732e-04 - mae: 0.0150 - mse: 5.0732e-04 - val_loss: 5.6032e-04 - val_mae: 0.0160 - val_mse: 5.6032e-04\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.8748e-04 - mae: 0.0146 - mse: 4.8748e-04\n",
      "Epoch 115: val_loss improved from 0.00056 to 0.00055, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.0736e-04 - mae: 0.0150 - mse: 5.0736e-04 - val_loss: 5.4782e-04 - val_mae: 0.0157 - val_mse: 5.4782e-04\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.3539e-04 - mae: 0.0154 - mse: 5.3539e-04\n",
      "Epoch 116: val_loss improved from 0.00055 to 0.00054, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9253e-04 - mae: 0.0148 - mse: 4.9253e-04 - val_loss: 5.3987e-04 - val_mae: 0.0155 - val_mse: 5.3987e-04\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5656e-04 - mae: 0.0142 - mse: 4.5656e-04\n",
      "Epoch 117: val_loss improved from 0.00054 to 0.00052, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.8346e-04 - mae: 0.0148 - mse: 4.8346e-04 - val_loss: 5.1783e-04 - val_mae: 0.0153 - val_mse: 5.1783e-04\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5757e-04 - mae: 0.0143 - mse: 4.5757e-04\n",
      "Epoch 118: val_loss improved from 0.00052 to 0.00051, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.7066e-04 - mae: 0.0145 - mse: 4.7066e-04 - val_loss: 5.1293e-04 - val_mae: 0.0153 - val_mse: 5.1293e-04\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1721e-04 - mae: 0.0137 - mse: 4.1721e-04\n",
      "Epoch 119: val_loss improved from 0.00051 to 0.00050, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.6397e-04 - mae: 0.0143 - mse: 4.6397e-04 - val_loss: 5.0481e-04 - val_mae: 0.0152 - val_mse: 5.0481e-04\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1353e-04 - mae: 0.0135 - mse: 4.1353e-04\n",
      "Epoch 120: val_loss improved from 0.00050 to 0.00049, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.5237e-04 - mae: 0.0141 - mse: 4.5237e-04 - val_loss: 4.9184e-04 - val_mae: 0.0150 - val_mse: 4.9184e-04\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3207e-04 - mae: 0.0138 - mse: 4.3207e-04\n",
      "Epoch 121: val_loss improved from 0.00049 to 0.00047, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.4467e-04 - mae: 0.0140 - mse: 4.4467e-04 - val_loss: 4.7345e-04 - val_mae: 0.0146 - val_mse: 4.7345e-04\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1039e-04 - mae: 0.0138 - mse: 4.1039e-04\n",
      "Epoch 122: val_loss did not improve from 0.00047\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.3575e-04 - mae: 0.0139 - mse: 4.3575e-04 - val_loss: 4.7564e-04 - val_mae: 0.0149 - val_mse: 4.7564e-04\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4652e-04 - mae: 0.0142 - mse: 4.4652e-04\n",
      "Epoch 123: val_loss improved from 0.00047 to 0.00047, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.3139e-04 - mae: 0.0139 - mse: 4.3139e-04 - val_loss: 4.7217e-04 - val_mae: 0.0148 - val_mse: 4.7217e-04\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2098e-04 - mae: 0.0137 - mse: 4.2098e-04\n",
      "Epoch 124: val_loss improved from 0.00047 to 0.00046, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.2161e-04 - mae: 0.0137 - mse: 4.2161e-04 - val_loss: 4.6432e-04 - val_mae: 0.0147 - val_mse: 4.6432e-04\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9712e-04 - mae: 0.0134 - mse: 3.9712e-04\n",
      "Epoch 125: val_loss improved from 0.00046 to 0.00044, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 4.1598e-04 - mae: 0.0138 - mse: 4.1598e-04 - val_loss: 4.4467e-04 - val_mae: 0.0142 - val_mse: 4.4467e-04\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1834e-04 - mae: 0.0137 - mse: 4.1834e-04\n",
      "Epoch 126: val_loss improved from 0.00044 to 0.00044, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 4.0726e-04 - mae: 0.0136 - mse: 4.0726e-04 - val_loss: 4.3755e-04 - val_mae: 0.0143 - val_mse: 4.3755e-04\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.9691e-04 - mae: 0.0136 - mse: 3.9691e-04\n",
      "Epoch 127: val_loss improved from 0.00044 to 0.00043, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.9984e-04 - mae: 0.0135 - mse: 3.9984e-04 - val_loss: 4.2958e-04 - val_mae: 0.0141 - val_mse: 4.2958e-04\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.0549e-04 - mae: 0.0135 - mse: 4.0549e-04\n",
      "Epoch 128: val_loss improved from 0.00043 to 0.00043, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.9354e-04 - mae: 0.0133 - mse: 3.9354e-04 - val_loss: 4.2937e-04 - val_mae: 0.0141 - val_mse: 4.2937e-04\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0989e-04 - mae: 0.0135 - mse: 4.0989e-04\n",
      "Epoch 129: val_loss improved from 0.00043 to 0.00043, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.8708e-04 - mae: 0.0133 - mse: 3.8708e-04 - val_loss: 4.2557e-04 - val_mae: 0.0140 - val_mse: 4.2557e-04\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 4.0361e-04 - mae: 0.0132 - mse: 4.0361e-04\n",
      "Epoch 130: val_loss improved from 0.00043 to 0.00042, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.7971e-04 - mae: 0.0131 - mse: 3.7971e-04 - val_loss: 4.1906e-04 - val_mae: 0.0140 - val_mse: 4.1906e-04\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.2869e-04 - mae: 0.0125 - mse: 3.2869e-04\n",
      "Epoch 131: val_loss improved from 0.00042 to 0.00041, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.7962e-04 - mae: 0.0131 - mse: 3.7962e-04 - val_loss: 4.1141e-04 - val_mae: 0.0137 - val_mse: 4.1141e-04\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.9172e-04 - mae: 0.0133 - mse: 3.9172e-04\n",
      "Epoch 132: val_loss did not improve from 0.00041\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 3.6272e-04 - mae: 0.0128 - mse: 3.6272e-04 - val_loss: 4.2909e-04 - val_mae: 0.0141 - val_mse: 4.2909e-04\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.6779e-04 - mae: 0.0130 - mse: 3.6779e-04\n",
      "Epoch 133: val_loss improved from 0.00041 to 0.00040, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.6813e-04 - mae: 0.0130 - mse: 3.6813e-04 - val_loss: 4.0439e-04 - val_mae: 0.0136 - val_mse: 4.0439e-04\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.4718e-04 - mae: 0.0127 - mse: 3.4718e-04\n",
      "Epoch 134: val_loss improved from 0.00040 to 0.00039, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.5174e-04 - mae: 0.0126 - mse: 3.5174e-04 - val_loss: 3.9222e-04 - val_mae: 0.0133 - val_mse: 3.9222e-04\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.3936e-04 - mae: 0.0124 - mse: 3.3936e-04\n",
      "Epoch 135: val_loss did not improve from 0.00039\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.5040e-04 - mae: 0.0126 - mse: 3.5040e-04 - val_loss: 3.9346e-04 - val_mae: 0.0133 - val_mse: 3.9346e-04\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.6610e-04 - mae: 0.0128 - mse: 3.6610e-04\n",
      "Epoch 136: val_loss improved from 0.00039 to 0.00038, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 3.4339e-04 - mae: 0.0125 - mse: 3.4339e-04 - val_loss: 3.8301e-04 - val_mae: 0.0132 - val_mse: 3.8301e-04\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.3619e-04 - mae: 0.0123 - mse: 3.3619e-04\n",
      "Epoch 137: val_loss improved from 0.00038 to 0.00038, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.4061e-04 - mae: 0.0124 - mse: 3.4061e-04 - val_loss: 3.7749e-04 - val_mae: 0.0131 - val_mse: 3.7749e-04\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.1487e-04 - mae: 0.0120 - mse: 3.1487e-04\n",
      "Epoch 138: val_loss did not improve from 0.00038\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.2963e-04 - mae: 0.0122 - mse: 3.2963e-04 - val_loss: 3.8754e-04 - val_mae: 0.0134 - val_mse: 3.8754e-04\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0437e-04 - mae: 0.0119 - mse: 3.0437e-04\n",
      "Epoch 139: val_loss did not improve from 0.00038\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3086e-04 - mae: 0.0124 - mse: 3.3086e-04 - val_loss: 3.7787e-04 - val_mae: 0.0133 - val_mse: 3.7787e-04\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8377e-04 - mae: 0.0116 - mse: 2.8377e-04\n",
      "Epoch 140: val_loss improved from 0.00038 to 0.00037, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2581e-04 - mae: 0.0122 - mse: 3.2581e-04 - val_loss: 3.7128e-04 - val_mae: 0.0133 - val_mse: 3.7128e-04\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0811e-04 - mae: 0.0119 - mse: 3.0811e-04\n",
      "Epoch 141: val_loss improved from 0.00037 to 0.00037, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2116e-04 - mae: 0.0122 - mse: 3.2116e-04 - val_loss: 3.6651e-04 - val_mae: 0.0130 - val_mse: 3.6651e-04\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.1394e-04 - mae: 0.0119 - mse: 3.1394e-04\n",
      "Epoch 142: val_loss did not improve from 0.00037\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 3.1563e-04 - mae: 0.0120 - mse: 3.1563e-04 - val_loss: 3.6816e-04 - val_mae: 0.0130 - val_mse: 3.6816e-04\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2475e-04 - mae: 0.0122 - mse: 3.2475e-04\n",
      "Epoch 143: val_loss improved from 0.00037 to 0.00036, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.1256e-04 - mae: 0.0121 - mse: 3.1256e-04 - val_loss: 3.5897e-04 - val_mae: 0.0130 - val_mse: 3.5897e-04\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8294e-04 - mae: 0.0115 - mse: 2.8294e-04\n",
      "Epoch 144: val_loss improved from 0.00036 to 0.00035, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.0721e-04 - mae: 0.0120 - mse: 3.0721e-04 - val_loss: 3.5154e-04 - val_mae: 0.0128 - val_mse: 3.5154e-04\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0548e-04 - mae: 0.0120 - mse: 3.0548e-04\n",
      "Epoch 145: val_loss improved from 0.00035 to 0.00035, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 3.0185e-04 - mae: 0.0118 - mse: 3.0185e-04 - val_loss: 3.4586e-04 - val_mae: 0.0127 - val_mse: 3.4586e-04\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.0171e-04 - mae: 0.0117 - mse: 3.0171e-04\n",
      "Epoch 146: val_loss improved from 0.00035 to 0.00034, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.9772e-04 - mae: 0.0117 - mse: 2.9772e-04 - val_loss: 3.4404e-04 - val_mae: 0.0128 - val_mse: 3.4404e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.8053e-04 - mae: 0.0112 - mse: 2.8053e-04\n",
      "Epoch 147: val_loss improved from 0.00034 to 0.00034, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.9231e-04 - mae: 0.0117 - mse: 2.9231e-04 - val_loss: 3.3784e-04 - val_mae: 0.0126 - val_mse: 3.3784e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9229e-04 - mae: 0.0117 - mse: 2.9229e-04\n",
      "Epoch 148: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.9185e-04 - mae: 0.0116 - mse: 2.9185e-04 - val_loss: 3.3844e-04 - val_mae: 0.0126 - val_mse: 3.3844e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8977e-04 - mae: 0.0116 - mse: 2.8977e-04\n",
      "Epoch 149: val_loss improved from 0.00034 to 0.00034, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.8652e-04 - mae: 0.0115 - mse: 2.8652e-04 - val_loss: 3.3530e-04 - val_mae: 0.0125 - val_mse: 3.3530e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7000e-04 - mae: 0.0111 - mse: 2.7000e-04\n",
      "Epoch 150: val_loss did not improve from 0.00034\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8134e-04 - mae: 0.0114 - mse: 2.8134e-04 - val_loss: 3.3836e-04 - val_mae: 0.0126 - val_mse: 3.3836e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.9963e-04 - mae: 0.0117 - mse: 2.9963e-04\n",
      "Epoch 151: val_loss improved from 0.00034 to 0.00032, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.8306e-04 - mae: 0.0115 - mse: 2.8306e-04 - val_loss: 3.2066e-04 - val_mae: 0.0122 - val_mse: 3.2066e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6617e-04 - mae: 0.0110 - mse: 2.6617e-04\n",
      "Epoch 152: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.7575e-04 - mae: 0.0113 - mse: 2.7575e-04 - val_loss: 3.2177e-04 - val_mae: 0.0122 - val_mse: 3.2177e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6136e-04 - mae: 0.0109 - mse: 2.6136e-04\n",
      "Epoch 153: val_loss did not improve from 0.00032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7087e-04 - mae: 0.0112 - mse: 2.7087e-04 - val_loss: 3.2879e-04 - val_mae: 0.0122 - val_mse: 3.2879e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.9295e-04 - mae: 0.0115 - mse: 2.9295e-04\n",
      "Epoch 154: val_loss improved from 0.00032 to 0.00032, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.7344e-04 - mae: 0.0113 - mse: 2.7344e-04 - val_loss: 3.2020e-04 - val_mae: 0.0121 - val_mse: 3.2020e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6718e-04 - mae: 0.0111 - mse: 2.6718e-04\n",
      "Epoch 155: val_loss improved from 0.00032 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.6565e-04 - mae: 0.0110 - mse: 2.6565e-04 - val_loss: 3.1289e-04 - val_mae: 0.0119 - val_mse: 3.1289e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.7296e-04 - mae: 0.0112 - mse: 2.7296e-04\n",
      "Epoch 156: val_loss improved from 0.00031 to 0.00031, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.6151e-04 - mae: 0.0110 - mse: 2.6151e-04 - val_loss: 3.0781e-04 - val_mae: 0.0119 - val_mse: 3.0781e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.5507e-04 - mae: 0.0108 - mse: 2.5507e-04\n",
      "Epoch 157: val_loss improved from 0.00031 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2.5340e-04 - mae: 0.0108 - mse: 2.5340e-04 - val_loss: 3.0205e-04 - val_mae: 0.0118 - val_mse: 3.0205e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3543e-04 - mae: 0.0107 - mse: 2.3543e-04\n",
      "Epoch 158: val_loss improved from 0.00030 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.5157e-04 - mae: 0.0108 - mse: 2.5157e-04 - val_loss: 3.0002e-04 - val_mae: 0.0117 - val_mse: 3.0002e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2221e-04 - mae: 0.0102 - mse: 2.2221e-04\n",
      "Epoch 159: val_loss improved from 0.00030 to 0.00030, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.4825e-04 - mae: 0.0107 - mse: 2.4825e-04 - val_loss: 2.9574e-04 - val_mae: 0.0116 - val_mse: 2.9574e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4757e-04 - mae: 0.0106 - mse: 2.4757e-04\n",
      "Epoch 160: val_loss improved from 0.00030 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 2.4501e-04 - mae: 0.0106 - mse: 2.4501e-04 - val_loss: 2.8822e-04 - val_mae: 0.0115 - val_mse: 2.8822e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6444e-04 - mae: 0.0109 - mse: 2.6444e-04\n",
      "Epoch 161: val_loss improved from 0.00029 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.4313e-04 - mae: 0.0106 - mse: 2.4313e-04 - val_loss: 2.8790e-04 - val_mae: 0.0114 - val_mse: 2.8790e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.4516e-04 - mae: 0.0106 - mse: 2.4516e-04\n",
      "Epoch 162: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.3711e-04 - mae: 0.0104 - mse: 2.3711e-04 - val_loss: 2.9047e-04 - val_mae: 0.0116 - val_mse: 2.9047e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3825e-04 - mae: 0.0103 - mse: 2.3825e-04\n",
      "Epoch 163: val_loss improved from 0.00029 to 0.00029, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 2.3999e-04 - mae: 0.0104 - mse: 2.3999e-04 - val_loss: 2.8597e-04 - val_mae: 0.0114 - val_mse: 2.8597e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2756e-04 - mae: 0.0102 - mse: 2.2756e-04\n",
      "Epoch 164: val_loss did not improve from 0.00029\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3237e-04 - mae: 0.0103 - mse: 2.3237e-04 - val_loss: 2.8659e-04 - val_mae: 0.0115 - val_mse: 2.8659e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2645e-04 - mae: 0.0102 - mse: 2.2645e-04\n",
      "Epoch 165: val_loss improved from 0.00029 to 0.00028, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 2.3170e-04 - mae: 0.0104 - mse: 2.3170e-04 - val_loss: 2.7751e-04 - val_mae: 0.0113 - val_mse: 2.7751e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.2776e-04 - mae: 0.0102 - mse: 2.2776e-04\n",
      "Epoch 166: val_loss improved from 0.00028 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.3017e-04 - mae: 0.0103 - mse: 2.3017e-04 - val_loss: 2.7031e-04 - val_mae: 0.0111 - val_mse: 2.7031e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1178e-04 - mae: 0.0100 - mse: 2.1178e-04\n",
      "Epoch 167: val_loss improved from 0.00027 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.2590e-04 - mae: 0.0101 - mse: 2.2590e-04 - val_loss: 2.6973e-04 - val_mae: 0.0112 - val_mse: 2.6973e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1482e-04 - mae: 0.0098 - mse: 2.1482e-04\n",
      "Epoch 168: val_loss improved from 0.00027 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 2.2299e-04 - mae: 0.0102 - mse: 2.2299e-04 - val_loss: 2.6911e-04 - val_mae: 0.0111 - val_mse: 2.6911e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8810e-04 - mae: 0.0093 - mse: 1.8810e-04\n",
      "Epoch 169: val_loss improved from 0.00027 to 0.00027, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.2178e-04 - mae: 0.0101 - mse: 2.2178e-04 - val_loss: 2.6637e-04 - val_mae: 0.0110 - val_mse: 2.6637e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2344e-04 - mae: 0.0102 - mse: 2.2344e-04\n",
      "Epoch 170: val_loss improved from 0.00027 to 0.00026, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2.1770e-04 - mae: 0.0101 - mse: 2.1770e-04 - val_loss: 2.6418e-04 - val_mae: 0.0111 - val_mse: 2.6418e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9973e-04 - mae: 0.0099 - mse: 1.9973e-04\n",
      "Epoch 171: val_loss improved from 0.00026 to 0.00026, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 2.1447e-04 - mae: 0.0100 - mse: 2.1447e-04 - val_loss: 2.5695e-04 - val_mae: 0.0110 - val_mse: 2.5695e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2537e-04 - mae: 0.0103 - mse: 2.2537e-04\n",
      "Epoch 172: val_loss improved from 0.00026 to 0.00025, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.1419e-04 - mae: 0.0101 - mse: 2.1419e-04 - val_loss: 2.4944e-04 - val_mae: 0.0108 - val_mse: 2.4944e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8651e-04 - mae: 0.0095 - mse: 1.8651e-04\n",
      "Epoch 173: val_loss did not improve from 0.00025\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2.0780e-04 - mae: 0.0098 - mse: 2.0780e-04 - val_loss: 2.5240e-04 - val_mae: 0.0109 - val_mse: 2.5240e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1883e-04 - mae: 0.0101 - mse: 2.1883e-04\n",
      "Epoch 174: val_loss improved from 0.00025 to 0.00025, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 2.1094e-04 - mae: 0.0100 - mse: 2.1094e-04 - val_loss: 2.4782e-04 - val_mae: 0.0106 - val_mse: 2.4782e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0011e-04 - mae: 0.0097 - mse: 2.0011e-04\n",
      "Epoch 175: val_loss did not improve from 0.00025\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0645e-04 - mae: 0.0098 - mse: 2.0645e-04 - val_loss: 2.5346e-04 - val_mae: 0.0108 - val_mse: 2.5346e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9656e-04 - mae: 0.0097 - mse: 1.9656e-04\n",
      "Epoch 176: val_loss did not improve from 0.00025\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.0557e-04 - mae: 0.0098 - mse: 2.0557e-04 - val_loss: 2.5191e-04 - val_mae: 0.0108 - val_mse: 2.5191e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9389e-04 - mae: 0.0096 - mse: 1.9389e-04\n",
      "Epoch 177: val_loss improved from 0.00025 to 0.00024, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0161e-04 - mae: 0.0097 - mse: 2.0161e-04 - val_loss: 2.4408e-04 - val_mae: 0.0106 - val_mse: 2.4408e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1298e-04 - mae: 0.0100 - mse: 2.1298e-04\n",
      "Epoch 178: val_loss improved from 0.00024 to 0.00024, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.9991e-04 - mae: 0.0097 - mse: 1.9991e-04 - val_loss: 2.4314e-04 - val_mae: 0.0105 - val_mse: 2.4314e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.1879e-04 - mae: 0.0100 - mse: 2.1879e-04\n",
      "Epoch 179: val_loss did not improve from 0.00024\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.9732e-04 - mae: 0.0096 - mse: 1.9732e-04 - val_loss: 2.4583e-04 - val_mae: 0.0105 - val_mse: 2.4583e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0022e-04 - mae: 0.0096 - mse: 2.0022e-04\n",
      "Epoch 180: val_loss improved from 0.00024 to 0.00024, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.9479e-04 - mae: 0.0095 - mse: 1.9479e-04 - val_loss: 2.3982e-04 - val_mae: 0.0106 - val_mse: 2.3982e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9249e-04 - mae: 0.0093 - mse: 1.9249e-04\n",
      "Epoch 181: val_loss improved from 0.00024 to 0.00023, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.9394e-04 - mae: 0.0095 - mse: 1.9394e-04 - val_loss: 2.3407e-04 - val_mae: 0.0105 - val_mse: 2.3407e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9876e-04 - mae: 0.0095 - mse: 1.9876e-04\n",
      "Epoch 182: val_loss improved from 0.00023 to 0.00023, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.9186e-04 - mae: 0.0094 - mse: 1.9186e-04 - val_loss: 2.3195e-04 - val_mae: 0.0103 - val_mse: 2.3195e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9186e-04 - mae: 0.0093 - mse: 1.9186e-04\n",
      "Epoch 183: val_loss did not improve from 0.00023\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8904e-04 - mae: 0.0094 - mse: 1.8904e-04 - val_loss: 2.3304e-04 - val_mae: 0.0103 - val_mse: 2.3304e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7653e-04 - mae: 0.0092 - mse: 1.7653e-04\n",
      "Epoch 184: val_loss improved from 0.00023 to 0.00023, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8713e-04 - mae: 0.0093 - mse: 1.8713e-04 - val_loss: 2.2898e-04 - val_mae: 0.0102 - val_mse: 2.2898e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8043e-04 - mae: 0.0092 - mse: 1.8043e-04\n",
      "Epoch 185: val_loss did not improve from 0.00023\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.8555e-04 - mae: 0.0093 - mse: 1.8555e-04 - val_loss: 2.3295e-04 - val_mae: 0.0104 - val_mse: 2.3295e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7936e-04 - mae: 0.0093 - mse: 1.7936e-04\n",
      "Epoch 186: val_loss did not improve from 0.00023\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.8475e-04 - mae: 0.0093 - mse: 1.8475e-04 - val_loss: 2.3312e-04 - val_mae: 0.0103 - val_mse: 2.3312e-04\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8840e-04 - mae: 0.0094 - mse: 1.8840e-04\n",
      "Epoch 187: val_loss did not improve from 0.00023\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8135e-04 - mae: 0.0092 - mse: 1.8135e-04 - val_loss: 2.3485e-04 - val_mae: 0.0103 - val_mse: 2.3485e-04\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7917e-04 - mae: 0.0091 - mse: 1.7917e-04\n",
      "Epoch 188: val_loss did not improve from 0.00023\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8159e-04 - mae: 0.0092 - mse: 1.8159e-04 - val_loss: 2.3079e-04 - val_mae: 0.0101 - val_mse: 2.3079e-04\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7169e-04 - mae: 0.0088 - mse: 1.7169e-04\n",
      "Epoch 189: val_loss did not improve from 0.00023\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.8017e-04 - mae: 0.0091 - mse: 1.8017e-04 - val_loss: 2.3025e-04 - val_mae: 0.0102 - val_mse: 2.3025e-04\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7822e-04 - mae: 0.0091 - mse: 1.7822e-04\n",
      "Epoch 190: val_loss improved from 0.00023 to 0.00022, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.7880e-04 - mae: 0.0091 - mse: 1.7880e-04 - val_loss: 2.2452e-04 - val_mae: 0.0101 - val_mse: 2.2452e-04\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8306e-04 - mae: 0.0092 - mse: 1.8306e-04\n",
      "Epoch 191: val_loss improved from 0.00022 to 0.00022, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.8048e-04 - mae: 0.0092 - mse: 1.8048e-04 - val_loss: 2.2219e-04 - val_mae: 0.0101 - val_mse: 2.2219e-04\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6859e-04 - mae: 0.0089 - mse: 1.6859e-04\n",
      "Epoch 192: val_loss did not improve from 0.00022\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7371e-04 - mae: 0.0090 - mse: 1.7371e-04 - val_loss: 2.3936e-04 - val_mae: 0.0104 - val_mse: 2.3936e-04\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.8788e-04 - mae: 0.0094 - mse: 1.8788e-04\n",
      "Epoch 193: val_loss improved from 0.00022 to 0.00022, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.8007e-04 - mae: 0.0092 - mse: 1.8007e-04 - val_loss: 2.2199e-04 - val_mae: 0.0101 - val_mse: 2.2199e-04\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.6709e-04 - mae: 0.0089 - mse: 1.6709e-04\n",
      "Epoch 194: val_loss improved from 0.00022 to 0.00022, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.7371e-04 - mae: 0.0090 - mse: 1.7371e-04 - val_loss: 2.1577e-04 - val_mae: 0.0099 - val_mse: 2.1577e-04\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6313e-04 - mae: 0.0088 - mse: 1.6313e-04\n",
      "Epoch 195: val_loss did not improve from 0.00022\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7425e-04 - mae: 0.0090 - mse: 1.7425e-04 - val_loss: 2.2156e-04 - val_mae: 0.0099 - val_mse: 2.2156e-04\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4371e-04 - mae: 0.0084 - mse: 1.4371e-04\n",
      "Epoch 196: val_loss did not improve from 0.00022\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.7275e-04 - mae: 0.0090 - mse: 1.7275e-04 - val_loss: 2.2032e-04 - val_mae: 0.0099 - val_mse: 2.2032e-04\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5748e-04 - mae: 0.0086 - mse: 1.5748e-04\n",
      "Epoch 197: val_loss did not improve from 0.00022\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.6841e-04 - mae: 0.0088 - mse: 1.6841e-04 - val_loss: 2.2010e-04 - val_mae: 0.0100 - val_mse: 2.2010e-04\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7251e-04 - mae: 0.0091 - mse: 1.7251e-04\n",
      "Epoch 198: val_loss improved from 0.00022 to 0.00021, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7025e-04 - mae: 0.0090 - mse: 1.7025e-04 - val_loss: 2.1421e-04 - val_mae: 0.0099 - val_mse: 2.1421e-04\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7550e-04 - mae: 0.0090 - mse: 1.7550e-04\n",
      "Epoch 199: val_loss improved from 0.00021 to 0.00021, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.6678e-04 - mae: 0.0089 - mse: 1.6678e-04 - val_loss: 2.1325e-04 - val_mae: 0.0099 - val_mse: 2.1325e-04\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5572e-04 - mae: 0.0085 - mse: 1.5572e-04\n",
      "Epoch 200: val_loss did not improve from 0.00021\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6440e-04 - mae: 0.0088 - mse: 1.6440e-04 - val_loss: 2.1345e-04 - val_mae: 0.0099 - val_mse: 2.1345e-04\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6114e-04 - mae: 0.0087 - mse: 1.6114e-04\n",
      "Epoch 201: val_loss improved from 0.00021 to 0.00021, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6280e-04 - mae: 0.0087 - mse: 1.6280e-04 - val_loss: 2.1009e-04 - val_mae: 0.0098 - val_mse: 2.1009e-04\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6008e-04 - mae: 0.0087 - mse: 1.6008e-04\n",
      "Epoch 202: val_loss improved from 0.00021 to 0.00021, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6088e-04 - mae: 0.0087 - mse: 1.6088e-04 - val_loss: 2.0879e-04 - val_mae: 0.0097 - val_mse: 2.0879e-04\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5344e-04 - mae: 0.0084 - mse: 1.5344e-04\n",
      "Epoch 203: val_loss did not improve from 0.00021\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5805e-04 - mae: 0.0086 - mse: 1.5805e-04 - val_loss: 2.0950e-04 - val_mae: 0.0097 - val_mse: 2.0950e-04\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4348e-04 - mae: 0.0081 - mse: 1.4348e-04\n",
      "Epoch 204: val_loss improved from 0.00021 to 0.00021, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5868e-04 - mae: 0.0086 - mse: 1.5868e-04 - val_loss: 2.0534e-04 - val_mae: 0.0095 - val_mse: 2.0534e-04\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5359e-04 - mae: 0.0085 - mse: 1.5359e-04\n",
      "Epoch 205: val_loss improved from 0.00021 to 0.00020, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5600e-04 - mae: 0.0085 - mse: 1.5600e-04 - val_loss: 2.0160e-04 - val_mae: 0.0095 - val_mse: 2.0160e-04\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4663e-04 - mae: 0.0083 - mse: 1.4663e-04\n",
      "Epoch 206: val_loss did not improve from 0.00020\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5414e-04 - mae: 0.0084 - mse: 1.5414e-04 - val_loss: 2.0460e-04 - val_mae: 0.0096 - val_mse: 2.0460e-04\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4103e-04 - mae: 0.0081 - mse: 1.4103e-04\n",
      "Epoch 207: val_loss improved from 0.00020 to 0.00020, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.5297e-04 - mae: 0.0084 - mse: 1.5297e-04 - val_loss: 2.0087e-04 - val_mae: 0.0095 - val_mse: 2.0087e-04\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6290e-04 - mae: 0.0086 - mse: 1.6290e-04\n",
      "Epoch 208: val_loss improved from 0.00020 to 0.00019, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.5269e-04 - mae: 0.0084 - mse: 1.5269e-04 - val_loss: 1.9472e-04 - val_mae: 0.0093 - val_mse: 1.9472e-04\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3681e-04 - mae: 0.0080 - mse: 1.3681e-04\n",
      "Epoch 209: val_loss did not improve from 0.00019\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4972e-04 - mae: 0.0083 - mse: 1.4972e-04 - val_loss: 1.9706e-04 - val_mae: 0.0094 - val_mse: 1.9706e-04\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3543e-04 - mae: 0.0080 - mse: 1.3543e-04\n",
      "Epoch 210: val_loss improved from 0.00019 to 0.00019, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4937e-04 - mae: 0.0083 - mse: 1.4937e-04 - val_loss: 1.9408e-04 - val_mae: 0.0093 - val_mse: 1.9408e-04\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5679e-04 - mae: 0.0084 - mse: 1.5679e-04\n",
      "Epoch 211: val_loss improved from 0.00019 to 0.00019, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4684e-04 - mae: 0.0082 - mse: 1.4684e-04 - val_loss: 1.9093e-04 - val_mae: 0.0093 - val_mse: 1.9093e-04\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5856e-04 - mae: 0.0084 - mse: 1.5856e-04\n",
      "Epoch 212: val_loss improved from 0.00019 to 0.00019, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4604e-04 - mae: 0.0082 - mse: 1.4604e-04 - val_loss: 1.8945e-04 - val_mae: 0.0093 - val_mse: 1.8945e-04\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4211e-04 - mae: 0.0081 - mse: 1.4211e-04\n",
      "Epoch 213: val_loss improved from 0.00019 to 0.00019, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.4588e-04 - mae: 0.0082 - mse: 1.4588e-04 - val_loss: 1.8610e-04 - val_mae: 0.0091 - val_mse: 1.8610e-04\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5663e-04 - mae: 0.0085 - mse: 1.5663e-04\n",
      "Epoch 214: val_loss did not improve from 0.00019\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4291e-04 - mae: 0.0081 - mse: 1.4291e-04 - val_loss: 1.8933e-04 - val_mae: 0.0092 - val_mse: 1.8933e-04\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4022e-04 - mae: 0.0081 - mse: 1.4022e-04\n",
      "Epoch 215: val_loss did not improve from 0.00019\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4334e-04 - mae: 0.0082 - mse: 1.4334e-04 - val_loss: 1.9150e-04 - val_mae: 0.0091 - val_mse: 1.9150e-04\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4782e-04 - mae: 0.0082 - mse: 1.4782e-04\n",
      "Epoch 216: val_loss did not improve from 0.00019\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.4208e-04 - mae: 0.0081 - mse: 1.4208e-04 - val_loss: 1.8886e-04 - val_mae: 0.0091 - val_mse: 1.8886e-04\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2774e-04 - mae: 0.0078 - mse: 1.2774e-04\n",
      "Epoch 217: val_loss improved from 0.00019 to 0.00019, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.4015e-04 - mae: 0.0080 - mse: 1.4015e-04 - val_loss: 1.8599e-04 - val_mae: 0.0091 - val_mse: 1.8599e-04\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4250e-04 - mae: 0.0080 - mse: 1.4250e-04\n",
      "Epoch 218: val_loss improved from 0.00019 to 0.00018, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3982e-04 - mae: 0.0080 - mse: 1.3982e-04 - val_loss: 1.8368e-04 - val_mae: 0.0089 - val_mse: 1.8368e-04\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5419e-04 - mae: 0.0082 - mse: 1.5419e-04\n",
      "Epoch 219: val_loss did not improve from 0.00018\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3701e-04 - mae: 0.0079 - mse: 1.3701e-04 - val_loss: 1.8621e-04 - val_mae: 0.0091 - val_mse: 1.8621e-04\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4884e-04 - mae: 0.0082 - mse: 1.4884e-04\n",
      "Epoch 220: val_loss improved from 0.00018 to 0.00018, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.3759e-04 - mae: 0.0080 - mse: 1.3759e-04 - val_loss: 1.7960e-04 - val_mae: 0.0089 - val_mse: 1.7960e-04\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3511e-04 - mae: 0.0078 - mse: 1.3511e-04\n",
      "Epoch 221: val_loss improved from 0.00018 to 0.00018, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3763e-04 - mae: 0.0079 - mse: 1.3763e-04 - val_loss: 1.7852e-04 - val_mae: 0.0088 - val_mse: 1.7852e-04\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4385e-04 - mae: 0.0081 - mse: 1.4385e-04\n",
      "Epoch 222: val_loss improved from 0.00018 to 0.00018, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3593e-04 - mae: 0.0079 - mse: 1.3593e-04 - val_loss: 1.7674e-04 - val_mae: 0.0088 - val_mse: 1.7674e-04\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3079e-04 - mae: 0.0078 - mse: 1.3079e-04\n",
      "Epoch 223: val_loss improved from 0.00018 to 0.00017, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3517e-04 - mae: 0.0078 - mse: 1.3517e-04 - val_loss: 1.7411e-04 - val_mae: 0.0088 - val_mse: 1.7411e-04\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3754e-04 - mae: 0.0080 - mse: 1.3754e-04\n",
      "Epoch 224: val_loss improved from 0.00017 to 0.00017, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3476e-04 - mae: 0.0078 - mse: 1.3476e-04 - val_loss: 1.7346e-04 - val_mae: 0.0088 - val_mse: 1.7346e-04\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4562e-04 - mae: 0.0079 - mse: 1.4562e-04\n",
      "Epoch 225: val_loss did not improve from 0.00017\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.3156e-04 - mae: 0.0077 - mse: 1.3156e-04 - val_loss: 1.7708e-04 - val_mae: 0.0089 - val_mse: 1.7708e-04\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4213e-04 - mae: 0.0081 - mse: 1.4213e-04\n",
      "Epoch 226: val_loss improved from 0.00017 to 0.00017, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3153e-04 - mae: 0.0078 - mse: 1.3153e-04 - val_loss: 1.7272e-04 - val_mae: 0.0088 - val_mse: 1.7272e-04\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1961e-04 - mae: 0.0075 - mse: 1.1961e-04\n",
      "Epoch 227: val_loss improved from 0.00017 to 0.00017, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.3166e-04 - mae: 0.0077 - mse: 1.3166e-04 - val_loss: 1.7136e-04 - val_mae: 0.0087 - val_mse: 1.7136e-04\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3457e-04 - mae: 0.0079 - mse: 1.3457e-04\n",
      "Epoch 228: val_loss improved from 0.00017 to 0.00017, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3009e-04 - mae: 0.0077 - mse: 1.3009e-04 - val_loss: 1.7076e-04 - val_mae: 0.0088 - val_mse: 1.7076e-04\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3228e-04 - mae: 0.0077 - mse: 1.3228e-04\n",
      "Epoch 229: val_loss improved from 0.00017 to 0.00016, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.3036e-04 - mae: 0.0077 - mse: 1.3036e-04 - val_loss: 1.6472e-04 - val_mae: 0.0087 - val_mse: 1.6472e-04\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3338e-04 - mae: 0.0078 - mse: 1.3338e-04\n",
      "Epoch 230: val_loss improved from 0.00016 to 0.00016, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.2843e-04 - mae: 0.0076 - mse: 1.2843e-04 - val_loss: 1.6438e-04 - val_mae: 0.0086 - val_mse: 1.6438e-04\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3464e-04 - mae: 0.0078 - mse: 1.3464e-04\n",
      "Epoch 231: val_loss improved from 0.00016 to 0.00016, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2742e-04 - mae: 0.0076 - mse: 1.2742e-04 - val_loss: 1.6432e-04 - val_mae: 0.0085 - val_mse: 1.6432e-04\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3229e-04 - mae: 0.0077 - mse: 1.3229e-04\n",
      "Epoch 232: val_loss improved from 0.00016 to 0.00016, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.2689e-04 - mae: 0.0076 - mse: 1.2689e-04 - val_loss: 1.6170e-04 - val_mae: 0.0085 - val_mse: 1.6170e-04\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1519e-04 - mae: 0.0074 - mse: 1.1519e-04\n",
      "Epoch 233: val_loss improved from 0.00016 to 0.00016, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2666e-04 - mae: 0.0076 - mse: 1.2666e-04 - val_loss: 1.6054e-04 - val_mae: 0.0085 - val_mse: 1.6054e-04\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2552e-04 - mae: 0.0076 - mse: 1.2552e-04\n",
      "Epoch 234: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2382e-04 - mae: 0.0075 - mse: 1.2382e-04 - val_loss: 1.6649e-04 - val_mae: 0.0087 - val_mse: 1.6649e-04\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3711e-04 - mae: 0.0079 - mse: 1.3711e-04\n",
      "Epoch 235: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2515e-04 - mae: 0.0075 - mse: 1.2515e-04 - val_loss: 1.6461e-04 - val_mae: 0.0086 - val_mse: 1.6461e-04\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2367e-04 - mae: 0.0074 - mse: 1.2367e-04\n",
      "Epoch 236: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2342e-04 - mae: 0.0074 - mse: 1.2342e-04 - val_loss: 1.6469e-04 - val_mae: 0.0086 - val_mse: 1.6469e-04\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1909e-04 - mae: 0.0074 - mse: 1.1909e-04\n",
      "Epoch 237: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2371e-04 - mae: 0.0075 - mse: 1.2371e-04 - val_loss: 1.6257e-04 - val_mae: 0.0085 - val_mse: 1.6257e-04\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1639e-04 - mae: 0.0073 - mse: 1.1639e-04\n",
      "Epoch 238: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2207e-04 - mae: 0.0075 - mse: 1.2207e-04 - val_loss: 1.6499e-04 - val_mae: 0.0086 - val_mse: 1.6499e-04\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2519e-04 - mae: 0.0075 - mse: 1.2519e-04\n",
      "Epoch 239: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.2039e-04 - mae: 0.0074 - mse: 1.2039e-04 - val_loss: 1.6215e-04 - val_mae: 0.0085 - val_mse: 1.6215e-04\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0623e-04 - mae: 0.0070 - mse: 1.0623e-04\n",
      "Epoch 240: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.2207e-04 - mae: 0.0074 - mse: 1.2207e-04 - val_loss: 1.6086e-04 - val_mae: 0.0085 - val_mse: 1.6086e-04\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1409e-04 - mae: 0.0073 - mse: 1.1409e-04\n",
      "Epoch 241: val_loss did not improve from 0.00016\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1958e-04 - mae: 0.0073 - mse: 1.1958e-04 - val_loss: 1.6080e-04 - val_mae: 0.0085 - val_mse: 1.6080e-04\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.2197e-04 - mae: 0.0074 - mse: 1.2197e-04\n",
      "Epoch 242: val_loss improved from 0.00016 to 0.00016, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.2033e-04 - mae: 0.0074 - mse: 1.2033e-04 - val_loss: 1.5556e-04 - val_mae: 0.0083 - val_mse: 1.5556e-04\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3096e-04 - mae: 0.0076 - mse: 1.3096e-04\n",
      "Epoch 243: val_loss improved from 0.00016 to 0.00015, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1852e-04 - mae: 0.0073 - mse: 1.1852e-04 - val_loss: 1.5173e-04 - val_mae: 0.0082 - val_mse: 1.5173e-04\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0797e-04 - mae: 0.0071 - mse: 1.0797e-04\n",
      "Epoch 244: val_loss did not improve from 0.00015\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1837e-04 - mae: 0.0073 - mse: 1.1837e-04 - val_loss: 1.5557e-04 - val_mae: 0.0084 - val_mse: 1.5557e-04\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2198e-04 - mae: 0.0074 - mse: 1.2198e-04\n",
      "Epoch 245: val_loss did not improve from 0.00015\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1651e-04 - mae: 0.0073 - mse: 1.1651e-04 - val_loss: 1.5468e-04 - val_mae: 0.0083 - val_mse: 1.5468e-04\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1669e-04 - mae: 0.0074 - mse: 1.1669e-04\n",
      "Epoch 246: val_loss improved from 0.00015 to 0.00015, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1660e-04 - mae: 0.0073 - mse: 1.1660e-04 - val_loss: 1.5015e-04 - val_mae: 0.0082 - val_mse: 1.5015e-04\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3144e-04 - mae: 0.0076 - mse: 1.3144e-04\n",
      "Epoch 247: val_loss improved from 0.00015 to 0.00015, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.1561e-04 - mae: 0.0072 - mse: 1.1561e-04 - val_loss: 1.4976e-04 - val_mae: 0.0082 - val_mse: 1.4976e-04\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0245e-04 - mae: 0.0068 - mse: 1.0245e-04\n",
      "Epoch 248: val_loss did not improve from 0.00015\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1462e-04 - mae: 0.0072 - mse: 1.1462e-04 - val_loss: 1.5218e-04 - val_mae: 0.0082 - val_mse: 1.5218e-04\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2345e-04 - mae: 0.0076 - mse: 1.2345e-04\n",
      "Epoch 249: val_loss did not improve from 0.00015\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1628e-04 - mae: 0.0073 - mse: 1.1628e-04 - val_loss: 1.5432e-04 - val_mae: 0.0083 - val_mse: 1.5432e-04\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1108e-04 - mae: 0.0071 - mse: 1.1108e-04\n",
      "Epoch 250: val_loss did not improve from 0.00015\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 1.1271e-04 - mae: 0.0071 - mse: 1.1271e-04 - val_loss: 1.5104e-04 - val_mae: 0.0082 - val_mse: 1.5104e-04\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0486e-04 - mae: 0.0070 - mse: 1.0486e-04\n",
      "Epoch 251: val_loss improved from 0.00015 to 0.00015, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 1.1251e-04 - mae: 0.0071 - mse: 1.1251e-04 - val_loss: 1.4548e-04 - val_mae: 0.0081 - val_mse: 1.4548e-04\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2672e-04 - mae: 0.0075 - mse: 1.2672e-04\n",
      "Epoch 252: val_loss improved from 0.00015 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1156e-04 - mae: 0.0071 - mse: 1.1156e-04 - val_loss: 1.4371e-04 - val_mae: 0.0079 - val_mse: 1.4371e-04\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3133e-05 - mae: 0.0065 - mse: 9.3133e-05\n",
      "Epoch 253: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1050e-04 - mae: 0.0070 - mse: 1.1050e-04 - val_loss: 1.4841e-04 - val_mae: 0.0080 - val_mse: 1.4841e-04\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0240e-04 - mae: 0.0068 - mse: 1.0240e-04\n",
      "Epoch 254: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1032e-04 - mae: 0.0070 - mse: 1.1032e-04 - val_loss: 1.4537e-04 - val_mae: 0.0080 - val_mse: 1.4537e-04\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1943e-04 - mae: 0.0073 - mse: 1.1943e-04\n",
      "Epoch 255: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0948e-04 - mae: 0.0070 - mse: 1.0948e-04 - val_loss: 1.4216e-04 - val_mae: 0.0080 - val_mse: 1.4216e-04\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0316e-04 - mae: 0.0067 - mse: 1.0316e-04\n",
      "Epoch 256: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0903e-04 - mae: 0.0070 - mse: 1.0903e-04 - val_loss: 1.4532e-04 - val_mae: 0.0081 - val_mse: 1.4532e-04\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1320e-04 - mae: 0.0071 - mse: 1.1320e-04\n",
      "Epoch 257: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1008e-04 - mae: 0.0071 - mse: 1.1008e-04 - val_loss: 1.4465e-04 - val_mae: 0.0080 - val_mse: 1.4465e-04\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0681e-04 - mae: 0.0070 - mse: 1.0681e-04\n",
      "Epoch 258: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0812e-04 - mae: 0.0070 - mse: 1.0812e-04 - val_loss: 1.4239e-04 - val_mae: 0.0080 - val_mse: 1.4239e-04\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0374e-04 - mae: 0.0069 - mse: 1.0374e-04\n",
      "Epoch 259: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0891e-04 - mae: 0.0070 - mse: 1.0891e-04 - val_loss: 1.4070e-04 - val_mae: 0.0079 - val_mse: 1.4070e-04\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0262e-04 - mae: 0.0069 - mse: 1.0262e-04\n",
      "Epoch 260: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0761e-04 - mae: 0.0069 - mse: 1.0761e-04 - val_loss: 1.3993e-04 - val_mae: 0.0080 - val_mse: 1.3993e-04\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1204e-04 - mae: 0.0070 - mse: 1.1204e-04\n",
      "Epoch 261: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0763e-04 - mae: 0.0070 - mse: 1.0763e-04 - val_loss: 1.4029e-04 - val_mae: 0.0080 - val_mse: 1.4029e-04\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1168e-04 - mae: 0.0070 - mse: 1.1168e-04\n",
      "Epoch 262: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0620e-04 - mae: 0.0069 - mse: 1.0620e-04 - val_loss: 1.4141e-04 - val_mae: 0.0080 - val_mse: 1.4141e-04\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1565e-04 - mae: 0.0071 - mse: 1.1565e-04\n",
      "Epoch 263: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0663e-04 - mae: 0.0069 - mse: 1.0663e-04 - val_loss: 1.3922e-04 - val_mae: 0.0079 - val_mse: 1.3922e-04\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0046e-04 - mae: 0.0068 - mse: 1.0046e-04\n",
      "Epoch 264: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0585e-04 - mae: 0.0069 - mse: 1.0585e-04 - val_loss: 1.3852e-04 - val_mae: 0.0078 - val_mse: 1.3852e-04\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0597e-04 - mae: 0.0069 - mse: 1.0597e-04\n",
      "Epoch 265: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0357e-04 - mae: 0.0068 - mse: 1.0357e-04 - val_loss: 1.3997e-04 - val_mae: 0.0079 - val_mse: 1.3997e-04\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1952e-05 - mae: 0.0063 - mse: 9.1952e-05\n",
      "Epoch 266: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0497e-04 - mae: 0.0068 - mse: 1.0497e-04 - val_loss: 1.4188e-04 - val_mae: 0.0079 - val_mse: 1.4188e-04\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1069e-04 - mae: 0.0069 - mse: 1.1069e-04\n",
      "Epoch 267: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0389e-04 - mae: 0.0068 - mse: 1.0389e-04 - val_loss: 1.4216e-04 - val_mae: 0.0079 - val_mse: 1.4216e-04\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0261e-04 - mae: 0.0068 - mse: 1.0261e-04\n",
      "Epoch 268: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.0579e-04 - mae: 0.0069 - mse: 1.0579e-04 - val_loss: 1.3791e-04 - val_mae: 0.0078 - val_mse: 1.3791e-04\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1632e-04 - mae: 0.0070 - mse: 1.1632e-04\n",
      "Epoch 269: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.0482e-04 - mae: 0.0068 - mse: 1.0482e-04 - val_loss: 1.3775e-04 - val_mae: 0.0077 - val_mse: 1.3775e-04\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.3890e-05 - mae: 0.0065 - mse: 9.3890e-05\n",
      "Epoch 270: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0519e-04 - mae: 0.0068 - mse: 1.0519e-04 - val_loss: 1.3871e-04 - val_mae: 0.0078 - val_mse: 1.3871e-04\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0535e-04 - mae: 0.0068 - mse: 1.0535e-04\n",
      "Epoch 271: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0275e-04 - mae: 0.0067 - mse: 1.0275e-04 - val_loss: 1.3759e-04 - val_mae: 0.0079 - val_mse: 1.3759e-04\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0060e-04 - mae: 0.0069 - mse: 1.0060e-04\n",
      "Epoch 272: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.0404e-04 - mae: 0.0068 - mse: 1.0404e-04 - val_loss: 1.4396e-04 - val_mae: 0.0081 - val_mse: 1.4396e-04\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0522e-04 - mae: 0.0069 - mse: 1.0522e-04\n",
      "Epoch 273: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0302e-04 - mae: 0.0068 - mse: 1.0302e-04 - val_loss: 1.4106e-04 - val_mae: 0.0079 - val_mse: 1.4106e-04\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0690e-04 - mae: 0.0069 - mse: 1.0690e-04\n",
      "Epoch 274: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0228e-04 - mae: 0.0068 - mse: 1.0228e-04 - val_loss: 1.3589e-04 - val_mae: 0.0077 - val_mse: 1.3589e-04\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0309e-04 - mae: 0.0068 - mse: 1.0309e-04\n",
      "Epoch 275: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0137e-04 - mae: 0.0067 - mse: 1.0137e-04 - val_loss: 1.3690e-04 - val_mae: 0.0078 - val_mse: 1.3690e-04\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0804e-04 - mae: 0.0069 - mse: 1.0804e-04\n",
      "Epoch 276: val_loss improved from 0.00014 to 0.00014, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0103e-04 - mae: 0.0067 - mse: 1.0103e-04 - val_loss: 1.3546e-04 - val_mae: 0.0076 - val_mse: 1.3546e-04\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5663e-05 - mae: 0.0065 - mse: 9.5663e-05\n",
      "Epoch 277: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0058e-04 - mae: 0.0067 - mse: 1.0058e-04 - val_loss: 1.3747e-04 - val_mae: 0.0077 - val_mse: 1.3747e-04\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0602e-04 - mae: 0.0067 - mse: 1.0602e-04\n",
      "Epoch 278: val_loss did not improve from 0.00014\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.0022e-04 - mae: 0.0067 - mse: 1.0022e-04 - val_loss: 1.3848e-04 - val_mae: 0.0078 - val_mse: 1.3848e-04\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0366e-04 - mae: 0.0068 - mse: 1.0366e-04\n",
      "Epoch 279: val_loss improved from 0.00014 to 0.00013, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.8611e-05 - mae: 0.0066 - mse: 9.8611e-05 - val_loss: 1.3179e-04 - val_mae: 0.0077 - val_mse: 1.3179e-04\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1024e-04 - mae: 0.0069 - mse: 1.1024e-04\n",
      "Epoch 280: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.9575e-05 - mae: 0.0066 - mse: 9.9575e-05 - val_loss: 1.3202e-04 - val_mae: 0.0077 - val_mse: 1.3202e-04\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0151e-04 - mae: 0.0065 - mse: 1.0151e-04\n",
      "Epoch 281: val_loss improved from 0.00013 to 0.00013, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.7675e-05 - mae: 0.0065 - mse: 9.7675e-05 - val_loss: 1.3174e-04 - val_mae: 0.0076 - val_mse: 1.3174e-04\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.5001e-05 - mae: 0.0063 - mse: 9.5001e-05\n",
      "Epoch 282: val_loss improved from 0.00013 to 0.00013, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.6384e-05 - mae: 0.0065 - mse: 9.6384e-05 - val_loss: 1.2964e-04 - val_mae: 0.0075 - val_mse: 1.2964e-04\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.1827e-05 - mae: 0.0061 - mse: 8.1827e-05\n",
      "Epoch 283: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.6105e-05 - mae: 0.0065 - mse: 9.6105e-05 - val_loss: 1.3125e-04 - val_mae: 0.0076 - val_mse: 1.3125e-04\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5133e-05 - mae: 0.0064 - mse: 9.5133e-05\n",
      "Epoch 284: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.5337e-05 - mae: 0.0065 - mse: 9.5337e-05 - val_loss: 1.3467e-04 - val_mae: 0.0076 - val_mse: 1.3467e-04\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0518e-04 - mae: 0.0068 - mse: 1.0518e-04\n",
      "Epoch 285: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.7027e-05 - mae: 0.0065 - mse: 9.7027e-05 - val_loss: 1.3133e-04 - val_mae: 0.0075 - val_mse: 1.3133e-04\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.7476e-05 - mae: 0.0065 - mse: 9.7476e-05\n",
      "Epoch 286: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.5155e-05 - mae: 0.0065 - mse: 9.5155e-05 - val_loss: 1.3234e-04 - val_mae: 0.0075 - val_mse: 1.3234e-04\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5425e-05 - mae: 0.0063 - mse: 8.5425e-05\n",
      "Epoch 287: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.6125e-05 - mae: 0.0065 - mse: 9.6125e-05 - val_loss: 1.2977e-04 - val_mae: 0.0074 - val_mse: 1.2977e-04\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6053e-05 - mae: 0.0065 - mse: 9.6053e-05\n",
      "Epoch 288: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.3877e-05 - mae: 0.0064 - mse: 9.3877e-05 - val_loss: 1.3222e-04 - val_mae: 0.0076 - val_mse: 1.3222e-04\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0535e-04 - mae: 0.0068 - mse: 1.0535e-04\n",
      "Epoch 289: val_loss improved from 0.00013 to 0.00013, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 9.4379e-05 - mae: 0.0064 - mse: 9.4379e-05 - val_loss: 1.2954e-04 - val_mae: 0.0075 - val_mse: 1.2954e-04\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0117e-05 - mae: 0.0062 - mse: 9.0117e-05\n",
      "Epoch 290: val_loss improved from 0.00013 to 0.00013, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.3776e-05 - mae: 0.0064 - mse: 9.3776e-05 - val_loss: 1.2740e-04 - val_mae: 0.0075 - val_mse: 1.2740e-04\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0121e-04 - mae: 0.0065 - mse: 1.0121e-04\n",
      "Epoch 291: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4420e-05 - mae: 0.0064 - mse: 9.4420e-05 - val_loss: 1.3095e-04 - val_mae: 0.0075 - val_mse: 1.3095e-04\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0286e-04 - mae: 0.0067 - mse: 1.0286e-04\n",
      "Epoch 292: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 9.4183e-05 - mae: 0.0064 - mse: 9.4183e-05 - val_loss: 1.3283e-04 - val_mae: 0.0074 - val_mse: 1.3283e-04\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0651e-04 - mae: 0.0067 - mse: 1.0651e-04\n",
      "Epoch 293: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 9.5375e-05 - mae: 0.0064 - mse: 9.5375e-05 - val_loss: 1.2881e-04 - val_mae: 0.0075 - val_mse: 1.2881e-04\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.9903e-05 - mae: 0.0065 - mse: 9.9903e-05\n",
      "Epoch 294: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 9.3540e-05 - mae: 0.0064 - mse: 9.3540e-05 - val_loss: 1.2880e-04 - val_mae: 0.0075 - val_mse: 1.2880e-04\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7754e-05 - mae: 0.0065 - mse: 9.7754e-05\n",
      "Epoch 295: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.2473e-05 - mae: 0.0064 - mse: 9.2473e-05 - val_loss: 1.3007e-04 - val_mae: 0.0075 - val_mse: 1.3007e-04\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.7424e-05 - mae: 0.0063 - mse: 8.7424e-05\n",
      "Epoch 296: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.3722e-05 - mae: 0.0064 - mse: 9.3722e-05 - val_loss: 1.2785e-04 - val_mae: 0.0074 - val_mse: 1.2785e-04\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8532e-05 - mae: 0.0064 - mse: 9.8532e-05\n",
      "Epoch 297: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.2228e-05 - mae: 0.0063 - mse: 9.2228e-05 - val_loss: 1.2940e-04 - val_mae: 0.0073 - val_mse: 1.2940e-04\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2166e-05 - mae: 0.0063 - mse: 9.2166e-05\n",
      "Epoch 298: val_loss improved from 0.00013 to 0.00013, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.1969e-05 - mae: 0.0063 - mse: 9.1969e-05 - val_loss: 1.2514e-04 - val_mae: 0.0072 - val_mse: 1.2514e-04\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3982e-05 - mae: 0.0060 - mse: 8.3982e-05\n",
      "Epoch 299: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.0040e-05 - mae: 0.0062 - mse: 9.0040e-05 - val_loss: 1.2548e-04 - val_mae: 0.0074 - val_mse: 1.2548e-04\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8702e-05 - mae: 0.0062 - mse: 8.8702e-05\n",
      "Epoch 300: val_loss did not improve from 0.00013\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.1322e-05 - mae: 0.0063 - mse: 9.1322e-05 - val_loss: 1.2517e-04 - val_mae: 0.0073 - val_mse: 1.2517e-04\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1529e-05 - mae: 0.0061 - mse: 9.1529e-05\n",
      "Epoch 301: val_loss improved from 0.00013 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.9395e-05 - mae: 0.0062 - mse: 8.9395e-05 - val_loss: 1.2458e-04 - val_mae: 0.0073 - val_mse: 1.2458e-04\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 6.7778e-05 - mae: 0.0057 - mse: 6.7778e-05\n",
      "Epoch 302: val_loss improved from 0.00012 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.1470e-05 - mae: 0.0063 - mse: 9.1470e-05 - val_loss: 1.2142e-04 - val_mae: 0.0073 - val_mse: 1.2142e-04\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2116e-05 - mae: 0.0061 - mse: 8.2116e-05\n",
      "Epoch 303: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 8.9061e-05 - mae: 0.0063 - mse: 8.9061e-05 - val_loss: 1.2696e-04 - val_mae: 0.0076 - val_mse: 1.2696e-04\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6273e-05 - mae: 0.0062 - mse: 8.6273e-05\n",
      "Epoch 304: val_loss improved from 0.00012 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 9.0506e-05 - mae: 0.0063 - mse: 9.0506e-05 - val_loss: 1.1962e-04 - val_mae: 0.0073 - val_mse: 1.1962e-04\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9300e-05 - mae: 0.0062 - mse: 8.9300e-05\n",
      "Epoch 305: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.9930e-05 - mae: 0.0063 - mse: 8.9930e-05 - val_loss: 1.1988e-04 - val_mae: 0.0072 - val_mse: 1.1988e-04\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2060e-05 - mae: 0.0063 - mse: 9.2060e-05\n",
      "Epoch 306: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.9167e-05 - mae: 0.0062 - mse: 8.9167e-05 - val_loss: 1.2449e-04 - val_mae: 0.0073 - val_mse: 1.2449e-04\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0536e-04 - mae: 0.0068 - mse: 1.0536e-04\n",
      "Epoch 307: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.9628e-05 - mae: 0.0063 - mse: 8.9628e-05 - val_loss: 1.2107e-04 - val_mae: 0.0073 - val_mse: 1.2107e-04\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8705e-05 - mae: 0.0061 - mse: 8.8705e-05\n",
      "Epoch 308: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.8137e-05 - mae: 0.0061 - mse: 8.8137e-05 - val_loss: 1.2339e-04 - val_mae: 0.0073 - val_mse: 1.2339e-04\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6240e-05 - mae: 0.0060 - mse: 8.6240e-05\n",
      "Epoch 309: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.7976e-05 - mae: 0.0061 - mse: 8.7976e-05 - val_loss: 1.2518e-04 - val_mae: 0.0073 - val_mse: 1.2518e-04\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4793e-05 - mae: 0.0062 - mse: 9.4793e-05\n",
      "Epoch 310: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.6922e-05 - mae: 0.0061 - mse: 8.6922e-05 - val_loss: 1.2062e-04 - val_mae: 0.0072 - val_mse: 1.2062e-04\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9464e-05 - mae: 0.0062 - mse: 8.9464e-05\n",
      "Epoch 311: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.8448e-05 - mae: 0.0061 - mse: 8.8448e-05 - val_loss: 1.2009e-04 - val_mae: 0.0071 - val_mse: 1.2009e-04\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2241e-05 - mae: 0.0056 - mse: 7.2241e-05\n",
      "Epoch 312: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.6503e-05 - mae: 0.0060 - mse: 8.6503e-05 - val_loss: 1.2615e-04 - val_mae: 0.0074 - val_mse: 1.2615e-04\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5480e-05 - mae: 0.0060 - mse: 8.5480e-05\n",
      "Epoch 313: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.7689e-05 - mae: 0.0061 - mse: 8.7689e-05 - val_loss: 1.2158e-04 - val_mae: 0.0072 - val_mse: 1.2158e-04\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1406e-05 - mae: 0.0061 - mse: 9.1406e-05\n",
      "Epoch 314: val_loss improved from 0.00012 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 8.5759e-05 - mae: 0.0060 - mse: 8.5759e-05 - val_loss: 1.1889e-04 - val_mae: 0.0071 - val_mse: 1.1889e-04\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 8.8619e-05 - mae: 0.0062 - mse: 8.8619e-05\n",
      "Epoch 315: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 8.5433e-05 - mae: 0.0061 - mse: 8.5433e-05 - val_loss: 1.2145e-04 - val_mae: 0.0072 - val_mse: 1.2145e-04\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.5911e-05 - mae: 0.0062 - mse: 9.5911e-05\n",
      "Epoch 316: val_loss improved from 0.00012 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.5669e-05 - mae: 0.0060 - mse: 8.5669e-05 - val_loss: 1.1803e-04 - val_mae: 0.0071 - val_mse: 1.1803e-04\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7941e-05 - mae: 0.0059 - mse: 7.7941e-05\n",
      "Epoch 317: val_loss improved from 0.00012 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 8.6700e-05 - mae: 0.0060 - mse: 8.6700e-05 - val_loss: 1.1605e-04 - val_mae: 0.0070 - val_mse: 1.1605e-04\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0253e-05 - mae: 0.0058 - mse: 8.0253e-05\n",
      "Epoch 318: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.4716e-05 - mae: 0.0059 - mse: 8.4716e-05 - val_loss: 1.2104e-04 - val_mae: 0.0071 - val_mse: 1.2104e-04\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.1028e-05 - mae: 0.0061 - mse: 9.1028e-05\n",
      "Epoch 319: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.4201e-05 - mae: 0.0060 - mse: 8.4201e-05 - val_loss: 1.1730e-04 - val_mae: 0.0071 - val_mse: 1.1730e-04\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5721e-05 - mae: 0.0061 - mse: 8.5721e-05\n",
      "Epoch 320: val_loss improved from 0.00012 to 0.00012, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.5776e-05 - mae: 0.0060 - mse: 8.5776e-05 - val_loss: 1.1525e-04 - val_mae: 0.0070 - val_mse: 1.1525e-04\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6811e-05 - mae: 0.0057 - mse: 7.6811e-05\n",
      "Epoch 321: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.3331e-05 - mae: 0.0059 - mse: 8.3331e-05 - val_loss: 1.1796e-04 - val_mae: 0.0071 - val_mse: 1.1796e-04\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0573e-04 - mae: 0.0067 - mse: 1.0573e-04\n",
      "Epoch 322: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.3577e-05 - mae: 0.0060 - mse: 8.3577e-05 - val_loss: 1.1531e-04 - val_mae: 0.0070 - val_mse: 1.1531e-04\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8648e-05 - mae: 0.0055 - mse: 6.8648e-05\n",
      "Epoch 323: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.3399e-05 - mae: 0.0059 - mse: 8.3399e-05 - val_loss: 1.1592e-04 - val_mae: 0.0069 - val_mse: 1.1592e-04\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9503e-05 - mae: 0.0059 - mse: 8.9503e-05\n",
      "Epoch 324: val_loss did not improve from 0.00012\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.2156e-05 - mae: 0.0058 - mse: 8.2156e-05 - val_loss: 1.1614e-04 - val_mae: 0.0070 - val_mse: 1.1614e-04\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.5371e-05 - mae: 0.0057 - mse: 7.5371e-05\n",
      "Epoch 325: val_loss improved from 0.00012 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.1019e-05 - mae: 0.0058 - mse: 8.1019e-05 - val_loss: 1.1398e-04 - val_mae: 0.0070 - val_mse: 1.1398e-04\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7596e-05 - mae: 0.0058 - mse: 7.7596e-05\n",
      "Epoch 326: val_loss improved from 0.00011 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 8.2237e-05 - mae: 0.0059 - mse: 8.2237e-05 - val_loss: 1.1360e-04 - val_mae: 0.0069 - val_mse: 1.1360e-04\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4240e-05 - mae: 0.0058 - mse: 8.4240e-05\n",
      "Epoch 327: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.0776e-05 - mae: 0.0058 - mse: 8.0776e-05 - val_loss: 1.1444e-04 - val_mae: 0.0069 - val_mse: 1.1444e-04\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0025e-05 - mae: 0.0058 - mse: 8.0025e-05\n",
      "Epoch 328: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.0080e-05 - mae: 0.0058 - mse: 8.0080e-05 - val_loss: 1.1508e-04 - val_mae: 0.0069 - val_mse: 1.1508e-04\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4946e-05 - mae: 0.0057 - mse: 7.4946e-05\n",
      "Epoch 329: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 8.2532e-05 - mae: 0.0058 - mse: 8.2532e-05 - val_loss: 1.1521e-04 - val_mae: 0.0070 - val_mse: 1.1521e-04\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0426e-05 - mae: 0.0055 - mse: 7.0426e-05\n",
      "Epoch 330: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1648e-05 - mae: 0.0058 - mse: 8.1648e-05 - val_loss: 1.1364e-04 - val_mae: 0.0070 - val_mse: 1.1364e-04\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3663e-05 - mae: 0.0059 - mse: 8.3663e-05\n",
      "Epoch 331: val_loss improved from 0.00011 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 8.1298e-05 - mae: 0.0058 - mse: 8.1298e-05 - val_loss: 1.1124e-04 - val_mae: 0.0069 - val_mse: 1.1124e-04\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1976e-05 - mae: 0.0062 - mse: 9.1976e-05\n",
      "Epoch 332: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.1416e-05 - mae: 0.0059 - mse: 8.1416e-05 - val_loss: 1.1247e-04 - val_mae: 0.0069 - val_mse: 1.1247e-04\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9991e-05 - mae: 0.0056 - mse: 6.9991e-05\n",
      "Epoch 333: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.1221e-05 - mae: 0.0058 - mse: 8.1221e-05 - val_loss: 1.1171e-04 - val_mae: 0.0069 - val_mse: 1.1171e-04\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3981e-05 - mae: 0.0056 - mse: 7.3981e-05\n",
      "Epoch 334: val_loss improved from 0.00011 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.0715e-05 - mae: 0.0058 - mse: 8.0715e-05 - val_loss: 1.0967e-04 - val_mae: 0.0069 - val_mse: 1.0967e-04\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.8483e-05 - mae: 0.0056 - mse: 7.8483e-05\n",
      "Epoch 335: val_loss improved from 0.00011 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 8.0175e-05 - mae: 0.0058 - mse: 8.0175e-05 - val_loss: 1.0721e-04 - val_mae: 0.0068 - val_mse: 1.0721e-04\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9313e-05 - mae: 0.0057 - mse: 7.9313e-05\n",
      "Epoch 336: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.9905e-05 - mae: 0.0058 - mse: 7.9905e-05 - val_loss: 1.0806e-04 - val_mae: 0.0068 - val_mse: 1.0806e-04\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.6735e-05 - mae: 0.0053 - mse: 6.6735e-05\n",
      "Epoch 337: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.8983e-05 - mae: 0.0057 - mse: 7.8983e-05 - val_loss: 1.0862e-04 - val_mae: 0.0068 - val_mse: 1.0862e-04\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7819e-05 - mae: 0.0060 - mse: 8.7819e-05\n",
      "Epoch 338: val_loss improved from 0.00011 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.9897e-05 - mae: 0.0058 - mse: 7.9897e-05 - val_loss: 1.0693e-04 - val_mae: 0.0067 - val_mse: 1.0693e-04\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4528e-05 - mae: 0.0056 - mse: 7.4528e-05\n",
      "Epoch 339: val_loss improved from 0.00011 to 0.00011, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.7325e-05 - mae: 0.0057 - mse: 7.7325e-05 - val_loss: 1.0521e-04 - val_mae: 0.0067 - val_mse: 1.0521e-04\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6189e-05 - mae: 0.0060 - mse: 8.6189e-05\n",
      "Epoch 340: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.8077e-05 - mae: 0.0057 - mse: 7.8077e-05 - val_loss: 1.0753e-04 - val_mae: 0.0068 - val_mse: 1.0753e-04\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0083e-05 - mae: 0.0057 - mse: 8.0083e-05\n",
      "Epoch 341: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.7518e-05 - mae: 0.0057 - mse: 7.7518e-05 - val_loss: 1.1149e-04 - val_mae: 0.0069 - val_mse: 1.1149e-04\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9891e-05 - mae: 0.0057 - mse: 7.9891e-05\n",
      "Epoch 342: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7903e-05 - mae: 0.0057 - mse: 7.7903e-05 - val_loss: 1.0956e-04 - val_mae: 0.0068 - val_mse: 1.0956e-04\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.7696e-05 - mae: 0.0054 - mse: 6.7696e-05\n",
      "Epoch 343: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7640e-05 - mae: 0.0057 - mse: 7.7640e-05 - val_loss: 1.0866e-04 - val_mae: 0.0068 - val_mse: 1.0866e-04\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2176e-05 - mae: 0.0054 - mse: 7.2176e-05\n",
      "Epoch 344: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.8779e-05 - mae: 0.0056 - mse: 7.8779e-05 - val_loss: 1.0891e-04 - val_mae: 0.0067 - val_mse: 1.0891e-04\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5103e-05 - mae: 0.0055 - mse: 7.5103e-05\n",
      "Epoch 345: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.7255e-05 - mae: 0.0057 - mse: 7.7255e-05 - val_loss: 1.0945e-04 - val_mae: 0.0068 - val_mse: 1.0945e-04\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.5154e-05 - mae: 0.0055 - mse: 7.5154e-05\n",
      "Epoch 346: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.8417e-05 - mae: 0.0057 - mse: 7.8417e-05 - val_loss: 1.0594e-04 - val_mae: 0.0068 - val_mse: 1.0594e-04\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3307e-05 - mae: 0.0057 - mse: 8.3307e-05\n",
      "Epoch 347: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.7571e-05 - mae: 0.0057 - mse: 7.7571e-05 - val_loss: 1.0726e-04 - val_mae: 0.0068 - val_mse: 1.0726e-04\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0764e-05 - mae: 0.0054 - mse: 7.0764e-05\n",
      "Epoch 348: val_loss did not improve from 0.00011\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.7002e-05 - mae: 0.0057 - mse: 7.7002e-05 - val_loss: 1.0785e-04 - val_mae: 0.0068 - val_mse: 1.0785e-04\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2928e-05 - mae: 0.0056 - mse: 7.2928e-05\n",
      "Epoch 349: val_loss improved from 0.00011 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 7.6437e-05 - mae: 0.0056 - mse: 7.6437e-05 - val_loss: 1.0315e-04 - val_mae: 0.0066 - val_mse: 1.0315e-04\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4464e-05 - mae: 0.0059 - mse: 8.4464e-05\n",
      "Epoch 350: val_loss improved from 0.00010 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.6211e-05 - mae: 0.0056 - mse: 7.6211e-05 - val_loss: 1.0258e-04 - val_mae: 0.0067 - val_mse: 1.0258e-04\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.8558e-05 - mae: 0.0057 - mse: 7.8558e-05\n",
      "Epoch 351: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.7526e-05 - mae: 0.0057 - mse: 7.7526e-05 - val_loss: 1.0362e-04 - val_mae: 0.0067 - val_mse: 1.0362e-04\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5198e-05 - mae: 0.0057 - mse: 7.5198e-05\n",
      "Epoch 352: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.5869e-05 - mae: 0.0056 - mse: 7.5869e-05 - val_loss: 1.0459e-04 - val_mae: 0.0067 - val_mse: 1.0459e-04\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3325e-05 - mae: 0.0056 - mse: 7.3325e-05\n",
      "Epoch 353: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.5215e-05 - mae: 0.0056 - mse: 7.5215e-05 - val_loss: 1.0727e-04 - val_mae: 0.0067 - val_mse: 1.0727e-04\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5838e-05 - mae: 0.0055 - mse: 7.5838e-05\n",
      "Epoch 354: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.5560e-05 - mae: 0.0055 - mse: 7.5560e-05 - val_loss: 1.0947e-04 - val_mae: 0.0068 - val_mse: 1.0947e-04\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.9972e-05 - mae: 0.0054 - mse: 6.9972e-05\n",
      "Epoch 355: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7172e-05 - mae: 0.0057 - mse: 7.7172e-05 - val_loss: 1.0663e-04 - val_mae: 0.0067 - val_mse: 1.0663e-04\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6008e-05 - mae: 0.0055 - mse: 7.6008e-05\n",
      "Epoch 356: val_loss improved from 0.00010 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.5279e-05 - mae: 0.0055 - mse: 7.5279e-05 - val_loss: 1.0205e-04 - val_mae: 0.0066 - val_mse: 1.0205e-04\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0185e-05 - mae: 0.0058 - mse: 8.0185e-05\n",
      "Epoch 357: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.7727e-05 - mae: 0.0057 - mse: 7.7727e-05 - val_loss: 1.0414e-04 - val_mae: 0.0067 - val_mse: 1.0414e-04\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5238e-05 - mae: 0.0055 - mse: 7.5238e-05\n",
      "Epoch 358: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 7.6410e-05 - mae: 0.0056 - mse: 7.6410e-05 - val_loss: 1.0914e-04 - val_mae: 0.0069 - val_mse: 1.0914e-04\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.3192e-05 - mae: 0.0056 - mse: 7.3192e-05\n",
      "Epoch 359: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.7366e-05 - mae: 0.0057 - mse: 7.7366e-05 - val_loss: 1.0302e-04 - val_mae: 0.0067 - val_mse: 1.0302e-04\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6558e-05 - mae: 0.0058 - mse: 7.6558e-05\n",
      "Epoch 360: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.7786e-05 - mae: 0.0057 - mse: 7.7786e-05 - val_loss: 1.0322e-04 - val_mae: 0.0066 - val_mse: 1.0322e-04\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.4132e-05 - mae: 0.0058 - mse: 8.4132e-05\n",
      "Epoch 361: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.5571e-05 - mae: 0.0056 - mse: 7.5571e-05 - val_loss: 1.0428e-04 - val_mae: 0.0066 - val_mse: 1.0428e-04\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3584e-05 - mae: 0.0058 - mse: 8.3584e-05\n",
      "Epoch 362: val_loss improved from 0.00010 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 7.4357e-05 - mae: 0.0055 - mse: 7.4357e-05 - val_loss: 1.0150e-04 - val_mae: 0.0066 - val_mse: 1.0150e-04\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1439e-05 - mae: 0.0057 - mse: 8.1439e-05\n",
      "Epoch 363: val_loss improved from 0.00010 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.5647e-05 - mae: 0.0056 - mse: 7.5647e-05 - val_loss: 1.0074e-04 - val_mae: 0.0066 - val_mse: 1.0074e-04\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8057e-05 - mae: 0.0050 - mse: 5.8057e-05\n",
      "Epoch 364: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.4516e-05 - mae: 0.0055 - mse: 7.4516e-05 - val_loss: 1.0385e-04 - val_mae: 0.0067 - val_mse: 1.0385e-04\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0013e-05 - mae: 0.0055 - mse: 7.0013e-05\n",
      "Epoch 365: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 7.4478e-05 - mae: 0.0056 - mse: 7.4478e-05 - val_loss: 1.0413e-04 - val_mae: 0.0067 - val_mse: 1.0413e-04\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.2022e-05 - mae: 0.0057 - mse: 8.2022e-05\n",
      "Epoch 366: val_loss improved from 0.00010 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.4658e-05 - mae: 0.0056 - mse: 7.4658e-05 - val_loss: 9.8397e-05 - val_mae: 0.0065 - val_mse: 9.8397e-05\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4865e-05 - mae: 0.0054 - mse: 7.4865e-05\n",
      "Epoch 367: val_loss improved from 0.00010 to 0.00010, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.3335e-05 - mae: 0.0055 - mse: 7.3335e-05 - val_loss: 9.7931e-05 - val_mae: 0.0065 - val_mse: 9.7931e-05\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3850e-05 - mae: 0.0055 - mse: 7.3850e-05\n",
      "Epoch 368: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.4682e-05 - mae: 0.0055 - mse: 7.4682e-05 - val_loss: 9.9246e-05 - val_mae: 0.0065 - val_mse: 9.9246e-05\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7529e-05 - mae: 0.0056 - mse: 7.7529e-05\n",
      "Epoch 369: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.3964e-05 - mae: 0.0055 - mse: 7.3964e-05 - val_loss: 9.8011e-05 - val_mae: 0.0064 - val_mse: 9.8011e-05\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5447e-05 - mae: 0.0055 - mse: 7.5447e-05\n",
      "Epoch 370: val_loss did not improve from 0.00010\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.4962e-05 - mae: 0.0055 - mse: 7.4962e-05 - val_loss: 9.8842e-05 - val_mae: 0.0065 - val_mse: 9.8842e-05\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.7171e-05 - mae: 0.0056 - mse: 7.7171e-05\n",
      "Epoch 371: val_loss improved from 0.00010 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.4079e-05 - mae: 0.0055 - mse: 7.4079e-05 - val_loss: 9.4988e-05 - val_mae: 0.0064 - val_mse: 9.4988e-05\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3097e-05 - mae: 0.0055 - mse: 7.3097e-05\n",
      "Epoch 372: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.2235e-05 - mae: 0.0054 - mse: 7.2235e-05 - val_loss: 9.8992e-05 - val_mae: 0.0065 - val_mse: 9.8992e-05\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.9524e-05 - mae: 0.0053 - mse: 6.9524e-05\n",
      "Epoch 373: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.5620e-05 - mae: 0.0056 - mse: 7.5620e-05 - val_loss: 9.7039e-05 - val_mae: 0.0064 - val_mse: 9.7039e-05\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6782e-05 - mae: 0.0054 - mse: 7.6782e-05\n",
      "Epoch 374: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2996e-05 - mae: 0.0054 - mse: 7.2996e-05 - val_loss: 9.5686e-05 - val_mae: 0.0064 - val_mse: 9.5686e-05\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4850e-05 - mae: 0.0056 - mse: 7.4850e-05\n",
      "Epoch 375: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.3992e-05 - mae: 0.0055 - mse: 7.3992e-05 - val_loss: 1.0139e-04 - val_mae: 0.0066 - val_mse: 1.0139e-04\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7398e-05 - mae: 0.0054 - mse: 6.7398e-05\n",
      "Epoch 376: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.3255e-05 - mae: 0.0055 - mse: 7.3255e-05 - val_loss: 9.7827e-05 - val_mae: 0.0064 - val_mse: 9.7827e-05\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2975e-05 - mae: 0.0054 - mse: 7.2975e-05\n",
      "Epoch 377: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.1886e-05 - mae: 0.0054 - mse: 7.1886e-05 - val_loss: 9.9108e-05 - val_mae: 0.0065 - val_mse: 9.9108e-05\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1961e-05 - mae: 0.0051 - mse: 6.1961e-05\n",
      "Epoch 378: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.1995e-05 - mae: 0.0053 - mse: 7.1995e-05 - val_loss: 1.0215e-04 - val_mae: 0.0066 - val_mse: 1.0215e-04\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2433e-05 - mae: 0.0055 - mse: 7.2433e-05\n",
      "Epoch 379: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.3024e-05 - mae: 0.0055 - mse: 7.3024e-05 - val_loss: 9.6178e-05 - val_mae: 0.0064 - val_mse: 9.6178e-05\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.0350e-05 - mae: 0.0056 - mse: 8.0350e-05\n",
      "Epoch 380: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 7.2742e-05 - mae: 0.0054 - mse: 7.2742e-05 - val_loss: 9.5968e-05 - val_mae: 0.0063 - val_mse: 9.5968e-05\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7198e-05 - mae: 0.0054 - mse: 7.7198e-05\n",
      "Epoch 381: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.1000e-05 - mae: 0.0053 - mse: 7.1000e-05 - val_loss: 9.7146e-05 - val_mae: 0.0064 - val_mse: 9.7146e-05\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9451e-05 - mae: 0.0053 - mse: 6.9451e-05\n",
      "Epoch 382: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0462e-05 - mae: 0.0053 - mse: 7.0462e-05 - val_loss: 9.8323e-05 - val_mae: 0.0064 - val_mse: 9.8323e-05\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6432e-05 - mae: 0.0055 - mse: 7.6432e-05\n",
      "Epoch 383: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0915e-05 - mae: 0.0053 - mse: 7.0915e-05 - val_loss: 9.8509e-05 - val_mae: 0.0064 - val_mse: 9.8509e-05\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3393e-05 - mae: 0.0050 - mse: 6.3393e-05\n",
      "Epoch 384: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.1905e-05 - mae: 0.0053 - mse: 7.1905e-05 - val_loss: 9.8911e-05 - val_mae: 0.0064 - val_mse: 9.8911e-05\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6869e-05 - mae: 0.0054 - mse: 7.6869e-05\n",
      "Epoch 385: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0888e-05 - mae: 0.0053 - mse: 7.0888e-05 - val_loss: 9.8971e-05 - val_mae: 0.0064 - val_mse: 9.8971e-05\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5280e-05 - mae: 0.0050 - mse: 6.5280e-05\n",
      "Epoch 386: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0318e-05 - mae: 0.0053 - mse: 7.0318e-05 - val_loss: 9.9564e-05 - val_mae: 0.0064 - val_mse: 9.9564e-05\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2680e-05 - mae: 0.0054 - mse: 7.2680e-05\n",
      "Epoch 387: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 7.0987e-05 - mae: 0.0053 - mse: 7.0987e-05 - val_loss: 9.7661e-05 - val_mae: 0.0064 - val_mse: 9.7661e-05\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3191e-05 - mae: 0.0050 - mse: 6.3191e-05\n",
      "Epoch 388: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0770e-05 - mae: 0.0053 - mse: 7.0770e-05 - val_loss: 9.9633e-05 - val_mae: 0.0065 - val_mse: 9.9633e-05\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5033e-05 - mae: 0.0054 - mse: 7.5033e-05\n",
      "Epoch 389: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.1168e-05 - mae: 0.0053 - mse: 7.1168e-05 - val_loss: 9.8567e-05 - val_mae: 0.0065 - val_mse: 9.8567e-05\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5885e-05 - mae: 0.0052 - mse: 6.5885e-05\n",
      "Epoch 390: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.0235e-05 - mae: 0.0054 - mse: 7.0235e-05 - val_loss: 9.5369e-05 - val_mae: 0.0064 - val_mse: 9.5369e-05\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3761e-05 - mae: 0.0053 - mse: 7.3761e-05\n",
      "Epoch 391: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.0362e-05 - mae: 0.0053 - mse: 7.0362e-05 - val_loss: 9.7895e-05 - val_mae: 0.0064 - val_mse: 9.7895e-05\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8129e-05 - mae: 0.0053 - mse: 6.8129e-05\n",
      "Epoch 392: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1367e-05 - mae: 0.0054 - mse: 7.1367e-05 - val_loss: 9.9729e-05 - val_mae: 0.0064 - val_mse: 9.9729e-05\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1926e-05 - mae: 0.0053 - mse: 7.1926e-05\n",
      "Epoch 393: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7.0703e-05 - mae: 0.0053 - mse: 7.0703e-05 - val_loss: 9.8068e-05 - val_mae: 0.0064 - val_mse: 9.8068e-05\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4147e-05 - mae: 0.0051 - mse: 6.4147e-05\n",
      "Epoch 394: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 7.0415e-05 - mae: 0.0053 - mse: 7.0415e-05 - val_loss: 9.5189e-05 - val_mae: 0.0063 - val_mse: 9.5189e-05\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5484e-05 - mae: 0.0051 - mse: 6.5484e-05\n",
      "Epoch 395: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.8175e-05 - mae: 0.0052 - mse: 6.8175e-05 - val_loss: 9.8811e-05 - val_mae: 0.0064 - val_mse: 9.8811e-05\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1981e-05 - mae: 0.0051 - mse: 6.1981e-05\n",
      "Epoch 396: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.8730e-05 - mae: 0.0053 - mse: 6.8730e-05 - val_loss: 9.3938e-05 - val_mae: 0.0062 - val_mse: 9.3938e-05\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.8105e-05 - mae: 0.0052 - mse: 6.8105e-05\n",
      "Epoch 397: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.8763e-05 - mae: 0.0052 - mse: 6.8763e-05 - val_loss: 9.4134e-05 - val_mae: 0.0062 - val_mse: 9.4134e-05\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9299e-05 - mae: 0.0052 - mse: 6.9299e-05\n",
      "Epoch 398: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.7380e-05 - mae: 0.0051 - mse: 6.7380e-05 - val_loss: 9.6693e-05 - val_mae: 0.0063 - val_mse: 9.6693e-05\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7158e-05 - mae: 0.0051 - mse: 6.7158e-05\n",
      "Epoch 399: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.8750e-05 - mae: 0.0052 - mse: 6.8750e-05 - val_loss: 9.5311e-05 - val_mae: 0.0062 - val_mse: 9.5311e-05\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7119e-05 - mae: 0.0051 - mse: 6.7119e-05\n",
      "Epoch 400: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.6463e-05 - mae: 0.0051 - mse: 6.6463e-05 - val_loss: 9.6992e-05 - val_mae: 0.0063 - val_mse: 9.6992e-05\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4633e-05 - mae: 0.0048 - mse: 5.4633e-05\n",
      "Epoch 401: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.8125e-05 - mae: 0.0052 - mse: 6.8125e-05 - val_loss: 9.3766e-05 - val_mae: 0.0061 - val_mse: 9.3766e-05\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5209e-05 - mae: 0.0050 - mse: 6.5209e-05\n",
      "Epoch 402: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.6445e-05 - mae: 0.0051 - mse: 6.6445e-05 - val_loss: 9.8188e-05 - val_mae: 0.0063 - val_mse: 9.8188e-05\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0985e-05 - mae: 0.0051 - mse: 6.0985e-05\n",
      "Epoch 403: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6.7987e-05 - mae: 0.0052 - mse: 6.7987e-05 - val_loss: 9.5763e-05 - val_mae: 0.0064 - val_mse: 9.5763e-05\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 6.5710e-05 - mae: 0.0052 - mse: 6.5710e-05\n",
      "Epoch 404: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.9012e-05 - mae: 0.0053 - mse: 6.9012e-05 - val_loss: 1.0023e-04 - val_mae: 0.0065 - val_mse: 1.0023e-04\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1304e-05 - mae: 0.0053 - mse: 7.1304e-05\n",
      "Epoch 405: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.0785e-05 - mae: 0.0053 - mse: 7.0785e-05 - val_loss: 9.7711e-05 - val_mae: 0.0064 - val_mse: 9.7711e-05\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4703e-05 - mae: 0.0051 - mse: 6.4703e-05\n",
      "Epoch 406: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.0151e-05 - mae: 0.0053 - mse: 7.0151e-05 - val_loss: 9.4234e-05 - val_mae: 0.0064 - val_mse: 9.4234e-05\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7635e-05 - mae: 0.0054 - mse: 6.7635e-05\n",
      "Epoch 407: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.8692e-05 - mae: 0.0053 - mse: 6.8692e-05 - val_loss: 1.0222e-04 - val_mae: 0.0066 - val_mse: 1.0222e-04\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1837e-05 - mae: 0.0051 - mse: 6.1837e-05\n",
      "Epoch 408: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.9921e-05 - mae: 0.0053 - mse: 6.9921e-05 - val_loss: 9.5745e-05 - val_mae: 0.0064 - val_mse: 9.5745e-05\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7012e-05 - mae: 0.0052 - mse: 6.7012e-05\n",
      "Epoch 409: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.0075e-05 - mae: 0.0053 - mse: 7.0075e-05 - val_loss: 8.9721e-05 - val_mae: 0.0061 - val_mse: 8.9721e-05\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0260e-05 - mae: 0.0050 - mse: 6.0260e-05\n",
      "Epoch 410: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7936e-05 - mae: 0.0052 - mse: 6.7936e-05 - val_loss: 9.7865e-05 - val_mae: 0.0064 - val_mse: 9.7865e-05\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1805e-05 - mae: 0.0052 - mse: 7.1805e-05\n",
      "Epoch 411: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9517e-05 - mae: 0.0052 - mse: 6.9517e-05 - val_loss: 9.3837e-05 - val_mae: 0.0064 - val_mse: 9.3837e-05\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4552e-05 - mae: 0.0054 - mse: 7.4552e-05\n",
      "Epoch 412: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.9310e-05 - mae: 0.0053 - mse: 6.9310e-05 - val_loss: 9.3888e-05 - val_mae: 0.0064 - val_mse: 9.3888e-05\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3243e-05 - mae: 0.0051 - mse: 6.3243e-05\n",
      "Epoch 413: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.8294e-05 - mae: 0.0052 - mse: 6.8294e-05 - val_loss: 9.5459e-05 - val_mae: 0.0063 - val_mse: 9.5459e-05\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2121e-05 - mae: 0.0054 - mse: 7.2121e-05\n",
      "Epoch 414: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8874e-05 - mae: 0.0053 - mse: 6.8874e-05 - val_loss: 9.0325e-05 - val_mae: 0.0062 - val_mse: 9.0325e-05\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3808e-05 - mae: 0.0051 - mse: 6.3808e-05\n",
      "Epoch 415: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.7999e-05 - mae: 0.0052 - mse: 6.7999e-05 - val_loss: 9.3761e-05 - val_mae: 0.0063 - val_mse: 9.3761e-05\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4378e-05 - mae: 0.0051 - mse: 6.4378e-05\n",
      "Epoch 416: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.6909e-05 - mae: 0.0052 - mse: 6.6909e-05 - val_loss: 9.1488e-05 - val_mae: 0.0062 - val_mse: 9.1488e-05\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0770e-05 - mae: 0.0048 - mse: 6.0770e-05\n",
      "Epoch 417: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5259e-05 - mae: 0.0051 - mse: 6.5259e-05 - val_loss: 9.0515e-05 - val_mae: 0.0062 - val_mse: 9.0515e-05\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3899e-05 - mae: 0.0051 - mse: 6.3899e-05\n",
      "Epoch 418: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.6808e-05 - mae: 0.0052 - mse: 6.6808e-05 - val_loss: 9.6078e-05 - val_mae: 0.0064 - val_mse: 9.6078e-05\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2401e-05 - mae: 0.0053 - mse: 7.2401e-05\n",
      "Epoch 419: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.6341e-05 - mae: 0.0052 - mse: 6.6341e-05 - val_loss: 8.9718e-05 - val_mae: 0.0061 - val_mse: 8.9718e-05\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.5470e-05 - mae: 0.0050 - mse: 6.5470e-05\n",
      "Epoch 420: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 6.4902e-05 - mae: 0.0050 - mse: 6.4902e-05 - val_loss: 8.9821e-05 - val_mae: 0.0061 - val_mse: 8.9821e-05\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6810e-05 - mae: 0.0050 - mse: 6.6810e-05\n",
      "Epoch 421: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.4000e-05 - mae: 0.0049 - mse: 6.4000e-05 - val_loss: 9.4980e-05 - val_mae: 0.0062 - val_mse: 9.4980e-05\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9348e-05 - mae: 0.0051 - mse: 6.9348e-05\n",
      "Epoch 422: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5305e-05 - mae: 0.0050 - mse: 6.5305e-05 - val_loss: 9.1103e-05 - val_mae: 0.0062 - val_mse: 9.1103e-05\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3846e-05 - mae: 0.0043 - mse: 4.3846e-05\n",
      "Epoch 423: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.5082e-05 - mae: 0.0050 - mse: 6.5082e-05 - val_loss: 8.8334e-05 - val_mae: 0.0061 - val_mse: 8.8334e-05\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9123e-05 - mae: 0.0048 - mse: 5.9123e-05\n",
      "Epoch 424: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3273e-05 - mae: 0.0049 - mse: 6.3273e-05 - val_loss: 8.8671e-05 - val_mae: 0.0061 - val_mse: 8.8671e-05\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5636e-05 - mae: 0.0047 - mse: 5.5636e-05\n",
      "Epoch 425: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.3573e-05 - mae: 0.0050 - mse: 6.3573e-05 - val_loss: 8.8930e-05 - val_mae: 0.0061 - val_mse: 8.8930e-05\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1936e-05 - mae: 0.0052 - mse: 7.1936e-05\n",
      "Epoch 426: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 6.3814e-05 - mae: 0.0050 - mse: 6.3814e-05 - val_loss: 8.6295e-05 - val_mae: 0.0060 - val_mse: 8.6295e-05\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.5988e-05 - mae: 0.0049 - mse: 6.5988e-05\n",
      "Epoch 427: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.3190e-05 - mae: 0.0049 - mse: 6.3190e-05 - val_loss: 8.5902e-05 - val_mae: 0.0060 - val_mse: 8.5902e-05\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3728e-05 - mae: 0.0050 - mse: 6.3728e-05\n",
      "Epoch 428: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4974e-05 - mae: 0.0050 - mse: 6.4974e-05 - val_loss: 8.8739e-05 - val_mae: 0.0061 - val_mse: 8.8739e-05\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2440e-05 - mae: 0.0046 - mse: 5.2440e-05\n",
      "Epoch 429: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.4436e-05 - mae: 0.0050 - mse: 6.4436e-05 - val_loss: 9.0152e-05 - val_mae: 0.0061 - val_mse: 9.0152e-05\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4288e-05 - mae: 0.0049 - mse: 6.4288e-05\n",
      "Epoch 430: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5026e-05 - mae: 0.0050 - mse: 6.5026e-05 - val_loss: 8.7518e-05 - val_mae: 0.0060 - val_mse: 8.7518e-05\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1750e-05 - mae: 0.0045 - mse: 5.1750e-05\n",
      "Epoch 431: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3371e-05 - mae: 0.0049 - mse: 6.3371e-05 - val_loss: 8.8080e-05 - val_mae: 0.0061 - val_mse: 8.8080e-05\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5807e-05 - mae: 0.0050 - mse: 6.5807e-05\n",
      "Epoch 432: val_loss improved from 0.00009 to 0.00009, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.4655e-05 - mae: 0.0050 - mse: 6.4655e-05 - val_loss: 8.5514e-05 - val_mae: 0.0059 - val_mse: 8.5514e-05\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3439e-05 - mae: 0.0049 - mse: 6.3439e-05\n",
      "Epoch 433: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3347e-05 - mae: 0.0049 - mse: 6.3347e-05 - val_loss: 8.7123e-05 - val_mae: 0.0061 - val_mse: 8.7123e-05\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6434e-05 - mae: 0.0049 - mse: 6.6434e-05\n",
      "Epoch 434: val_loss did not improve from 0.00009\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.2607e-05 - mae: 0.0049 - mse: 6.2607e-05 - val_loss: 8.7093e-05 - val_mae: 0.0061 - val_mse: 8.7093e-05\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6094e-05 - mae: 0.0047 - mse: 5.6094e-05\n",
      "Epoch 435: val_loss improved from 0.00009 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.3651e-05 - mae: 0.0050 - mse: 6.3651e-05 - val_loss: 8.2379e-05 - val_mae: 0.0059 - val_mse: 8.2379e-05\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9950e-05 - mae: 0.0048 - mse: 5.9950e-05\n",
      "Epoch 436: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2709e-05 - mae: 0.0049 - mse: 6.2709e-05 - val_loss: 8.2499e-05 - val_mae: 0.0058 - val_mse: 8.2499e-05\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5975e-05 - mae: 0.0046 - mse: 5.5975e-05\n",
      "Epoch 437: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1957e-05 - mae: 0.0049 - mse: 6.1957e-05 - val_loss: 8.4742e-05 - val_mae: 0.0060 - val_mse: 8.4742e-05\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6960e-05 - mae: 0.0050 - mse: 6.6960e-05\n",
      "Epoch 438: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.2323e-05 - mae: 0.0049 - mse: 6.2323e-05 - val_loss: 8.2889e-05 - val_mae: 0.0059 - val_mse: 8.2889e-05\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.2324e-05 - mae: 0.0049 - mse: 6.2324e-05\n",
      "Epoch 439: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 6.1557e-05 - mae: 0.0049 - mse: 6.1557e-05 - val_loss: 8.4650e-05 - val_mae: 0.0059 - val_mse: 8.4650e-05\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8764e-05 - mae: 0.0045 - mse: 4.8764e-05\n",
      "Epoch 440: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 6.1134e-05 - mae: 0.0048 - mse: 6.1134e-05 - val_loss: 8.5616e-05 - val_mae: 0.0059 - val_mse: 8.5616e-05\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0816e-05 - mae: 0.0045 - mse: 5.0816e-05\n",
      "Epoch 441: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1476e-05 - mae: 0.0048 - mse: 6.1476e-05 - val_loss: 8.4264e-05 - val_mae: 0.0059 - val_mse: 8.4264e-05\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6199e-05 - mae: 0.0046 - mse: 5.6199e-05\n",
      "Epoch 442: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.2299e-05 - mae: 0.0048 - mse: 6.2299e-05 - val_loss: 8.6022e-05 - val_mae: 0.0060 - val_mse: 8.6022e-05\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1261e-05 - mae: 0.0048 - mse: 6.1261e-05\n",
      "Epoch 443: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2696e-05 - mae: 0.0049 - mse: 6.2696e-05 - val_loss: 8.6416e-05 - val_mae: 0.0059 - val_mse: 8.6416e-05\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.3247e-05 - mae: 0.0048 - mse: 6.3247e-05\n",
      "Epoch 444: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3587e-05 - mae: 0.0050 - mse: 6.3587e-05 - val_loss: 8.7099e-05 - val_mae: 0.0059 - val_mse: 8.7099e-05\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1292e-05 - mae: 0.0048 - mse: 6.1292e-05\n",
      "Epoch 445: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1222e-05 - mae: 0.0048 - mse: 6.1222e-05 - val_loss: 8.8074e-05 - val_mae: 0.0060 - val_mse: 8.8074e-05\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.2721e-05 - mae: 0.0049 - mse: 6.2721e-05\n",
      "Epoch 446: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 6.3662e-05 - mae: 0.0050 - mse: 6.3662e-05 - val_loss: 9.4296e-05 - val_mae: 0.0063 - val_mse: 9.4296e-05\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.9600e-05 - mae: 0.0052 - mse: 6.9600e-05\n",
      "Epoch 447: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.3899e-05 - mae: 0.0049 - mse: 6.3899e-05 - val_loss: 8.9486e-05 - val_mae: 0.0062 - val_mse: 8.9486e-05\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1811e-05 - mae: 0.0051 - mse: 7.1811e-05\n",
      "Epoch 448: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.4542e-05 - mae: 0.0050 - mse: 6.4542e-05 - val_loss: 9.0960e-05 - val_mae: 0.0061 - val_mse: 9.0960e-05\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0689e-05 - mae: 0.0049 - mse: 6.0689e-05\n",
      "Epoch 449: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2770e-05 - mae: 0.0049 - mse: 6.2770e-05 - val_loss: 8.7861e-05 - val_mae: 0.0060 - val_mse: 8.7861e-05\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3666e-05 - mae: 0.0043 - mse: 4.3666e-05\n",
      "Epoch 450: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0924e-05 - mae: 0.0048 - mse: 6.0924e-05 - val_loss: 8.5902e-05 - val_mae: 0.0060 - val_mse: 8.5902e-05\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5474e-05 - mae: 0.0050 - mse: 6.5474e-05\n",
      "Epoch 451: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.3533e-05 - mae: 0.0050 - mse: 6.3533e-05 - val_loss: 8.6245e-05 - val_mae: 0.0060 - val_mse: 8.6245e-05\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3662e-05 - mae: 0.0050 - mse: 6.3662e-05\n",
      "Epoch 452: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.1034e-05 - mae: 0.0049 - mse: 6.1034e-05 - val_loss: 8.6318e-05 - val_mae: 0.0060 - val_mse: 8.6318e-05\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.9274e-05 - mae: 0.0049 - mse: 5.9274e-05\n",
      "Epoch 453: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.1890e-05 - mae: 0.0049 - mse: 6.1890e-05 - val_loss: 8.5299e-05 - val_mae: 0.0060 - val_mse: 8.5299e-05\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6620e-05 - mae: 0.0048 - mse: 5.6620e-05\n",
      "Epoch 454: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1887e-05 - mae: 0.0049 - mse: 6.1887e-05 - val_loss: 8.3357e-05 - val_mae: 0.0058 - val_mse: 8.3357e-05\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4482e-05 - mae: 0.0046 - mse: 5.4482e-05\n",
      "Epoch 455: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.9948e-05 - mae: 0.0048 - mse: 5.9948e-05 - val_loss: 8.4271e-05 - val_mae: 0.0059 - val_mse: 8.4271e-05\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3179e-05 - mae: 0.0046 - mse: 5.3179e-05\n",
      "Epoch 456: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.9696e-05 - mae: 0.0047 - mse: 5.9696e-05 - val_loss: 8.2968e-05 - val_mae: 0.0058 - val_mse: 8.2968e-05\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6226e-05 - mae: 0.0046 - mse: 5.6226e-05\n",
      "Epoch 457: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.0977e-05 - mae: 0.0047 - mse: 6.0977e-05 - val_loss: 8.2391e-05 - val_mae: 0.0059 - val_mse: 8.2391e-05\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8369e-05 - mae: 0.0047 - mse: 5.8369e-05\n",
      "Epoch 458: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.0618e-05 - mae: 0.0048 - mse: 6.0618e-05 - val_loss: 8.0958e-05 - val_mae: 0.0058 - val_mse: 8.0958e-05\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.7332e-05 - mae: 0.0043 - mse: 4.7332e-05\n",
      "Epoch 459: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.0301e-05 - mae: 0.0047 - mse: 6.0301e-05 - val_loss: 8.2069e-05 - val_mae: 0.0059 - val_mse: 8.2069e-05\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.1128e-05 - mae: 0.0049 - mse: 6.1128e-05\n",
      "Epoch 460: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.0160e-05 - mae: 0.0048 - mse: 6.0160e-05 - val_loss: 8.5923e-05 - val_mae: 0.0060 - val_mse: 8.5923e-05\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.6476e-05 - mae: 0.0046 - mse: 5.6476e-05\n",
      "Epoch 461: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.1843e-05 - mae: 0.0048 - mse: 6.1843e-05 - val_loss: 8.3411e-05 - val_mae: 0.0059 - val_mse: 8.3411e-05\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9640e-05 - mae: 0.0052 - mse: 6.9640e-05\n",
      "Epoch 462: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1518e-05 - mae: 0.0049 - mse: 6.1518e-05 - val_loss: 8.3290e-05 - val_mae: 0.0059 - val_mse: 8.3290e-05\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0655e-05 - mae: 0.0051 - mse: 7.0655e-05\n",
      "Epoch 463: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1935e-05 - mae: 0.0049 - mse: 6.1935e-05 - val_loss: 8.1702e-05 - val_mae: 0.0058 - val_mse: 8.1702e-05\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2361e-05 - mae: 0.0049 - mse: 6.2361e-05\n",
      "Epoch 464: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.0030e-05 - mae: 0.0048 - mse: 6.0030e-05 - val_loss: 8.2206e-05 - val_mae: 0.0059 - val_mse: 8.2206e-05\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9072e-05 - mae: 0.0048 - mse: 5.9072e-05\n",
      "Epoch 465: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.1365e-05 - mae: 0.0049 - mse: 6.1365e-05 - val_loss: 8.3142e-05 - val_mae: 0.0058 - val_mse: 8.3142e-05\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7456e-05 - mae: 0.0049 - mse: 6.7456e-05\n",
      "Epoch 466: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0434e-05 - mae: 0.0048 - mse: 6.0434e-05 - val_loss: 8.1223e-05 - val_mae: 0.0057 - val_mse: 8.1223e-05\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4404e-05 - mae: 0.0048 - mse: 6.4404e-05\n",
      "Epoch 467: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0513e-05 - mae: 0.0048 - mse: 6.0513e-05 - val_loss: 8.1935e-05 - val_mae: 0.0058 - val_mse: 8.1935e-05\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6461e-05 - mae: 0.0050 - mse: 6.6461e-05\n",
      "Epoch 468: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0265e-05 - mae: 0.0048 - mse: 6.0265e-05 - val_loss: 8.1333e-05 - val_mae: 0.0058 - val_mse: 8.1333e-05\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8916e-05 - mae: 0.0047 - mse: 5.8916e-05\n",
      "Epoch 469: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9472e-05 - mae: 0.0047 - mse: 5.9472e-05 - val_loss: 7.9859e-05 - val_mae: 0.0058 - val_mse: 7.9859e-05\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8157e-05 - mae: 0.0044 - mse: 4.8157e-05\n",
      "Epoch 470: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.0348e-05 - mae: 0.0047 - mse: 6.0348e-05 - val_loss: 8.1814e-05 - val_mae: 0.0058 - val_mse: 8.1814e-05\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3889e-05 - mae: 0.0047 - mse: 6.3889e-05\n",
      "Epoch 471: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.9091e-05 - mae: 0.0047 - mse: 5.9091e-05 - val_loss: 8.1319e-05 - val_mae: 0.0057 - val_mse: 8.1319e-05\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1913e-05 - mae: 0.0045 - mse: 5.1913e-05\n",
      "Epoch 472: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.8496e-05 - mae: 0.0047 - mse: 5.8496e-05 - val_loss: 8.0912e-05 - val_mae: 0.0057 - val_mse: 8.0912e-05\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0709e-05 - mae: 0.0044 - mse: 5.0709e-05\n",
      "Epoch 473: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.8743e-05 - mae: 0.0047 - mse: 5.8743e-05 - val_loss: 7.9816e-05 - val_mae: 0.0057 - val_mse: 7.9816e-05\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1864e-05 - mae: 0.0047 - mse: 6.1864e-05\n",
      "Epoch 474: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7635e-05 - mae: 0.0046 - mse: 5.7635e-05 - val_loss: 7.9911e-05 - val_mae: 0.0057 - val_mse: 7.9911e-05\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3288e-05 - mae: 0.0049 - mse: 6.3288e-05\n",
      "Epoch 475: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8580e-05 - mae: 0.0047 - mse: 5.8580e-05 - val_loss: 8.2802e-05 - val_mae: 0.0059 - val_mse: 8.2802e-05\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0823e-05 - mae: 0.0047 - mse: 6.0823e-05\n",
      "Epoch 476: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8877e-05 - mae: 0.0047 - mse: 5.8877e-05 - val_loss: 7.9931e-05 - val_mae: 0.0058 - val_mse: 7.9931e-05\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7489e-05 - mae: 0.0050 - mse: 6.7489e-05\n",
      "Epoch 477: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.0070e-05 - mae: 0.0047 - mse: 6.0070e-05 - val_loss: 8.2926e-05 - val_mae: 0.0058 - val_mse: 8.2926e-05\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4398e-05 - mae: 0.0048 - mse: 6.4398e-05\n",
      "Epoch 478: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.4600e-05 - mae: 0.0050 - mse: 6.4600e-05 - val_loss: 8.3190e-05 - val_mae: 0.0058 - val_mse: 8.3190e-05\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5316e-05 - mae: 0.0050 - mse: 6.5316e-05\n",
      "Epoch 479: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.4665e-05 - mae: 0.0050 - mse: 6.4665e-05 - val_loss: 8.1506e-05 - val_mae: 0.0058 - val_mse: 8.1506e-05\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2517e-05 - mae: 0.0049 - mse: 6.2517e-05\n",
      "Epoch 480: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.2180e-05 - mae: 0.0049 - mse: 6.2180e-05 - val_loss: 1.1388e-04 - val_mae: 0.0069 - val_mse: 1.1388e-04\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.9446e-05 - mae: 0.0055 - mse: 7.9446e-05\n",
      "Epoch 481: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.2105e-05 - mae: 0.0053 - mse: 7.2105e-05 - val_loss: 9.7502e-05 - val_mae: 0.0065 - val_mse: 9.7502e-05\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.0055e-05 - mae: 0.0056 - mse: 8.0055e-05\n",
      "Epoch 482: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1347e-05 - mae: 0.0057 - mse: 8.1347e-05 - val_loss: 1.1313e-04 - val_mae: 0.0071 - val_mse: 1.1313e-04\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5276e-05 - mae: 0.0060 - mse: 8.5276e-05\n",
      "Epoch 483: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 9.3414e-05 - mae: 0.0062 - mse: 9.3414e-05 - val_loss: 9.5845e-05 - val_mae: 0.0065 - val_mse: 9.5845e-05\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3365e-05 - mae: 0.0056 - mse: 7.3365e-05\n",
      "Epoch 484: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.6928e-05 - mae: 0.0060 - mse: 8.6928e-05 - val_loss: 9.1799e-05 - val_mae: 0.0064 - val_mse: 9.1799e-05\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8779e-05 - mae: 0.0053 - mse: 6.8779e-05\n",
      "Epoch 485: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.5418e-05 - mae: 0.0057 - mse: 7.5418e-05 - val_loss: 1.1595e-04 - val_mae: 0.0070 - val_mse: 1.1595e-04\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1882e-05 - mae: 0.0058 - mse: 8.1882e-05\n",
      "Epoch 486: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.1333e-05 - mae: 0.0058 - mse: 8.1333e-05 - val_loss: 1.0951e-04 - val_mae: 0.0072 - val_mse: 1.0951e-04\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0863e-04 - mae: 0.0069 - mse: 1.0863e-04\n",
      "Epoch 487: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 9.2227e-05 - mae: 0.0064 - mse: 9.2227e-05 - val_loss: 1.3597e-04 - val_mae: 0.0081 - val_mse: 1.3597e-04\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5195e-05 - mae: 0.0066 - mse: 9.5195e-05\n",
      "Epoch 488: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 8.9068e-05 - mae: 0.0063 - mse: 8.9068e-05 - val_loss: 1.0557e-04 - val_mae: 0.0071 - val_mse: 1.0557e-04\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2021e-05 - mae: 0.0062 - mse: 8.2021e-05\n",
      "Epoch 489: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 8.9493e-05 - mae: 0.0065 - mse: 8.9493e-05 - val_loss: 9.1668e-05 - val_mae: 0.0063 - val_mse: 9.1668e-05\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2065e-05 - mae: 0.0053 - mse: 7.2065e-05\n",
      "Epoch 490: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.7636e-05 - mae: 0.0061 - mse: 8.7636e-05 - val_loss: 9.0326e-05 - val_mae: 0.0062 - val_mse: 9.0326e-05\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1838e-05 - mae: 0.0053 - mse: 7.1838e-05\n",
      "Epoch 491: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.9751e-05 - mae: 0.0056 - mse: 7.9751e-05 - val_loss: 9.7646e-05 - val_mae: 0.0065 - val_mse: 9.7646e-05\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.3355e-05 - mae: 0.0059 - mse: 8.3355e-05\n",
      "Epoch 492: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.8959e-05 - mae: 0.0057 - mse: 7.8959e-05 - val_loss: 2.0369e-04 - val_mae: 0.0092 - val_mse: 2.0369e-04\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3646e-04 - mae: 0.0073 - mse: 1.3646e-04\n",
      "Epoch 493: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1849e-04 - mae: 0.0068 - mse: 1.1849e-04 - val_loss: 1.6341e-04 - val_mae: 0.0087 - val_mse: 1.6341e-04\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4319e-04 - mae: 0.0078 - mse: 1.4319e-04\n",
      "Epoch 494: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.4244e-04 - mae: 0.0076 - mse: 1.4244e-04 - val_loss: 1.3744e-04 - val_mae: 0.0081 - val_mse: 1.3744e-04\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0709e-04 - mae: 0.0069 - mse: 1.0709e-04\n",
      "Epoch 495: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4244e-04 - mae: 0.0076 - mse: 1.4244e-04 - val_loss: 9.8569e-05 - val_mae: 0.0068 - val_mse: 9.8569e-05\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5096e-05 - mae: 0.0057 - mse: 7.5096e-05\n",
      "Epoch 496: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0150e-04 - mae: 0.0065 - mse: 1.0150e-04 - val_loss: 1.3666e-04 - val_mae: 0.0079 - val_mse: 1.3666e-04\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0124e-04 - mae: 0.0064 - mse: 1.0124e-04\n",
      "Epoch 497: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0227e-04 - mae: 0.0066 - mse: 1.0227e-04 - val_loss: 2.0282e-04 - val_mae: 0.0097 - val_mse: 2.0282e-04\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4570e-04 - mae: 0.0079 - mse: 1.4570e-04\n",
      "Epoch 498: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.2309e-04 - mae: 0.0073 - mse: 1.2309e-04 - val_loss: 1.3574e-04 - val_mae: 0.0082 - val_mse: 1.3574e-04\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2510e-04 - mae: 0.0078 - mse: 1.2510e-04\n",
      "Epoch 499: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.2917e-04 - mae: 0.0077 - mse: 1.2917e-04 - val_loss: 1.4517e-04 - val_mae: 0.0085 - val_mse: 1.4517e-04\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1564e-04 - mae: 0.0075 - mse: 1.1564e-04\n",
      "Epoch 500: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2027e-04 - mae: 0.0076 - mse: 1.2027e-04 - val_loss: 1.1601e-04 - val_mae: 0.0072 - val_mse: 1.1601e-04\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9407e-05 - mae: 0.0060 - mse: 7.9407e-05\n",
      "Epoch 501: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.0217e-04 - mae: 0.0067 - mse: 1.0217e-04 - val_loss: 1.0266e-04 - val_mae: 0.0071 - val_mse: 1.0266e-04\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1005e-05 - mae: 0.0060 - mse: 8.1005e-05\n",
      "Epoch 502: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.2059e-05 - mae: 0.0061 - mse: 8.2059e-05 - val_loss: 1.4258e-04 - val_mae: 0.0080 - val_mse: 1.4258e-04\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0149e-04 - mae: 0.0070 - mse: 1.0149e-04\n",
      "Epoch 503: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.9681e-05 - mae: 0.0068 - mse: 9.9681e-05 - val_loss: 1.3063e-04 - val_mae: 0.0081 - val_mse: 1.3063e-04\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1338e-04 - mae: 0.0076 - mse: 1.1338e-04\n",
      "Epoch 504: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1270e-04 - mae: 0.0074 - mse: 1.1270e-04 - val_loss: 1.1110e-04 - val_mae: 0.0074 - val_mse: 1.1110e-04\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9164e-05 - mae: 0.0067 - mse: 8.9164e-05\n",
      "Epoch 505: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.8698e-05 - mae: 0.0070 - mse: 9.8698e-05 - val_loss: 9.4409e-05 - val_mae: 0.0066 - val_mse: 9.4409e-05\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6177e-05 - mae: 0.0058 - mse: 7.6177e-05\n",
      "Epoch 506: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.3490e-05 - mae: 0.0062 - mse: 8.3490e-05 - val_loss: 9.7377e-05 - val_mae: 0.0068 - val_mse: 9.7377e-05\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1426e-05 - mae: 0.0057 - mse: 7.1426e-05\n",
      "Epoch 507: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.9516e-05 - mae: 0.0061 - mse: 7.9516e-05 - val_loss: 1.1197e-04 - val_mae: 0.0075 - val_mse: 1.1197e-04\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7601e-05 - mae: 0.0069 - mse: 9.7601e-05\n",
      "Epoch 508: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.2023e-05 - mae: 0.0062 - mse: 8.2023e-05 - val_loss: 9.5905e-05 - val_mae: 0.0067 - val_mse: 9.5905e-05\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1276e-05 - mae: 0.0062 - mse: 8.1276e-05\n",
      "Epoch 509: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.4986e-05 - mae: 0.0059 - mse: 7.4986e-05 - val_loss: 8.7345e-05 - val_mae: 0.0061 - val_mse: 8.7345e-05\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5887e-05 - mae: 0.0054 - mse: 7.5887e-05\n",
      "Epoch 510: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.9244e-05 - mae: 0.0055 - mse: 6.9244e-05 - val_loss: 8.9148e-05 - val_mae: 0.0063 - val_mse: 8.9148e-05\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6886e-05 - mae: 0.0054 - mse: 6.6886e-05\n",
      "Epoch 511: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.0110e-05 - mae: 0.0055 - mse: 7.0110e-05 - val_loss: 9.1132e-05 - val_mae: 0.0064 - val_mse: 9.1132e-05\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7620e-05 - mae: 0.0053 - mse: 6.7620e-05\n",
      "Epoch 512: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7121e-05 - mae: 0.0053 - mse: 6.7121e-05 - val_loss: 8.6822e-05 - val_mae: 0.0062 - val_mse: 8.6822e-05\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4584e-05 - mae: 0.0053 - mse: 6.4584e-05\n",
      "Epoch 513: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.7397e-05 - mae: 0.0053 - mse: 6.7397e-05 - val_loss: 8.6107e-05 - val_mae: 0.0062 - val_mse: 8.6107e-05\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7900e-05 - mae: 0.0056 - mse: 7.7900e-05\n",
      "Epoch 514: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.4779e-05 - mae: 0.0053 - mse: 6.4779e-05 - val_loss: 8.5115e-05 - val_mae: 0.0062 - val_mse: 8.5115e-05\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0306e-05 - mae: 0.0051 - mse: 6.0306e-05\n",
      "Epoch 515: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.4491e-05 - mae: 0.0053 - mse: 6.4491e-05 - val_loss: 8.9220e-05 - val_mae: 0.0064 - val_mse: 8.9220e-05\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6051e-05 - mae: 0.0058 - mse: 7.6051e-05\n",
      "Epoch 516: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.6451e-05 - mae: 0.0054 - mse: 6.6451e-05 - val_loss: 8.8028e-05 - val_mae: 0.0062 - val_mse: 8.8028e-05\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9084e-05 - mae: 0.0054 - mse: 6.9084e-05\n",
      "Epoch 517: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.8156e-05 - mae: 0.0054 - mse: 6.8156e-05 - val_loss: 7.9311e-05 - val_mae: 0.0057 - val_mse: 7.9311e-05\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0587e-05 - mae: 0.0046 - mse: 6.0587e-05\n",
      "Epoch 518: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.9218e-05 - mae: 0.0048 - mse: 5.9218e-05 - val_loss: 8.1948e-05 - val_mae: 0.0060 - val_mse: 8.1948e-05\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.2361e-05 - mae: 0.0049 - mse: 6.2361e-05\n",
      "Epoch 519: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.9534e-05 - mae: 0.0048 - mse: 5.9534e-05 - val_loss: 8.3882e-05 - val_mae: 0.0061 - val_mse: 8.3882e-05\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.5015e-05 - mae: 0.0051 - mse: 6.5015e-05\n",
      "Epoch 520: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.3358e-05 - mae: 0.0051 - mse: 6.3358e-05 - val_loss: 7.8796e-05 - val_mae: 0.0058 - val_mse: 7.8796e-05\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.7266e-05 - mae: 0.0047 - mse: 5.7266e-05\n",
      "Epoch 521: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 6.1296e-05 - mae: 0.0049 - mse: 6.1296e-05 - val_loss: 7.7072e-05 - val_mae: 0.0056 - val_mse: 7.7072e-05\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.7065e-05 - mae: 0.0046 - mse: 5.7065e-05\n",
      "Epoch 522: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 5.9346e-05 - mae: 0.0048 - mse: 5.9346e-05 - val_loss: 8.1956e-05 - val_mae: 0.0060 - val_mse: 8.1956e-05\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8476e-05 - mae: 0.0048 - mse: 5.8476e-05\n",
      "Epoch 523: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0418e-05 - mae: 0.0048 - mse: 6.0418e-05 - val_loss: 7.9412e-05 - val_mae: 0.0058 - val_mse: 7.9412e-05\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7008e-05 - mae: 0.0048 - mse: 5.7008e-05\n",
      "Epoch 524: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.2035e-05 - mae: 0.0050 - mse: 6.2035e-05 - val_loss: 7.9820e-05 - val_mae: 0.0057 - val_mse: 7.9820e-05\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9111e-05 - mae: 0.0048 - mse: 5.9111e-05\n",
      "Epoch 525: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.0401e-05 - mae: 0.0049 - mse: 6.0401e-05 - val_loss: 8.0062e-05 - val_mae: 0.0057 - val_mse: 8.0062e-05\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4539e-05 - mae: 0.0049 - mse: 6.4539e-05\n",
      "Epoch 526: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.9027e-05 - mae: 0.0048 - mse: 5.9027e-05 - val_loss: 7.7122e-05 - val_mae: 0.0057 - val_mse: 7.7122e-05\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.9717e-05 - mae: 0.0047 - mse: 5.9717e-05\n",
      "Epoch 527: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.6892e-05 - mae: 0.0047 - mse: 5.6892e-05 - val_loss: 7.7597e-05 - val_mae: 0.0058 - val_mse: 7.7597e-05\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6704e-05 - mae: 0.0048 - mse: 5.6704e-05\n",
      "Epoch 528: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9762e-05 - mae: 0.0049 - mse: 5.9762e-05 - val_loss: 7.7401e-05 - val_mae: 0.0057 - val_mse: 7.7401e-05\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0755e-05 - mae: 0.0045 - mse: 5.0755e-05\n",
      "Epoch 529: val_loss did not improve from 0.00008\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.8788e-05 - mae: 0.0047 - mse: 5.8788e-05 - val_loss: 7.8728e-05 - val_mae: 0.0057 - val_mse: 7.8728e-05\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4249e-05 - mae: 0.0043 - mse: 4.4249e-05\n",
      "Epoch 530: val_loss improved from 0.00008 to 0.00008, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 5.9183e-05 - mae: 0.0047 - mse: 5.9183e-05 - val_loss: 7.5339e-05 - val_mae: 0.0056 - val_mse: 7.5339e-05\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.6331e-05 - mae: 0.0044 - mse: 5.6331e-05\n",
      "Epoch 531: val_loss improved from 0.00008 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.7533e-05 - mae: 0.0046 - mse: 5.7533e-05 - val_loss: 7.4883e-05 - val_mae: 0.0056 - val_mse: 7.4883e-05\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.8746e-05 - mae: 0.0047 - mse: 5.8746e-05\n",
      "Epoch 532: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6387e-05 - mae: 0.0046 - mse: 5.6387e-05 - val_loss: 7.6575e-05 - val_mae: 0.0057 - val_mse: 7.6575e-05\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0373e-05 - mae: 0.0051 - mse: 7.0373e-05\n",
      "Epoch 533: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 5.8028e-05 - mae: 0.0047 - mse: 5.8028e-05 - val_loss: 7.4434e-05 - val_mae: 0.0056 - val_mse: 7.4434e-05\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9196e-05 - mae: 0.0045 - mse: 4.9196e-05\n",
      "Epoch 534: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.6624e-05 - mae: 0.0046 - mse: 5.6624e-05 - val_loss: 7.4985e-05 - val_mae: 0.0056 - val_mse: 7.4985e-05\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0713e-05 - mae: 0.0047 - mse: 6.0713e-05\n",
      "Epoch 535: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.5809e-05 - mae: 0.0046 - mse: 5.5809e-05 - val_loss: 7.5550e-05 - val_mae: 0.0057 - val_mse: 7.5550e-05\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8582e-05 - mae: 0.0046 - mse: 5.8582e-05\n",
      "Epoch 536: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.5777e-05 - mae: 0.0046 - mse: 5.5777e-05 - val_loss: 7.4827e-05 - val_mae: 0.0056 - val_mse: 7.4827e-05\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7410e-05 - mae: 0.0045 - mse: 5.7410e-05\n",
      "Epoch 537: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.6479e-05 - mae: 0.0046 - mse: 5.6479e-05 - val_loss: 7.4558e-05 - val_mae: 0.0055 - val_mse: 7.4558e-05\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7907e-05 - mae: 0.0044 - mse: 4.7907e-05\n",
      "Epoch 538: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.5244e-05 - mae: 0.0045 - mse: 5.5244e-05 - val_loss: 8.1513e-05 - val_mae: 0.0058 - val_mse: 8.1513e-05\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8072e-05 - mae: 0.0048 - mse: 5.8072e-05\n",
      "Epoch 539: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7398e-05 - mae: 0.0047 - mse: 5.7398e-05 - val_loss: 8.1651e-05 - val_mae: 0.0059 - val_mse: 8.1651e-05\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4095e-05 - mae: 0.0049 - mse: 6.4095e-05\n",
      "Epoch 540: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.0058e-05 - mae: 0.0048 - mse: 6.0058e-05 - val_loss: 7.4671e-05 - val_mae: 0.0056 - val_mse: 7.4671e-05\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7680e-05 - mae: 0.0044 - mse: 4.7680e-05\n",
      "Epoch 541: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.7073e-05 - mae: 0.0046 - mse: 5.7073e-05 - val_loss: 7.6429e-05 - val_mae: 0.0057 - val_mse: 7.6429e-05\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0117e-05 - mae: 0.0048 - mse: 6.0117e-05\n",
      "Epoch 542: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.6506e-05 - mae: 0.0047 - mse: 5.6506e-05 - val_loss: 7.7974e-05 - val_mae: 0.0058 - val_mse: 7.7974e-05\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6924e-05 - mae: 0.0047 - mse: 5.6924e-05\n",
      "Epoch 543: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.7534e-05 - mae: 0.0047 - mse: 5.7534e-05 - val_loss: 7.6278e-05 - val_mae: 0.0058 - val_mse: 7.6278e-05\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3177e-05 - mae: 0.0046 - mse: 5.3177e-05\n",
      "Epoch 544: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.8398e-05 - mae: 0.0048 - mse: 5.8398e-05 - val_loss: 7.4573e-05 - val_mae: 0.0056 - val_mse: 7.4573e-05\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9254e-05 - mae: 0.0044 - mse: 4.9254e-05\n",
      "Epoch 545: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 5.7427e-05 - mae: 0.0048 - mse: 5.7427e-05 - val_loss: 7.4251e-05 - val_mae: 0.0055 - val_mse: 7.4251e-05\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9125e-05 - mae: 0.0047 - mse: 5.9125e-05\n",
      "Epoch 546: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.7006e-05 - mae: 0.0047 - mse: 5.7006e-05 - val_loss: 7.4747e-05 - val_mae: 0.0056 - val_mse: 7.4747e-05\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5799e-05 - mae: 0.0046 - mse: 5.5799e-05\n",
      "Epoch 547: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5761e-05 - mae: 0.0045 - mse: 5.5761e-05 - val_loss: 7.6211e-05 - val_mae: 0.0056 - val_mse: 7.6211e-05\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0085e-05 - mae: 0.0047 - mse: 6.0085e-05\n",
      "Epoch 548: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.8009e-05 - mae: 0.0046 - mse: 5.8009e-05 - val_loss: 7.1596e-05 - val_mae: 0.0055 - val_mse: 7.1596e-05\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3750e-05 - mae: 0.0045 - mse: 5.3750e-05\n",
      "Epoch 549: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.7210e-05 - mae: 0.0047 - mse: 5.7210e-05 - val_loss: 7.6897e-05 - val_mae: 0.0056 - val_mse: 7.6897e-05\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1622e-05 - mae: 0.0044 - mse: 5.1622e-05\n",
      "Epoch 550: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.7868e-05 - mae: 0.0046 - mse: 5.7868e-05 - val_loss: 7.6255e-05 - val_mae: 0.0056 - val_mse: 7.6255e-05\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6563e-05 - mae: 0.0046 - mse: 5.6563e-05\n",
      "Epoch 551: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.9153e-05 - mae: 0.0047 - mse: 5.9153e-05 - val_loss: 8.4916e-05 - val_mae: 0.0059 - val_mse: 8.4916e-05\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5189e-05 - mae: 0.0047 - mse: 5.5189e-05\n",
      "Epoch 552: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.1796e-05 - mae: 0.0048 - mse: 6.1796e-05 - val_loss: 8.7220e-05 - val_mae: 0.0060 - val_mse: 8.7220e-05\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9213e-05 - mae: 0.0048 - mse: 5.9213e-05\n",
      "Epoch 553: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.0920e-05 - mae: 0.0049 - mse: 6.0920e-05 - val_loss: 7.5932e-05 - val_mae: 0.0056 - val_mse: 7.5932e-05\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0805e-05 - mae: 0.0047 - mse: 6.0805e-05\n",
      "Epoch 554: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.8492e-05 - mae: 0.0047 - mse: 5.8492e-05 - val_loss: 7.8152e-05 - val_mae: 0.0058 - val_mse: 7.8152e-05\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8558e-05 - mae: 0.0048 - mse: 5.8558e-05\n",
      "Epoch 555: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.7990e-05 - mae: 0.0047 - mse: 5.7990e-05 - val_loss: 8.2074e-05 - val_mae: 0.0059 - val_mse: 8.2074e-05\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.0647e-05 - mae: 0.0050 - mse: 6.0647e-05\n",
      "Epoch 556: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.0631e-05 - mae: 0.0050 - mse: 6.0631e-05 - val_loss: 7.6144e-05 - val_mae: 0.0058 - val_mse: 7.6144e-05\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5785e-05 - mae: 0.0047 - mse: 5.5785e-05\n",
      "Epoch 557: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.8372e-05 - mae: 0.0048 - mse: 5.8372e-05 - val_loss: 7.6776e-05 - val_mae: 0.0057 - val_mse: 7.6776e-05\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4919e-05 - mae: 0.0049 - mse: 6.4919e-05\n",
      "Epoch 558: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.6705e-05 - mae: 0.0047 - mse: 5.6705e-05 - val_loss: 7.5468e-05 - val_mae: 0.0057 - val_mse: 7.5468e-05\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8536e-05 - mae: 0.0049 - mse: 5.8536e-05\n",
      "Epoch 559: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.7749e-05 - mae: 0.0048 - mse: 5.7749e-05 - val_loss: 7.7050e-05 - val_mae: 0.0057 - val_mse: 7.7050e-05\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.1764e-05 - mae: 0.0048 - mse: 6.1764e-05\n",
      "Epoch 560: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.7496e-05 - mae: 0.0047 - mse: 5.7496e-05 - val_loss: 7.3487e-05 - val_mae: 0.0055 - val_mse: 7.3487e-05\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 5.7175e-05 - mae: 0.0045 - mse: 5.7175e-05\n",
      "Epoch 561: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.5079e-05 - mae: 0.0045 - mse: 5.5079e-05 - val_loss: 7.3169e-05 - val_mae: 0.0054 - val_mse: 7.3169e-05\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0523e-05 - mae: 0.0043 - mse: 5.0523e-05\n",
      "Epoch 562: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.3667e-05 - mae: 0.0044 - mse: 5.3667e-05 - val_loss: 7.7914e-05 - val_mae: 0.0058 - val_mse: 7.7914e-05\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5213e-05 - mae: 0.0050 - mse: 6.5213e-05\n",
      "Epoch 563: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8004e-05 - mae: 0.0047 - mse: 5.8004e-05 - val_loss: 7.7660e-05 - val_mae: 0.0057 - val_mse: 7.7660e-05\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7797e-05 - mae: 0.0045 - mse: 5.7797e-05\n",
      "Epoch 564: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.6968e-05 - mae: 0.0046 - mse: 5.6968e-05 - val_loss: 7.4051e-05 - val_mae: 0.0055 - val_mse: 7.4051e-05\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7823e-05 - mae: 0.0042 - mse: 4.7823e-05\n",
      "Epoch 565: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.9249e-05 - mae: 0.0047 - mse: 5.9249e-05 - val_loss: 7.6539e-05 - val_mae: 0.0057 - val_mse: 7.6539e-05\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1124e-05 - mae: 0.0046 - mse: 6.1124e-05\n",
      "Epoch 566: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.5707e-05 - mae: 0.0046 - mse: 5.5707e-05 - val_loss: 7.6704e-05 - val_mae: 0.0057 - val_mse: 7.6704e-05\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1132e-05 - mae: 0.0050 - mse: 6.1132e-05\n",
      "Epoch 567: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.7894e-05 - mae: 0.0048 - mse: 5.7894e-05 - val_loss: 7.5200e-05 - val_mae: 0.0057 - val_mse: 7.5200e-05\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8612e-05 - mae: 0.0049 - mse: 5.8612e-05\n",
      "Epoch 568: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.7700e-05 - mae: 0.0048 - mse: 5.7700e-05 - val_loss: 7.3293e-05 - val_mae: 0.0056 - val_mse: 7.3293e-05\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.3064e-05 - mae: 0.0047 - mse: 5.3064e-05\n",
      "Epoch 569: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.7644e-05 - mae: 0.0048 - mse: 5.7644e-05 - val_loss: 7.3570e-05 - val_mae: 0.0055 - val_mse: 7.3570e-05\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.9222e-05 - mae: 0.0046 - mse: 5.9222e-05\n",
      "Epoch 570: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.5212e-05 - mae: 0.0046 - mse: 5.5212e-05 - val_loss: 6.9945e-05 - val_mae: 0.0053 - val_mse: 6.9945e-05\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9345e-05 - mae: 0.0042 - mse: 4.9345e-05\n",
      "Epoch 571: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4841e-05 - mae: 0.0045 - mse: 5.4841e-05 - val_loss: 7.0526e-05 - val_mae: 0.0054 - val_mse: 7.0526e-05\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4028e-05 - mae: 0.0043 - mse: 5.4028e-05\n",
      "Epoch 572: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.3560e-05 - mae: 0.0044 - mse: 5.3560e-05 - val_loss: 7.2292e-05 - val_mae: 0.0055 - val_mse: 7.2292e-05\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0736e-05 - mae: 0.0046 - mse: 6.0736e-05\n",
      "Epoch 573: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.3198e-05 - mae: 0.0044 - mse: 5.3198e-05 - val_loss: 7.3906e-05 - val_mae: 0.0057 - val_mse: 7.3906e-05\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5739e-05 - mae: 0.0048 - mse: 5.5739e-05\n",
      "Epoch 574: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.5198e-05 - mae: 0.0046 - mse: 5.5198e-05 - val_loss: 7.4363e-05 - val_mae: 0.0056 - val_mse: 7.4363e-05\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5404e-05 - mae: 0.0046 - mse: 5.5404e-05\n",
      "Epoch 575: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.5481e-05 - mae: 0.0045 - mse: 5.5481e-05 - val_loss: 7.0717e-05 - val_mae: 0.0055 - val_mse: 7.0717e-05\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7632e-05 - mae: 0.0044 - mse: 4.7632e-05\n",
      "Epoch 576: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.7832e-05 - mae: 0.0047 - mse: 5.7832e-05 - val_loss: 7.7570e-05 - val_mae: 0.0057 - val_mse: 7.7570e-05\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4519e-05 - mae: 0.0047 - mse: 5.4519e-05\n",
      "Epoch 577: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.1978e-05 - mae: 0.0048 - mse: 6.1978e-05 - val_loss: 7.4902e-05 - val_mae: 0.0056 - val_mse: 7.4902e-05\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1373e-05 - mae: 0.0047 - mse: 5.1373e-05\n",
      "Epoch 578: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.7355e-05 - mae: 0.0051 - mse: 6.7355e-05 - val_loss: 8.8082e-05 - val_mae: 0.0061 - val_mse: 8.8082e-05\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2497e-05 - mae: 0.0052 - mse: 7.2497e-05\n",
      "Epoch 579: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.6190e-05 - mae: 0.0054 - mse: 7.6190e-05 - val_loss: 8.5017e-05 - val_mae: 0.0062 - val_mse: 8.5017e-05\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8713e-05 - mae: 0.0053 - mse: 6.8713e-05\n",
      "Epoch 580: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 7.5824e-05 - mae: 0.0055 - mse: 7.5824e-05 - val_loss: 7.9951e-05 - val_mae: 0.0059 - val_mse: 7.9951e-05\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2455e-05 - mae: 0.0048 - mse: 6.2455e-05\n",
      "Epoch 581: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.2372e-05 - mae: 0.0049 - mse: 6.2372e-05 - val_loss: 9.3599e-05 - val_mae: 0.0062 - val_mse: 9.3599e-05\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2323e-05 - mae: 0.0053 - mse: 7.2323e-05\n",
      "Epoch 582: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.3441e-05 - mae: 0.0050 - mse: 6.3441e-05 - val_loss: 7.8170e-05 - val_mae: 0.0059 - val_mse: 7.8170e-05\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7690e-05 - mae: 0.0051 - mse: 6.7690e-05\n",
      "Epoch 583: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1609e-05 - mae: 0.0050 - mse: 6.1609e-05 - val_loss: 9.3869e-05 - val_mae: 0.0065 - val_mse: 9.3869e-05\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.2554e-05 - mae: 0.0058 - mse: 8.2554e-05\n",
      "Epoch 584: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.7431e-05 - mae: 0.0053 - mse: 6.7431e-05 - val_loss: 8.0838e-05 - val_mae: 0.0059 - val_mse: 8.0838e-05\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2971e-05 - mae: 0.0051 - mse: 6.2971e-05\n",
      "Epoch 585: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.3356e-05 - mae: 0.0051 - mse: 6.3356e-05 - val_loss: 7.7813e-05 - val_mae: 0.0059 - val_mse: 7.7813e-05\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0784e-05 - mae: 0.0049 - mse: 6.0784e-05\n",
      "Epoch 586: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.2833e-05 - mae: 0.0050 - mse: 6.2833e-05 - val_loss: 7.5825e-05 - val_mae: 0.0057 - val_mse: 7.5825e-05\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.5372e-05 - mae: 0.0046 - mse: 5.5372e-05\n",
      "Epoch 587: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1017e-05 - mae: 0.0049 - mse: 6.1017e-05 - val_loss: 7.5289e-05 - val_mae: 0.0056 - val_mse: 7.5289e-05\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2968e-05 - mae: 0.0046 - mse: 5.2968e-05\n",
      "Epoch 588: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 5.9242e-05 - mae: 0.0048 - mse: 5.9242e-05 - val_loss: 9.0904e-05 - val_mae: 0.0065 - val_mse: 9.0904e-05\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2288e-05 - mae: 0.0055 - mse: 7.2288e-05\n",
      "Epoch 589: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5115e-05 - mae: 0.0053 - mse: 6.5115e-05 - val_loss: 9.3287e-05 - val_mae: 0.0065 - val_mse: 9.3287e-05\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8048e-05 - mae: 0.0059 - mse: 7.8048e-05\n",
      "Epoch 590: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0741e-05 - mae: 0.0055 - mse: 7.0741e-05 - val_loss: 7.9412e-05 - val_mae: 0.0061 - val_mse: 7.9412e-05\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8161e-05 - mae: 0.0056 - mse: 6.8161e-05\n",
      "Epoch 591: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.6939e-05 - mae: 0.0055 - mse: 6.6939e-05 - val_loss: 7.6831e-05 - val_mae: 0.0059 - val_mse: 7.6831e-05\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7725e-05 - mae: 0.0050 - mse: 5.7725e-05\n",
      "Epoch 592: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 6.4973e-05 - mae: 0.0053 - mse: 6.4973e-05 - val_loss: 7.3936e-05 - val_mae: 0.0055 - val_mse: 7.3936e-05\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.9603e-05 - mae: 0.0047 - mse: 5.9603e-05\n",
      "Epoch 593: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.0471e-05 - mae: 0.0050 - mse: 6.0471e-05 - val_loss: 7.2813e-05 - val_mae: 0.0057 - val_mse: 7.2813e-05\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0768e-05 - mae: 0.0049 - mse: 6.0768e-05\n",
      "Epoch 594: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.8985e-05 - mae: 0.0050 - mse: 5.8985e-05 - val_loss: 7.8304e-05 - val_mae: 0.0059 - val_mse: 7.8304e-05\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4674e-05 - mae: 0.0051 - mse: 6.4674e-05\n",
      "Epoch 595: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.9649e-05 - mae: 0.0050 - mse: 5.9649e-05 - val_loss: 8.3031e-05 - val_mae: 0.0061 - val_mse: 8.3031e-05\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6743e-05 - mae: 0.0053 - mse: 6.6743e-05\n",
      "Epoch 596: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.3788e-05 - mae: 0.0051 - mse: 6.3788e-05 - val_loss: 8.0739e-05 - val_mae: 0.0060 - val_mse: 8.0739e-05\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7684e-05 - mae: 0.0052 - mse: 6.7684e-05\n",
      "Epoch 597: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.0049e-05 - mae: 0.0049 - mse: 6.0049e-05 - val_loss: 7.6762e-05 - val_mae: 0.0056 - val_mse: 7.6762e-05\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5646e-05 - mae: 0.0047 - mse: 5.5646e-05\n",
      "Epoch 598: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6315e-05 - mae: 0.0047 - mse: 5.6315e-05 - val_loss: 7.2317e-05 - val_mae: 0.0055 - val_mse: 7.2317e-05\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6342e-05 - mae: 0.0043 - mse: 4.6342e-05\n",
      "Epoch 599: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3117e-05 - mae: 0.0044 - mse: 5.3117e-05 - val_loss: 7.5951e-05 - val_mae: 0.0056 - val_mse: 7.5951e-05\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8350e-05 - mae: 0.0043 - mse: 4.8350e-05\n",
      "Epoch 600: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3613e-05 - mae: 0.0045 - mse: 5.3613e-05 - val_loss: 7.4714e-05 - val_mae: 0.0056 - val_mse: 7.4714e-05\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2798e-05 - mae: 0.0044 - mse: 5.2798e-05\n",
      "Epoch 601: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.4563e-05 - mae: 0.0045 - mse: 5.4563e-05 - val_loss: 7.0019e-05 - val_mae: 0.0054 - val_mse: 7.0019e-05\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9472e-05 - mae: 0.0044 - mse: 4.9472e-05\n",
      "Epoch 602: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.3311e-05 - mae: 0.0044 - mse: 5.3311e-05 - val_loss: 7.2677e-05 - val_mae: 0.0054 - val_mse: 7.2677e-05\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2410e-05 - mae: 0.0043 - mse: 5.2410e-05\n",
      "Epoch 603: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.2739e-05 - mae: 0.0044 - mse: 5.2739e-05 - val_loss: 7.0080e-05 - val_mae: 0.0053 - val_mse: 7.0080e-05\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3092e-05 - mae: 0.0044 - mse: 5.3092e-05\n",
      "Epoch 604: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.1651e-05 - mae: 0.0043 - mse: 5.1651e-05 - val_loss: 6.9323e-05 - val_mae: 0.0053 - val_mse: 6.9323e-05\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0847e-05 - mae: 0.0043 - mse: 5.0847e-05\n",
      "Epoch 605: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.1424e-05 - mae: 0.0043 - mse: 5.1424e-05 - val_loss: 6.9604e-05 - val_mae: 0.0052 - val_mse: 6.9604e-05\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8262e-05 - mae: 0.0037 - mse: 3.8262e-05\n",
      "Epoch 606: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0119e-05 - mae: 0.0042 - mse: 5.0119e-05 - val_loss: 6.9500e-05 - val_mae: 0.0053 - val_mse: 6.9500e-05\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6869e-05 - mae: 0.0042 - mse: 4.6869e-05\n",
      "Epoch 607: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.1726e-05 - mae: 0.0043 - mse: 5.1726e-05 - val_loss: 7.6319e-05 - val_mae: 0.0055 - val_mse: 7.6319e-05\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0763e-05 - mae: 0.0046 - mse: 6.0763e-05\n",
      "Epoch 608: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4551e-05 - mae: 0.0044 - mse: 5.4551e-05 - val_loss: 6.7147e-05 - val_mae: 0.0052 - val_mse: 6.7147e-05\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.4412e-05 - mae: 0.0041 - mse: 4.4412e-05\n",
      "Epoch 609: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.1530e-05 - mae: 0.0043 - mse: 5.1530e-05 - val_loss: 6.6657e-05 - val_mae: 0.0052 - val_mse: 6.6657e-05\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7452e-05 - mae: 0.0041 - mse: 4.7452e-05\n",
      "Epoch 610: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.2615e-05 - mae: 0.0043 - mse: 5.2615e-05 - val_loss: 6.7187e-05 - val_mae: 0.0053 - val_mse: 6.7187e-05\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9780e-05 - mae: 0.0043 - mse: 4.9780e-05\n",
      "Epoch 611: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3068e-05 - mae: 0.0044 - mse: 5.3068e-05 - val_loss: 6.9153e-05 - val_mae: 0.0054 - val_mse: 6.9153e-05\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4992e-05 - mae: 0.0041 - mse: 4.4992e-05\n",
      "Epoch 612: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.2359e-05 - mae: 0.0043 - mse: 5.2359e-05 - val_loss: 6.6813e-05 - val_mae: 0.0051 - val_mse: 6.6813e-05\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8778e-05 - mae: 0.0042 - mse: 4.8778e-05\n",
      "Epoch 613: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0265e-05 - mae: 0.0042 - mse: 5.0265e-05 - val_loss: 6.6781e-05 - val_mae: 0.0052 - val_mse: 6.6781e-05\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8233e-05 - mae: 0.0040 - mse: 4.8233e-05\n",
      "Epoch 614: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.0647e-05 - mae: 0.0042 - mse: 5.0647e-05 - val_loss: 6.6106e-05 - val_mae: 0.0051 - val_mse: 6.6106e-05\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4385e-05 - mae: 0.0043 - mse: 5.4385e-05\n",
      "Epoch 615: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0242e-05 - mae: 0.0042 - mse: 5.0242e-05 - val_loss: 6.8026e-05 - val_mae: 0.0052 - val_mse: 6.8026e-05\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9631e-05 - mae: 0.0042 - mse: 4.9631e-05\n",
      "Epoch 616: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.0204e-05 - mae: 0.0041 - mse: 5.0204e-05 - val_loss: 6.7155e-05 - val_mae: 0.0052 - val_mse: 6.7155e-05\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.2050e-05 - mae: 0.0040 - mse: 4.2050e-05\n",
      "Epoch 617: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.2154e-05 - mae: 0.0043 - mse: 5.2154e-05 - val_loss: 6.7446e-05 - val_mae: 0.0052 - val_mse: 6.7446e-05\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6373e-05 - mae: 0.0044 - mse: 5.6373e-05\n",
      "Epoch 618: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.1530e-05 - mae: 0.0043 - mse: 5.1530e-05 - val_loss: 6.7638e-05 - val_mae: 0.0053 - val_mse: 6.7638e-05\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1080e-05 - mae: 0.0043 - mse: 5.1080e-05\n",
      "Epoch 619: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1560e-05 - mae: 0.0043 - mse: 5.1560e-05 - val_loss: 7.0783e-05 - val_mae: 0.0055 - val_mse: 7.0783e-05\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7178e-05 - mae: 0.0042 - mse: 4.7178e-05\n",
      "Epoch 620: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.2193e-05 - mae: 0.0043 - mse: 5.2193e-05 - val_loss: 6.7608e-05 - val_mae: 0.0052 - val_mse: 6.7608e-05\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3795e-05 - mae: 0.0043 - mse: 5.3795e-05\n",
      "Epoch 621: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.1303e-05 - mae: 0.0043 - mse: 5.1303e-05 - val_loss: 6.5810e-05 - val_mae: 0.0051 - val_mse: 6.5810e-05\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 4.9504e-05 - mae: 0.0041 - mse: 4.9504e-05\n",
      "Epoch 622: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.1278e-05 - mae: 0.0042 - mse: 5.1278e-05 - val_loss: 6.8816e-05 - val_mae: 0.0053 - val_mse: 6.8816e-05\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7017e-05 - mae: 0.0036 - mse: 3.7017e-05\n",
      "Epoch 623: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.1597e-05 - mae: 0.0042 - mse: 5.1597e-05 - val_loss: 7.3436e-05 - val_mae: 0.0054 - val_mse: 7.3436e-05\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.0435e-05 - mae: 0.0043 - mse: 5.0435e-05\n",
      "Epoch 624: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.2584e-05 - mae: 0.0043 - mse: 5.2584e-05 - val_loss: 7.2771e-05 - val_mae: 0.0056 - val_mse: 7.2771e-05\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.4609e-05 - mae: 0.0046 - mse: 5.4609e-05\n",
      "Epoch 625: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3676e-05 - mae: 0.0045 - mse: 5.3676e-05 - val_loss: 7.0585e-05 - val_mae: 0.0054 - val_mse: 7.0585e-05\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6276e-05 - mae: 0.0048 - mse: 5.6276e-05\n",
      "Epoch 626: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.4482e-05 - mae: 0.0046 - mse: 5.4482e-05 - val_loss: 7.5706e-05 - val_mae: 0.0057 - val_mse: 7.5706e-05\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7858e-05 - mae: 0.0047 - mse: 5.7858e-05\n",
      "Epoch 627: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.4562e-05 - mae: 0.0046 - mse: 5.4562e-05 - val_loss: 6.9660e-05 - val_mae: 0.0054 - val_mse: 6.9660e-05\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.1231e-05 - mae: 0.0045 - mse: 5.1231e-05\n",
      "Epoch 628: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.4233e-05 - mae: 0.0046 - mse: 5.4233e-05 - val_loss: 7.1472e-05 - val_mae: 0.0054 - val_mse: 7.1472e-05\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5731e-05 - mae: 0.0045 - mse: 5.5731e-05\n",
      "Epoch 629: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.4356e-05 - mae: 0.0045 - mse: 5.4356e-05 - val_loss: 6.6477e-05 - val_mae: 0.0052 - val_mse: 6.6477e-05\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6748e-05 - mae: 0.0042 - mse: 4.6748e-05\n",
      "Epoch 630: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.2107e-05 - mae: 0.0043 - mse: 5.2107e-05 - val_loss: 7.6483e-05 - val_mae: 0.0057 - val_mse: 7.6483e-05\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5525e-05 - mae: 0.0045 - mse: 5.5525e-05\n",
      "Epoch 631: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5221e-05 - mae: 0.0045 - mse: 5.5221e-05 - val_loss: 6.8580e-05 - val_mae: 0.0053 - val_mse: 6.8580e-05\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6851e-05 - mae: 0.0045 - mse: 5.6851e-05\n",
      "Epoch 632: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2226e-05 - mae: 0.0044 - mse: 5.2226e-05 - val_loss: 7.1682e-05 - val_mae: 0.0054 - val_mse: 7.1682e-05\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9839e-05 - mae: 0.0043 - mse: 4.9839e-05\n",
      "Epoch 633: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.3946e-05 - mae: 0.0044 - mse: 5.3946e-05 - val_loss: 7.2573e-05 - val_mae: 0.0055 - val_mse: 7.2573e-05\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1717e-05 - mae: 0.0046 - mse: 6.1717e-05\n",
      "Epoch 634: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4043e-05 - mae: 0.0045 - mse: 5.4043e-05 - val_loss: 7.4858e-05 - val_mae: 0.0056 - val_mse: 7.4858e-05\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8207e-05 - mae: 0.0041 - mse: 3.8207e-05\n",
      "Epoch 635: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4518e-05 - mae: 0.0046 - mse: 5.4518e-05 - val_loss: 7.7205e-05 - val_mae: 0.0056 - val_mse: 7.7205e-05\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6637e-05 - mae: 0.0045 - mse: 5.6637e-05\n",
      "Epoch 636: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5872e-05 - mae: 0.0046 - mse: 5.5872e-05 - val_loss: 6.9302e-05 - val_mae: 0.0054 - val_mse: 6.9302e-05\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9656e-05 - mae: 0.0041 - mse: 3.9656e-05\n",
      "Epoch 637: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4790e-05 - mae: 0.0046 - mse: 5.4790e-05 - val_loss: 7.0630e-05 - val_mae: 0.0054 - val_mse: 7.0630e-05\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0505e-05 - mae: 0.0049 - mse: 6.0505e-05\n",
      "Epoch 638: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2626e-05 - mae: 0.0045 - mse: 5.2626e-05 - val_loss: 8.2093e-05 - val_mae: 0.0060 - val_mse: 8.2093e-05\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1272e-05 - mae: 0.0050 - mse: 6.1272e-05\n",
      "Epoch 639: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.9200e-05 - mae: 0.0048 - mse: 5.9200e-05 - val_loss: 7.1190e-05 - val_mae: 0.0055 - val_mse: 7.1190e-05\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4521e-05 - mae: 0.0050 - mse: 6.4521e-05\n",
      "Epoch 640: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6459e-05 - mae: 0.0048 - mse: 5.6459e-05 - val_loss: 6.7921e-05 - val_mae: 0.0053 - val_mse: 6.7921e-05\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8399e-05 - mae: 0.0043 - mse: 4.8399e-05\n",
      "Epoch 641: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.2801e-05 - mae: 0.0046 - mse: 5.2801e-05 - val_loss: 7.2989e-05 - val_mae: 0.0055 - val_mse: 7.2989e-05\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0984e-05 - mae: 0.0045 - mse: 5.0984e-05\n",
      "Epoch 642: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4029e-05 - mae: 0.0046 - mse: 5.4029e-05 - val_loss: 7.1674e-05 - val_mae: 0.0055 - val_mse: 7.1674e-05\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6697e-05 - mae: 0.0048 - mse: 5.6697e-05\n",
      "Epoch 643: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3216e-05 - mae: 0.0045 - mse: 5.3216e-05 - val_loss: 7.3208e-05 - val_mae: 0.0056 - val_mse: 7.3208e-05\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4053e-05 - mae: 0.0050 - mse: 6.4053e-05\n",
      "Epoch 644: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6041e-05 - mae: 0.0048 - mse: 5.6041e-05 - val_loss: 7.1428e-05 - val_mae: 0.0055 - val_mse: 7.1428e-05\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6872e-05 - mae: 0.0045 - mse: 4.6872e-05\n",
      "Epoch 645: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.7075e-05 - mae: 0.0048 - mse: 5.7075e-05 - val_loss: 7.2951e-05 - val_mae: 0.0056 - val_mse: 7.2951e-05\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0526e-05 - mae: 0.0044 - mse: 5.0526e-05\n",
      "Epoch 646: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.5466e-05 - mae: 0.0046 - mse: 5.5466e-05 - val_loss: 7.5101e-05 - val_mae: 0.0057 - val_mse: 7.5101e-05\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3415e-05 - mae: 0.0050 - mse: 6.3415e-05\n",
      "Epoch 647: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7745e-05 - mae: 0.0048 - mse: 5.7745e-05 - val_loss: 7.1034e-05 - val_mae: 0.0055 - val_mse: 7.1034e-05\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8948e-05 - mae: 0.0046 - mse: 4.8948e-05\n",
      "Epoch 648: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.6430e-05 - mae: 0.0047 - mse: 5.6430e-05 - val_loss: 6.8239e-05 - val_mae: 0.0053 - val_mse: 6.8239e-05\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0327e-05 - mae: 0.0044 - mse: 5.0327e-05\n",
      "Epoch 649: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.2351e-05 - mae: 0.0045 - mse: 5.2351e-05 - val_loss: 6.8901e-05 - val_mae: 0.0053 - val_mse: 6.8901e-05\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.3456e-05 - mae: 0.0041 - mse: 4.3456e-05\n",
      "Epoch 650: val_loss improved from 0.00007 to 0.00007, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.3337e-05 - mae: 0.0044 - mse: 5.3337e-05 - val_loss: 6.5522e-05 - val_mae: 0.0052 - val_mse: 6.5522e-05\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.5251e-05 - mae: 0.0041 - mse: 4.5251e-05\n",
      "Epoch 651: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.1892e-05 - mae: 0.0044 - mse: 5.1892e-05 - val_loss: 7.0638e-05 - val_mae: 0.0053 - val_mse: 7.0638e-05\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6515e-05 - mae: 0.0040 - mse: 4.6515e-05\n",
      "Epoch 652: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0957e-05 - mae: 0.0043 - mse: 5.0957e-05 - val_loss: 6.8510e-05 - val_mae: 0.0054 - val_mse: 6.8510e-05\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2786e-05 - mae: 0.0045 - mse: 5.2786e-05\n",
      "Epoch 653: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3046e-05 - mae: 0.0045 - mse: 5.3046e-05 - val_loss: 6.6127e-05 - val_mae: 0.0051 - val_mse: 6.6127e-05\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.8479e-05 - mae: 0.0039 - mse: 3.8479e-05\n",
      "Epoch 654: val_loss did not improve from 0.00007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.9641e-05 - mae: 0.0042 - mse: 4.9641e-05 - val_loss: 7.2608e-05 - val_mae: 0.0055 - val_mse: 7.2608e-05\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3088e-05 - mae: 0.0044 - mse: 5.3088e-05\n",
      "Epoch 655: val_loss improved from 0.00007 to 0.00006, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.1487e-05 - mae: 0.0043 - mse: 5.1487e-05 - val_loss: 6.2599e-05 - val_mae: 0.0051 - val_mse: 6.2599e-05\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.0839e-05 - mae: 0.0043 - mse: 5.0839e-05\n",
      "Epoch 656: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0309e-05 - mae: 0.0043 - mse: 5.0309e-05 - val_loss: 6.7777e-05 - val_mae: 0.0052 - val_mse: 6.7777e-05\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6798e-05 - mae: 0.0046 - mse: 5.6798e-05\n",
      "Epoch 657: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1152e-05 - mae: 0.0044 - mse: 5.1152e-05 - val_loss: 6.8144e-05 - val_mae: 0.0053 - val_mse: 6.8144e-05\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.4462e-05 - mae: 0.0046 - mse: 5.4462e-05\n",
      "Epoch 658: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3852e-05 - mae: 0.0045 - mse: 5.3852e-05 - val_loss: 6.5598e-05 - val_mae: 0.0051 - val_mse: 6.5598e-05\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8040e-05 - mae: 0.0041 - mse: 4.8040e-05\n",
      "Epoch 659: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9513e-05 - mae: 0.0042 - mse: 4.9513e-05 - val_loss: 6.7284e-05 - val_mae: 0.0052 - val_mse: 6.7284e-05\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7370e-05 - mae: 0.0038 - mse: 3.7370e-05\n",
      "Epoch 660: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1008e-05 - mae: 0.0043 - mse: 5.1008e-05 - val_loss: 6.9193e-05 - val_mae: 0.0054 - val_mse: 6.9193e-05\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2854e-05 - mae: 0.0044 - mse: 5.2854e-05\n",
      "Epoch 661: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.3440e-05 - mae: 0.0045 - mse: 5.3440e-05 - val_loss: 7.1436e-05 - val_mae: 0.0054 - val_mse: 7.1436e-05\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1254e-05 - mae: 0.0044 - mse: 5.1254e-05\n",
      "Epoch 662: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3789e-05 - mae: 0.0045 - mse: 5.3789e-05 - val_loss: 7.1522e-05 - val_mae: 0.0055 - val_mse: 7.1522e-05\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9561e-05 - mae: 0.0044 - mse: 4.9561e-05\n",
      "Epoch 663: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3426e-05 - mae: 0.0045 - mse: 5.3426e-05 - val_loss: 7.0721e-05 - val_mae: 0.0054 - val_mse: 7.0721e-05\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5431e-05 - mae: 0.0048 - mse: 5.5431e-05\n",
      "Epoch 664: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3930e-05 - mae: 0.0046 - mse: 5.3930e-05 - val_loss: 6.9068e-05 - val_mae: 0.0054 - val_mse: 6.9068e-05\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8292e-05 - mae: 0.0043 - mse: 4.8292e-05\n",
      "Epoch 665: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.0869e-05 - mae: 0.0043 - mse: 5.0869e-05 - val_loss: 6.4977e-05 - val_mae: 0.0052 - val_mse: 6.4977e-05\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6968e-05 - mae: 0.0045 - mse: 5.6968e-05\n",
      "Epoch 666: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.0960e-05 - mae: 0.0044 - mse: 5.0960e-05 - val_loss: 6.5694e-05 - val_mae: 0.0053 - val_mse: 6.5694e-05\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.0198e-05 - mae: 0.0044 - mse: 5.0198e-05\n",
      "Epoch 667: val_loss improved from 0.00006 to 0.00006, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 5.2139e-05 - mae: 0.0045 - mse: 5.2139e-05 - val_loss: 6.2532e-05 - val_mae: 0.0050 - val_mse: 6.2532e-05\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.2061e-05 - mae: 0.0043 - mse: 5.2061e-05\n",
      "Epoch 668: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.9155e-05 - mae: 0.0043 - mse: 4.9155e-05 - val_loss: 6.4505e-05 - val_mae: 0.0052 - val_mse: 6.4505e-05\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2874e-05 - mae: 0.0039 - mse: 4.2874e-05\n",
      "Epoch 669: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9553e-05 - mae: 0.0042 - mse: 4.9553e-05 - val_loss: 6.5849e-05 - val_mae: 0.0052 - val_mse: 6.5849e-05\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9000e-05 - mae: 0.0042 - mse: 4.9000e-05\n",
      "Epoch 670: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0062e-05 - mae: 0.0043 - mse: 5.0062e-05 - val_loss: 6.5537e-05 - val_mae: 0.0052 - val_mse: 6.5537e-05\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1479e-05 - mae: 0.0043 - mse: 5.1479e-05\n",
      "Epoch 671: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.1435e-05 - mae: 0.0044 - mse: 5.1435e-05 - val_loss: 6.7486e-05 - val_mae: 0.0053 - val_mse: 6.7486e-05\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9543e-05 - mae: 0.0047 - mse: 5.9543e-05\n",
      "Epoch 672: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.2403e-05 - mae: 0.0045 - mse: 5.2403e-05 - val_loss: 6.4896e-05 - val_mae: 0.0053 - val_mse: 6.4896e-05\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1654e-05 - mae: 0.0047 - mse: 5.1654e-05\n",
      "Epoch 673: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1039e-05 - mae: 0.0045 - mse: 5.1039e-05 - val_loss: 6.9784e-05 - val_mae: 0.0055 - val_mse: 6.9784e-05\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4160e-05 - mae: 0.0042 - mse: 4.4160e-05\n",
      "Epoch 674: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1494e-05 - mae: 0.0044 - mse: 5.1494e-05 - val_loss: 6.4069e-05 - val_mae: 0.0051 - val_mse: 6.4069e-05\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.4477e-05 - mae: 0.0045 - mse: 5.4477e-05\n",
      "Epoch 675: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.0105e-05 - mae: 0.0043 - mse: 5.0105e-05 - val_loss: 6.4109e-05 - val_mae: 0.0051 - val_mse: 6.4109e-05\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6406e-05 - mae: 0.0040 - mse: 4.6406e-05\n",
      "Epoch 676: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7781e-05 - mae: 0.0041 - mse: 4.7781e-05 - val_loss: 6.7200e-05 - val_mae: 0.0052 - val_mse: 6.7200e-05\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7322e-05 - mae: 0.0045 - mse: 5.7322e-05\n",
      "Epoch 677: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.9085e-05 - mae: 0.0042 - mse: 4.9085e-05 - val_loss: 6.9636e-05 - val_mae: 0.0053 - val_mse: 6.9636e-05\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2990e-05 - mae: 0.0044 - mse: 5.2990e-05\n",
      "Epoch 678: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 4.8523e-05 - mae: 0.0042 - mse: 4.8523e-05 - val_loss: 6.7571e-05 - val_mae: 0.0053 - val_mse: 6.7571e-05\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5884e-05 - mae: 0.0045 - mse: 5.5884e-05\n",
      "Epoch 679: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.9799e-05 - mae: 0.0043 - mse: 4.9799e-05 - val_loss: 6.6433e-05 - val_mae: 0.0053 - val_mse: 6.6433e-05\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.3611e-05 - mae: 0.0041 - mse: 4.3611e-05\n",
      "Epoch 680: val_loss improved from 0.00006 to 0.00006, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.9386e-05 - mae: 0.0042 - mse: 4.9386e-05 - val_loss: 6.1392e-05 - val_mae: 0.0049 - val_mse: 6.1392e-05\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7833e-05 - mae: 0.0044 - mse: 5.7833e-05\n",
      "Epoch 681: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.7034e-05 - mae: 0.0040 - mse: 4.7034e-05 - val_loss: 6.4292e-05 - val_mae: 0.0051 - val_mse: 6.4292e-05\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6137e-05 - mae: 0.0044 - mse: 5.6137e-05\n",
      "Epoch 682: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.8261e-05 - mae: 0.0041 - mse: 4.8261e-05 - val_loss: 6.3188e-05 - val_mae: 0.0051 - val_mse: 6.3188e-05\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2895e-05 - mae: 0.0040 - mse: 4.2895e-05\n",
      "Epoch 683: val_loss improved from 0.00006 to 0.00006, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.7974e-05 - mae: 0.0042 - mse: 4.7974e-05 - val_loss: 6.0408e-05 - val_mae: 0.0049 - val_mse: 6.0408e-05\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.1615e-05 - mae: 0.0038 - mse: 4.1615e-05\n",
      "Epoch 684: val_loss improved from 0.00006 to 0.00006, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.6739e-05 - mae: 0.0040 - mse: 4.6739e-05 - val_loss: 5.9418e-05 - val_mae: 0.0049 - val_mse: 5.9418e-05\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8955e-05 - mae: 0.0040 - mse: 4.8955e-05\n",
      "Epoch 685: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.7151e-05 - mae: 0.0040 - mse: 4.7151e-05 - val_loss: 6.2901e-05 - val_mae: 0.0050 - val_mse: 6.2901e-05\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8192e-05 - mae: 0.0041 - mse: 4.8192e-05\n",
      "Epoch 686: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7549e-05 - mae: 0.0040 - mse: 4.7549e-05 - val_loss: 6.0026e-05 - val_mae: 0.0049 - val_mse: 6.0026e-05\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1611e-05 - mae: 0.0041 - mse: 5.1611e-05\n",
      "Epoch 687: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 4.6771e-05 - mae: 0.0040 - mse: 4.6771e-05 - val_loss: 6.0613e-05 - val_mae: 0.0049 - val_mse: 6.0613e-05\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9677e-05 - mae: 0.0040 - mse: 4.9677e-05\n",
      "Epoch 688: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.6643e-05 - mae: 0.0039 - mse: 4.6643e-05 - val_loss: 6.6639e-05 - val_mae: 0.0051 - val_mse: 6.6639e-05\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.2090e-05 - mae: 0.0036 - mse: 3.2090e-05\n",
      "Epoch 689: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0058e-05 - mae: 0.0041 - mse: 5.0058e-05 - val_loss: 6.4854e-05 - val_mae: 0.0051 - val_mse: 6.4854e-05\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8580e-05 - mae: 0.0041 - mse: 4.8580e-05\n",
      "Epoch 690: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1561e-05 - mae: 0.0042 - mse: 5.1561e-05 - val_loss: 6.7425e-05 - val_mae: 0.0052 - val_mse: 6.7425e-05\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.9585e-05 - mae: 0.0039 - mse: 3.9585e-05\n",
      "Epoch 691: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.5021e-05 - mae: 0.0044 - mse: 5.5021e-05 - val_loss: 6.8468e-05 - val_mae: 0.0053 - val_mse: 6.8468e-05\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3000e-05 - mae: 0.0044 - mse: 5.3000e-05\n",
      "Epoch 692: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7237e-05 - mae: 0.0046 - mse: 5.7237e-05 - val_loss: 6.4751e-05 - val_mae: 0.0051 - val_mse: 6.4751e-05\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.7118e-05 - mae: 0.0042 - mse: 4.7118e-05\n",
      "Epoch 693: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3609e-05 - mae: 0.0045 - mse: 5.3609e-05 - val_loss: 8.1925e-05 - val_mae: 0.0060 - val_mse: 8.1925e-05\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8655e-05 - mae: 0.0048 - mse: 5.8655e-05\n",
      "Epoch 694: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.8184e-05 - mae: 0.0048 - mse: 5.8184e-05 - val_loss: 7.4440e-05 - val_mae: 0.0058 - val_mse: 7.4440e-05\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7596e-05 - mae: 0.0052 - mse: 6.7596e-05\n",
      "Epoch 695: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.1758e-05 - mae: 0.0050 - mse: 6.1758e-05 - val_loss: 6.9961e-05 - val_mae: 0.0055 - val_mse: 6.9961e-05\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8844e-05 - mae: 0.0047 - mse: 5.8844e-05\n",
      "Epoch 696: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4025e-05 - mae: 0.0046 - mse: 5.4025e-05 - val_loss: 6.9946e-05 - val_mae: 0.0055 - val_mse: 6.9946e-05\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9453e-05 - mae: 0.0048 - mse: 5.9453e-05\n",
      "Epoch 697: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3698e-05 - mae: 0.0046 - mse: 5.3698e-05 - val_loss: 6.9541e-05 - val_mae: 0.0055 - val_mse: 6.9541e-05\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1795e-05 - mae: 0.0050 - mse: 6.1795e-05\n",
      "Epoch 698: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.8712e-05 - mae: 0.0049 - mse: 5.8712e-05 - val_loss: 7.9827e-05 - val_mae: 0.0058 - val_mse: 7.9827e-05\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2548e-05 - mae: 0.0053 - mse: 7.2548e-05\n",
      "Epoch 699: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.6234e-05 - mae: 0.0051 - mse: 6.6234e-05 - val_loss: 9.5946e-05 - val_mae: 0.0066 - val_mse: 9.5946e-05\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4350e-05 - mae: 0.0050 - mse: 6.4350e-05\n",
      "Epoch 700: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.4849e-05 - mae: 0.0055 - mse: 7.4849e-05 - val_loss: 1.2001e-04 - val_mae: 0.0076 - val_mse: 1.2001e-04\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.2098e-05 - mae: 0.0063 - mse: 9.2098e-05\n",
      "Epoch 701: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8.5627e-05 - mae: 0.0060 - mse: 8.5627e-05 - val_loss: 7.8102e-05 - val_mae: 0.0058 - val_mse: 7.8102e-05\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7895e-05 - mae: 0.0053 - mse: 6.7895e-05\n",
      "Epoch 702: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 6.2259e-05 - mae: 0.0051 - mse: 6.2259e-05 - val_loss: 7.3628e-05 - val_mae: 0.0056 - val_mse: 7.3628e-05\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.6700e-05 - mae: 0.0047 - mse: 5.6700e-05\n",
      "Epoch 703: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.8001e-05 - mae: 0.0048 - mse: 5.8001e-05 - val_loss: 6.8659e-05 - val_mae: 0.0055 - val_mse: 6.8659e-05\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9294e-05 - mae: 0.0045 - mse: 4.9294e-05\n",
      "Epoch 704: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8305e-05 - mae: 0.0048 - mse: 5.8305e-05 - val_loss: 6.8989e-05 - val_mae: 0.0055 - val_mse: 6.8989e-05\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2174e-05 - mae: 0.0046 - mse: 5.2174e-05\n",
      "Epoch 705: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6763e-05 - mae: 0.0048 - mse: 5.6763e-05 - val_loss: 6.8328e-05 - val_mae: 0.0054 - val_mse: 6.8328e-05\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1884e-05 - mae: 0.0044 - mse: 5.1884e-05\n",
      "Epoch 706: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3698e-05 - mae: 0.0046 - mse: 5.3698e-05 - val_loss: 6.5343e-05 - val_mae: 0.0052 - val_mse: 6.5343e-05\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.4545e-05 - mae: 0.0046 - mse: 5.4545e-05\n",
      "Epoch 707: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 5.1765e-05 - mae: 0.0045 - mse: 5.1765e-05 - val_loss: 7.4729e-05 - val_mae: 0.0057 - val_mse: 7.4729e-05\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3662e-05 - mae: 0.0047 - mse: 5.3662e-05\n",
      "Epoch 708: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.5102e-05 - mae: 0.0047 - mse: 5.5102e-05 - val_loss: 7.2809e-05 - val_mae: 0.0058 - val_mse: 7.2809e-05\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4059e-05 - mae: 0.0051 - mse: 6.4059e-05\n",
      "Epoch 709: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6738e-05 - mae: 0.0048 - mse: 5.6738e-05 - val_loss: 7.4897e-05 - val_mae: 0.0056 - val_mse: 7.4897e-05\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0490e-05 - mae: 0.0049 - mse: 6.0490e-05\n",
      "Epoch 710: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5290e-05 - mae: 0.0046 - mse: 5.5290e-05 - val_loss: 6.8682e-05 - val_mae: 0.0055 - val_mse: 6.8682e-05\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1715e-05 - mae: 0.0048 - mse: 6.1715e-05\n",
      "Epoch 711: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.4878e-05 - mae: 0.0046 - mse: 5.4878e-05 - val_loss: 7.7023e-05 - val_mae: 0.0058 - val_mse: 7.7023e-05\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6088e-05 - mae: 0.0047 - mse: 5.6088e-05\n",
      "Epoch 712: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 5.4442e-05 - mae: 0.0046 - mse: 5.4442e-05 - val_loss: 6.6033e-05 - val_mae: 0.0053 - val_mse: 6.6033e-05\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.4824e-05 - mae: 0.0041 - mse: 4.4824e-05\n",
      "Epoch 713: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.3664e-05 - mae: 0.0046 - mse: 5.3664e-05 - val_loss: 7.7189e-05 - val_mae: 0.0058 - val_mse: 7.7189e-05\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4781e-05 - mae: 0.0052 - mse: 6.4781e-05\n",
      "Epoch 714: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1923e-05 - mae: 0.0050 - mse: 6.1923e-05 - val_loss: 6.8423e-05 - val_mae: 0.0055 - val_mse: 6.8423e-05\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1889e-05 - mae: 0.0044 - mse: 5.1889e-05\n",
      "Epoch 715: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5899e-05 - mae: 0.0051 - mse: 6.5899e-05 - val_loss: 1.1915e-04 - val_mae: 0.0071 - val_mse: 1.1915e-04\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.9770e-05 - mae: 0.0060 - mse: 9.9770e-05\n",
      "Epoch 716: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0572e-04 - mae: 0.0061 - mse: 1.0572e-04 - val_loss: 1.0272e-04 - val_mae: 0.0070 - val_mse: 1.0272e-04\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.0634e-05 - mae: 0.0062 - mse: 9.0634e-05\n",
      "Epoch 717: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0536e-04 - mae: 0.0064 - mse: 1.0536e-04 - val_loss: 9.1674e-05 - val_mae: 0.0066 - val_mse: 9.1674e-05\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.8467e-05 - mae: 0.0055 - mse: 6.8467e-05\n",
      "Epoch 718: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1798e-04 - mae: 0.0066 - mse: 1.1798e-04 - val_loss: 1.2706e-04 - val_mae: 0.0079 - val_mse: 1.2706e-04\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3004e-04 - mae: 0.0077 - mse: 1.3004e-04\n",
      "Epoch 719: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.5054e-04 - mae: 0.0076 - mse: 1.5054e-04 - val_loss: 9.8711e-05 - val_mae: 0.0067 - val_mse: 9.8711e-05\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7352e-05 - mae: 0.0053 - mse: 6.7352e-05\n",
      "Epoch 720: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1854e-04 - mae: 0.0066 - mse: 1.1854e-04 - val_loss: 1.0623e-04 - val_mae: 0.0070 - val_mse: 1.0623e-04\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0634e-05 - mae: 0.0056 - mse: 7.0634e-05\n",
      "Epoch 721: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.2379e-04 - mae: 0.0069 - mse: 1.2379e-04 - val_loss: 1.1175e-04 - val_mae: 0.0074 - val_mse: 1.1175e-04\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0526e-04 - mae: 0.0069 - mse: 1.0526e-04\n",
      "Epoch 722: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4938e-04 - mae: 0.0081 - mse: 1.4938e-04 - val_loss: 1.7817e-04 - val_mae: 0.0090 - val_mse: 1.7817e-04\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.4921e-04 - mae: 0.0080 - mse: 1.4921e-04\n",
      "Epoch 723: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6910e-04 - mae: 0.0086 - mse: 1.6910e-04 - val_loss: 1.4546e-04 - val_mae: 0.0080 - val_mse: 1.4546e-04\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2963e-04 - mae: 0.0075 - mse: 1.2963e-04\n",
      "Epoch 724: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.5179e-04 - mae: 0.0082 - mse: 1.5179e-04 - val_loss: 1.5349e-04 - val_mae: 0.0089 - val_mse: 1.5349e-04\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3993e-04 - mae: 0.0084 - mse: 1.3993e-04\n",
      "Epoch 725: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3937e-04 - mae: 0.0083 - mse: 1.3937e-04 - val_loss: 2.3307e-04 - val_mae: 0.0108 - val_mse: 2.3307e-04\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6987e-04 - mae: 0.0089 - mse: 1.6987e-04\n",
      "Epoch 726: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.4876e-04 - mae: 0.0083 - mse: 1.4876e-04 - val_loss: 1.9852e-04 - val_mae: 0.0098 - val_mse: 1.9852e-04\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.1594e-04 - mae: 0.0101 - mse: 2.1594e-04\n",
      "Epoch 727: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.7362e-04 - mae: 0.0089 - mse: 1.7362e-04 - val_loss: 1.8783e-04 - val_mae: 0.0089 - val_mse: 1.8783e-04\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.0108e-04 - mae: 0.0092 - mse: 2.0108e-04\n",
      "Epoch 728: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6677e-04 - mae: 0.0083 - mse: 1.6677e-04 - val_loss: 1.8045e-04 - val_mae: 0.0093 - val_mse: 1.8045e-04\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4303e-04 - mae: 0.0078 - mse: 1.4303e-04\n",
      "Epoch 729: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3271e-04 - mae: 0.0077 - mse: 1.3271e-04 - val_loss: 1.8200e-04 - val_mae: 0.0091 - val_mse: 1.8200e-04\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3257e-04 - mae: 0.0077 - mse: 1.3257e-04\n",
      "Epoch 730: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 1.3154e-04 - mae: 0.0077 - mse: 1.3154e-04 - val_loss: 1.5774e-04 - val_mae: 0.0086 - val_mse: 1.5774e-04\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1956e-04 - mae: 0.0072 - mse: 1.1956e-04\n",
      "Epoch 731: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2441e-04 - mae: 0.0075 - mse: 1.2441e-04 - val_loss: 9.4023e-05 - val_mae: 0.0069 - val_mse: 9.4023e-05\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.7301e-05 - mae: 0.0061 - mse: 7.7301e-05\n",
      "Epoch 732: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.8870e-05 - mae: 0.0067 - mse: 9.8870e-05 - val_loss: 1.0586e-04 - val_mae: 0.0072 - val_mse: 1.0586e-04\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.1747e-05 - mae: 0.0066 - mse: 9.1747e-05\n",
      "Epoch 733: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.0317e-05 - mae: 0.0065 - mse: 9.0317e-05 - val_loss: 1.6485e-04 - val_mae: 0.0087 - val_mse: 1.6485e-04\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2817e-04 - mae: 0.0078 - mse: 1.2817e-04\n",
      "Epoch 734: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 1.1065e-04 - mae: 0.0071 - mse: 1.1065e-04 - val_loss: 1.7580e-04 - val_mae: 0.0087 - val_mse: 1.7580e-04\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.5749e-04 - mae: 0.0081 - mse: 1.5749e-04\n",
      "Epoch 735: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.3528e-04 - mae: 0.0075 - mse: 1.3528e-04 - val_loss: 1.6402e-04 - val_mae: 0.0084 - val_mse: 1.6402e-04\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4078e-04 - mae: 0.0078 - mse: 1.4078e-04\n",
      "Epoch 736: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1945e-04 - mae: 0.0072 - mse: 1.1945e-04 - val_loss: 1.2999e-04 - val_mae: 0.0078 - val_mse: 1.2999e-04\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1839e-04 - mae: 0.0073 - mse: 1.1839e-04\n",
      "Epoch 737: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.0728e-04 - mae: 0.0069 - mse: 1.0728e-04 - val_loss: 9.9632e-05 - val_mae: 0.0070 - val_mse: 9.9632e-05\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.3977e-05 - mae: 0.0066 - mse: 9.3977e-05\n",
      "Epoch 738: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.0434e-05 - mae: 0.0066 - mse: 9.0434e-05 - val_loss: 9.0564e-05 - val_mae: 0.0065 - val_mse: 9.0564e-05\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9240e-05 - mae: 0.0057 - mse: 6.9240e-05\n",
      "Epoch 739: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8.4657e-05 - mae: 0.0063 - mse: 8.4657e-05 - val_loss: 9.6873e-05 - val_mae: 0.0069 - val_mse: 9.6873e-05\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3287e-05 - mae: 0.0059 - mse: 7.3287e-05\n",
      "Epoch 740: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.9546e-05 - mae: 0.0062 - mse: 7.9546e-05 - val_loss: 8.3847e-05 - val_mae: 0.0064 - val_mse: 8.3847e-05\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7787e-05 - mae: 0.0055 - mse: 6.7787e-05\n",
      "Epoch 741: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.5047e-05 - mae: 0.0059 - mse: 7.5047e-05 - val_loss: 8.1715e-05 - val_mae: 0.0063 - val_mse: 8.1715e-05\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6540e-05 - mae: 0.0059 - mse: 7.6540e-05\n",
      "Epoch 742: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.4719e-05 - mae: 0.0060 - mse: 7.4719e-05 - val_loss: 8.3425e-05 - val_mae: 0.0065 - val_mse: 8.3425e-05\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.6550e-05 - mae: 0.0059 - mse: 7.6550e-05\n",
      "Epoch 743: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.2506e-05 - mae: 0.0058 - mse: 7.2506e-05 - val_loss: 7.5030e-05 - val_mae: 0.0059 - val_mse: 7.5030e-05\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.6830e-05 - mae: 0.0055 - mse: 6.6830e-05\n",
      "Epoch 744: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.9003e-05 - mae: 0.0056 - mse: 6.9003e-05 - val_loss: 6.7575e-05 - val_mae: 0.0056 - val_mse: 6.7575e-05\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5847e-05 - mae: 0.0054 - mse: 6.5847e-05\n",
      "Epoch 745: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1191e-05 - mae: 0.0053 - mse: 6.1191e-05 - val_loss: 9.3087e-05 - val_mae: 0.0067 - val_mse: 9.3087e-05\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.6415e-05 - mae: 0.0059 - mse: 7.6415e-05\n",
      "Epoch 746: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.1995e-05 - mae: 0.0057 - mse: 7.1995e-05 - val_loss: 1.3901e-04 - val_mae: 0.0081 - val_mse: 1.3901e-04\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2074e-04 - mae: 0.0072 - mse: 1.2074e-04\n",
      "Epoch 747: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0057e-04 - mae: 0.0064 - mse: 1.0057e-04 - val_loss: 1.2360e-04 - val_mae: 0.0079 - val_mse: 1.2360e-04\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1083e-04 - mae: 0.0071 - mse: 1.1083e-04\n",
      "Epoch 748: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.7721e-05 - mae: 0.0066 - mse: 9.7721e-05 - val_loss: 1.2001e-04 - val_mae: 0.0074 - val_mse: 1.2001e-04\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5599e-05 - mae: 0.0067 - mse: 9.5599e-05\n",
      "Epoch 749: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.5417e-05 - mae: 0.0063 - mse: 8.5417e-05 - val_loss: 9.6473e-05 - val_mae: 0.0071 - val_mse: 9.6473e-05\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.6173e-05 - mae: 0.0066 - mse: 8.6173e-05\n",
      "Epoch 750: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1975e-05 - mae: 0.0064 - mse: 8.1975e-05 - val_loss: 7.9393e-05 - val_mae: 0.0062 - val_mse: 7.9393e-05\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1376e-05 - mae: 0.0060 - mse: 7.1376e-05\n",
      "Epoch 751: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 7.3116e-05 - mae: 0.0060 - mse: 7.3116e-05 - val_loss: 8.2478e-05 - val_mae: 0.0064 - val_mse: 8.2478e-05\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1744e-05 - mae: 0.0059 - mse: 7.1744e-05\n",
      "Epoch 752: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.7909e-05 - mae: 0.0058 - mse: 6.7909e-05 - val_loss: 7.3576e-05 - val_mae: 0.0059 - val_mse: 7.3576e-05\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.0157e-05 - mae: 0.0052 - mse: 6.0157e-05\n",
      "Epoch 753: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.2441e-05 - mae: 0.0053 - mse: 6.2441e-05 - val_loss: 8.5987e-05 - val_mae: 0.0063 - val_mse: 8.5987e-05\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5637e-05 - mae: 0.0057 - mse: 7.5637e-05\n",
      "Epoch 754: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.6109e-05 - mae: 0.0054 - mse: 6.6109e-05 - val_loss: 7.7732e-05 - val_mae: 0.0060 - val_mse: 7.7732e-05\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.2536e-05 - mae: 0.0056 - mse: 7.2536e-05\n",
      "Epoch 755: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.5636e-05 - mae: 0.0053 - mse: 6.5636e-05 - val_loss: 7.4972e-05 - val_mae: 0.0057 - val_mse: 7.4972e-05\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0945e-05 - mae: 0.0050 - mse: 5.0945e-05\n",
      "Epoch 756: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.8792e-05 - mae: 0.0050 - mse: 5.8792e-05 - val_loss: 6.4937e-05 - val_mae: 0.0053 - val_mse: 6.4937e-05\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.9233e-05 - mae: 0.0045 - mse: 4.9233e-05\n",
      "Epoch 757: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.3496e-05 - mae: 0.0047 - mse: 5.3496e-05 - val_loss: 6.5521e-05 - val_mae: 0.0052 - val_mse: 6.5521e-05\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2755e-05 - mae: 0.0044 - mse: 5.2755e-05\n",
      "Epoch 758: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0151e-05 - mae: 0.0044 - mse: 5.0151e-05 - val_loss: 6.1567e-05 - val_mae: 0.0051 - val_mse: 6.1567e-05\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3204e-05 - mae: 0.0044 - mse: 5.3204e-05\n",
      "Epoch 759: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 5.0304e-05 - mae: 0.0045 - mse: 5.0304e-05 - val_loss: 6.2042e-05 - val_mae: 0.0051 - val_mse: 6.2042e-05\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4031e-05 - mae: 0.0041 - mse: 4.4031e-05\n",
      "Epoch 760: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 4.8551e-05 - mae: 0.0043 - mse: 4.8551e-05 - val_loss: 7.5257e-05 - val_mae: 0.0058 - val_mse: 7.5257e-05\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.0542e-05 - mae: 0.0049 - mse: 6.0542e-05\n",
      "Epoch 761: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0810e-05 - mae: 0.0045 - mse: 5.0810e-05 - val_loss: 6.3013e-05 - val_mae: 0.0052 - val_mse: 6.3013e-05\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.7522e-05 - mae: 0.0048 - mse: 5.7522e-05\n",
      "Epoch 762: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.0792e-05 - mae: 0.0045 - mse: 5.0792e-05 - val_loss: 6.9375e-05 - val_mae: 0.0054 - val_mse: 6.9375e-05\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5737e-05 - mae: 0.0043 - mse: 4.5737e-05\n",
      "Epoch 763: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 5.2875e-05 - mae: 0.0045 - mse: 5.2875e-05 - val_loss: 6.2303e-05 - val_mae: 0.0051 - val_mse: 6.2303e-05\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5186e-05 - mae: 0.0044 - mse: 5.5186e-05\n",
      "Epoch 764: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7321e-05 - mae: 0.0047 - mse: 5.7321e-05 - val_loss: 7.9644e-05 - val_mae: 0.0059 - val_mse: 7.9644e-05\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.9236e-05 - mae: 0.0046 - mse: 4.9236e-05\n",
      "Epoch 765: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.4660e-05 - mae: 0.0051 - mse: 6.4660e-05 - val_loss: 7.1428e-05 - val_mae: 0.0056 - val_mse: 7.1428e-05\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.8007e-05 - mae: 0.0046 - mse: 4.8007e-05\n",
      "Epoch 766: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.0969e-05 - mae: 0.0050 - mse: 6.0969e-05 - val_loss: 6.8808e-05 - val_mae: 0.0056 - val_mse: 6.8808e-05\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0222e-05 - mae: 0.0051 - mse: 6.0222e-05\n",
      "Epoch 767: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.4331e-05 - mae: 0.0052 - mse: 6.4331e-05 - val_loss: 8.1756e-05 - val_mae: 0.0063 - val_mse: 8.1756e-05\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4301e-05 - mae: 0.0059 - mse: 7.4301e-05\n",
      "Epoch 768: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.8686e-05 - mae: 0.0055 - mse: 6.8686e-05 - val_loss: 8.5687e-05 - val_mae: 0.0064 - val_mse: 8.5687e-05\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.9967e-05 - mae: 0.0061 - mse: 7.9967e-05\n",
      "Epoch 769: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 7.1335e-05 - mae: 0.0057 - mse: 7.1335e-05 - val_loss: 8.8342e-05 - val_mae: 0.0066 - val_mse: 8.8342e-05\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.4977e-05 - mae: 0.0064 - mse: 8.4977e-05\n",
      "Epoch 770: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.5082e-05 - mae: 0.0059 - mse: 7.5082e-05 - val_loss: 7.0828e-05 - val_mae: 0.0057 - val_mse: 7.0828e-05\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.5190e-05 - mae: 0.0056 - mse: 6.5190e-05\n",
      "Epoch 771: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 6.4405e-05 - mae: 0.0055 - mse: 6.4405e-05 - val_loss: 9.0960e-05 - val_mae: 0.0068 - val_mse: 9.0960e-05\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.1241e-05 - mae: 0.0056 - mse: 6.1241e-05\n",
      "Epoch 772: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.5804e-05 - mae: 0.0055 - mse: 6.5804e-05 - val_loss: 6.9562e-05 - val_mae: 0.0058 - val_mse: 6.9562e-05\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1113e-05 - mae: 0.0056 - mse: 7.1113e-05\n",
      "Epoch 773: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.2015e-05 - mae: 0.0053 - mse: 6.2015e-05 - val_loss: 6.5755e-05 - val_mae: 0.0054 - val_mse: 6.5755e-05\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.1388e-05 - mae: 0.0048 - mse: 5.1388e-05\n",
      "Epoch 774: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5873e-05 - mae: 0.0049 - mse: 5.5873e-05 - val_loss: 8.8052e-05 - val_mae: 0.0064 - val_mse: 8.8052e-05\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.7288e-05 - mae: 0.0057 - mse: 6.7288e-05\n",
      "Epoch 775: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5390e-05 - mae: 0.0054 - mse: 6.5390e-05 - val_loss: 8.1437e-05 - val_mae: 0.0063 - val_mse: 8.1437e-05\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.3157e-05 - mae: 0.0058 - mse: 7.3157e-05\n",
      "Epoch 776: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.3934e-05 - mae: 0.0053 - mse: 6.3934e-05 - val_loss: 7.3463e-05 - val_mae: 0.0056 - val_mse: 7.3463e-05\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4495e-05 - mae: 0.0052 - mse: 6.4495e-05\n",
      "Epoch 777: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7661e-05 - mae: 0.0049 - mse: 5.7661e-05 - val_loss: 7.3108e-05 - val_mae: 0.0059 - val_mse: 7.3108e-05\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0193e-05 - mae: 0.0053 - mse: 6.0193e-05\n",
      "Epoch 778: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.5431e-05 - mae: 0.0048 - mse: 5.5431e-05 - val_loss: 6.9730e-05 - val_mae: 0.0056 - val_mse: 6.9730e-05\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.6989e-05 - mae: 0.0048 - mse: 5.6989e-05\n",
      "Epoch 779: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.2142e-05 - mae: 0.0046 - mse: 5.2142e-05 - val_loss: 7.2811e-05 - val_mae: 0.0058 - val_mse: 7.2811e-05\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.0730e-05 - mae: 0.0047 - mse: 5.0730e-05\n",
      "Epoch 780: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 5.3082e-05 - mae: 0.0047 - mse: 5.3082e-05 - val_loss: 6.6052e-05 - val_mae: 0.0054 - val_mse: 6.6052e-05\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.3037e-05 - mae: 0.0047 - mse: 5.3037e-05\n",
      "Epoch 781: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 5.2490e-05 - mae: 0.0047 - mse: 5.2490e-05 - val_loss: 6.2287e-05 - val_mae: 0.0053 - val_mse: 6.2287e-05\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3390e-05 - mae: 0.0048 - mse: 5.3390e-05\n",
      "Epoch 782: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0176e-05 - mae: 0.0045 - mse: 5.0176e-05 - val_loss: 6.2047e-05 - val_mae: 0.0052 - val_mse: 6.2047e-05\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9184e-05 - mae: 0.0045 - mse: 4.9184e-05\n",
      "Epoch 783: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 4.9891e-05 - mae: 0.0044 - mse: 4.9891e-05 - val_loss: 6.2254e-05 - val_mae: 0.0051 - val_mse: 6.2254e-05\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.9422e-05 - mae: 0.0044 - mse: 4.9422e-05\n",
      "Epoch 784: val_loss improved from 0.00006 to 0.00006, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 4.8783e-05 - mae: 0.0044 - mse: 4.8783e-05 - val_loss: 5.7198e-05 - val_mae: 0.0049 - val_mse: 5.7198e-05\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.5007e-05 - mae: 0.0043 - mse: 4.5007e-05\n",
      "Epoch 785: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.8396e-05 - mae: 0.0044 - mse: 4.8396e-05 - val_loss: 6.5645e-05 - val_mae: 0.0054 - val_mse: 6.5645e-05\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1062e-05 - mae: 0.0047 - mse: 5.1062e-05\n",
      "Epoch 786: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4.9329e-05 - mae: 0.0044 - mse: 4.9329e-05 - val_loss: 6.1050e-05 - val_mae: 0.0051 - val_mse: 6.1050e-05\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3045e-05 - mae: 0.0047 - mse: 5.3045e-05\n",
      "Epoch 787: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9145e-05 - mae: 0.0045 - mse: 4.9145e-05 - val_loss: 6.6403e-05 - val_mae: 0.0054 - val_mse: 6.6403e-05\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.1058e-05 - mae: 0.0045 - mse: 5.1058e-05\n",
      "Epoch 788: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1548e-05 - mae: 0.0045 - mse: 5.1548e-05 - val_loss: 6.8090e-05 - val_mae: 0.0055 - val_mse: 6.8090e-05\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2617e-05 - mae: 0.0046 - mse: 5.2617e-05\n",
      "Epoch 789: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.9921e-05 - mae: 0.0044 - mse: 4.9921e-05 - val_loss: 6.8274e-05 - val_mae: 0.0055 - val_mse: 6.8274e-05\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.8777e-05 - mae: 0.0046 - mse: 4.8777e-05\n",
      "Epoch 790: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.4709e-05 - mae: 0.0046 - mse: 5.4709e-05 - val_loss: 6.8473e-05 - val_mae: 0.0054 - val_mse: 6.8473e-05\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5083e-05 - mae: 0.0048 - mse: 5.5083e-05\n",
      "Epoch 791: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.5486e-05 - mae: 0.0047 - mse: 5.5486e-05 - val_loss: 7.6084e-05 - val_mae: 0.0059 - val_mse: 7.6084e-05\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.9757e-05 - mae: 0.0051 - mse: 5.9757e-05\n",
      "Epoch 792: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.6228e-05 - mae: 0.0048 - mse: 5.6228e-05 - val_loss: 6.7202e-05 - val_mae: 0.0055 - val_mse: 6.7202e-05\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2231e-05 - mae: 0.0047 - mse: 5.2231e-05\n",
      "Epoch 793: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3641e-05 - mae: 0.0047 - mse: 5.3641e-05 - val_loss: 7.1312e-05 - val_mae: 0.0056 - val_mse: 7.1312e-05\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3826e-05 - mae: 0.0048 - mse: 5.3826e-05\n",
      "Epoch 794: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.4304e-05 - mae: 0.0048 - mse: 5.4304e-05 - val_loss: 6.5563e-05 - val_mae: 0.0053 - val_mse: 6.5563e-05\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1938e-05 - mae: 0.0043 - mse: 4.1938e-05\n",
      "Epoch 795: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 5.0068e-05 - mae: 0.0044 - mse: 5.0068e-05 - val_loss: 6.7738e-05 - val_mae: 0.0055 - val_mse: 6.7738e-05\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.5921e-05 - mae: 0.0051 - mse: 6.5921e-05\n",
      "Epoch 796: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.4846e-05 - mae: 0.0047 - mse: 5.4846e-05 - val_loss: 5.9416e-05 - val_mae: 0.0052 - val_mse: 5.9416e-05\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.6833e-05 - mae: 0.0045 - mse: 4.6833e-05\n",
      "Epoch 797: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 5.5315e-05 - mae: 0.0048 - mse: 5.5315e-05 - val_loss: 6.9213e-05 - val_mae: 0.0057 - val_mse: 6.9213e-05\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 5.9058e-05 - mae: 0.0051 - mse: 5.9058e-05\n",
      "Epoch 798: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.7161e-05 - mae: 0.0050 - mse: 5.7161e-05 - val_loss: 7.7462e-05 - val_mae: 0.0062 - val_mse: 7.7462e-05\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.3321e-05 - mae: 0.0059 - mse: 7.3321e-05\n",
      "Epoch 799: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.1489e-05 - mae: 0.0053 - mse: 6.1489e-05 - val_loss: 7.3008e-05 - val_mae: 0.0058 - val_mse: 7.3008e-05\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.0266e-05 - mae: 0.0049 - mse: 5.0266e-05\n",
      "Epoch 800: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 5.8126e-05 - mae: 0.0050 - mse: 5.8126e-05 - val_loss: 6.6767e-05 - val_mae: 0.0057 - val_mse: 6.6767e-05\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.0304e-05 - mae: 0.0052 - mse: 6.0304e-05\n",
      "Epoch 801: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 5.7915e-05 - mae: 0.0050 - mse: 5.7915e-05 - val_loss: 8.7262e-05 - val_mae: 0.0066 - val_mse: 8.7262e-05\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.4790e-05 - mae: 0.0059 - mse: 7.4790e-05\n",
      "Epoch 802: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.4289e-05 - mae: 0.0054 - mse: 6.4289e-05 - val_loss: 7.3165e-05 - val_mae: 0.0060 - val_mse: 7.3165e-05\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0235e-05 - mae: 0.0058 - mse: 7.0235e-05\n",
      "Epoch 803: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1130e-05 - mae: 0.0052 - mse: 6.1130e-05 - val_loss: 7.2668e-05 - val_mae: 0.0060 - val_mse: 7.2668e-05\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3086e-05 - mae: 0.0055 - mse: 6.3086e-05\n",
      "Epoch 804: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9317e-05 - mae: 0.0052 - mse: 5.9317e-05 - val_loss: 7.3742e-05 - val_mae: 0.0059 - val_mse: 7.3742e-05\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 7.1796e-05 - mae: 0.0059 - mse: 7.1796e-05\n",
      "Epoch 805: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 6.5036e-05 - mae: 0.0055 - mse: 6.5036e-05 - val_loss: 7.9711e-05 - val_mae: 0.0064 - val_mse: 7.9711e-05\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5116e-05 - mae: 0.0061 - mse: 7.5116e-05\n",
      "Epoch 806: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.8504e-05 - mae: 0.0056 - mse: 6.8504e-05 - val_loss: 8.1781e-05 - val_mae: 0.0061 - val_mse: 8.1781e-05\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.3293e-05 - mae: 0.0061 - mse: 8.3293e-05\n",
      "Epoch 807: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.8647e-05 - mae: 0.0055 - mse: 6.8647e-05 - val_loss: 8.3529e-05 - val_mae: 0.0063 - val_mse: 8.3529e-05\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4271e-05 - mae: 0.0061 - mse: 7.4271e-05\n",
      "Epoch 808: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.0593e-05 - mae: 0.0056 - mse: 7.0593e-05 - val_loss: 7.4627e-05 - val_mae: 0.0061 - val_mse: 7.4627e-05\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2681e-05 - mae: 0.0063 - mse: 8.2681e-05\n",
      "Epoch 809: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.6255e-05 - mae: 0.0056 - mse: 6.6255e-05 - val_loss: 9.6979e-05 - val_mae: 0.0071 - val_mse: 9.6979e-05\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2207e-05 - mae: 0.0065 - mse: 8.2207e-05\n",
      "Epoch 810: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.3584e-05 - mae: 0.0060 - mse: 7.3584e-05 - val_loss: 7.7185e-05 - val_mae: 0.0061 - val_mse: 7.7185e-05\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8773e-05 - mae: 0.0058 - mse: 6.8773e-05\n",
      "Epoch 811: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.5024e-05 - mae: 0.0055 - mse: 6.5024e-05 - val_loss: 7.2870e-05 - val_mae: 0.0058 - val_mse: 7.2870e-05\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.4716e-05 - mae: 0.0054 - mse: 6.4716e-05\n",
      "Epoch 812: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5.9853e-05 - mae: 0.0051 - mse: 5.9853e-05 - val_loss: 7.9856e-05 - val_mae: 0.0063 - val_mse: 7.9856e-05\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5309e-05 - mae: 0.0056 - mse: 6.5309e-05\n",
      "Epoch 813: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 6.1223e-05 - mae: 0.0053 - mse: 6.1223e-05 - val_loss: 8.8355e-05 - val_mae: 0.0067 - val_mse: 8.8355e-05\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0873e-05 - mae: 0.0060 - mse: 7.0873e-05\n",
      "Epoch 814: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.4012e-05 - mae: 0.0054 - mse: 6.4012e-05 - val_loss: 7.2256e-05 - val_mae: 0.0059 - val_mse: 7.2256e-05\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.0217e-05 - mae: 0.0058 - mse: 7.0217e-05\n",
      "Epoch 815: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.9705e-05 - mae: 0.0052 - mse: 5.9705e-05 - val_loss: 7.7717e-05 - val_mae: 0.0062 - val_mse: 7.7717e-05\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.8103e-05 - mae: 0.0055 - mse: 5.8103e-05\n",
      "Epoch 816: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.1168e-05 - mae: 0.0052 - mse: 6.1168e-05 - val_loss: 7.1607e-05 - val_mae: 0.0058 - val_mse: 7.1607e-05\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.9707e-05 - mae: 0.0056 - mse: 6.9707e-05\n",
      "Epoch 817: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.9837e-05 - mae: 0.0051 - mse: 5.9837e-05 - val_loss: 7.5279e-05 - val_mae: 0.0060 - val_mse: 7.5279e-05\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5846e-05 - mae: 0.0050 - mse: 5.5846e-05\n",
      "Epoch 818: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5213e-05 - mae: 0.0049 - mse: 5.5213e-05 - val_loss: 8.2597e-05 - val_mae: 0.0063 - val_mse: 8.2597e-05\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.5297e-05 - mae: 0.0062 - mse: 7.5297e-05\n",
      "Epoch 819: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.0438e-05 - mae: 0.0057 - mse: 7.0438e-05 - val_loss: 8.0239e-05 - val_mae: 0.0062 - val_mse: 8.0239e-05\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1663e-05 - mae: 0.0059 - mse: 7.1663e-05\n",
      "Epoch 820: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.3288e-05 - mae: 0.0054 - mse: 6.3288e-05 - val_loss: 8.5620e-05 - val_mae: 0.0065 - val_mse: 8.5620e-05\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1580e-05 - mae: 0.0058 - mse: 7.1580e-05\n",
      "Epoch 821: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.5723e-05 - mae: 0.0054 - mse: 6.5723e-05 - val_loss: 8.4329e-05 - val_mae: 0.0063 - val_mse: 8.4329e-05\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1390e-05 - mae: 0.0058 - mse: 7.1390e-05\n",
      "Epoch 822: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.1976e-05 - mae: 0.0052 - mse: 6.1976e-05 - val_loss: 7.7849e-05 - val_mae: 0.0060 - val_mse: 7.7849e-05\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1743e-05 - mae: 0.0058 - mse: 7.1743e-05\n",
      "Epoch 823: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1938e-05 - mae: 0.0053 - mse: 6.1938e-05 - val_loss: 8.4831e-05 - val_mae: 0.0064 - val_mse: 8.4831e-05\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1862e-05 - mae: 0.0055 - mse: 6.1862e-05\n",
      "Epoch 824: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.1195e-05 - mae: 0.0052 - mse: 6.1195e-05 - val_loss: 8.4926e-05 - val_mae: 0.0065 - val_mse: 8.4926e-05\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.9094e-05 - mae: 0.0062 - mse: 7.9094e-05\n",
      "Epoch 825: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.5592e-05 - mae: 0.0054 - mse: 6.5592e-05 - val_loss: 8.6875e-05 - val_mae: 0.0064 - val_mse: 8.6875e-05\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.7804e-05 - mae: 0.0059 - mse: 7.7804e-05\n",
      "Epoch 826: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5253e-05 - mae: 0.0053 - mse: 6.5253e-05 - val_loss: 7.0756e-05 - val_mae: 0.0057 - val_mse: 7.0756e-05\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.4061e-05 - mae: 0.0054 - mse: 6.4061e-05\n",
      "Epoch 827: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 6.2493e-05 - mae: 0.0053 - mse: 6.2493e-05 - val_loss: 8.4307e-05 - val_mae: 0.0064 - val_mse: 8.4307e-05\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5605e-05 - mae: 0.0060 - mse: 7.5605e-05\n",
      "Epoch 828: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.3453e-05 - mae: 0.0058 - mse: 7.3453e-05 - val_loss: 1.1240e-04 - val_mae: 0.0074 - val_mse: 1.1240e-04\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0817e-04 - mae: 0.0072 - mse: 1.0817e-04\n",
      "Epoch 829: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.6502e-05 - mae: 0.0065 - mse: 9.6502e-05 - val_loss: 1.2595e-04 - val_mae: 0.0080 - val_mse: 1.2595e-04\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2093e-04 - mae: 0.0077 - mse: 1.2093e-04\n",
      "Epoch 830: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0485e-04 - mae: 0.0070 - mse: 1.0485e-04 - val_loss: 1.2160e-04 - val_mae: 0.0079 - val_mse: 1.2160e-04\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4041e-04 - mae: 0.0086 - mse: 1.4041e-04\n",
      "Epoch 831: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.1140e-04 - mae: 0.0073 - mse: 1.1140e-04 - val_loss: 1.2858e-04 - val_mae: 0.0080 - val_mse: 1.2858e-04\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4862e-04 - mae: 0.0086 - mse: 1.4862e-04\n",
      "Epoch 832: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 1.1535e-04 - mae: 0.0074 - mse: 1.1535e-04 - val_loss: 1.0899e-04 - val_mae: 0.0073 - val_mse: 1.0899e-04\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2592e-04 - mae: 0.0079 - mse: 1.2592e-04\n",
      "Epoch 833: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.0559e-04 - mae: 0.0070 - mse: 1.0559e-04 - val_loss: 1.1729e-04 - val_mae: 0.0079 - val_mse: 1.1729e-04\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2513e-04 - mae: 0.0082 - mse: 1.2513e-04\n",
      "Epoch 834: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1066e-04 - mae: 0.0074 - mse: 1.1066e-04 - val_loss: 9.9063e-05 - val_mae: 0.0071 - val_mse: 9.9063e-05\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0022e-04 - mae: 0.0072 - mse: 1.0022e-04\n",
      "Epoch 835: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 9.0802e-05 - mae: 0.0066 - mse: 9.0802e-05 - val_loss: 1.0422e-04 - val_mae: 0.0073 - val_mse: 1.0422e-04\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1014e-04 - mae: 0.0074 - mse: 1.1014e-04\n",
      "Epoch 836: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.2880e-05 - mae: 0.0066 - mse: 9.2880e-05 - val_loss: 9.5671e-05 - val_mae: 0.0069 - val_mse: 9.5671e-05\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.4270e-05 - mae: 0.0068 - mse: 9.4270e-05\n",
      "Epoch 837: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7.8579e-05 - mae: 0.0060 - mse: 7.8579e-05 - val_loss: 1.0668e-04 - val_mae: 0.0075 - val_mse: 1.0668e-04\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.6668e-05 - mae: 0.0070 - mse: 9.6668e-05\n",
      "Epoch 838: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.0683e-05 - mae: 0.0061 - mse: 8.0683e-05 - val_loss: 7.6922e-05 - val_mae: 0.0063 - val_mse: 7.6922e-05\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.9986e-05 - mae: 0.0067 - mse: 8.9986e-05\n",
      "Epoch 839: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 7.3910e-05 - mae: 0.0059 - mse: 7.3910e-05 - val_loss: 8.1434e-05 - val_mae: 0.0064 - val_mse: 8.1434e-05\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7582e-05 - mae: 0.0060 - mse: 6.7582e-05\n",
      "Epoch 840: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.2312e-05 - mae: 0.0059 - mse: 7.2312e-05 - val_loss: 7.4967e-05 - val_mae: 0.0060 - val_mse: 7.4967e-05\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2346e-05 - mae: 0.0057 - mse: 7.2346e-05\n",
      "Epoch 841: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5460e-05 - mae: 0.0055 - mse: 6.5460e-05 - val_loss: 7.3302e-05 - val_mae: 0.0059 - val_mse: 7.3302e-05\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.3032e-05 - mae: 0.0053 - mse: 6.3032e-05\n",
      "Epoch 842: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.1808e-05 - mae: 0.0052 - mse: 6.1808e-05 - val_loss: 7.3116e-05 - val_mae: 0.0059 - val_mse: 7.3116e-05\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.6483e-05 - mae: 0.0056 - mse: 6.6483e-05\n",
      "Epoch 843: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.6271e-05 - mae: 0.0055 - mse: 6.6271e-05 - val_loss: 6.8756e-05 - val_mae: 0.0058 - val_mse: 6.8756e-05\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3582e-05 - mae: 0.0056 - mse: 6.3582e-05\n",
      "Epoch 844: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.3528e-05 - mae: 0.0054 - mse: 6.3528e-05 - val_loss: 9.0423e-05 - val_mae: 0.0064 - val_mse: 9.0423e-05\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0007e-05 - mae: 0.0061 - mse: 8.0007e-05\n",
      "Epoch 845: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 6.9265e-05 - mae: 0.0055 - mse: 6.9265e-05 - val_loss: 8.6959e-05 - val_mae: 0.0064 - val_mse: 8.6959e-05\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.0370e-05 - mae: 0.0057 - mse: 7.0370e-05\n",
      "Epoch 846: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.5867e-05 - mae: 0.0054 - mse: 6.5867e-05 - val_loss: 7.1285e-05 - val_mae: 0.0058 - val_mse: 7.1285e-05\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7419e-05 - mae: 0.0057 - mse: 6.7419e-05\n",
      "Epoch 847: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 6.0787e-05 - mae: 0.0053 - mse: 6.0787e-05 - val_loss: 7.9301e-05 - val_mae: 0.0060 - val_mse: 7.9301e-05\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5233e-05 - mae: 0.0060 - mse: 8.5233e-05\n",
      "Epoch 848: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.0131e-05 - mae: 0.0054 - mse: 7.0131e-05 - val_loss: 7.8814e-05 - val_mae: 0.0063 - val_mse: 7.8814e-05\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9265e-05 - mae: 0.0058 - mse: 6.9265e-05\n",
      "Epoch 849: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.4889e-05 - mae: 0.0054 - mse: 6.4889e-05 - val_loss: 8.1999e-05 - val_mae: 0.0064 - val_mse: 8.1999e-05\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0846e-05 - mae: 0.0054 - mse: 6.0846e-05\n",
      "Epoch 850: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8460e-05 - mae: 0.0051 - mse: 5.8460e-05 - val_loss: 8.4446e-05 - val_mae: 0.0061 - val_mse: 8.4446e-05\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2010e-05 - mae: 0.0057 - mse: 7.2010e-05\n",
      "Epoch 851: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.8434e-05 - mae: 0.0055 - mse: 6.8434e-05 - val_loss: 8.1570e-05 - val_mae: 0.0064 - val_mse: 8.1570e-05\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.0367e-05 - mae: 0.0062 - mse: 8.0367e-05\n",
      "Epoch 852: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 6.9391e-05 - mae: 0.0056 - mse: 6.9391e-05 - val_loss: 7.0483e-05 - val_mae: 0.0059 - val_mse: 7.0483e-05\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2144e-05 - mae: 0.0053 - mse: 6.2144e-05\n",
      "Epoch 853: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.7579e-05 - mae: 0.0050 - mse: 5.7579e-05 - val_loss: 7.2104e-05 - val_mae: 0.0055 - val_mse: 7.2104e-05\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5516e-05 - mae: 0.0052 - mse: 6.5516e-05\n",
      "Epoch 854: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.3493e-05 - mae: 0.0051 - mse: 6.3493e-05 - val_loss: 6.1187e-05 - val_mae: 0.0054 - val_mse: 6.1187e-05\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.6232e-05 - mae: 0.0050 - mse: 5.6232e-05\n",
      "Epoch 855: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.3692e-05 - mae: 0.0048 - mse: 5.3692e-05 - val_loss: 7.5913e-05 - val_mae: 0.0060 - val_mse: 7.5913e-05\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6348e-05 - mae: 0.0051 - mse: 5.6348e-05\n",
      "Epoch 856: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.6436e-05 - mae: 0.0050 - mse: 5.6436e-05 - val_loss: 7.5236e-05 - val_mae: 0.0061 - val_mse: 7.5236e-05\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.9193e-05 - mae: 0.0058 - mse: 6.9193e-05\n",
      "Epoch 857: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.3238e-05 - mae: 0.0054 - mse: 6.3238e-05 - val_loss: 7.3299e-05 - val_mae: 0.0059 - val_mse: 7.3299e-05\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.1012e-05 - mae: 0.0053 - mse: 6.1012e-05\n",
      "Epoch 858: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 5.8550e-05 - mae: 0.0052 - mse: 5.8550e-05 - val_loss: 7.2501e-05 - val_mae: 0.0058 - val_mse: 7.2501e-05\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.4486e-05 - mae: 0.0060 - mse: 7.4486e-05\n",
      "Epoch 859: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6.6044e-05 - mae: 0.0054 - mse: 6.6044e-05 - val_loss: 8.0130e-05 - val_mae: 0.0063 - val_mse: 8.0130e-05\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0039e-05 - mae: 0.0057 - mse: 7.0039e-05\n",
      "Epoch 860: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 6.3644e-05 - mae: 0.0053 - mse: 6.3644e-05 - val_loss: 8.0560e-05 - val_mae: 0.0063 - val_mse: 8.0560e-05\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5284e-05 - mae: 0.0056 - mse: 6.5284e-05\n",
      "Epoch 861: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6.1901e-05 - mae: 0.0052 - mse: 6.1901e-05 - val_loss: 8.3320e-05 - val_mae: 0.0065 - val_mse: 8.3320e-05\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5527e-05 - mae: 0.0061 - mse: 7.5527e-05\n",
      "Epoch 862: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4215e-05 - mae: 0.0054 - mse: 6.4215e-05 - val_loss: 6.6916e-05 - val_mae: 0.0055 - val_mse: 6.6916e-05\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 5.9151e-05 - mae: 0.0053 - mse: 5.9151e-05\n",
      "Epoch 863: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.5751e-05 - mae: 0.0049 - mse: 5.5751e-05 - val_loss: 6.7942e-05 - val_mae: 0.0057 - val_mse: 6.7942e-05\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.0914e-05 - mae: 0.0057 - mse: 7.0914e-05\n",
      "Epoch 864: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.6873e-05 - mae: 0.0050 - mse: 5.6873e-05 - val_loss: 7.0552e-05 - val_mae: 0.0057 - val_mse: 7.0552e-05\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.7813e-05 - mae: 0.0053 - mse: 5.7813e-05\n",
      "Epoch 865: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.8219e-05 - mae: 0.0051 - mse: 5.8219e-05 - val_loss: 8.3324e-05 - val_mae: 0.0061 - val_mse: 8.3324e-05\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.1325e-05 - mae: 0.0056 - mse: 7.1325e-05\n",
      "Epoch 866: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.1187e-05 - mae: 0.0054 - mse: 7.1187e-05 - val_loss: 7.0413e-05 - val_mae: 0.0057 - val_mse: 7.0413e-05\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6725e-05 - mae: 0.0056 - mse: 6.6725e-05\n",
      "Epoch 867: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.3439e-05 - mae: 0.0053 - mse: 6.3439e-05 - val_loss: 7.6019e-05 - val_mae: 0.0060 - val_mse: 7.6019e-05\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.5941e-05 - mae: 0.0059 - mse: 6.5941e-05\n",
      "Epoch 868: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 6.2652e-05 - mae: 0.0053 - mse: 6.2652e-05 - val_loss: 7.0985e-05 - val_mae: 0.0059 - val_mse: 7.0985e-05\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8392e-05 - mae: 0.0059 - mse: 6.8392e-05\n",
      "Epoch 869: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.3368e-05 - mae: 0.0054 - mse: 6.3368e-05 - val_loss: 6.5075e-05 - val_mae: 0.0055 - val_mse: 6.5075e-05\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2372e-05 - mae: 0.0053 - mse: 6.2372e-05\n",
      "Epoch 870: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 5.4029e-05 - mae: 0.0048 - mse: 5.4029e-05 - val_loss: 7.4947e-05 - val_mae: 0.0059 - val_mse: 7.4947e-05\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4213e-05 - mae: 0.0056 - mse: 7.4213e-05\n",
      "Epoch 871: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.0508e-05 - mae: 0.0051 - mse: 6.0508e-05 - val_loss: 8.0046e-05 - val_mae: 0.0061 - val_mse: 8.0046e-05\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1330e-05 - mae: 0.0056 - mse: 7.1330e-05\n",
      "Epoch 872: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 6.2219e-05 - mae: 0.0051 - mse: 6.2219e-05 - val_loss: 9.5016e-05 - val_mae: 0.0068 - val_mse: 9.5016e-05\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5886e-05 - mae: 0.0065 - mse: 8.5886e-05\n",
      "Epoch 873: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 7.3497e-05 - mae: 0.0058 - mse: 7.3497e-05 - val_loss: 8.4689e-05 - val_mae: 0.0064 - val_mse: 8.4689e-05\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.5712e-05 - mae: 0.0060 - mse: 7.5712e-05\n",
      "Epoch 874: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 6.5121e-05 - mae: 0.0054 - mse: 6.5121e-05 - val_loss: 7.8092e-05 - val_mae: 0.0061 - val_mse: 7.8092e-05\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6732e-05 - mae: 0.0057 - mse: 6.6732e-05\n",
      "Epoch 875: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 6.2802e-05 - mae: 0.0053 - mse: 6.2802e-05 - val_loss: 1.0304e-04 - val_mae: 0.0072 - val_mse: 1.0304e-04\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0518e-05 - mae: 0.0062 - mse: 8.0518e-05\n",
      "Epoch 876: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 6.9574e-05 - mae: 0.0057 - mse: 6.9574e-05 - val_loss: 7.8193e-05 - val_mae: 0.0059 - val_mse: 7.8193e-05\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.2124e-05 - mae: 0.0056 - mse: 7.2124e-05\n",
      "Epoch 877: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 5.9663e-05 - mae: 0.0050 - mse: 5.9663e-05 - val_loss: 8.4335e-05 - val_mae: 0.0062 - val_mse: 8.4335e-05\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.2457e-05 - mae: 0.0053 - mse: 6.2457e-05\n",
      "Epoch 878: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 6.1675e-05 - mae: 0.0051 - mse: 6.1675e-05 - val_loss: 7.6993e-05 - val_mae: 0.0061 - val_mse: 7.6993e-05\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1744e-05 - mae: 0.0060 - mse: 7.1744e-05\n",
      "Epoch 879: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.5447e-05 - mae: 0.0056 - mse: 6.5447e-05 - val_loss: 9.2484e-05 - val_mae: 0.0068 - val_mse: 9.2484e-05\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9867e-05 - mae: 0.0068 - mse: 8.9867e-05\n",
      "Epoch 880: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 7.3372e-05 - mae: 0.0059 - mse: 7.3372e-05 - val_loss: 9.4014e-05 - val_mae: 0.0070 - val_mse: 9.4014e-05\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1300e-05 - mae: 0.0064 - mse: 8.1300e-05\n",
      "Epoch 881: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 7.4989e-05 - mae: 0.0060 - mse: 7.4989e-05 - val_loss: 1.0042e-04 - val_mae: 0.0072 - val_mse: 1.0042e-04\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4516e-05 - mae: 0.0068 - mse: 8.4516e-05\n",
      "Epoch 882: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 8.2487e-05 - mae: 0.0064 - mse: 8.2487e-05 - val_loss: 9.8050e-05 - val_mae: 0.0070 - val_mse: 9.8050e-05\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0157e-05 - mae: 0.0065 - mse: 8.0157e-05\n",
      "Epoch 883: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 7.9351e-05 - mae: 0.0062 - mse: 7.9351e-05 - val_loss: 9.5339e-05 - val_mae: 0.0070 - val_mse: 9.5339e-05\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.1607e-04 - mae: 0.0077 - mse: 1.1607e-04\n",
      "Epoch 884: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 9.6494e-05 - mae: 0.0069 - mse: 9.6494e-05 - val_loss: 8.6057e-05 - val_mae: 0.0067 - val_mse: 8.6057e-05\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7483e-05 - mae: 0.0071 - mse: 9.7483e-05\n",
      "Epoch 885: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8.9023e-05 - mae: 0.0064 - mse: 8.9023e-05 - val_loss: 1.4208e-04 - val_mae: 0.0081 - val_mse: 1.4208e-04\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3429e-04 - mae: 0.0077 - mse: 1.3429e-04\n",
      "Epoch 886: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.1348e-04 - mae: 0.0070 - mse: 1.1348e-04 - val_loss: 1.0751e-04 - val_mae: 0.0076 - val_mse: 1.0751e-04\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2522e-04 - mae: 0.0081 - mse: 1.2522e-04\n",
      "Epoch 887: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0003e-04 - mae: 0.0071 - mse: 1.0003e-04 - val_loss: 1.1889e-04 - val_mae: 0.0078 - val_mse: 1.1889e-04\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2161e-04 - mae: 0.0080 - mse: 1.2161e-04\n",
      "Epoch 888: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 1.0177e-04 - mae: 0.0070 - mse: 1.0177e-04 - val_loss: 1.3143e-04 - val_mae: 0.0082 - val_mse: 1.3143e-04\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4804e-04 - mae: 0.0087 - mse: 1.4804e-04\n",
      "Epoch 889: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.1332e-04 - mae: 0.0073 - mse: 1.1332e-04 - val_loss: 1.4895e-04 - val_mae: 0.0087 - val_mse: 1.4895e-04\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5138e-04 - mae: 0.0088 - mse: 1.5138e-04\n",
      "Epoch 890: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.1522e-04 - mae: 0.0073 - mse: 1.1522e-04 - val_loss: 1.5768e-04 - val_mae: 0.0089 - val_mse: 1.5768e-04\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2239e-04 - mae: 0.0077 - mse: 1.2239e-04\n",
      "Epoch 891: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0946e-04 - mae: 0.0070 - mse: 1.0946e-04 - val_loss: 1.7209e-04 - val_mae: 0.0093 - val_mse: 1.7209e-04\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.5562e-04 - mae: 0.0087 - mse: 1.5562e-04\n",
      "Epoch 892: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.3104e-04 - mae: 0.0078 - mse: 1.3104e-04 - val_loss: 1.5094e-04 - val_mae: 0.0086 - val_mse: 1.5094e-04\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6772e-04 - mae: 0.0092 - mse: 1.6772e-04\n",
      "Epoch 893: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3305e-04 - mae: 0.0078 - mse: 1.3305e-04 - val_loss: 1.7075e-04 - val_mae: 0.0094 - val_mse: 1.7075e-04\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.5128e-04 - mae: 0.0090 - mse: 1.5128e-04\n",
      "Epoch 894: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.4264e-04 - mae: 0.0084 - mse: 1.4264e-04 - val_loss: 2.5728e-04 - val_mae: 0.0114 - val_mse: 2.5728e-04\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7108e-04 - mae: 0.0118 - mse: 2.7108e-04\n",
      "Epoch 895: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 2.1719e-04 - mae: 0.0101 - mse: 2.1719e-04 - val_loss: 2.5901e-04 - val_mae: 0.0118 - val_mse: 2.5901e-04\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4661e-04 - mae: 0.0117 - mse: 2.4661e-04\n",
      "Epoch 896: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.9776e-04 - mae: 0.0100 - mse: 1.9776e-04 - val_loss: 2.1974e-04 - val_mae: 0.0107 - val_mse: 2.1974e-04\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.3871e-04 - mae: 0.0113 - mse: 2.3871e-04\n",
      "Epoch 897: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.9861e-04 - mae: 0.0099 - mse: 1.9861e-04 - val_loss: 2.2366e-04 - val_mae: 0.0107 - val_mse: 2.2366e-04\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3003e-04 - mae: 0.0110 - mse: 2.3003e-04\n",
      "Epoch 898: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8474e-04 - mae: 0.0094 - mse: 1.8474e-04 - val_loss: 1.8484e-04 - val_mae: 0.0101 - val_mse: 1.8484e-04\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.8343e-04 - mae: 0.0099 - mse: 1.8343e-04\n",
      "Epoch 899: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.7490e-04 - mae: 0.0095 - mse: 1.7490e-04 - val_loss: 2.2158e-04 - val_mae: 0.0109 - val_mse: 2.2158e-04\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2294e-04 - mae: 0.0111 - mse: 2.2294e-04\n",
      "Epoch 900: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0810e-04 - mae: 0.0103 - mse: 2.0810e-04 - val_loss: 1.9872e-04 - val_mae: 0.0103 - val_mse: 1.9872e-04\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3420e-04 - mae: 0.0112 - mse: 2.3420e-04\n",
      "Epoch 901: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 2.0536e-04 - mae: 0.0102 - mse: 2.0536e-04 - val_loss: 1.9699e-04 - val_mae: 0.0101 - val_mse: 1.9699e-04\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.9655e-04 - mae: 0.0102 - mse: 1.9655e-04\n",
      "Epoch 902: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.7777e-04 - mae: 0.0096 - mse: 1.7777e-04 - val_loss: 1.5653e-04 - val_mae: 0.0091 - val_mse: 1.5653e-04\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6937e-04 - mae: 0.0095 - mse: 1.6937e-04\n",
      "Epoch 903: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.6761e-04 - mae: 0.0093 - mse: 1.6761e-04 - val_loss: 1.9111e-04 - val_mae: 0.0097 - val_mse: 1.9111e-04\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 1.9367e-04 - mae: 0.0098 - mse: 1.9367e-04\n",
      "Epoch 904: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.7810e-04 - mae: 0.0092 - mse: 1.7810e-04 - val_loss: 1.3434e-04 - val_mae: 0.0084 - val_mse: 1.3434e-04\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4505e-04 - mae: 0.0086 - mse: 1.4505e-04\n",
      "Epoch 905: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.4749e-04 - mae: 0.0085 - mse: 1.4749e-04 - val_loss: 1.7517e-04 - val_mae: 0.0098 - val_mse: 1.7517e-04\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.7200e-04 - mae: 0.0096 - mse: 1.7200e-04\n",
      "Epoch 906: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.5560e-04 - mae: 0.0087 - mse: 1.5560e-04 - val_loss: 1.9019e-04 - val_mae: 0.0101 - val_mse: 1.9019e-04\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.8722e-04 - mae: 0.0101 - mse: 1.8722e-04\n",
      "Epoch 907: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.6293e-04 - mae: 0.0092 - mse: 1.6293e-04 - val_loss: 2.1237e-04 - val_mae: 0.0110 - val_mse: 2.1237e-04\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.3277e-04 - mae: 0.0113 - mse: 2.3277e-04\n",
      "Epoch 908: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 2.1993e-04 - mae: 0.0105 - mse: 2.1993e-04 - val_loss: 2.7484e-04 - val_mae: 0.0125 - val_mse: 2.7484e-04\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.2167e-04 - mae: 0.0134 - mse: 3.2167e-04\n",
      "Epoch 909: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.0750e-04 - mae: 0.0125 - mse: 3.0750e-04 - val_loss: 3.9704e-04 - val_mae: 0.0146 - val_mse: 3.9704e-04\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3984e-04 - mae: 0.0155 - mse: 4.3984e-04\n",
      "Epoch 910: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 3.7747e-04 - mae: 0.0141 - mse: 3.7747e-04 - val_loss: 2.6348e-04 - val_mae: 0.0120 - val_mse: 2.6348e-04\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1682e-04 - mae: 0.0131 - mse: 3.1682e-04\n",
      "Epoch 911: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8834e-04 - mae: 0.0125 - mse: 2.8834e-04 - val_loss: 2.5483e-04 - val_mae: 0.0112 - val_mse: 2.5483e-04\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.4994e-04 - mae: 0.0114 - mse: 2.4994e-04\n",
      "Epoch 912: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 2.2949e-04 - mae: 0.0110 - mse: 2.2949e-04 - val_loss: 1.9885e-04 - val_mae: 0.0103 - val_mse: 1.9885e-04\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9618e-04 - mae: 0.0103 - mse: 1.9618e-04\n",
      "Epoch 913: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.2937e-04 - mae: 0.0109 - mse: 2.2937e-04 - val_loss: 2.8441e-04 - val_mae: 0.0129 - val_mse: 2.8441e-04\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.6898e-04 - mae: 0.0125 - mse: 2.6898e-04\n",
      "Epoch 914: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.4945e-04 - mae: 0.0117 - mse: 2.4945e-04 - val_loss: 1.5036e-04 - val_mae: 0.0089 - val_mse: 1.5036e-04\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6816e-04 - mae: 0.0093 - mse: 1.6816e-04\n",
      "Epoch 915: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8243e-04 - mae: 0.0097 - mse: 1.8243e-04 - val_loss: 1.6078e-04 - val_mae: 0.0090 - val_mse: 1.6078e-04\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6793e-04 - mae: 0.0090 - mse: 1.6793e-04\n",
      "Epoch 916: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.8713e-04 - mae: 0.0094 - mse: 1.8713e-04 - val_loss: 9.7408e-05 - val_mae: 0.0074 - val_mse: 9.7408e-05\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7593e-05 - mae: 0.0074 - mse: 9.7593e-05\n",
      "Epoch 917: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4558e-04 - mae: 0.0089 - mse: 1.4558e-04 - val_loss: 1.6961e-04 - val_mae: 0.0094 - val_mse: 1.6961e-04\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6552e-04 - mae: 0.0092 - mse: 1.6552e-04\n",
      "Epoch 918: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.8883e-04 - mae: 0.0100 - mse: 1.8883e-04 - val_loss: 1.0837e-04 - val_mae: 0.0075 - val_mse: 1.0837e-04\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.0957e-04 - mae: 0.0077 - mse: 1.0957e-04\n",
      "Epoch 919: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.3941e-04 - mae: 0.0086 - mse: 1.3941e-04 - val_loss: 1.3211e-04 - val_mae: 0.0085 - val_mse: 1.3211e-04\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5992e-04 - mae: 0.0090 - mse: 1.5992e-04\n",
      "Epoch 920: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 1.7739e-04 - mae: 0.0096 - mse: 1.7739e-04 - val_loss: 1.4423e-04 - val_mae: 0.0087 - val_mse: 1.4423e-04\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6897e-04 - mae: 0.0096 - mse: 1.6897e-04\n",
      "Epoch 921: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.7487e-04 - mae: 0.0096 - mse: 1.7487e-04 - val_loss: 1.4572e-04 - val_mae: 0.0086 - val_mse: 1.4572e-04\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2005e-04 - mae: 0.0079 - mse: 1.2005e-04\n",
      "Epoch 922: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 1.4256e-04 - mae: 0.0084 - mse: 1.4256e-04 - val_loss: 1.5010e-04 - val_mae: 0.0087 - val_mse: 1.5010e-04\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.1029e-04 - mae: 0.0073 - mse: 1.1029e-04\n",
      "Epoch 923: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2792e-04 - mae: 0.0077 - mse: 1.2792e-04 - val_loss: 1.3701e-04 - val_mae: 0.0085 - val_mse: 1.3701e-04\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2686e-04 - mae: 0.0080 - mse: 1.2686e-04\n",
      "Epoch 924: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.1994e-04 - mae: 0.0076 - mse: 1.1994e-04 - val_loss: 1.5436e-04 - val_mae: 0.0086 - val_mse: 1.5436e-04\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7022e-04 - mae: 0.0084 - mse: 1.7022e-04\n",
      "Epoch 925: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.4668e-04 - mae: 0.0080 - mse: 1.4668e-04 - val_loss: 2.7805e-04 - val_mae: 0.0106 - val_mse: 2.7805e-04\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.9355e-04 - mae: 0.0085 - mse: 1.9355e-04\n",
      "Epoch 926: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.7115e-04 - mae: 0.0083 - mse: 1.7115e-04 - val_loss: 1.9008e-04 - val_mae: 0.0099 - val_mse: 1.9008e-04\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.6684e-04 - mae: 0.0087 - mse: 1.6684e-04\n",
      "Epoch 927: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 1.6847e-04 - mae: 0.0087 - mse: 1.6847e-04 - val_loss: 1.5957e-04 - val_mae: 0.0093 - val_mse: 1.5957e-04\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.6418e-04 - mae: 0.0094 - mse: 1.6418e-04\n",
      "Epoch 928: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3986e-04 - mae: 0.0085 - mse: 1.3986e-04 - val_loss: 1.0623e-04 - val_mae: 0.0073 - val_mse: 1.0623e-04\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3652e-04 - mae: 0.0084 - mse: 1.3652e-04\n",
      "Epoch 929: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.1613e-04 - mae: 0.0076 - mse: 1.1613e-04 - val_loss: 1.5104e-04 - val_mae: 0.0086 - val_mse: 1.5104e-04\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.5870e-04 - mae: 0.0091 - mse: 1.5870e-04\n",
      "Epoch 930: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.3272e-04 - mae: 0.0083 - mse: 1.3272e-04 - val_loss: 1.1571e-04 - val_mae: 0.0077 - val_mse: 1.1571e-04\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1643e-04 - mae: 0.0079 - mse: 1.1643e-04\n",
      "Epoch 931: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2050e-04 - mae: 0.0080 - mse: 1.2050e-04 - val_loss: 7.0636e-05 - val_mae: 0.0059 - val_mse: 7.0636e-05\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5106e-05 - mae: 0.0052 - mse: 5.5106e-05\n",
      "Epoch 932: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7.4889e-05 - mae: 0.0060 - mse: 7.4889e-05 - val_loss: 7.7081e-05 - val_mae: 0.0060 - val_mse: 7.7081e-05\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0875e-05 - mae: 0.0053 - mse: 6.0875e-05\n",
      "Epoch 933: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6.8869e-05 - mae: 0.0057 - mse: 6.8869e-05 - val_loss: 8.0906e-05 - val_mae: 0.0063 - val_mse: 8.0906e-05\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2404e-05 - mae: 0.0060 - mse: 7.2404e-05\n",
      "Epoch 934: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7.3438e-05 - mae: 0.0059 - mse: 7.3438e-05 - val_loss: 9.6470e-05 - val_mae: 0.0068 - val_mse: 9.6470e-05\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7566e-05 - mae: 0.0066 - mse: 9.7566e-05\n",
      "Epoch 935: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 9.0473e-05 - mae: 0.0065 - mse: 9.0473e-05 - val_loss: 8.9878e-05 - val_mae: 0.0066 - val_mse: 8.9878e-05\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0306e-04 - mae: 0.0071 - mse: 1.0306e-04\n",
      "Epoch 936: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.0719e-04 - mae: 0.0070 - mse: 1.0719e-04 - val_loss: 6.7911e-05 - val_mae: 0.0058 - val_mse: 6.7911e-05\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6661e-05 - mae: 0.0057 - mse: 6.6661e-05\n",
      "Epoch 937: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 8.3935e-05 - mae: 0.0063 - mse: 8.3935e-05 - val_loss: 1.5357e-04 - val_mae: 0.0090 - val_mse: 1.5357e-04\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.4109e-04 - mae: 0.0082 - mse: 1.4109e-04\n",
      "Epoch 938: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.2106e-04 - mae: 0.0074 - mse: 1.2106e-04 - val_loss: 1.6477e-04 - val_mae: 0.0088 - val_mse: 1.6477e-04\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5742e-04 - mae: 0.0081 - mse: 1.5742e-04\n",
      "Epoch 939: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 1.2626e-04 - mae: 0.0073 - mse: 1.2626e-04 - val_loss: 1.7016e-04 - val_mae: 0.0083 - val_mse: 1.7016e-04\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4600e-04 - mae: 0.0075 - mse: 1.4600e-04\n",
      "Epoch 940: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 1.2455e-04 - mae: 0.0070 - mse: 1.2455e-04 - val_loss: 9.3346e-05 - val_mae: 0.0065 - val_mse: 9.3346e-05\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 9.3998e-05 - mae: 0.0064 - mse: 9.3998e-05\n",
      "Epoch 941: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 9.8383e-05 - mae: 0.0065 - mse: 9.8383e-05 - val_loss: 7.5757e-05 - val_mae: 0.0060 - val_mse: 7.5757e-05\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7904e-05 - mae: 0.0057 - mse: 6.7904e-05\n",
      "Epoch 942: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.1115e-05 - mae: 0.0061 - mse: 8.1115e-05 - val_loss: 9.2156e-05 - val_mae: 0.0066 - val_mse: 9.2156e-05\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2790e-05 - mae: 0.0063 - mse: 8.2790e-05\n",
      "Epoch 943: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 7.5832e-05 - mae: 0.0059 - mse: 7.5832e-05 - val_loss: 1.3369e-04 - val_mae: 0.0082 - val_mse: 1.3369e-04\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1363e-04 - mae: 0.0074 - mse: 1.1363e-04\n",
      "Epoch 944: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0344e-04 - mae: 0.0071 - mse: 1.0344e-04 - val_loss: 9.9465e-05 - val_mae: 0.0068 - val_mse: 9.9465e-05\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6976e-05 - mae: 0.0068 - mse: 9.6976e-05\n",
      "Epoch 945: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 9.8438e-05 - mae: 0.0069 - mse: 9.8438e-05 - val_loss: 8.5727e-05 - val_mae: 0.0064 - val_mse: 8.5727e-05\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0545e-05 - mae: 0.0056 - mse: 7.0545e-05\n",
      "Epoch 946: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8.9144e-05 - mae: 0.0064 - mse: 8.9144e-05 - val_loss: 1.5259e-04 - val_mae: 0.0085 - val_mse: 1.5259e-04\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2436e-04 - mae: 0.0074 - mse: 1.2436e-04\n",
      "Epoch 947: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1983e-04 - mae: 0.0072 - mse: 1.1983e-04 - val_loss: 1.3385e-04 - val_mae: 0.0076 - val_mse: 1.3385e-04\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1231e-04 - mae: 0.0069 - mse: 1.1231e-04\n",
      "Epoch 948: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.1864e-04 - mae: 0.0072 - mse: 1.1864e-04 - val_loss: 1.1108e-04 - val_mae: 0.0071 - val_mse: 1.1108e-04\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.0081e-04 - mae: 0.0065 - mse: 1.0081e-04\n",
      "Epoch 949: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.1819e-04 - mae: 0.0070 - mse: 1.1819e-04 - val_loss: 1.0683e-04 - val_mae: 0.0070 - val_mse: 1.0683e-04\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.6304e-05 - mae: 0.0064 - mse: 9.6304e-05\n",
      "Epoch 950: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 9.8422e-05 - mae: 0.0065 - mse: 9.8422e-05 - val_loss: 9.4022e-05 - val_mae: 0.0066 - val_mse: 9.4022e-05\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8513e-05 - mae: 0.0062 - mse: 8.8513e-05\n",
      "Epoch 951: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 8.4183e-05 - mae: 0.0061 - mse: 8.4183e-05 - val_loss: 1.2069e-04 - val_mae: 0.0077 - val_mse: 1.2069e-04\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1994e-04 - mae: 0.0077 - mse: 1.1994e-04\n",
      "Epoch 952: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.0476e-04 - mae: 0.0070 - mse: 1.0476e-04 - val_loss: 1.7156e-04 - val_mae: 0.0090 - val_mse: 1.7156e-04\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3970e-04 - mae: 0.0083 - mse: 1.3970e-04\n",
      "Epoch 953: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 1.2334e-04 - mae: 0.0078 - mse: 1.2334e-04 - val_loss: 1.2942e-04 - val_mae: 0.0082 - val_mse: 1.2942e-04\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3106e-04 - mae: 0.0082 - mse: 1.3106e-04\n",
      "Epoch 954: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 1.3464e-04 - mae: 0.0085 - mse: 1.3464e-04 - val_loss: 1.1067e-04 - val_mae: 0.0075 - val_mse: 1.1067e-04\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0695e-04 - mae: 0.0073 - mse: 1.0695e-04\n",
      "Epoch 955: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 1.1461e-04 - mae: 0.0076 - mse: 1.1461e-04 - val_loss: 8.0472e-05 - val_mae: 0.0062 - val_mse: 8.0472e-05\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.6079e-05 - mae: 0.0061 - mse: 7.6079e-05\n",
      "Epoch 956: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 8.6152e-05 - mae: 0.0066 - mse: 8.6152e-05 - val_loss: 9.4880e-05 - val_mae: 0.0069 - val_mse: 9.4880e-05\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2921e-05 - mae: 0.0061 - mse: 7.2921e-05\n",
      "Epoch 957: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.8151e-05 - mae: 0.0061 - mse: 7.8151e-05 - val_loss: 1.1576e-04 - val_mae: 0.0076 - val_mse: 1.1576e-04\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0511e-04 - mae: 0.0073 - mse: 1.0511e-04\n",
      "Epoch 958: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 9.9927e-05 - mae: 0.0070 - mse: 9.9927e-05 - val_loss: 9.5319e-05 - val_mae: 0.0069 - val_mse: 9.5319e-05\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.5507e-05 - mae: 0.0064 - mse: 8.5507e-05\n",
      "Epoch 959: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 8.8045e-05 - mae: 0.0064 - mse: 8.8045e-05 - val_loss: 8.8845e-05 - val_mae: 0.0066 - val_mse: 8.8845e-05\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.5972e-05 - mae: 0.0059 - mse: 7.5972e-05\n",
      "Epoch 960: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 7.8605e-05 - mae: 0.0059 - mse: 7.8605e-05 - val_loss: 9.8729e-05 - val_mae: 0.0071 - val_mse: 9.8729e-05\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.9139e-05 - mae: 0.0067 - mse: 8.9139e-05\n",
      "Epoch 961: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 8.8481e-05 - mae: 0.0064 - mse: 8.8481e-05 - val_loss: 8.3611e-05 - val_mae: 0.0064 - val_mse: 8.3611e-05\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 7.4167e-05 - mae: 0.0058 - mse: 7.4167e-05\n",
      "Epoch 962: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 6.9082e-05 - mae: 0.0057 - mse: 6.9082e-05 - val_loss: 9.3248e-05 - val_mae: 0.0068 - val_mse: 9.3248e-05\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 8.1332e-05 - mae: 0.0060 - mse: 8.1332e-05\n",
      "Epoch 963: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 7.8452e-05 - mae: 0.0060 - mse: 7.8452e-05 - val_loss: 9.0453e-05 - val_mae: 0.0067 - val_mse: 9.0453e-05\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.0362e-05 - mae: 0.0063 - mse: 8.0362e-05\n",
      "Epoch 964: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 7.9240e-05 - mae: 0.0063 - mse: 7.9240e-05 - val_loss: 7.1843e-05 - val_mae: 0.0061 - val_mse: 7.1843e-05\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.3871e-05 - mae: 0.0055 - mse: 6.3871e-05\n",
      "Epoch 965: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 6.4564e-05 - mae: 0.0055 - mse: 6.4564e-05 - val_loss: 7.7077e-05 - val_mae: 0.0061 - val_mse: 7.7077e-05\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3277e-05 - mae: 0.0054 - mse: 6.3277e-05\n",
      "Epoch 966: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 5.9979e-05 - mae: 0.0053 - mse: 5.9979e-05 - val_loss: 7.7146e-05 - val_mae: 0.0061 - val_mse: 7.7146e-05\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6136e-05 - mae: 0.0054 - mse: 6.6136e-05\n",
      "Epoch 967: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 6.3510e-05 - mae: 0.0053 - mse: 6.3510e-05 - val_loss: 6.2755e-05 - val_mae: 0.0054 - val_mse: 6.2755e-05\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2224e-05 - mae: 0.0048 - mse: 5.2224e-05\n",
      "Epoch 968: val_loss did not improve from 0.00006\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 5.3575e-05 - mae: 0.0049 - mse: 5.3575e-05 - val_loss: 5.8884e-05 - val_mae: 0.0051 - val_mse: 5.8884e-05\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 4.7771e-05 - mae: 0.0045 - mse: 4.7771e-05\n",
      "Epoch 969: val_loss improved from 0.00006 to 0.00005, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 5.2705e-05 - mae: 0.0048 - mse: 5.2705e-05 - val_loss: 5.3112e-05 - val_mae: 0.0048 - val_mse: 5.3112e-05\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8067e-05 - mae: 0.0043 - mse: 4.8067e-05\n",
      "Epoch 970: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 4.8839e-05 - mae: 0.0045 - mse: 4.8839e-05 - val_loss: 6.2291e-05 - val_mae: 0.0053 - val_mse: 6.2291e-05\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7773e-05 - mae: 0.0049 - mse: 5.7773e-05\n",
      "Epoch 971: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.9976e-05 - mae: 0.0045 - mse: 4.9976e-05 - val_loss: 7.3139e-05 - val_mae: 0.0059 - val_mse: 7.3139e-05\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.0538e-05 - mae: 0.0051 - mse: 6.0538e-05\n",
      "Epoch 972: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 5.2659e-05 - mae: 0.0046 - mse: 5.2659e-05 - val_loss: 6.1903e-05 - val_mae: 0.0053 - val_mse: 6.1903e-05\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8124e-05 - mae: 0.0050 - mse: 5.8124e-05\n",
      "Epoch 973: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 4.9164e-05 - mae: 0.0045 - mse: 4.9164e-05 - val_loss: 5.5383e-05 - val_mae: 0.0050 - val_mse: 5.5383e-05\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7375e-05 - mae: 0.0040 - mse: 3.7375e-05\n",
      "Epoch 974: val_loss improved from 0.00005 to 0.00005, saving model to ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/model/PO-ROMA_fed_model.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 4.5226e-05 - mae: 0.0042 - mse: 4.5226e-05 - val_loss: 4.9489e-05 - val_mae: 0.0045 - val_mse: 4.9489e-05\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.8894e-05 - mae: 0.0038 - mse: 3.8894e-05\n",
      "Epoch 975: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 4.3811e-05 - mae: 0.0042 - mse: 4.3811e-05 - val_loss: 5.1708e-05 - val_mae: 0.0047 - val_mse: 5.1708e-05\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.6571e-05 - mae: 0.0042 - mse: 4.6571e-05\n",
      "Epoch 976: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.4347e-05 - mae: 0.0041 - mse: 4.4347e-05 - val_loss: 5.4606e-05 - val_mae: 0.0049 - val_mse: 5.4606e-05\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0303e-05 - mae: 0.0040 - mse: 4.0303e-05\n",
      "Epoch 977: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 4.1261e-05 - mae: 0.0040 - mse: 4.1261e-05 - val_loss: 6.1782e-05 - val_mae: 0.0051 - val_mse: 6.1782e-05\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6760e-05 - mae: 0.0045 - mse: 4.6760e-05\n",
      "Epoch 978: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 4.8234e-05 - mae: 0.0044 - mse: 4.8234e-05 - val_loss: 5.5619e-05 - val_mae: 0.0050 - val_mse: 5.5619e-05\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9319e-05 - mae: 0.0043 - mse: 4.9319e-05\n",
      "Epoch 979: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4.6207e-05 - mae: 0.0043 - mse: 4.6207e-05 - val_loss: 5.7165e-05 - val_mae: 0.0050 - val_mse: 5.7165e-05\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 4.2713e-05 - mae: 0.0042 - mse: 4.2713e-05\n",
      "Epoch 980: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.7344e-05 - mae: 0.0043 - mse: 4.7344e-05 - val_loss: 5.0544e-05 - val_mae: 0.0046 - val_mse: 5.0544e-05\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2078e-05 - mae: 0.0039 - mse: 4.2078e-05\n",
      "Epoch 981: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 4.1155e-05 - mae: 0.0039 - mse: 4.1155e-05 - val_loss: 5.8706e-05 - val_mae: 0.0050 - val_mse: 5.8706e-05\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6134e-05 - mae: 0.0047 - mse: 5.6134e-05\n",
      "Epoch 982: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 4.9059e-05 - mae: 0.0043 - mse: 4.9059e-05 - val_loss: 6.8862e-05 - val_mae: 0.0055 - val_mse: 6.8862e-05\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5503e-05 - mae: 0.0047 - mse: 5.5503e-05\n",
      "Epoch 983: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 5.0946e-05 - mae: 0.0045 - mse: 5.0946e-05 - val_loss: 6.9728e-05 - val_mae: 0.0056 - val_mse: 6.9728e-05\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.0366e-05 - mae: 0.0050 - mse: 6.0366e-05\n",
      "Epoch 984: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.8797e-05 - mae: 0.0049 - mse: 5.8797e-05 - val_loss: 5.4003e-05 - val_mae: 0.0047 - val_mse: 5.4003e-05\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5121e-05 - mae: 0.0040 - mse: 4.5121e-05\n",
      "Epoch 985: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 4.7928e-05 - mae: 0.0043 - mse: 4.7928e-05 - val_loss: 5.2171e-05 - val_mae: 0.0048 - val_mse: 5.2171e-05\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0217e-05 - mae: 0.0044 - mse: 5.0217e-05\n",
      "Epoch 986: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 4.4094e-05 - mae: 0.0042 - mse: 4.4094e-05 - val_loss: 7.5143e-05 - val_mae: 0.0059 - val_mse: 7.5143e-05\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.5840e-05 - mae: 0.0053 - mse: 6.5840e-05\n",
      "Epoch 987: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.5200e-05 - mae: 0.0048 - mse: 5.5200e-05 - val_loss: 6.5513e-05 - val_mae: 0.0054 - val_mse: 6.5513e-05\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4671e-05 - mae: 0.0051 - mse: 5.4671e-05\n",
      "Epoch 988: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5.4381e-05 - mae: 0.0049 - mse: 5.4381e-05 - val_loss: 5.4903e-05 - val_mae: 0.0050 - val_mse: 5.4903e-05\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2393e-05 - mae: 0.0047 - mse: 5.2393e-05\n",
      "Epoch 989: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 4.8057e-05 - mae: 0.0044 - mse: 4.8057e-05 - val_loss: 5.0234e-05 - val_mae: 0.0045 - val_mse: 5.0234e-05\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.7834e-05 - mae: 0.0039 - mse: 3.7834e-05\n",
      "Epoch 990: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5253e-05 - mae: 0.0042 - mse: 4.5253e-05 - val_loss: 6.3249e-05 - val_mae: 0.0053 - val_mse: 6.3249e-05\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2304e-05 - mae: 0.0047 - mse: 5.2304e-05\n",
      "Epoch 991: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 4.8620e-05 - mae: 0.0044 - mse: 4.8620e-05 - val_loss: 6.7586e-05 - val_mae: 0.0055 - val_mse: 6.7586e-05\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.6130e-05 - mae: 0.0047 - mse: 5.6130e-05\n",
      "Epoch 992: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 5.1256e-05 - mae: 0.0045 - mse: 5.1256e-05 - val_loss: 6.6459e-05 - val_mae: 0.0054 - val_mse: 6.6459e-05\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9633e-05 - mae: 0.0048 - mse: 5.9633e-05\n",
      "Epoch 993: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.1062e-05 - mae: 0.0045 - mse: 5.1062e-05 - val_loss: 5.4518e-05 - val_mae: 0.0047 - val_mse: 5.4518e-05\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9235e-05 - mae: 0.0044 - mse: 4.9235e-05\n",
      "Epoch 994: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5.0993e-05 - mae: 0.0045 - mse: 5.0993e-05 - val_loss: 6.8332e-05 - val_mae: 0.0056 - val_mse: 6.8332e-05\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.6368e-05 - mae: 0.0050 - mse: 5.6368e-05\n",
      "Epoch 995: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 5.4852e-05 - mae: 0.0049 - mse: 5.4852e-05 - val_loss: 6.6970e-05 - val_mae: 0.0056 - val_mse: 6.6970e-05\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4565e-05 - mae: 0.0051 - mse: 5.4565e-05\n",
      "Epoch 996: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 5.3308e-05 - mae: 0.0048 - mse: 5.3308e-05 - val_loss: 7.6858e-05 - val_mae: 0.0060 - val_mse: 7.6858e-05\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5118e-05 - mae: 0.0056 - mse: 6.5118e-05\n",
      "Epoch 997: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 5.9809e-05 - mae: 0.0052 - mse: 5.9809e-05 - val_loss: 8.8866e-05 - val_mae: 0.0064 - val_mse: 8.8866e-05\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4822e-05 - mae: 0.0060 - mse: 7.4822e-05\n",
      "Epoch 998: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 7.0569e-05 - mae: 0.0056 - mse: 7.0569e-05 - val_loss: 7.2209e-05 - val_mae: 0.0060 - val_mse: 7.2209e-05\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.8037e-05 - mae: 0.0057 - mse: 6.8037e-05\n",
      "Epoch 999: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 6.2812e-05 - mae: 0.0055 - mse: 6.2812e-05 - val_loss: 6.6838e-05 - val_mae: 0.0056 - val_mse: 6.6838e-05\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6719e-05 - mae: 0.0055 - mse: 6.6719e-05\n",
      "Epoch 1000: val_loss did not improve from 0.00005\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 6.1111e-05 - mae: 0.0054 - mse: 6.1111e-05 - val_loss: 6.9053e-05 - val_mae: 0.0058 - val_mse: 6.9053e-05\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "--- federated after local fine-tuning ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/vnvjtlb516n5mswtv7rf58b80000gn/T/ipykernel_1855/2011710758.py:96: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k--\" (-> color='k'). The keyword argument will take precedence.\n",
      "  axes[1].plot([plot_min, plot_max], [plot_min, plot_max], 'k--', alpha=0.5, label='Perfetto (y=x)', color = 'red')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo 60 plot in: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/federated_fd/TEST\n",
      "Plot salvati correttamente.\n",
      "Test MAE: 0.0112\n",
      "Test RMSE: 0.0173\n",
      "Test MAPE: 0.14%\n",
      "Test R2: 1.0000\n",
      "Valore medio del test set: 9.3573\n",
      "\n",
      "Log salvato in: ../RISULTATI/2025-11-30/esperimento_PO-ROMA_14-19-09/federated_fd_evaluation_log.json\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip(model, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred)\n",
    "    y_test_np = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    print(f\"--- {name} ---\")\n",
    "    #plot_diagnosis_gradient(y_pred, y_test_np, max_samples_heatmap=10, scatter_sample_ratio=0.7)\n",
    "    evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/{name.replace(' ', '_').lower()}_evaluation_log.json\")\n",
    "    save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/{name.replace(\" \", \"_\").lower()}/TEST', prefix=\"pred_plot\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    if name == 'federated':\n",
    "        model.fit(X_train, y_train, epochs=1000, batch_size=128, callbacks=[model_checkpoint_callback], validation_split=0.2)\n",
    "        model.load_weights(checkpoint_filepath)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = scaler_y.inverse_transform(y_pred)\n",
    "        print(f\"--- {name} after local fine-tuning ---\")\n",
    "        plot_diagnosis_gradient(y_pred, y_test_np, save_path=f\"{name}_pred_quality\", max_samples_heatmap=10, scatter_sample_ratio=0.7)\n",
    "        save_prediction_plots(y_test_np, y_pred, output_dir=f'{exp_dir}/{name.replace(\" \", \"_\").lower()}_fd/TEST', prefix=\"pred_plot\")\n",
    "        evaluate_and_log(y_test_np, y_pred, log_path=f\"{exp_dir}/{name.replace(' ', '_').lower()}_fd_evaluation_log.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
